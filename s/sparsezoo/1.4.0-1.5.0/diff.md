# Comparing `tmp/sparsezoo-1.4.0-py3-none-any.whl.zip` & `tmp/sparsezoo-1.5.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,45 +1,69 @@
-Zip file size: 92033 bytes, number of entries: 43
--rw-rw-r--  2.0 unx      772 b- defN 23-Feb-16 17:22 sparsezoo/__init__.py
--rw-rw-r--  2.0 unx     2904 b- defN 23-Feb-16 17:22 sparsezoo/download_main.py
--rw-rw-r--  2.0 unx    14650 b- defN 23-Feb-16 17:22 sparsezoo/main.py
--rw-rw-r--  2.0 unx     4134 b- defN 23-Feb-16 17:22 sparsezoo/package.py
--rw-rw-r--  2.0 unx     1491 b- defN 23-Feb-16 17:23 sparsezoo/version.py
--rw-rw-r--  2.0 unx      711 b- defN 23-Feb-16 17:22 sparsezoo/analysis/__init__.py
--rw-rw-r--  2.0 unx    31815 b- defN 23-Feb-16 17:22 sparsezoo/analysis/analysis.py
--rw-rw-r--  2.0 unx      633 b- defN 23-Feb-16 17:22 sparsezoo/analysis/utils/__init__.py
--rw-rw-r--  2.0 unx    14714 b- defN 23-Feb-16 17:22 sparsezoo/analysis/utils/chart.py
--rw-rw-r--  2.0 unx     6969 b- defN 23-Feb-16 17:22 sparsezoo/analysis/utils/models.py
--rw-rw-r--  2.0 unx      666 b- defN 23-Feb-16 17:22 sparsezoo/inference/__init__.py
--rw-rw-r--  2.0 unx     5813 b- defN 23-Feb-16 17:22 sparsezoo/inference/inference_runner.py
--rw-rw-r--  2.0 unx      676 b- defN 23-Feb-16 17:22 sparsezoo/model/__init__.py
--rw-rw-r--  2.0 unx    27720 b- defN 23-Feb-16 17:22 sparsezoo/model/model.py
--rw-rw-r--  2.0 unx     1924 b- defN 23-Feb-16 17:22 sparsezoo/model/result_utils.py
--rw-rw-r--  2.0 unx    20892 b- defN 23-Feb-16 17:22 sparsezoo/model/utils.py
--rw-rw-r--  2.0 unx      706 b- defN 23-Feb-16 17:22 sparsezoo/objects/__init__.py
--rw-rw-r--  2.0 unx     9619 b- defN 23-Feb-16 17:22 sparsezoo/objects/directories.py
--rw-rw-r--  2.0 unx    11331 b- defN 23-Feb-16 17:22 sparsezoo/objects/directory.py
--rw-rw-r--  2.0 unx    11375 b- defN 23-Feb-16 17:22 sparsezoo/objects/file.py
--rw-rw-r--  2.0 unx      656 b- defN 23-Feb-16 17:22 sparsezoo/search/__init__.py
--rw-rw-r--  2.0 unx     5681 b- defN 23-Feb-16 17:22 sparsezoo/search/search.py
--rw-rw-r--  2.0 unx     1209 b- defN 23-Feb-16 17:22 sparsezoo/utils/__init__.py
--rw-rw-r--  2.0 unx     5449 b- defN 23-Feb-16 17:22 sparsezoo/utils/authentication.py
--rw-rw-r--  2.0 unx    11681 b- defN 23-Feb-16 17:22 sparsezoo/utils/calculate_ops.py
--rw-rw-r--  2.0 unx    11125 b- defN 23-Feb-16 17:22 sparsezoo/utils/data.py
--rw-rw-r--  2.0 unx     6837 b- defN 23-Feb-16 17:22 sparsezoo/utils/download.py
--rw-rw-r--  2.0 unx     9003 b- defN 23-Feb-16 17:22 sparsezoo/utils/graph_editor.py
--rw-rw-r--  2.0 unx     2647 b- defN 23-Feb-16 17:22 sparsezoo/utils/helpers.py
--rw-rw-r--  2.0 unx    11721 b- defN 23-Feb-16 17:22 sparsezoo/utils/node_inference.py
--rw-rw-r--  2.0 unx     8786 b- defN 23-Feb-16 17:22 sparsezoo/utils/numpy.py
--rw-rw-r--  2.0 unx    14420 b- defN 23-Feb-16 17:22 sparsezoo/utils/onnx.py
--rw-rw-r--  2.0 unx     4618 b- defN 23-Feb-16 17:22 sparsezoo/utils/requests.py
--rw-rw-r--  2.0 unx      687 b- defN 23-Feb-16 17:22 sparsezoo/validation/__init__.py
--rw-rw-r--  2.0 unx     2117 b- defN 23-Feb-16 17:22 sparsezoo/validation/integrations.py
--rw-rw-r--  2.0 unx     8780 b- defN 23-Feb-16 17:22 sparsezoo/validation/validator.py
--rw-rw-r--  2.0 unx    11353 b- defN 23-Feb-16 17:23 sparsezoo-1.4.0.dist-info/LICENSE
--rw-rw-r--  2.0 unx    19718 b- defN 23-Feb-16 17:23 sparsezoo-1.4.0.dist-info/METADATA
--rw-rw-r--  2.0 unx     1414 b- defN 23-Feb-16 17:23 sparsezoo-1.4.0.dist-info/NOTICE
--rw-rw-r--  2.0 unx       92 b- defN 23-Feb-16 17:23 sparsezoo-1.4.0.dist-info/WHEEL
--rw-rw-r--  2.0 unx      101 b- defN 23-Feb-16 17:23 sparsezoo-1.4.0.dist-info/entry_points.txt
--rw-rw-r--  2.0 unx       10 b- defN 23-Feb-16 17:23 sparsezoo-1.4.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     3660 b- defN 23-Feb-16 17:23 sparsezoo-1.4.0.dist-info/RECORD
-43 files, 311280 bytes uncompressed, 86217 bytes compressed:  72.3%
+Zip file size: 131712 bytes, number of entries: 67
+-rw-rw-r--  2.0 unx     1002 b- defN 23-Jun-01 17:00 sparsezoo/__init__.py
+-rw-rw-r--  2.0 unx     4873 b- defN 23-Jun-01 17:00 sparsezoo/analytics.py
+-rw-rw-r--  2.0 unx     4090 b- defN 23-Jun-01 17:00 sparsezoo/analyze_cli.py
+-rw-rw-r--  2.0 unx     3015 b- defN 23-Jun-01 17:00 sparsezoo/download_main.py
+-rw-rw-r--  2.0 unx    14757 b- defN 23-Jun-01 17:00 sparsezoo/main.py
+-rw-rw-r--  2.0 unx     4134 b- defN 23-Jun-01 17:00 sparsezoo/package.py
+-rw-rw-r--  2.0 unx     1491 b- defN 23-Jun-01 17:00 sparsezoo/version.py
+-rw-rw-r--  2.0 unx      685 b- defN 23-Jun-01 17:00 sparsezoo/analyze/__init__.py
+-rw-rw-r--  2.0 unx    46300 b- defN 23-Jun-01 17:00 sparsezoo/analyze/analysis.py
+-rw-rw-r--  2.0 unx     5517 b- defN 23-Jun-01 17:00 sparsezoo/analyze/cli.py
+-rw-rw-r--  2.0 unx      633 b- defN 23-Jun-01 17:00 sparsezoo/analyze/utils/__init__.py
+-rw-rw-r--  2.0 unx    15300 b- defN 23-Jun-01 17:00 sparsezoo/analyze/utils/chart.py
+-rw-rw-r--  2.0 unx     6969 b- defN 23-Jun-01 17:00 sparsezoo/analyze/utils/models.py
+-rw-rw-r--  2.0 unx      732 b- defN 23-Jun-01 17:00 sparsezoo/api/__init__.py
+-rw-rw-r--  2.0 unx     1332 b- defN 23-Jun-01 17:00 sparsezoo/api/exceptions.py
+-rw-rw-r--  2.0 unx     2915 b- defN 23-Jun-01 17:00 sparsezoo/api/graphql.py
+-rw-rw-r--  2.0 unx     6332 b- defN 23-Jun-01 17:00 sparsezoo/api/query_parser.py
+-rw-rw-r--  2.0 unx     1750 b- defN 23-Jun-01 17:00 sparsezoo/api/utils.py
+-rw-rw-r--  2.0 unx      653 b- defN 23-Jun-01 17:00 sparsezoo/deployment_package/__init__.py
+-rw-rw-r--  2.0 unx     7694 b- defN 23-Jun-01 17:00 sparsezoo/deployment_package/cli.py
+-rw-rw-r--  2.0 unx     2138 b- defN 23-Jun-01 17:00 sparsezoo/deployment_package/main.py
+-rw-rw-r--  2.0 unx      886 b- defN 23-Jun-01 17:00 sparsezoo/deployment_package/docker/Dockerfile
+-rw-rw-r--  2.0 unx      898 b- defN 23-Jun-01 17:00 sparsezoo/deployment_package/docker/helpers.py
+-rw-rw-r--  2.0 unx      680 b- defN 23-Jun-01 17:00 sparsezoo/deployment_package/utils/__init__.py
+-rw-rw-r--  2.0 unx     4177 b- defN 23-Jun-01 17:00 sparsezoo/deployment_package/utils/extractors.py
+-rw-rw-r--  2.0 unx    12563 b- defN 23-Jun-01 17:00 sparsezoo/deployment_package/utils/utils.py
+-rw-rw-r--  2.0 unx      666 b- defN 23-Jun-01 17:00 sparsezoo/inference/__init__.py
+-rw-rw-r--  2.0 unx     5813 b- defN 23-Jun-01 17:00 sparsezoo/inference/inference_runner.py
+-rw-rw-r--  2.0 unx      676 b- defN 23-Jun-01 17:00 sparsezoo/model/__init__.py
+-rw-rw-r--  2.0 unx    27803 b- defN 23-Jun-01 17:00 sparsezoo/model/model.py
+-rw-rw-r--  2.0 unx     2127 b- defN 23-Jun-01 17:00 sparsezoo/model/result_utils.py
+-rw-rw-r--  2.0 unx    22638 b- defN 23-Jun-01 17:00 sparsezoo/model/utils.py
+-rw-rw-r--  2.0 unx      706 b- defN 23-Jun-01 17:00 sparsezoo/objects/__init__.py
+-rw-rw-r--  2.0 unx     9619 b- defN 23-Jun-01 17:00 sparsezoo/objects/directories.py
+-rw-rw-r--  2.0 unx    11339 b- defN 23-Jun-01 17:00 sparsezoo/objects/directory.py
+-rw-rw-r--  2.0 unx    11323 b- defN 23-Jun-01 17:00 sparsezoo/objects/file.py
+-rw-rw-r--  2.0 unx      656 b- defN 23-Jun-01 17:00 sparsezoo/search/__init__.py
+-rw-rw-r--  2.0 unx     5796 b- defN 23-Jun-01 17:00 sparsezoo/search/search.py
+-rw-rw-r--  2.0 unx     1238 b- defN 23-Jun-01 17:00 sparsezoo/utils/__init__.py
+-rw-rw-r--  2.0 unx     5449 b- defN 23-Jun-01 17:00 sparsezoo/utils/authentication.py
+-rw-rw-r--  2.0 unx    11681 b- defN 23-Jun-01 17:00 sparsezoo/utils/calculate_ops.py
+-rw-rw-r--  2.0 unx     3993 b- defN 23-Jun-01 17:00 sparsezoo/utils/constants.py
+-rw-rw-r--  2.0 unx    11125 b- defN 23-Jun-01 17:00 sparsezoo/utils/data.py
+-rw-rw-r--  2.0 unx     6835 b- defN 23-Jun-01 17:00 sparsezoo/utils/download.py
+-rw-rw-r--  2.0 unx     2114 b- defN 23-Jun-01 17:00 sparsezoo/utils/gdpr.py
+-rw-rw-r--  2.0 unx     9003 b- defN 23-Jun-01 17:00 sparsezoo/utils/graph_editor.py
+-rw-rw-r--  2.0 unx     3203 b- defN 23-Jun-01 17:00 sparsezoo/utils/helpers.py
+-rw-rw-r--  2.0 unx    11721 b- defN 23-Jun-01 17:00 sparsezoo/utils/node_inference.py
+-rw-rw-r--  2.0 unx     8786 b- defN 23-Jun-01 17:00 sparsezoo/utils/numpy.py
+-rw-rw-r--  2.0 unx    14420 b- defN 23-Jun-01 17:00 sparsezoo/utils/onnx.py
+-rw-rw-r--  2.0 unx     3269 b- defN 23-Jun-01 17:00 sparsezoo/utils/task_name.py
+-rw-rw-r--  2.0 unx      935 b- defN 23-Jun-01 17:00 sparsezoo/utils/standardization/__init__.py
+-rw-rw-r--  2.0 unx     2833 b- defN 23-Jun-01 17:00 sparsezoo/utils/standardization/feature_status.py
+-rw-rw-r--  2.0 unx     6783 b- defN 23-Jun-01 17:00 sparsezoo/utils/standardization/feature_status_page.py
+-rw-rw-r--  2.0 unx     5935 b- defN 23-Jun-01 17:00 sparsezoo/utils/standardization/feature_status_table.py
+-rw-rw-r--  2.0 unx     2376 b- defN 23-Jun-01 17:00 sparsezoo/utils/standardization/markdown_utils.py
+-rw-rw-r--  2.0 unx     4112 b- defN 23-Jun-01 17:00 sparsezoo/utils/standardization/write_status_pages.py
+-rw-rw-r--  2.0 unx      687 b- defN 23-Jun-01 17:00 sparsezoo/validation/__init__.py
+-rw-rw-r--  2.0 unx     2117 b- defN 23-Jun-01 17:00 sparsezoo/validation/integrations.py
+-rw-rw-r--  2.0 unx     8780 b- defN 23-Jun-01 17:00 sparsezoo/validation/validator.py
+-rw-rw-r--  2.0 unx    11353 b- defN 23-Jun-01 17:01 sparsezoo-1.5.0.dist-info/LICENSE
+-rw-rw-r--  2.0 unx    19808 b- defN 23-Jun-01 17:01 sparsezoo-1.5.0.dist-info/METADATA
+-rw-rw-r--  2.0 unx     1414 b- defN 23-Jun-01 17:01 sparsezoo-1.5.0.dist-info/NOTICE
+-rw-rw-r--  2.0 unx       92 b- defN 23-Jun-01 17:01 sparsezoo-1.5.0.dist-info/WHEEL
+-rw-rw-r--  2.0 unx      217 b- defN 23-Jun-01 17:01 sparsezoo-1.5.0.dist-info/entry_points.txt
+-rw-rw-r--  2.0 unx       10 b- defN 23-Jun-01 17:01 sparsezoo-1.5.0.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     5911 b- defN 23-Jun-01 17:01 sparsezoo-1.5.0.dist-info/RECORD
+67 files, 416878 bytes uncompressed, 122298 bytes compressed:  70.7%
```

## zipnote {}

```diff
@@ -1,35 +1,83 @@
 Filename: sparsezoo/__init__.py
 Comment: 
 
+Filename: sparsezoo/analytics.py
+Comment: 
+
+Filename: sparsezoo/analyze_cli.py
+Comment: 
+
 Filename: sparsezoo/download_main.py
 Comment: 
 
 Filename: sparsezoo/main.py
 Comment: 
 
 Filename: sparsezoo/package.py
 Comment: 
 
 Filename: sparsezoo/version.py
 Comment: 
 
-Filename: sparsezoo/analysis/__init__.py
+Filename: sparsezoo/analyze/__init__.py
+Comment: 
+
+Filename: sparsezoo/analyze/analysis.py
+Comment: 
+
+Filename: sparsezoo/analyze/cli.py
+Comment: 
+
+Filename: sparsezoo/analyze/utils/__init__.py
+Comment: 
+
+Filename: sparsezoo/analyze/utils/chart.py
+Comment: 
+
+Filename: sparsezoo/analyze/utils/models.py
+Comment: 
+
+Filename: sparsezoo/api/__init__.py
+Comment: 
+
+Filename: sparsezoo/api/exceptions.py
+Comment: 
+
+Filename: sparsezoo/api/graphql.py
+Comment: 
+
+Filename: sparsezoo/api/query_parser.py
+Comment: 
+
+Filename: sparsezoo/api/utils.py
 Comment: 
 
-Filename: sparsezoo/analysis/analysis.py
+Filename: sparsezoo/deployment_package/__init__.py
 Comment: 
 
-Filename: sparsezoo/analysis/utils/__init__.py
+Filename: sparsezoo/deployment_package/cli.py
 Comment: 
 
-Filename: sparsezoo/analysis/utils/chart.py
+Filename: sparsezoo/deployment_package/main.py
 Comment: 
 
-Filename: sparsezoo/analysis/utils/models.py
+Filename: sparsezoo/deployment_package/docker/Dockerfile
+Comment: 
+
+Filename: sparsezoo/deployment_package/docker/helpers.py
+Comment: 
+
+Filename: sparsezoo/deployment_package/utils/__init__.py
+Comment: 
+
+Filename: sparsezoo/deployment_package/utils/extractors.py
+Comment: 
+
+Filename: sparsezoo/deployment_package/utils/utils.py
 Comment: 
 
 Filename: sparsezoo/inference/__init__.py
 Comment: 
 
 Filename: sparsezoo/inference/inference_runner.py
 Comment: 
@@ -69,20 +117,26 @@
 
 Filename: sparsezoo/utils/authentication.py
 Comment: 
 
 Filename: sparsezoo/utils/calculate_ops.py
 Comment: 
 
+Filename: sparsezoo/utils/constants.py
+Comment: 
+
 Filename: sparsezoo/utils/data.py
 Comment: 
 
 Filename: sparsezoo/utils/download.py
 Comment: 
 
+Filename: sparsezoo/utils/gdpr.py
+Comment: 
+
 Filename: sparsezoo/utils/graph_editor.py
 Comment: 
 
 Filename: sparsezoo/utils/helpers.py
 Comment: 
 
 Filename: sparsezoo/utils/node_inference.py
@@ -90,41 +144,59 @@
 
 Filename: sparsezoo/utils/numpy.py
 Comment: 
 
 Filename: sparsezoo/utils/onnx.py
 Comment: 
 
-Filename: sparsezoo/utils/requests.py
+Filename: sparsezoo/utils/task_name.py
+Comment: 
+
+Filename: sparsezoo/utils/standardization/__init__.py
+Comment: 
+
+Filename: sparsezoo/utils/standardization/feature_status.py
+Comment: 
+
+Filename: sparsezoo/utils/standardization/feature_status_page.py
+Comment: 
+
+Filename: sparsezoo/utils/standardization/feature_status_table.py
+Comment: 
+
+Filename: sparsezoo/utils/standardization/markdown_utils.py
+Comment: 
+
+Filename: sparsezoo/utils/standardization/write_status_pages.py
 Comment: 
 
 Filename: sparsezoo/validation/__init__.py
 Comment: 
 
 Filename: sparsezoo/validation/integrations.py
 Comment: 
 
 Filename: sparsezoo/validation/validator.py
 Comment: 
 
-Filename: sparsezoo-1.4.0.dist-info/LICENSE
+Filename: sparsezoo-1.5.0.dist-info/LICENSE
 Comment: 
 
-Filename: sparsezoo-1.4.0.dist-info/METADATA
+Filename: sparsezoo-1.5.0.dist-info/METADATA
 Comment: 
 
-Filename: sparsezoo-1.4.0.dist-info/NOTICE
+Filename: sparsezoo-1.5.0.dist-info/NOTICE
 Comment: 
 
-Filename: sparsezoo-1.4.0.dist-info/WHEEL
+Filename: sparsezoo-1.5.0.dist-info/WHEEL
 Comment: 
 
-Filename: sparsezoo-1.4.0.dist-info/entry_points.txt
+Filename: sparsezoo-1.5.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: sparsezoo-1.4.0.dist-info/top_level.txt
+Filename: sparsezoo-1.5.0.dist-info/top_level.txt
 Comment: 
 
-Filename: sparsezoo-1.4.0.dist-info/RECORD
+Filename: sparsezoo-1.5.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## sparsezoo/__init__.py

```diff
@@ -9,14 +9,21 @@
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 # flake8: noqa
+# isort: skip_file
 
+from .api import *
 from .inference import *
 from .model import *
 from .objects import *
 from .search import *
 from .utils import *
 from .validation import *
+from . import deployment_package as deployment_package_module
+from .deployment_package import *
+from .analytics import sparsezoo_analytics as _analytics
+
+_analytics.send_event("python__init")
```

## sparsezoo/download_main.py

```diff
@@ -42,14 +42,15 @@
 
 
 """
 import argparse
 import logging
 
 from sparsezoo import Model
+from sparsezoo.analytics import sparsezoo_analytics
 
 
 __all__ = ["main"]
 
 LOGGER = logging.getLogger()
 
 
@@ -72,14 +73,15 @@
         help="The directory to save the model files in, "
         "defaults to the cache directory of the sparsezoo",
     )
 
     return parser.parse_args()
 
 
+@sparsezoo_analytics.send_event_decorator("cli__download")
 def main():
     args = parse_args()
     logging.basicConfig(level=logging.INFO)
 
     LOGGER.info("Downloading files from model '{}'".format(args.model_stub))
 
     if not isinstance(args.model_stub, str):
```

## sparsezoo/main.py

```diff
@@ -167,14 +167,15 @@
 
 
 """
 import argparse
 import logging
 
 from sparsezoo import Model, model_args_to_stub, search_models
+from sparsezoo.analytics import sparsezoo_analytics
 
 
 __all__ = ["main"]
 
 DOWNLOAD_COMMAND = "download"
 SEARCH_COMMAND = "search"
 
@@ -361,14 +362,15 @@
     for index, model in enumerate(models):
         result_index = (index + 1) + (args.page_length * (args.page - 1))
         header = f"{result_index}) {str(model)}"
         print(header)
         print("-------------------------")
 
 
+@sparsezoo_analytics.send_event_decorator("cli__main")
 def main():
     args = parse_args()
     logging.basicConfig(level=logging.INFO)
 
     if args.command == DOWNLOAD_COMMAND:
         LOGGER.info("Downloading files from model...")
         stub = model_args_to_stub(
```

## sparsezoo/version.py

```diff
@@ -16,15 +16,15 @@
 Functionality for storing and setting the version info for SparseZoo
 """
 
 
 from datetime import date
 
 
-version_base = "1.4.0"
+version_base = "1.5.0"
 is_release = True  # change to True to set the generated version as a release version
 
 
 def _generate_version():
     return (
         version_base
         if is_release
```

## sparsezoo/model/model.py

```diff
@@ -15,19 +15,21 @@
 import logging
 import os
 import re
 from typing import Any, Dict, Generator, List, Optional, Tuple, Union
 
 import numpy
 
+from sparsezoo.analytics import sparsezoo_analytics
 from sparsezoo.inference import ENGINES, InferenceRunner
 from sparsezoo.model.result_utils import ModelResult
 from sparsezoo.model.utils import (
     SAVE_DIR,
     ZOO_STUB_PREFIX,
+    is_stub,
     load_files_from_directory,
     load_files_from_stub,
     save_outputs_to_tar,
 )
 from sparsezoo.objects import (
     Directory,
     File,
@@ -69,19 +71,19 @@
 
     :param download_path: an optional string argument to specify the download
         directory of the Model. Defaults to `None` (the model is saved
         to sparsezoo cache directory)
     """
 
     def __init__(self, source: str, download_path: Optional[str] = None):
-
+        sparsezoo_analytics.send_event("python__model__init")
         self.source = source
         self._stub_params = {}
 
-        if self.source.startswith(ZOO_STUB_PREFIX):
+        if is_stub(self.source):
             # initializing the files and params from the stub
             _setup_args = self.initialize_model_from_stub(stub=self.source)
             files, path, url, validation_results, compressed_size = _setup_args
             if download_path is not None:
                 path = download_path  # overwrite cache path with user input
         else:
             # initializing the model from the path
@@ -347,15 +349,17 @@
         if params:
             self._validate_params(params=params)
             self._stub_params.update(params)
 
         path = os.path.join(SAVE_DIR, model_id)
         if not files:
             raise ValueError(f"No files found for given stub {stub}")
+
         url = os.path.dirname(files[0].get("url"))
+
         return files, path, url, validation_results, size
 
     @staticmethod
     def initialize_model_from_directory(
         directory: str,
     ) -> Tuple[List[Dict[str, str]], str, None]:
         """
@@ -539,15 +543,15 @@
                 files_found.append(file)
 
         if not files_found:
             return None
         elif len(files_found) == 1:
             return files_found[0]
 
-        elif display_name == "model.onnx" and len(files_found) == 2:
+        elif display_name == "model.onnx":
             # `model.onnx` file may be found twice:
             #   - directly in the root directory
             #   - inside `deployment` directory
             # if this is the case, return the first file
             # (the other one is a duplicate)
             return files_found[0]
         else:
```

## sparsezoo/model/result_utils.py

```diff
@@ -19,41 +19,49 @@
 
 
 class ModelResult(BaseModel):
     """
     Base class to store common result information
     """
 
-    result_type: str = Field(
-        description="A string representing the type of "
-        "result ex `training`, `inference`, etc"
-    )
     recorded_value: float = Field(description="The float value of the result")
     recorded_units: str = Field(description="The unit in which result is specified")
 
 
 class ValidationResult(ModelResult):
     """
     A class holding information for validation results
     """
 
+    result_type: str = Field(
+        description="A string representing the type of "
+        "result ex `training`, `inference`, etc",
+        default="inference",
+    )
+
     dataset_type: str = Field(
         description="A string representing the type of "
         "dataset used ex. `upstream`, `downstream`"
     )
     dataset_name: str = Field(
         description="The name of the dataset current " "result was measured on"
     )
 
 
 class ThroughputResults(ModelResult):
     """
     A class holding information for throughput based results
     """
 
+    result_type: str = Field(
+        description="A string representing the type of "
+        "result ex `training`, `inference`, etc",
+        default="training",
+    )
+
     device_info: str = Field(description="The device current result was measured on")
     num_cores: int = Field(
         description="Number of cores used while measuring " "this result"
     )
     batch_size: int = Field(
         description="The batch size used while measuring " "this result"
     )
```

## sparsezoo/model/utils.py

```diff
@@ -8,41 +8,45 @@
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+
 import copy
 import logging
 import os
+import re
 import shutil
 import warnings
 from collections import defaultdict
 from pathlib import Path
 from typing import Any, Callable, Dict, List, Optional, Set, Tuple, Union
 
+from sparsezoo.api.graphql import GraphQLAPI
 from sparsezoo.model.result_utils import (
     ModelResult,
     ThroughputResults,
     ValidationResult,
 )
 from sparsezoo.objects import Directory, File, NumpyDirectory
-from sparsezoo.utils import download_get_request, save_numpy
+from sparsezoo.utils import BASE_API_URL, convert_to_bool, save_numpy
 
 
 __all__ = [
     "restructure_request_json",
     "fetch_from_request_json",
     "setup_model",
     "load_files_from_stub",
     "load_files_from_directory",
     "ZOO_STUB_PREFIX",
     "SAVE_DIR",
     "COMPRESSED_FILE_NAME",
+    "get_model_metadata_from_stub",
 ]
 
 ALLOWED_FILE_TYPES = {
     "originals",
     "recipe",
     "onnx",
     "labels",
@@ -58,14 +62,34 @@
 _LOGGER = logging.getLogger(__name__)
 
 ZOO_STUB_PREFIX = "zoo:"
 CACHE_DIR = os.path.expanduser(os.path.join("~", ".cache", "sparsezoo"))
 SAVE_DIR = os.getenv("SPARSEZOO_MODELS_PATH", CACHE_DIR)
 COMPRESSED_FILE_NAME = "model.onnx.tar.gz"
 
+STUB_V1_REGEX_EXPR = (
+    r"^(zoo:)?"
+    r"(?P<domain>[\.A-z0-9_]+)"
+    r"/(?P<sub_domain>[\.A-z0-9_]+)"
+    r"/(?P<architecture>[\.A-z0-9_]+)(-(?P<sub_architecture>[\.A-z0-9_]+))?"
+    r"/(?P<framework>[\.A-z0-9_]+)"
+    r"/(?P<repo>[\.A-z0-9_]+)"
+    r"/(?P<dataset>[\.A-z0-9_]+)(-(?P<training_scheme>[\.A-z0-9_]+))?"
+    r"/(?P<sparse_tag>[\.A-z0-9_-]+)"
+)
+
+STUB_V2_REGEX_EXPR = (
+    r"^(zoo:)?"
+    r"(?P<architecture>[\.A-z0-9_]+)"
+    r"(-(?P<sub_architecture>[\.A-z0-9_]+))?"
+    r"-(?P<source_dataset>[\.A-z0-9_]+)"
+    r"(-(?P<training_dataset>[\.A-z0-9_]+))?"
+    r"-(?P<sparse_tag>[\.A-z0-9_]+)"
+)
+
 
 def load_files_from_directory(directory_path: str) -> List[Dict[str, Any]]:
     """
     :param directory_path: a path to the directory,
         that contains model files in the expected structure
     :return list of file dictionaries
     """
@@ -78,36 +102,19 @@
     files = [
         dict(display_name=display_name, path=os.path.join(directory_path, display_name))
         for display_name in display_names
     ]
     return files
 
 
-def _get_compressed_size(files: List[Dict[str, Any]]) -> Optional[int]:
-    """
-    Utility method to return compressed file size in bytes, if the size cannot
-    be inferred `None` is returned
-
-    :param files: List of file dictionaries
-    :return: `None` if file size cannot be determined, else an int representing
-        compressed size of the model in bytes
-    """
-    for file in files:
-        if file.get("display_name") == COMPRESSED_FILE_NAME:
-            return file.get("file_size")
-
-    _LOGGER.info("Compressed file-size not found!")
-
-
 def load_files_from_stub(
     stub: str,
     valid_params: Optional[List[str]] = None,
-    force_token_refresh: bool = False,
-) -> Tuple[
-    List[Dict[str, Any]], str, Dict[str, str], Dict[str, List[ModelResult]], int
+) -> Optional[
+    Tuple[List[Dict[str, Any]], str, Dict[str, str], Dict[str, List[ModelResult]], int]
 ]:
     """
     :param stub: the SparseZoo stub path to the model (optionally
         may include string arguments)
     :param valid_params: list of expected parameter names to be encoded in the
         stub. Will raise a warning if any unexpected param names are given. Leave
         as None to not raise any warnings. Default is None
@@ -118,32 +125,77 @@
         - parsed param dictionary
         - validation results dictionary
         - compressed model size in bytes
     """
     params = None
     if isinstance(stub, str):
         stub, params = parse_zoo_stub(stub=stub, valid_params=valid_params)
-    _LOGGER.debug(f"load_files_from_stub: loading files from {stub}")
-    response = download_get_request(
-        args=stub,
-        force_token_refresh=force_token_refresh,
+    _LOGGER.debug(f"load_files_from_stub: calling  files from {stub}")
+
+    arguments = get_model_metadata_from_stub(stub)
+
+    api = GraphQLAPI()
+
+    models = api.fetch(
+        operation_body="models",
+        arguments=arguments,
+        fields=[
+            "model_id",
+            "model_onnx_size_compressed_bytes",
+            "files",
+            "benchmark_results",
+            "training_results",
+        ],
     )
 
-    # piece of code required for backwards compatibility
-    model_response = response.get("model", {})
-    files = model_response.get("files", [])
-    files = restructure_request_json(request_json=files)
-    compressed_file_size = _get_compressed_size(files=files)
-    model_id = model_response.get("model_id")
-    if params is not None:
-        files = filter_files(files=files, params=params)
-
-    model_results = model_response.get("results")
-    validation_results = _parse_validation_metrics(model_results_response=model_results)
-    return files, model_id, params, validation_results, compressed_file_size
+    matching_models = len(models)
+    if matching_models == 0:
+        raise ValueError(
+            f"No matching models found with stub: {stub}." "Please try another stub"
+        )
+    if matching_models > 1:
+        logging.warning(
+            f"{len(models)} found from the stub: {stub}"
+            "Using the first model to obtain metadata."
+            "Proceed with caution"
+        )
+
+    if matching_models:
+        model = models[0]
+
+        model_id = model["model_id"]
+
+        files = model.get("files")
+        include_file_download_url(files)
+        files = restructure_request_json(request_json=files)
+
+        if params is not None:
+            files = filter_files(files=files, params=params)
+
+        training_results = model.get("training_results")
+
+        benchmark_results = model.get("benchmark_results")
+
+        model_onnx_size_compressed_bytes = model.get("model_onnx_size_compressed_bytes")
+
+        throughput_results = [
+            ThroughputResults(**benchmark_result)
+            for benchmark_result in benchmark_results
+        ]
+        validation_results = [
+            ValidationResult(**training_result) for training_result in training_results
+        ]
+
+        results: Dict[str, List[ModelResult]] = defaultdict(list)
+        results["validation"] = validation_results
+        results["throughput"] = throughput_results
+
+        return files, model_id, params, results, model_onnx_size_compressed_bytes
+
+    _LOGGER.warning(f"load_files_from_stub: No models found with the stub:{stub}")
 
 
 def filter_files(
     files: List[Dict[str, Any]], params: Dict[str, str]
 ) -> List[Dict[str, Any]]:
     """
     Use the `params` to extract only the relevant files from `files`
@@ -172,25 +224,25 @@
 
         files_filtered.append(file_dict)
 
     if not files_filtered:
         raise ValueError("No files found - the list of files is empty!")
 
     if num_recipe_file_dicts >= 2:
-        recipe_names = [
-            file_dict["display_name"]
-            for file_dict in files_filtered
-            if file_dict["file_type"] == "recipe"
-        ]
-        raise ValueError(
-            f"Found multiple recipes: {recipe_names}, "
-            f"for the string argument {expected_recipe_name}"
-        )
-    else:
-        return files_filtered
+        recipe_names = set()
+        for file_dict in files_filtered:
+            if file_dict["file_type"] == "recipe":
+                recipe_names.add(file_dict["display_name"])
+        if len(recipe_names) > 1:
+            raise ValueError(
+                f"Found multiple recipes: {recipe_names}, "
+                f"for the string argument {expected_recipe_name}"
+            )
+
+    return files_filtered
 
 
 def parse_zoo_stub(
     stub: str, valid_params: Optional[List[str]] = None
 ) -> Tuple[str, Dict[str, str]]:
     """
     :param stub: A SparseZoo model stub. i.e. 'model/stub/path',
@@ -284,14 +336,15 @@
         training_file_dict["file_type"] = "training"
         request_json[idx] = training_file_dict
 
     # create `deployment` folder
     onnx_model_dict_list = fetch_from_request_json(
         request_json, "display_name", "model.onnx"
     )
+    onnx_model_dict_list = [onnx_model_dict_list[0]]
     assert len(onnx_model_dict_list) == 1
     _, onnx_model_file_dict = copy.copy(onnx_model_dict_list[0])
     onnx_model_file_dict["file_type"] = "deployment"
     request_json.append(onnx_model_file_dict)
 
     training_file_names = [
         file_dict["display_name"]
@@ -520,37 +573,59 @@
 
 def _copy_and_overwrite(from_path, to_path, func):
     if os.path.exists(to_path):
         shutil.rmtree(to_path)
     func(from_path, to_path)
 
 
-def _parse_validation_metrics(
-    model_results_response: List[Dict[str, Union[str, float, int]]]
-) -> Dict[str, List[ModelResult]]:
-    results: Dict[str, List[ModelResult]] = defaultdict(list)
-    for result in model_results_response:
-        recorded_units = result.get("recorded_units").lower()
-        if recorded_units in ["items/seconds", "items/second"]:
-            key = "throughput"
-            current_result = ThroughputResults(
-                result_type=result.get("result_type"),
-                recorded_value=result.get("recorded_value"),
-                recorded_units=result.get("recorded_units"),
-                device_info=result.get("device_info"),
-                num_cores=result.get("num_cores"),
-                batch_size=result.get("batch_size"),
-            )
+def include_file_download_url(files: List[Dict]):
+    for file in files:
+        file["url"] = get_file_download_url(
+            model_id=file["model_id"], file_name=file["display_name"]
+        )
 
-        else:
-            current_result = ValidationResult(
-                result_type=result.get("result_type"),
-                recorded_value=result.get("recorded_value"),
-                recorded_units=recorded_units,
-                dataset_name=result.get("dataset_name"),
-                dataset_type=result.get("dataset_type"),
-            )
-            key = "validation"
 
-        results[key].append(current_result)
+def get_model_metadata_from_stub(stub: str) -> Dict[str, str]:
+    """Return a dictionary of the model metadata from stub"""
+
+    matches = re.match(STUB_V1_REGEX_EXPR, stub) or re.match(STUB_V2_REGEX_EXPR, stub)
+    if not matches:
+        return {}
+
+    if "source_dataset" in matches.groupdict():
+        return {"repo_name": stub}
+
+    if "dataset" in matches.groupdict():
+        return {
+            "domain": matches.group("domain"),
+            "sub_domain": matches.group("sub_domain"),
+            "architecture": matches.group("architecture"),
+            "sub_architecture": matches.group("sub_architecture"),
+            "framework": matches.group("framework"),
+            "repo": matches.group("repo"),
+            "dataset": matches.group("dataset"),
+            "sparse_tag": matches.group("sparse_tag"),
+        }
+
+    return {}
+
+
+def is_stub(candidate: str) -> bool:
+    return bool(
+        re.match(STUB_V1_REGEX_EXPR, candidate)
+        or re.match(STUB_V2_REGEX_EXPR, candidate)
+    )
+
+
+def get_file_download_url(
+    model_id: str,
+    file_name: str,
+    base_url: str = BASE_API_URL,
+):
+    """Url to download a file"""
+    download_url = f"{base_url}/v2/models/{model_id}/files/{file_name}"
+
+    # important, do not remove
+    if convert_to_bool(os.getenv("SPARSEZOO_TEST_MODE")):
+        download_url += "?increment_download=False"
 
-    return results
+    return download_url
```

## sparsezoo/objects/directory.py

```diff
@@ -16,15 +16,15 @@
 import os
 import pathlib
 import tarfile
 import time
 import traceback
 from typing import Dict, List, Optional, Union
 
-from sparsezoo import utils
+from sparsezoo.utils import download_file
 
 from .file import File
 
 
 __all__ = ["Directory", "is_directory"]
 
 
@@ -164,15 +164,15 @@
                 )
 
         # Directory can represent a tar file.
         if self.is_archive:
             new_file_path = os.path.join(destination_path, self.name)
             for attempt in range(retries):
                 try:
-                    utils.download_file(
+                    download_file(
                         url_path=self.url,
                         dest_path=new_file_path,
                         overwrite=overwrite,
                     )
 
                     self._path = new_file_path
                     return
```

## sparsezoo/objects/file.py

```diff
@@ -164,17 +164,15 @@
                 self._path = new_file_path
                 return
 
             except Exception as err:
                 logging.error(err)
                 logging.error(traceback.format_exc())
                 time.sleep(retry_sleep_sec)
-            logging.error(
-                f"Trying attempt {attempt + 1} of {retries}.", attempt + 1, retries
-            )
+            logging.error(f"Trying attempt {attempt + 1} of {retries}.")
         logging.error("Download retry failed...")
         raise Exception("Exceed max retry attempts: {} failed".format(retries))
 
     def validate(self, strict_mode: bool = True) -> bool:
         """
         Validate whether the File object is loadable or not.
```

## sparsezoo/search/search.py

```diff
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import logging
 from typing import List, Union
 
 from sparsezoo import Model
-from sparsezoo.utils import search_model_get_request
+from sparsezoo.api.graphql import GraphQLAPI
 
 
 __all__ = ["search_models", "model_args_to_stub"]
 
 
 def search_models(
     domain: str,
@@ -73,40 +73,46 @@
     :param override_parent_path: Path to override the default save path
         for where to save the parent folder for this file under
     :param force_token_refresh: True to refresh the auth token, False otherwise
     :param return_stubs: if True, found models will be returned as stubs only
         instead of retrieving full info for each found model. Default False
     :return: The requested list of Model instances
     """
+    sparse_tag_components = [sparse_name, sparse_category, sparse_target]
+
     args = {
         "domain": domain,
         "sub_domain": sub_domain,
         "architecture": architecture,
         "sub_architecture": sub_architecture,
         "framework": framework,
         "repo": repo,
         "dataset": dataset,
         "training_scheme": training_scheme,
-        "sparse_name": sparse_name,
-        "sparse_category": sparse_category,
-        "sparse_target": sparse_target,
         "release_version": release_version,
     }
+    if any(sparse_tag_components):
+        args.update(
+            {
+                "sparse_tag": "-".join(
+                    component for component in sparse_tag_components if component
+                )
+            }
+        )
 
-    args = {k: v for k, v in args.items() if v is not None}
+    arguments = {key: value for key, value in args.items() if value is not None}
 
     logging.debug(f"Search_models: searching models with args {args}")
-    response_json = search_model_get_request(
-        args=args,
-        page=page,
-        page_length=page_length,
-        force_token_refresh=force_token_refresh,
+
+    response_json = GraphQLAPI().fetch(
+        operation_body="models",
+        arguments=arguments,
     )
 
-    stubs = [model_args_to_stub(**model_dict) for model_dict in response_json["models"]]
+    stubs = [model_dict["stub"] for model_dict in response_json]
 
     if return_stubs:
         return stubs
 
     return [Model(stub) for stub in stubs]
```

## sparsezoo/utils/__init__.py

```diff
@@ -20,20 +20,21 @@
 from sparsezoo.utils.helpers import convert_to_bool
 
 BASE_API_URL = (
     os.getenv("SPARSEZOO_API_URL")
     if os.getenv("SPARSEZOO_API_URL")
     else "https://api.neuralmagic.com"
 )
-MODELS_API_URL = f"{BASE_API_URL}/models"
+MODELS_API_URL = f"{BASE_API_URL}/v2/models"
 LATEST_PACKAGE_VERSION_URL = f"{BASE_API_URL}/packages/check-latest"
 
 from .authentication import *
 from .graph_editor import *
 from .onnx import *
 from .calculate_ops import *
 from .data import *
 from .download import *
 from .helpers import *
 from .node_inference import *
 from .numpy import *
-from .requests import *
+from .task_name import *
+from .constants import *
```

## sparsezoo/utils/download.py

```diff
@@ -75,16 +75,16 @@
         try:
             os.remove(dest_path)
         except OSError as err:
             _LOGGER.warning(
                 "error encountered when removing older "
                 f"cache_file at {dest_path}: {err}"
             )
-
     request = requests.get(url_path, stream=True)
+
     request.raise_for_status()
     content_length = request.headers.get("content-length")
 
     try:
         content_length = int(content_length)
     except Exception:
         _LOGGER.debug(f"could not get content length for file at {url_path}")
@@ -94,15 +94,14 @@
         downloaded = 0
         yield DownloadProgress(0, downloaded, content_length, dest_path)
 
         with open(dest_path, "wb") as file:
             for chunk in request.iter_content(chunk_size=1024):
                 if not chunk:
                     continue
-
                 file.write(chunk)
                 file.flush()
 
                 downloaded += len(chunk)
 
                 yield DownloadProgress(
                     len(chunk), downloaded, content_length, dest_path
@@ -193,15 +192,14 @@
     :param show_progress: True to show a progress bar for the download,
         False otherwise
     :param progress_title: The title to show with the progress bar
     :raise PreviouslyDownloadedError: raised if file already exists at dest_path
         nad overwrite is False
     """
     bar = None
-
     for progress in download_file_iter(url_path, dest_path, overwrite, num_retries):
         if (
             bar is None
             and show_progress
             and progress.content_length
             and progress.content_length > 0
         ):
```

## sparsezoo/utils/helpers.py

```diff
@@ -9,24 +9,27 @@
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import glob
+import logging
 import os
+from contextlib import contextmanager
 from typing import Any
 
 
 __all__ = [
     "create_dirs",
     "create_parent_dirs",
     "clean_path",
     "remove_tar_duplicates",
     "convert_to_bool",
+    "disable_request_logs",
 ]
 
 
 def convert_to_bool(val: Any):
     """
     :param val: a value
     :return: False if value is a Falsy value e.g. 0, f, false, None, otherwise True.
@@ -83,7 +86,24 @@
 
 def clean_path(path: str) -> str:
     """
     :param path: the directory or file path to clean
     :return: a cleaned version that expands the user path and creates an absolute path
     """
     return os.path.abspath(os.path.expanduser(path))
+
+
+@contextmanager
+def disable_request_logs():
+    """
+    Context manager for disabling logs for a requests session
+    """
+    loggers = [logging.getLogger("requests"), logging.getLogger("urllib3")]
+
+    original_disabled_states = [logger.disabled for logger in loggers]
+    for logger in loggers:
+        logger.disabled = True
+
+    yield
+
+    for logger, original_disabled_state in zip(loggers, original_disabled_states):
+        logger.disabled = original_disabled_state
```

## Comparing `sparsezoo/analysis/__init__.py` & `sparsezoo/analyze/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -10,9 +10,9 @@
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 # flake8: noqa
 
-from .analysis import ModelAnalysis, NodeAnalysis
+from .analysis import *
 from .utils.chart import *
```

## Comparing `sparsezoo/analysis/utils/__init__.py` & `sparsezoo/analyze/utils/__init__.py`

 * *Files identical despite different names*

## Comparing `sparsezoo/analysis/utils/chart.py` & `sparsezoo/analyze/utils/chart.py`

 * *Files 5% similar despite different names*

```diff
@@ -12,26 +12,46 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from typing import Optional, Tuple
 
 import numpy
 
-import matplotlib.pyplot as plt
-from sparsezoo.analysis import ModelAnalysis, NodeAnalysis
+
+try:
+    import matplotlib.pyplot as plt
+
+    matplotlib_available = True
+except ImportError:
+    plt = None
+    matplotlib_available = False
+
+from sparsezoo.analyze.analysis import ModelAnalysis, NodeAnalysis
 
 
 __all__ = [
     "draw_sparsity_by_layer_chart",
     "draw_parameter_chart",
     "draw_operation_chart",
     "draw_parameter_operation_combined_chart",
 ]
 
 
+def check_matplotlib_installed() -> None:
+    """
+    Checks if matplotlib is installed and
+    raises an ImportError if not
+    """
+    if not matplotlib_available:
+        raise ImportError(
+            "matplotlib is required to use this function, "
+            "please install it with `pip install matplotlib>=3.0.0`"
+        )
+
+
 def draw_sparsity_by_layer_chart(
     model_analysis: ModelAnalysis,
     out_path: Optional[str] = None,
     model_name: str = "Model",
     figsize: Tuple[int, int] = (25, 15),
 ) -> None:
     """
@@ -41,14 +61,15 @@
 
     :param model_analysis: analysis of model whose chart is being drawn
     :param out_path: optional file path to save chart to
     :param model_name: name of model being analyzed, used in chart title
     :param figsize: keyword argument to pass to matplotlib figure
     :return: None
     """
+    check_matplotlib_installed()
     figure, axes = plt.subplots(figsize=figsize)
 
     # Set title
     figure.suptitle(f"{model_name} Sparsity per Layer")
 
     # Ingest node data
     parameterized_prunable_nodes = [
@@ -109,14 +130,15 @@
     :param out_path: optional file path to save chart to
     :param model_name: name of model being analyzed, used in chart title
     :param text_size: size of text to use for percent sparse labels
     :param bar_width: width of bars in chart
     :param figsize: keyword argument to pass to matplotlib figure
     :return: None
     """
+    check_matplotlib_installed()
     figure, param_axes = plt.subplots(figsize=figsize)
 
     # Set title
     figure.suptitle(f"{model_name} Number of Parameters per Layer")
 
     # Ingest node data
     parameterized_prunable_nodes = [
@@ -196,14 +218,15 @@
     :param out_path: optional file path to save chart to
     :param model_name: name of model being analyzed, used in chart title
     :param text_size: size of text to use for percent sparse labels
     :param bar_width: width of bars in chart
     :param figsize: keyword argument to pass to matplotlib figure
     :return: None
     """
+    check_matplotlib_installed()
     figure, ops_axes = plt.subplots(figsize=figsize)
 
     # Set title
     figure.suptitle(
         f"{model_name} Number of Floating-point / Integer Operations per Layer"
     )
 
@@ -282,14 +305,15 @@
     :param out_path: optional file path to save chart to
     :param model_name: name of model being analyzed, used in chart title
     :param text_size: size of text to use for percent sparse labels
     :param bar_width: width of bars in chart
     :param figsize: keyword argument to pass to matplotlib figure
     :return: None
     """
+    check_matplotlib_installed()
     figure, param_axes = plt.subplots(figsize=figsize)
     ops_axes = param_axes.twinx()
 
     # Set title
     figure.suptitle(f"{model_name} Number of Parameters and Operations per Layer")
 
     # Ingest node data
```

## Comparing `sparsezoo/analysis/utils/models.py` & `sparsezoo/analyze/utils/models.py`

 * *Files identical despite different names*

## Comparing `sparsezoo-1.4.0.dist-info/LICENSE` & `sparsezoo-1.5.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `sparsezoo-1.4.0.dist-info/METADATA` & `sparsezoo-1.5.0.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: sparsezoo
-Version: 1.4.0
+Version: 1.5.0
 Summary: Neural network model repository for highly sparse and sparse-quantized models with matching sparsification recipes
 Home-page: https://github.com/neuralmagic/sparsezoo
 Author: Neuralmagic, Inc.
 Author-email: support@neuralmagic.com
 License: Apache
 Keywords: inference,machine learning,neural network,deep learning model,models,computer vision,nlp,pretrained transfer learning,sparsity,pruning,quantization,sparse models,resnet,mobilenet,yolov3
 Platform: UNKNOWN
@@ -30,19 +30,22 @@
 Description-Content-Type: text/markdown
 Requires-Dist: numpy (<=1.21.6,>=1.0.0)
 Requires-Dist: onnx (<=1.12.0,>=1.5.0)
 Requires-Dist: pyyaml (>=5.1.0)
 Requires-Dist: requests (>=2.0.0)
 Requires-Dist: tqdm (>=4.0.0)
 Requires-Dist: pydantic (>=1.8.2)
-Requires-Dist: click (~=8.0.0)
+Requires-Dist: click (!=8.0.0,>=7.1.2)
 Requires-Dist: protobuf (<4,>=3.12.2)
+Requires-Dist: pandas (>1.3)
+Requires-Dist: py-machineid (>=0.3.0)
+Requires-Dist: geocoder (>=1.38.0)
 Provides-Extra: dev
 Requires-Dist: beautifulsoup4 (==4.9.3) ; extra == 'dev'
-Requires-Dist: black (==21.5b2) ; extra == 'dev'
+Requires-Dist: black (==22.12.0) ; extra == 'dev'
 Requires-Dist: flake8 (>=3.8.3) ; extra == 'dev'
 Requires-Dist: flaky (>=3.7.0) ; extra == 'dev'
 Requires-Dist: isort (>=5.7.0) ; extra == 'dev'
 Requires-Dist: m2r2 (~=0.2.7) ; extra == 'dev'
 Requires-Dist: mistune (==0.8.4) ; extra == 'dev'
 Requires-Dist: myst-parser (~=0.14.0) ; extra == 'dev'
 Requires-Dist: rinohtype (>=0.4.2) ; extra == 'dev'
@@ -112,15 +115,15 @@
     </a>
 </p>
 
 ## Overview
 
 [SparseZoo is a constantly-growing repository](https://sparsezoo.neuralmagic.com) of sparsified (pruned and pruned-quantized) models with matching sparsification recipes for neural networks. 
 It simplifies and accelerates your time-to-value in building performant deep learning models with a collection of inference-optimized models and recipes to prototype from. 
-Read more about sparsification [here.](https://docs.neuralmagic.com/main/source/getstarted.html#sparsification)
+Read [more about sparsification](https://docs.neuralmagic.com/user-guides/sparsification).
 
 Available via API and hosted in the cloud, the SparseZoo contains both baseline and models sparsified to different degrees of inference performance vs. baseline loss recovery. 
 Recipe-driven approaches built around sparsification algorithms allow you to use the models as given, transfer-learn from the models onto private datasets, or transfer the recipes to your architectures.
 
 The [GitHub repository](https://github.com/neuralmagic/sparsezoo) contains the Python API code to handle the connection and authentication to the cloud.
 
 <img alt="SparseZoo Flow" src="https://docs.neuralmagic.com/docs/source/infographics/sparsezoo.png" width="960px" />
```

### html2text {}

```diff
@@ -1,8 +1,8 @@
-Metadata-Version: 2.1 Name: sparsezoo Version: 1.4.0 Summary: Neural network
+Metadata-Version: 2.1 Name: sparsezoo Version: 1.5.0 Summary: Neural network
 model repository for highly sparse and sparse-quantized models with matching
 sparsification recipes Home-page: https://github.com/neuralmagic/sparsezoo
 Author: Neuralmagic, Inc. Author-email: support@neuralmagic.com License: Apache
 Keywords: inference,machine learning,neural network,deep learning
 model,models,computer vision,nlp,pretrained transfer
 learning,sparsity,pruning,quantization,sparse models,resnet,mobilenet,yolov3
 Platform: UNKNOWN Classifier: Development Status :: 5 - Production/Stable
@@ -17,30 +17,32 @@
 Classifier: Topic :: Scientific/Engineering Classifier: Topic :: Scientific/
 Engineering :: Artificial Intelligence Classifier: Topic :: Scientific/
 Engineering :: Mathematics Classifier: Topic :: Software Development
 Classifier: Topic :: Software Development :: Libraries :: Python Modules
 Requires-Python: >=3.7.0 Description-Content-Type: text/markdown Requires-Dist:
 numpy (<=1.21.6,>=1.0.0) Requires-Dist: onnx (<=1.12.0,>=1.5.0) Requires-Dist:
 pyyaml (>=5.1.0) Requires-Dist: requests (>=2.0.0) Requires-Dist: tqdm
-(>=4.0.0) Requires-Dist: pydantic (>=1.8.2) Requires-Dist: click (~=8.0.0)
-Requires-Dist: protobuf (<4,>=3.12.2) Provides-Extra: dev Requires-Dist:
-beautifulsoup4 (==4.9.3) ; extra == 'dev' Requires-Dist: black (==21.5b2) ;
-extra == 'dev' Requires-Dist: flake8 (>=3.8.3) ; extra == 'dev' Requires-Dist:
-flaky (>=3.7.0) ; extra == 'dev' Requires-Dist: isort (>=5.7.0) ; extra ==
-'dev' Requires-Dist: m2r2 (~=0.2.7) ; extra == 'dev' Requires-Dist: mistune
-(==0.8.4) ; extra == 'dev' Requires-Dist: myst-parser (~=0.14.0) ; extra ==
-'dev' Requires-Dist: rinohtype (>=0.4.2) ; extra == 'dev' Requires-Dist: sphinx
-(>=3.4.0) ; extra == 'dev' Requires-Dist: sphinx-copybutton (>=0.3.0) ; extra
-== 'dev' Requires-Dist: sphinx-markdown-tables (>=0.0.15) ; extra == 'dev'
-Requires-Dist: sphinx-multiversion (==0.2.4) ; extra == 'dev' Requires-Dist:
-pytest (>=6.0.0) ; extra == 'dev' Requires-Dist: sphinx-rtd-theme ; extra ==
-'dev' Requires-Dist: wheel (>=0.36.2) ; extra == 'dev' Requires-Dist:
-onnxruntime (>=1.0.0) ; extra == 'dev' Requires-Dist: matplotlib (>=3.0.0) ;
-extra == 'dev' Provides-Extra: nb Requires-Dist: ipywidgets (>=7.0.0) ; extra
-== 'nb' Requires-Dist: jupyter (>=1.0.0) ; extra == 'nb'
+(>=4.0.0) Requires-Dist: pydantic (>=1.8.2) Requires-Dist: click
+(!=8.0.0,>=7.1.2) Requires-Dist: protobuf (<4,>=3.12.2) Requires-Dist: pandas
+(>1.3) Requires-Dist: py-machineid (>=0.3.0) Requires-Dist: geocoder (>=1.38.0)
+Provides-Extra: dev Requires-Dist: beautifulsoup4 (==4.9.3) ; extra == 'dev'
+Requires-Dist: black (==22.12.0) ; extra == 'dev' Requires-Dist: flake8
+(>=3.8.3) ; extra == 'dev' Requires-Dist: flaky (>=3.7.0) ; extra == 'dev'
+Requires-Dist: isort (>=5.7.0) ; extra == 'dev' Requires-Dist: m2r2 (~=0.2.7) ;
+extra == 'dev' Requires-Dist: mistune (==0.8.4) ; extra == 'dev' Requires-Dist:
+myst-parser (~=0.14.0) ; extra == 'dev' Requires-Dist: rinohtype (>=0.4.2) ;
+extra == 'dev' Requires-Dist: sphinx (>=3.4.0) ; extra == 'dev' Requires-Dist:
+sphinx-copybutton (>=0.3.0) ; extra == 'dev' Requires-Dist: sphinx-markdown-
+tables (>=0.0.15) ; extra == 'dev' Requires-Dist: sphinx-multiversion (==0.2.4)
+; extra == 'dev' Requires-Dist: pytest (>=6.0.0) ; extra == 'dev' Requires-
+Dist: sphinx-rtd-theme ; extra == 'dev' Requires-Dist: wheel (>=0.36.2) ; extra
+== 'dev' Requires-Dist: onnxruntime (>=1.0.0) ; extra == 'dev' Requires-Dist:
+matplotlib (>=3.0.0) ; extra == 'dev' Provides-Extra: nb Requires-Dist:
+ipywidgets (>=7.0.0) ; extra == 'nb' Requires-Dist: jupyter (>=1.0.0) ; extra
+== 'nb'
 ****** [tool icon]SparseZoo ******
 **** Neural network model repository for highly sparse and sparse-quantized
 models with matching sparsification recipes ****
 [Documentation] [https://img.shields.io/badge/slack-purple?style=for-the-
 badge&logo=slack] [https://img.shields.io/badge/support%20forums-
 navy?style=for-the-badge&logo=github] [Main] [GitHub_release] [GitHub]
 [Contributor_Covenant] [https://img.shields.io/badge/-YouTube-red?&style=for-
@@ -49,21 +51,21 @@
 img.shields.io/twitter/follow/
 neuralmagic?color=darkgreen&label=Follow&style=social]
 ## Overview [SparseZoo is a constantly-growing repository](https://
 sparsezoo.neuralmagic.com) of sparsified (pruned and pruned-quantized) models
 with matching sparsification recipes for neural networks. It simplifies and
 accelerates your time-to-value in building performant deep learning models with
 a collection of inference-optimized models and recipes to prototype from. Read
-more about sparsification [here.](https://docs.neuralmagic.com/main/source/
-getstarted.html#sparsification) Available via API and hosted in the cloud, the
-SparseZoo contains both baseline and models sparsified to different degrees of
-inference performance vs. baseline loss recovery. Recipe-driven approaches
-built around sparsification algorithms allow you to use the models as given,
-transfer-learn from the models onto private datasets, or transfer the recipes
-to your architectures. The [GitHub repository](https://github.com/neuralmagic/
+[more about sparsification](https://docs.neuralmagic.com/user-guides/
+sparsification). Available via API and hosted in the cloud, the SparseZoo
+contains both baseline and models sparsified to different degrees of inference
+performance vs. baseline loss recovery. Recipe-driven approaches built around
+sparsification algorithms allow you to use the models as given, transfer-learn
+from the models onto private datasets, or transfer the recipes to your
+architectures. The [GitHub repository](https://github.com/neuralmagic/
 sparsezoo) contains the Python API code to handle the connection and
 authentication to the cloud. [SparseZoo Flow] ## Highlights - [Model Stub
 Architecture Overview](https://docs.neuralmagic.com/sparsezoo/source/
 models.html) - [Available Model Recipes](https://docs.neuralmagic.com/
 sparsezoo/source/recipes.html) - [sparsezoo.neuralmagic.com](https://
 sparsezoo.neuralmagic.com) ## Installation This repository is tested on Python
 3.7-3.9, and Linux/Debian systems. It is recommended to install in a [virtual
```

## Comparing `sparsezoo-1.4.0.dist-info/NOTICE` & `sparsezoo-1.5.0.dist-info/NOTICE`

 * *Files identical despite different names*

