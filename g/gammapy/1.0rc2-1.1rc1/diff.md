# Comparing `tmp/gammapy-1.0rc2.tar.gz` & `tmp/gammapy-1.1rc1.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "gammapy-1.0rc2.tar", last modified: Sun Nov  6 22:04:43 2022, max compression
+gzip compressed data, was "gammapy-1.1rc1.tar", last modified: Fri Jun  2 16:42:15 2023, max compression
```

## Comparing `gammapy-1.0rc2.tar` & `gammapy-1.1rc1.tar`

### file list

```diff
@@ -1,756 +1,779 @@
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.370033 gammapy-1.0rc2/
--rw-r--r--   0 runner    (1001) docker     (121)       60 2022-11-06 22:04:17.000000 gammapy-1.0rc2/.codacy.yml
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.258032 gammapy-1.0rc2/.github/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.258032 gammapy-1.0rc2/.github/ISSUE_TEMPLATE/
--rw-r--r--   0 runner    (1001) docker     (121)     1339 2022-11-06 22:04:17.000000 gammapy-1.0rc2/.github/ISSUE_TEMPLATE/bug_report.md
--rw-r--r--   0 runner    (1001) docker     (121)      607 2022-11-06 22:04:17.000000 gammapy-1.0rc2/.github/ISSUE_TEMPLATE/feature_request.md
--rw-r--r--   0 runner    (1001) docker     (121)     1027 2022-11-06 22:04:17.000000 gammapy-1.0rc2/.github/PULL_REQUEST_TEMPLATE.md
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.258032 gammapy-1.0rc2/.github/workflows/
--rw-r--r--   0 runner    (1001) docker     (121)     1225 2022-11-06 22:04:17.000000 gammapy-1.0rc2/.github/workflows/cffconvert.yml
--rw-r--r--   0 runner    (1001) docker     (121)     4856 2022-11-06 22:04:17.000000 gammapy-1.0rc2/.github/workflows/ci.yml
--rw-r--r--   0 runner    (1001) docker     (121)      432 2022-11-06 22:04:17.000000 gammapy-1.0rc2/.github/workflows/dispatch.yml
--rw-r--r--   0 runner    (1001) docker     (121)      497 2022-11-06 22:04:17.000000 gammapy-1.0rc2/.github/workflows/greetings.yml
--rw-r--r--   0 runner    (1001) docker     (121)     1881 2022-11-06 22:04:17.000000 gammapy-1.0rc2/.github/workflows/release.yml
--rw-r--r--   0 runner    (1001) docker     (121)     1448 2022-11-06 22:04:17.000000 gammapy-1.0rc2/.gitignore
--rw-r--r--   0 runner    (1001) docker     (121)     8978 2022-11-06 22:04:17.000000 gammapy-1.0rc2/.mailmap
--rw-r--r--   0 runner    (1001) docker     (121)      649 2022-11-06 22:04:17.000000 gammapy-1.0rc2/.pre-commit-config.yaml
--rw-r--r--   0 runner    (1001) docker     (121)     1814 2022-11-06 22:04:17.000000 gammapy-1.0rc2/CITATION
--rw-r--r--   0 runner    (1001) docker     (121)     9728 2022-11-06 22:04:17.000000 gammapy-1.0rc2/CITATION.cff
--rw-r--r--   0 runner    (1001) docker     (121)      123 2022-11-06 22:04:17.000000 gammapy-1.0rc2/CODE_OF_CONDUCT.md
--rw-r--r--   0 runner    (1001) docker     (121)     1491 2022-11-06 22:04:17.000000 gammapy-1.0rc2/LICENSE.rst
--rw-r--r--   0 runner    (1001) docker     (121)      390 2022-11-06 22:04:17.000000 gammapy-1.0rc2/LONG_DESCRIPTION.rst
--rw-r--r--   0 runner    (1001) docker     (121)      252 2022-11-06 22:04:17.000000 gammapy-1.0rc2/MANIFEST.in
--rw-r--r--   0 runner    (1001) docker     (121)     4688 2022-11-06 22:04:17.000000 gammapy-1.0rc2/Makefile
--rw-r--r--   0 runner    (1001) docker     (121)     1342 2022-11-06 22:04:43.370033 gammapy-1.0rc2/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (121)     1710 2022-11-06 22:04:17.000000 gammapy-1.0rc2/README.rst
--rw-r--r--   0 runner    (1001) docker     (121)    19901 2022-11-06 22:04:17.000000 gammapy-1.0rc2/codemeta.json
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.262032 gammapy-1.0rc2/dev/
--rw-r--r--   0 runner    (1001) docker     (121)      167 2022-11-06 22:04:17.000000 gammapy-1.0rc2/dev/README.rst
--rw-r--r--   0 runner    (1001) docker     (121)     2790 2022-11-06 22:04:17.000000 gammapy-1.0rc2/dev/authors.py
--rw-r--r--   0 runner    (1001) docker     (121)      648 2022-11-06 22:04:17.000000 gammapy-1.0rc2/dev/codemeta.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.262032 gammapy-1.0rc2/dev/codespell/
--rw-r--r--   0 runner    (1001) docker     (121)       40 2022-11-06 22:04:17.000000 gammapy-1.0rc2/dev/codespell/exclude-file.txt
--rw-r--r--   0 runner    (1001) docker     (121)       56 2022-11-06 22:04:17.000000 gammapy-1.0rc2/dev/codespell/ignore-words.txt
--rw-r--r--   0 runner    (1001) docker     (121)      794 2022-11-06 22:04:17.000000 gammapy-1.0rc2/dev/prepare-release.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.262032 gammapy-1.0rc2/docs/
--rw-r--r--   0 runner    (1001) docker     (121)     4581 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/Makefile
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.270032 gammapy-1.0rc2/docs/_static/
--rw-r--r--   0 runner    (1001) docker     (121)   173823 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/1d-analysis-image.png
--rw-r--r--   0 runner    (1001) docker     (121)   251116 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/2d-analysis-image.png
--rw-r--r--   0 runner    (1001) docker     (121)   285342 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/3d-analysis-image.png
--rw-r--r--   0 runner    (1001) docker     (121)   185375 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/DC1_3d.png
--rw-r--r--   0 runner    (1001) docker     (121)    25253 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/atom.png
--rw-r--r--   0 runner    (1001) docker     (121)    12024 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/box.png
--rw-r--r--   0 runner    (1001) docker     (121)   268580 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/data-flow-gammapy.png
--rw-r--r--   0 runner    (1001) docker     (121)    11218 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/galleryicon.png
--rw-r--r--   0 runner    (1001) docker     (121)     5911 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/gammapy.css
--rw-r--r--   0 runner    (1001) docker     (121)    78429 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/gammapy_banner.png
--rw-r--r--   0 runner    (1001) docker     (121)     3527 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/gammapy_logo.ico
--rw-r--r--   0 runner    (1001) docker     (121)    27023 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/gammapy_logo.png
--rw-r--r--   0 runner    (1001) docker     (121)    21439 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/gammapy_logo_nav.png
--rw-r--r--   0 runner    (1001) docker     (121)   255027 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/gammapy_maps.png
--rw-r--r--   0 runner    (1001) docker     (121)    19482 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/gears.png
--rw-r--r--   0 runner    (1001) docker     (121)    24809 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/glossaryicon.png
--rw-r--r--   0 runner    (1001) docker     (121)   286752 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/hgps_map_background_estimation.png
--rw-r--r--   0 runner    (1001) docker     (121)   274950 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/hgps_spectrum_background_estimation.png
--rw-r--r--   0 runner    (1001) docker     (121)     3519 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/index_api.svg
--rw-r--r--   0 runner    (1001) docker     (121)     2528 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/index_contribute.svg
--rw-r--r--   0 runner    (1001) docker     (121)     3977 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/index_getting_started.svg
--rw-r--r--   0 runner    (1001) docker     (121)     6429 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/index_user_guide.svg
--rw-r--r--   0 runner    (1001) docker     (121)    19367 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/install.png
--rw-r--r--   0 runner    (1001) docker     (121)    19104 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/upgrade.png
--rw-r--r--   0 runner    (1001) docker     (121)     9257 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_static/using.png
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.246032 gammapy-1.0rc2/docs/_templates/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.270032 gammapy-1.0rc2/docs/_templates/autosummary/
--rw-r--r--   0 runner    (1001) docker     (121)      250 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_templates/autosummary/base.rst
--rw-r--r--   0 runner    (1001) docker     (121)      251 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_templates/autosummary/class.rst
--rw-r--r--   0 runner    (1001) docker     (121)      252 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/_templates/autosummary/module.rst
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.270032 gammapy-1.0rc2/docs/api-reference/
--rw-r--r--   0 runner    (1001) docker     (121)      241 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/api-reference/analysis.rst
--rw-r--r--   0 runner    (1001) docker     (121)      400 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/api-reference/astro.rst
--rw-r--r--   0 runner    (1001) docker     (121)      220 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/api-reference/catalog.rst
--rw-r--r--   0 runner    (1001) docker     (121)      232 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/api-reference/data.rst
--rw-r--r--   0 runner    (1001) docker     (121)      229 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/api-reference/datasets.rst
--rw-r--r--   0 runner    (1001) docker     (121)      385 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/api-reference/estimators.rst
--rw-r--r--   0 runner    (1001) docker     (121)      411 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/api-reference/index.rst
--rw-r--r--   0 runner    (1001) docker     (121)      238 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/api-reference/irf.rst
--rw-r--r--   0 runner    (1001) docker     (121)      269 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/api-reference/makers.rst
--rw-r--r--   0 runner    (1001) docker     (121)      181 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/api-reference/maps.rst
--rw-r--r--   0 runner    (1001) docker     (121)      363 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/api-reference/modeling.rst
--rw-r--r--   0 runner    (1001) docker     (121)      209 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/api-reference/scripts.rst
--rw-r--r--   0 runner    (1001) docker     (121)      193 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/api-reference/stats.rst
--rw-r--r--   0 runner    (1001) docker     (121)     1171 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/api-reference/utils.rst
--rw-r--r--   0 runner    (1001) docker     (121)      294 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/api-reference/visualization.rst
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.270032 gammapy-1.0rc2/docs/binder/
--rw-r--r--   0 runner    (1001) docker     (121)      126 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/binder/requirements.txt
--rw-r--r--   0 runner    (1001) docker     (121)       10 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/binder/runtime.txt
--rw-r--r--   0 runner    (1001) docker     (121)    12160 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/conf.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.274032 gammapy-1.0rc2/docs/development/
--rw-r--r--   0 runner    (1001) docker     (121)     2280 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/dependencies.rst
--rw-r--r--   0 runner    (1001) docker     (121)    31126 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/dev_howto.rst
--rw-r--r--   0 runner    (1001) docker     (121)    15533 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/doc_howto.rst
--rw-r--r--   0 runner    (1001) docker     (121)      865 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/index.rst
--rw-r--r--   0 runner    (1001) docker     (121)    11067 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/intro.rst
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.278032 gammapy-1.0rc2/docs/development/pigs/
--rw-r--r--   0 runner    (1001) docker     (121)      848 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/index.rst
--rw-r--r--   0 runner    (1001) docker     (121)    10348 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-001.rst
--rw-r--r--   0 runner    (1001) docker     (121)     9973 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-002.rst
--rw-r--r--   0 runner    (1001) docker     (121)     7229 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-003.rst
--rw-r--r--   0 runner    (1001) docker     (121)     8538 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-004.rst
--rw-r--r--   0 runner    (1001) docker     (121)     8470 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-005.rst
--rw-r--r--   0 runner    (1001) docker     (121)    93165 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-006-class-diagram.png
--rw-r--r--   0 runner    (1001) docker     (121)    11244 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-006.rst
--rw-r--r--   0 runner    (1001) docker     (121)    18677 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-007.rst
--rw-r--r--   0 runner    (1001) docker     (121)    19998 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-008.rst
--rw-r--r--   0 runner    (1001) docker     (121)    12942 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-009.rst
--rw-r--r--   0 runner    (1001) docker     (121)    26320 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-010.rst
--rw-r--r--   0 runner    (1001) docker     (121)    11310 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-011.rst
--rw-r--r--   0 runner    (1001) docker     (121)    17401 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-012.rst
--rw-r--r--   0 runner    (1001) docker     (121)    12911 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-013.rst
--rw-r--r--   0 runner    (1001) docker     (121)     9474 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-014.rst
--rw-r--r--   0 runner    (1001) docker     (121)   118034 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-016-gammapy-package-organisation-proposal.png
--rw-r--r--   0 runner    (1001) docker     (121)   120184 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-016-gammapy-package-organisation-status.png
--rw-r--r--   0 runner    (1001) docker     (121)    10097 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-016.rst
--rw-r--r--   0 runner    (1001) docker     (121)    16069 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-018.rst
--rw-r--r--   0 runner    (1001) docker     (121)     7874 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-019.rst
--rw-r--r--   0 runner    (1001) docker     (121)     5987 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-020.rst
--rw-r--r--   0 runner    (1001) docker     (121)    11481 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-021.rst
--rw-r--r--   0 runner    (1001) docker     (121)    15219 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-022.rst
--rw-r--r--   0 runner    (1001) docker     (121)     5954 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-023.rst
--rw-r--r--   0 runner    (1001) docker     (121)    18059 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/pigs/pig-024.rst
--rw-r--r--   0 runner    (1001) docker     (121)     6850 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/release.rst
--rw-r--r--   0 runner    (1001) docker     (121)    10102 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/development/setup.rst
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.278032 gammapy-1.0rc2/docs/getting-started/
--rw-r--r--   0 runner    (1001) docker     (121)     2457 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/getting-started/environments.rst
--rw-r--r--   0 runner    (1001) docker     (121)     6383 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/getting-started/index.rst
--rw-r--r--   0 runner    (1001) docker     (121)     4398 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/getting-started/install.rst
--rw-r--r--   0 runner    (1001) docker     (121)     2642 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/getting-started/quickstart.rst
--rw-r--r--   0 runner    (1001) docker     (121)     1684 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/getting-started/troubleshooting.rst
--rw-r--r--   0 runner    (1001) docker     (121)     4538 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/getting-started/usage.rst
--rw-r--r--   0 runner    (1001) docker     (121)     2936 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/index.rst
--rw-r--r--   0 runner    (1001) docker     (121)     4549 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/make.bat
--rw-r--r--   0 runner    (1001) docker     (121)      439 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/nitpick-exceptions
--rw-r--r--   0 runner    (1001) docker     (121)     7677 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/references.txt
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.282032 gammapy-1.0rc2/docs/release-notes/
--rw-r--r--   0 runner    (1001) docker     (121)     1768 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/index.rst
--rw-r--r--   0 runner    (1001) docker     (121)     2967 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/v0.1.rst
--rw-r--r--   0 runner    (1001) docker     (121)     3216 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/v0.10.rst
--rw-r--r--   0 runner    (1001) docker     (121)     5907 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/v0.11.rst
--rw-r--r--   0 runner    (1001) docker     (121)     4787 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/v0.12.rst
--rw-r--r--   0 runner    (1001) docker     (121)     5088 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/v0.13.rst
--rw-r--r--   0 runner    (1001) docker     (121)     5401 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/v0.14.rst
--rw-r--r--   0 runner    (1001) docker     (121)     9750 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/v0.15.rst
--rw-r--r--   0 runner    (1001) docker     (121)     5661 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/v0.16.rst
--rw-r--r--   0 runner    (1001) docker     (121)     8210 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/v0.17.rst
--rw-r--r--   0 runner    (1001) docker     (121)      695 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/v0.18.1.rst
--rw-r--r--   0 runner    (1001) docker     (121)      730 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/v0.18.2.rst
--rw-r--r--   0 runner    (1001) docker     (121)    10000 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/v0.18.rst
--rw-r--r--   0 runner    (1001) docker     (121)    15018 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/v0.19.rst
--rw-r--r--   0 runner    (1001) docker     (121)     2060 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/v0.2.rst
--rw-r--r--   0 runner    (1001) docker     (121)     2433 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/v0.20.1.rst
--rw-r--r--   0 runner    (1001) docker     (121)     6692 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/v0.20.rst
--rw-r--r--   0 runner    (1001) docker     (121)     2418 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/v0.3.rst
--rw-r--r--   0 runner    (1001) docker     (121)     4583 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/v0.4.rst
--rw-r--r--   0 runner    (1001) docker     (121)     5428 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/v0.5.rst
--rw-r--r--   0 runner    (1001) docker     (121)     7359 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/v0.6.rst
--rw-r--r--   0 runner    (1001) docker     (121)    11532 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/v0.7.rst
--rw-r--r--   0 runner    (1001) docker     (121)    11529 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/v0.8.rst
--rw-r--r--   0 runner    (1001) docker     (121)     5258 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/v0.9.rst
--rw-r--r--   0 runner    (1001) docker     (121)     7193 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/release-notes/v1.0.rst
--rw-r--r--   0 runner    (1001) docker     (121)      852 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/serve.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.282032 gammapy-1.0rc2/docs/user-guide/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.282032 gammapy-1.0rc2/docs/user-guide/astro/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.282032 gammapy-1.0rc2/docs/user-guide/astro/darkmatter/
--rw-r--r--   0 runner    (1001) docker     (121)     5802 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/astro/darkmatter/index.rst
--rw-r--r--   0 runner    (1001) docker     (121)      984 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/astro/index.rst
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.286032 gammapy-1.0rc2/docs/user-guide/astro/population/
--rw-r--r--   0 runner    (1001) docker     (121)     2037 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/astro/population/index.rst
--rw-r--r--   0 runner    (1001) docker     (121)      799 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/astro/population/plot_radial_distributions.py
--rw-r--r--   0 runner    (1001) docker     (121)     1463 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/astro/population/plot_spiral_arm_models.py
--rw-r--r--   0 runner    (1001) docker     (121)     2159 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/astro/population/plot_spiral_arms.py
--rw-r--r--   0 runner    (1001) docker     (121)      784 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/astro/population/plot_velocity_distributions.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.286032 gammapy-1.0rc2/docs/user-guide/astro/source/
--rw-r--r--   0 runner    (1001) docker     (121)      492 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/astro/source/index.rst
--rw-r--r--   0 runner    (1001) docker     (121)      426 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/astro/source/plot_pulsar_spindown.py
--rw-r--r--   0 runner    (1001) docker     (121)      724 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/astro/source/plot_pwn_evolution.py
--rw-r--r--   0 runner    (1001) docker     (121)      774 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/astro/source/plot_snr_brightness_evolution.py
--rw-r--r--   0 runner    (1001) docker     (121)      752 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/astro/source/plot_snr_radius_evolution.py
--rw-r--r--   0 runner    (1001) docker     (121)      194 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/astro/source/pulsar.rst
--rw-r--r--   0 runner    (1001) docker     (121)      213 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/astro/source/pwn.rst
--rw-r--r--   0 runner    (1001) docker     (121)      367 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/astro/source/snr.rst
--rw-r--r--   0 runner    (1001) docker     (121)     1617 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/catalog.rst
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.286032 gammapy-1.0rc2/docs/user-guide/datasets/
--rw-r--r--   0 runner    (1001) docker     (121)     9876 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/datasets/index.rst
--rw-r--r--   0 runner    (1001) docker     (121)     2482 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/datasets/plot_stack.py
--rw-r--r--   0 runner    (1001) docker     (121)     5987 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/dl3.rst
--rw-r--r--   0 runner    (1001) docker     (121)     8536 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/estimators.rst
--rw-r--r--   0 runner    (1001) docker     (121)      779 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/hli.rst
--rw-r--r--   0 runner    (1001) docker     (121)    11833 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/howto.rst
--rw-r--r--   0 runner    (1001) docker     (121)     1744 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/index.rst
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.290032 gammapy-1.0rc2/docs/user-guide/irf/
--rw-r--r--   0 runner    (1001) docker     (121)      758 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/irf/aeff.rst
--rw-r--r--   0 runner    (1001) docker     (121)     1257 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/irf/bkg.rst
--rw-r--r--   0 runner    (1001) docker     (121)     3540 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/irf/edisp.rst
--rw-r--r--   0 runner    (1001) docker     (121)     5188 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/irf/index.rst
--rw-r--r--   0 runner    (1001) docker     (121)      299 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/irf/plot_aeff.py
--rw-r--r--   0 runner    (1001) docker     (121)      432 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/irf/plot_aeff_param.py
--rw-r--r--   0 runner    (1001) docker     (121)      282 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/irf/plot_bkg_3d.py
--rw-r--r--   0 runner    (1001) docker     (121)      301 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/irf/plot_edisp.py
--rw-r--r--   0 runner    (1001) docker     (121)      469 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/irf/plot_edisp_kernel.py
--rw-r--r--   0 runner    (1001) docker     (121)      497 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/irf/plot_edisp_kernel_param.py
--rw-r--r--   0 runner    (1001) docker     (121)      478 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/irf/plot_fermi_psf.py
--rw-r--r--   0 runner    (1001) docker     (121)      254 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/irf/plot_psf.py
--rw-r--r--   0 runner    (1001) docker     (121)     1367 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/irf/psf.rst
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.290032 gammapy-1.0rc2/docs/user-guide/makers/
--rw-r--r--   0 runner    (1001) docker     (121)     1225 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/makers/create_region.py
--rw-r--r--   0 runner    (1001) docker     (121)     2384 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/makers/fov.rst
--rw-r--r--   0 runner    (1001) docker     (121)      869 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/makers/index.rst
--rw-r--r--   0 runner    (1001) docker     (121)     1735 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/makers/make_rectangular_reflected_background.py
--rw-r--r--   0 runner    (1001) docker     (121)     2258 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/makers/make_reflected_regions.py
--rw-r--r--   0 runner    (1001) docker     (121)     4611 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/makers/reflected.rst
--rw-r--r--   0 runner    (1001) docker     (121)     2803 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/makers/ring.rst
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.290032 gammapy-1.0rc2/docs/user-guide/maps/
--rw-r--r--   0 runner    (1001) docker     (121)     1947 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/maps/hpxmap.rst
--rw-r--r--   0 runner    (1001) docker     (121)    12158 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/maps/index.rst
--rw-r--r--   0 runner    (1001) docker     (121)    19094 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/maps/regionmap.rst
--rw-r--r--   0 runner    (1001) docker     (121)     2343 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/modeling.rst
--rw-r--r--   0 runner    (1001) docker     (121)     3813 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/package.rst
--rw-r--r--   0 runner    (1001) docker     (121)     9574 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/references.rst
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.290032 gammapy-1.0rc2/docs/user-guide/scripts/
--rw-r--r--   0 runner    (1001) docker     (121)    12748 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/scripts/index.rst
--rw-r--r--   0 runner    (1001) docker     (121)      953 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/scripts/significance.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.294032 gammapy-1.0rc2/docs/user-guide/stats/
--rw-r--r--   0 runner    (1001) docker     (121)     5858 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/stats/fit_statistics.rst
--rw-r--r--   0 runner    (1001) docker     (121)    11561 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/stats/index.rst
--rw-r--r--   0 runner    (1001) docker     (121)     1741 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/stats/plot_cash_errors.py
--rw-r--r--   0 runner    (1001) docker     (121)     1350 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/stats/plot_cash_significance.py
--rw-r--r--   0 runner    (1001) docker     (121)     1740 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/stats/plot_wstat_errors.py
--rw-r--r--   0 runner    (1001) docker     (121)     1349 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/stats/plot_wstat_significance.py
--rw-r--r--   0 runner    (1001) docker     (121)     6544 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/stats/wstat_derivation.rst
--rw-r--r--   0 runner    (1001) docker     (121)     3703 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/utils.rst
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.294032 gammapy-1.0rc2/docs/user-guide/visualization/
--rw-r--r--   0 runner    (1001) docker     (121)     1077 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/visualization/colormap_example.py
--rw-r--r--   0 runner    (1001) docker     (121)     1358 2022-11-06 22:04:17.000000 gammapy-1.0rc2/docs/user-guide/visualization/index.rst
--rw-r--r--   0 runner    (1001) docker     (121)     1231 2022-11-06 22:04:17.000000 gammapy-1.0rc2/environment-dev.yml
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.294032 gammapy-1.0rc2/examples/
--rw-r--r--   0 runner    (1001) docker     (121)      666 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/README.rst
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.294032 gammapy-1.0rc2/examples/models/
--rw-r--r--   0 runner    (1001) docker     (121)      613 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/README.txt
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.294032 gammapy-1.0rc2/examples/models/spatial/
--rw-r--r--   0 runner    (1001) docker     (121)       59 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spatial/README.rst
--rw-r--r--   0 runner    (1001) docker     (121)      792 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spatial/plot_constant.py
--rw-r--r--   0 runner    (1001) docker     (121)     3606 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spatial/plot_disk.py
--rw-r--r--   0 runner    (1001) docker     (121)     3337 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spatial/plot_gauss.py
--rw-r--r--   0 runner    (1001) docker     (121)     2773 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spatial/plot_gen_gauss.py
--rw-r--r--   0 runner    (1001) docker     (121)     1270 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spatial/plot_point.py
--rw-r--r--   0 runner    (1001) docker     (121)     1519 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spatial/plot_shell.py
--rw-r--r--   0 runner    (1001) docker     (121)     2332 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spatial/plot_shell2.py
--rw-r--r--   0 runner    (1001) docker     (121)      928 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spatial/plot_template.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.298032 gammapy-1.0rc2/examples/models/spectral/
--rw-r--r--   0 runner    (1001) docker     (121)       62 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spectral/README.rst
--rw-r--r--   0 runner    (1001) docker     (121)     2665 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spectral/plot_absorbed.py
--rw-r--r--   0 runner    (1001) docker     (121)     1146 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spectral/plot_broken_powerlaw.py
--rw-r--r--   0 runner    (1001) docker     (121)     1063 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spectral/plot_compound.py
--rw-r--r--   0 runner    (1001) docker     (121)      742 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spectral/plot_constant_spectral.py
--rw-r--r--   0 runner    (1001) docker     (121)     1037 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spectral/plot_exp_cutoff_powerlaw.py
--rw-r--r--   0 runner    (1001) docker     (121)     1115 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spectral/plot_exp_cutoff_powerlaw_3fgl.py
--rw-r--r--   0 runner    (1001) docker     (121)      911 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spectral/plot_gauss_spectral.py
--rw-r--r--   0 runner    (1001) docker     (121)     1533 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spectral/plot_logparabola.py
--rw-r--r--   0 runner    (1001) docker     (121)     2629 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spectral/plot_naima.py
--rw-r--r--   0 runner    (1001) docker     (121)      953 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spectral/plot_piecewise_norm_spectral.py
--rw-r--r--   0 runner    (1001) docker     (121)      878 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spectral/plot_powerlaw.py
--rw-r--r--   0 runner    (1001) docker     (121)     1084 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spectral/plot_powerlaw2.py
--rw-r--r--   0 runner    (1001) docker     (121)     1099 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spectral/plot_smooth_broken_powerlaw.py
--rw-r--r--   0 runner    (1001) docker     (121)     1306 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spectral/plot_super_exp_cutoff_powerlaw_3fgl.py
--rw-r--r--   0 runner    (1001) docker     (121)     1760 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spectral/plot_super_exp_cutoff_powerlaw_4fgl.py
--rw-r--r--   0 runner    (1001) docker     (121)     1333 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spectral/plot_super_exp_cutoff_powerlaw_4fgl_dr1.py
--rw-r--r--   0 runner    (1001) docker     (121)     1584 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/spectral/plot_template_spectral.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.302032 gammapy-1.0rc2/examples/models/temporal/
--rw-r--r--   0 runner    (1001) docker     (121)       62 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/temporal/README.rst
--rw-r--r--   0 runner    (1001) docker     (121)      874 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/temporal/plot_constant_temporal.py
--rw-r--r--   0 runner    (1001) docker     (121)      970 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/temporal/plot_expdecay_temporal.py
--rw-r--r--   0 runner    (1001) docker     (121)     1022 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/temporal/plot_gaussian_temporal.py
--rw-r--r--   0 runner    (1001) docker     (121)     1457 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/temporal/plot_generalized_gaussian_temporal.py
--rw-r--r--   0 runner    (1001) docker     (121)      955 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/temporal/plot_linear_temporal.py
--rw-r--r--   0 runner    (1001) docker     (121)      966 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/temporal/plot_powerlaw_temporal.py
--rw-r--r--   0 runner    (1001) docker     (121)     1016 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/temporal/plot_sine_temporal.py
--rw-r--r--   0 runner    (1001) docker     (121)      953 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/temporal/plot_template_phase_temporal.py
--rw-r--r--   0 runner    (1001) docker     (121)      835 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/models/temporal/plot_template_temporal.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.302032 gammapy-1.0rc2/examples/tutorials/
--rw-r--r--   0 runner    (1001) docker     (121)      791 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/README.rst
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.306032 gammapy-1.0rc2/examples/tutorials/analysis-1d/
--rw-r--r--   0 runner    (1001) docker     (121)      310 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/analysis-1d/README.rst
--rw-r--r--   0 runner    (1001) docker     (121)     6397 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/analysis-1d/cta_sensitivity.py
--rw-r--r--   0 runner    (1001) docker     (121)    10559 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/analysis-1d/extended_source_spectral_analysis.py
--rw-r--r--   0 runner    (1001) docker     (121)     7647 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/analysis-1d/sed_fitting.py
--rw-r--r--   0 runner    (1001) docker     (121)    16448 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/analysis-1d/spectral_analysis.py
--rw-r--r--   0 runner    (1001) docker     (121)    13719 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/analysis-1d/spectral_analysis_hli.py
--rw-r--r--   0 runner    (1001) docker     (121)    12300 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/analysis-1d/spectral_analysis_rad_max.py
--rw-r--r--   0 runner    (1001) docker     (121)     7916 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/analysis-1d/spectrum_simulation.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.306032 gammapy-1.0rc2/examples/tutorials/analysis-2d/
--rw-r--r--   0 runner    (1001) docker     (121)       17 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/analysis-2d/README.rst
--rw-r--r--   0 runner    (1001) docker     (121)     7868 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/analysis-2d/detect.py
--rw-r--r--   0 runner    (1001) docker     (121)     5749 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/analysis-2d/modeling_2D.py
--rw-r--r--   0 runner    (1001) docker     (121)     9063 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/analysis-2d/ring_background.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.306032 gammapy-1.0rc2/examples/tutorials/analysis-3d/
--rw-r--r--   0 runner    (1001) docker     (121)       15 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/analysis-3d/README.rst
--rw-r--r--   0 runner    (1001) docker     (121)    14366 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/analysis-3d/analysis_3d.py
--rw-r--r--   0 runner    (1001) docker     (121)     8571 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/analysis-3d/analysis_mwl.py
--rw-r--r--   0 runner    (1001) docker     (121)    10744 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/analysis-3d/cta_data_analysis.py
--rw-r--r--   0 runner    (1001) docker     (121)    18119 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/analysis-3d/event_sampling.py
--rw-r--r--   0 runner    (1001) docker     (121)     8758 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/analysis-3d/flux_profiles.py
--rw-r--r--   0 runner    (1001) docker     (121)     7038 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/analysis-3d/simulate_3d.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.306032 gammapy-1.0rc2/examples/tutorials/analysis-time/
--rw-r--r--   0 runner    (1001) docker     (121)        9 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/analysis-time/README.rst
--rw-r--r--   0 runner    (1001) docker     (121)    11879 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/analysis-time/light_curve.py
--rw-r--r--   0 runner    (1001) docker     (121)     9340 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/analysis-time/light_curve_flare.py
--rw-r--r--   0 runner    (1001) docker     (121)    11210 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/analysis-time/light_curve_simulation.py
--rw-r--r--   0 runner    (1001) docker     (121)    10783 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/analysis-time/pulsar_analysis.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.310032 gammapy-1.0rc2/examples/tutorials/api/
--rw-r--r--   0 runner    (1001) docker     (121)      155 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/api/README.rst
--rw-r--r--   0 runner    (1001) docker     (121)     5373 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/api/astro_dark_matter.py
--rw-r--r--   0 runner    (1001) docker     (121)    12951 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/api/catalog.py
--rw-r--r--   0 runner    (1001) docker     (121)    18248 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/api/datasets.py
--rw-r--r--   0 runner    (1001) docker     (121)    18998 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/api/fitting.py
--rw-r--r--   0 runner    (1001) docker     (121)    13394 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/api/makers.py
--rw-r--r--   0 runner    (1001) docker     (121)    30617 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/api/maps.py
--rw-r--r--   0 runner    (1001) docker     (121)    15720 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/api/mask_maps.py
--rw-r--r--   0 runner    (1001) docker     (121)    15224 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/api/model_management.py
--rw-r--r--   0 runner    (1001) docker     (121)    26903 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/api/models.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.310032 gammapy-1.0rc2/examples/tutorials/data/
--rw-r--r--   0 runner    (1001) docker     (121)      367 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/data/README.rst
--rw-r--r--   0 runner    (1001) docker     (121)    14261 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/data/cta.py
--rw-r--r--   0 runner    (1001) docker     (121)    14596 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/data/fermi_lat.py
--rw-r--r--   0 runner    (1001) docker     (121)     6926 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/data/hess.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.310032 gammapy-1.0rc2/examples/tutorials/scripts/
--rw-r--r--   0 runner    (1001) docker     (121)      320 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/scripts/README.rst
--rw-r--r--   0 runner    (1001) docker     (121)      726 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/scripts/survey_map.py
--rw-r--r--   0 runner    (1001) docker     (121)      256 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/scripts/survey_map.rst
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.310032 gammapy-1.0rc2/examples/tutorials/starting/
--rw-r--r--   0 runner    (1001) docker     (121)      644 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/starting/README.rst
--rw-r--r--   0 runner    (1001) docker     (121)    13604 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/starting/analysis_1.py
--rw-r--r--   0 runner    (1001) docker     (121)    12223 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/starting/analysis_2.py
--rw-r--r--   0 runner    (1001) docker     (121)    14880 2022-11-06 22:04:17.000000 gammapy-1.0rc2/examples/tutorials/starting/overview.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.310032 gammapy-1.0rc2/gammapy/
--rw-r--r--   0 runner    (1001) docker     (121)     2227 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)      358 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/__main__.py
--rw-r--r--   0 runner    (1001) docker     (121)      356 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/_astropy_init.py
--rw-r--r--   0 runner    (1001) docker     (121)     2720 2022-11-06 22:04:42.000000 gammapy-1.0rc2/gammapy/_compiler.c
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.314032 gammapy-1.0rc2/gammapy/analysis/
--rw-r--r--   0 runner    (1001) docker     (121)      226 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/analysis/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.314032 gammapy-1.0rc2/gammapy/analysis/config/
--rw-r--r--   0 runner    (1001) docker     (121)     2277 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/analysis/config/docs.yaml
--rw-r--r--   0 runner    (1001) docker     (121)      512 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/analysis/config/example-1d.yaml
--rw-r--r--   0 runner    (1001) docker     (121)     1064 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/analysis/config/example-3d.yaml
--rw-r--r--   0 runner    (1001) docker     (121)      563 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/analysis/config/model-1d.yaml
--rw-r--r--   0 runner    (1001) docker     (121)     1011 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/analysis/config/model.yaml
--rw-r--r--   0 runner    (1001) docker     (121)     9054 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/analysis/config.py
--rw-r--r--   0 runner    (1001) docker     (121)    22499 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/analysis/core.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.314032 gammapy-1.0rc2/gammapy/analysis/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/analysis/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    15229 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/analysis/tests/test_analysis.py
--rw-r--r--   0 runner    (1001) docker     (121)     5046 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/analysis/tests/test_config.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.314032 gammapy-1.0rc2/gammapy/astro/
--rw-r--r--   0 runner    (1001) docker     (121)      114 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.314032 gammapy-1.0rc2/gammapy/astro/darkmatter/
--rw-r--r--   0 runner    (1001) docker     (121)      302 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/darkmatter/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     7130 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/darkmatter/profiles.py
--rw-r--r--   0 runner    (1001) docker     (121)     7409 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/darkmatter/spectra.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.314032 gammapy-1.0rc2/gammapy/astro/darkmatter/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/darkmatter/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)      579 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/darkmatter/tests/test_profiles.py
--rw-r--r--   0 runner    (1001) docker     (121)     1886 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/darkmatter/tests/test_spectra.py
--rw-r--r--   0 runner    (1001) docker     (121)     1062 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/darkmatter/tests/test_utils.py
--rw-r--r--   0 runner    (1001) docker     (121)     1723 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/darkmatter/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.318033 gammapy-1.0rc2/gammapy/astro/population/
--rw-r--r--   0 runner    (1001) docker     (121)     1386 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/population/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    14942 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/population/simulate.py
--rw-r--r--   0 runner    (1001) docker     (121)    16181 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/population/spatial.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.318033 gammapy-1.0rc2/gammapy/astro/population/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/population/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     7119 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/population/tests/test_simulate.py
--rw-r--r--   0 runner    (1001) docker     (121)     1458 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/population/tests/test_spatial.py
--rw-r--r--   0 runner    (1001) docker     (121)      849 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/population/tests/test_velocity.py
--rw-r--r--   0 runner    (1001) docker     (121)     3732 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/population/velocity.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.318033 gammapy-1.0rc2/gammapy/astro/source/
--rw-r--r--   0 runner    (1001) docker     (121)      295 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/source/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     5189 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/source/pulsar.py
--rw-r--r--   0 runner    (1001) docker     (121)     3916 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/source/pwn.py
--rw-r--r--   0 runner    (1001) docker     (121)    10627 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/source/snr.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.318033 gammapy-1.0rc2/gammapy/astro/source/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/source/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     3383 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/source/tests/test_pulsar.py
--rw-r--r--   0 runner    (1001) docker     (121)      675 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/source/tests/test_pwn.py
--rw-r--r--   0 runner    (1001) docker     (121)     1345 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/astro/source/tests/test_snr.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.318033 gammapy-1.0rc2/gammapy/catalog/
--rw-r--r--   0 runner    (1001) docker     (121)     1688 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     8679 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/core.py
--rw-r--r--   0 runner    (1001) docker     (121)    49484 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/fermi.py
--rw-r--r--   0 runner    (1001) docker     (121)    13985 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/gammacat.py
--rw-r--r--   0 runner    (1001) docker     (121)    10522 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/hawc.py
--rw-r--r--   0 runner    (1001) docker     (121)    38312 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/hess.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.322033 gammapy-1.0rc2/gammapy/catalog/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.322033 gammapy-1.0rc2/gammapy/catalog/tests/data/
--rw-r--r--   0 runner    (1001) docker     (121)     1402 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/data/2fhl_j0822.6-4250e.txt
--rw-r--r--   0 runner    (1001) docker     (121)     1202 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/data/2fhl_j1445.1-0329.txt
--rw-r--r--   0 runner    (1001) docker     (121)      370 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/data/2hwc_j0534+220.txt
--rw-r--r--   0 runner    (1001) docker     (121)      458 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/data/2hwc_j0631+169.txt
--rw-r--r--   0 runner    (1001) docker     (121)     2537 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/data/3fgl_J0000.1+6545.txt
--rw-r--r--   0 runner    (1001) docker     (121)     2877 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/data/3fgl_J0001.4+2120.txt
--rw-r--r--   0 runner    (1001) docker     (121)     2618 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/data/3fgl_J0023.4+0923.txt
--rw-r--r--   0 runner    (1001) docker     (121)     2685 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/data/3fgl_J0835.3-4510.txt
--rw-r--r--   0 runner    (1001) docker     (121)     2552 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/data/3fhl_j2301.9+5855e.txt
--rw-r--r--   0 runner    (1001) docker     (121)     2872 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/data/4fgl_J0000.3-7355.txt
--rw-r--r--   0 runner    (1001) docker     (121)     3264 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/data/4fgl_J0001.5+2113.txt
--rw-r--r--   0 runner    (1001) docker     (121)     3081 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/data/4fgl_J0002.8+6217.txt
--rw-r--r--   0 runner    (1001) docker     (121)     3273 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/data/4fgl_J1409.1-6121e.txt
--rw-r--r--   0 runner    (1001) docker     (121)     2425 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/data/gammacat_hess_j1813-178.txt
--rw-r--r--   0 runner    (1001) docker     (121)     2299 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/data/gammacat_hess_j1848-018.txt
--rw-r--r--   0 runner    (1001) docker     (121)     2993 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/data/gammacat_vela_x.txt
--rw-r--r--   0 runner    (1001) docker     (121)     6496 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/data/hess_j1713-397.txt
--rw-r--r--   0 runner    (1001) docker     (121)     5272 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/data/hess_j1825-137.txt
--rw-r--r--   0 runner    (1001) docker     (121)     4634 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/data/hess_j1930+188.txt
--rw-r--r--   0 runner    (1001) docker     (121)     1664 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/data/make.py
--rw-r--r--   0 runner    (1001) docker     (121)     2927 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/test_core.py
--rw-r--r--   0 runner    (1001) docker     (121)    23439 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/test_fermi.py
--rw-r--r--   0 runner    (1001) docker     (121)     6163 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/test_gammacat.py
--rw-r--r--   0 runner    (1001) docker     (121)     6704 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/test_hawc.py
--rw-r--r--   0 runner    (1001) docker     (121)    12366 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/catalog/tests/test_hess.py
--rw-r--r--   0 runner    (1001) docker     (121)     3382 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/conftest.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.326032 gammapy-1.0rc2/gammapy/data/
--rw-r--r--   0 runner    (1001) docker     (121)      706 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/data/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    25474 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/data/data_store.py
--rw-r--r--   0 runner    (1001) docker     (121)    34124 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/data/event_list.py
--rw-r--r--   0 runner    (1001) docker     (121)     3199 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/data/filters.py
--rw-r--r--   0 runner    (1001) docker     (121)    12091 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/data/gti.py
--rw-r--r--   0 runner    (1001) docker     (121)     6171 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/data/hdu_index_table.py
--rw-r--r--   0 runner    (1001) docker     (121)    14105 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/data/obs_table.py
--rw-r--r--   0 runner    (1001) docker     (121)    24486 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/data/observations.py
--rw-r--r--   0 runner    (1001) docker     (121)     4099 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/data/observers.py
--rw-r--r--   0 runner    (1001) docker     (121)    16530 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/data/pointing.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.326032 gammapy-1.0rc2/gammapy/data/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/data/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    10521 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/data/tests/test_data_store.py
--rw-r--r--   0 runner    (1001) docker     (121)     9396 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/data/tests/test_event_list.py
--rw-r--r--   0 runner    (1001) docker     (121)     2592 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/data/tests/test_filters.py
--rw-r--r--   0 runner    (1001) docker     (121)     4922 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/data/tests/test_gti.py
--rw-r--r--   0 runner    (1001) docker     (121)     4448 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/data/tests/test_hdu_index_table.py
--rw-r--r--   0 runner    (1001) docker     (121)    12481 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/data/tests/test_obs_table.py
--rw-r--r--   0 runner    (1001) docker     (121)    12710 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/data/tests/test_observations.py
--rw-r--r--   0 runner    (1001) docker     (121)      494 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/data/tests/test_observers.py
--rw-r--r--   0 runner    (1001) docker     (121)     8270 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/data/tests/test_pointing.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.330033 gammapy-1.0rc2/gammapy/datasets/
--rw-r--r--   0 runner    (1001) docker     (121)      869 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/datasets/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    16652 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/datasets/core.py
--rw-r--r--   0 runner    (1001) docker     (121)    18656 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/datasets/evaluator.py
--rw-r--r--   0 runner    (1001) docker     (121)    16859 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/datasets/flux_points.py
--rw-r--r--   0 runner    (1001) docker     (121)    12065 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/datasets/io.py
--rw-r--r--   0 runner    (1001) docker     (121)    93248 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/datasets/map.py
--rw-r--r--   0 runner    (1001) docker     (121)    13160 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/datasets/simulate.py
--rw-r--r--   0 runner    (1001) docker     (121)    13817 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/datasets/spectrum.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.330033 gammapy-1.0rc2/gammapy/datasets/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/datasets/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     2630 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/datasets/tests/test_datasets.py
--rw-r--r--   0 runner    (1001) docker     (121)     6923 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/datasets/tests/test_evaluator.py
--rw-r--r--   0 runner    (1001) docker     (121)     6802 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/datasets/tests/test_flux_points.py
--rw-r--r--   0 runner    (1001) docker     (121)     3646 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/datasets/tests/test_io.py
--rw-r--r--   0 runner    (1001) docker     (121)    63908 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/datasets/tests/test_map.py
--rw-r--r--   0 runner    (1001) docker     (121)    17535 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/datasets/tests/test_simulate.py
--rw-r--r--   0 runner    (1001) docker     (121)    40514 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/datasets/tests/test_spectrum.py
--rw-r--r--   0 runner    (1001) docker     (121)     1020 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/datasets/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.330033 gammapy-1.0rc2/gammapy/estimators/
--rw-r--r--   0 runner    (1001) docker     (121)     1056 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     2732 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/core.py
--rw-r--r--   0 runner    (1001) docker     (121)     6479 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/flux.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.330033 gammapy-1.0rc2/gammapy/estimators/map/
--rw-r--r--   0 runner    (1001) docker     (121)      244 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/map/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     9315 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/map/asmooth.py
--rw-r--r--   0 runner    (1001) docker     (121)    33843 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/map/core.py
--rw-r--r--   0 runner    (1001) docker     (121)    10086 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/map/excess.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.334033 gammapy-1.0rc2/gammapy/estimators/map/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/map/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     3877 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/map/tests/test_asmooth.py
--rw-r--r--   0 runner    (1001) docker     (121)    17259 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/map/tests/test_core.py
--rw-r--r--   0 runner    (1001) docker     (121)    12671 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/map/tests/test_excess.py
--rw-r--r--   0 runner    (1001) docker     (121)    10420 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/map/tests/test_ts.py
--rw-r--r--   0 runner    (1001) docker     (121)    25976 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/map/ts.py
--rw-r--r--   0 runner    (1001) docker     (121)     9985 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/parameter.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.334033 gammapy-1.0rc2/gammapy/estimators/points/
--rw-r--r--   0 runner    (1001) docker     (121)      341 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/points/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    23864 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/points/core.py
--rw-r--r--   0 runner    (1001) docker     (121)     5924 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/points/lightcurve.py
--rw-r--r--   0 runner    (1001) docker     (121)     5144 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/points/profile.py
--rw-r--r--   0 runner    (1001) docker     (121)     7250 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/points/sed.py
--rw-r--r--   0 runner    (1001) docker     (121)     5577 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/points/sensitivity.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.334033 gammapy-1.0rc2/gammapy/estimators/points/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/points/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    10438 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/points/tests/test_core.py
--rw-r--r--   0 runner    (1001) docker     (121)    23946 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/points/tests/test_lightcurve.py
--rw-r--r--   0 runner    (1001) docker     (121)     6355 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/points/tests/test_profile.py
--rw-r--r--   0 runner    (1001) docker     (121)    18438 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/points/tests/test_sed.py
--rw-r--r--   0 runner    (1001) docker     (121)     2559 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/points/tests/test_sensitivity.py
--rw-r--r--   0 runner    (1001) docker     (121)    13318 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/profile.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.334033 gammapy-1.0rc2/gammapy/estimators/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)      197 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/tests/test_core.py
--rw-r--r--   0 runner    (1001) docker     (121)     7809 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/tests/test_flux.py
--rw-r--r--   0 runner    (1001) docker     (121)     3472 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/tests/test_parameter_estimator.py
--rw-r--r--   0 runner    (1001) docker     (121)     4726 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/tests/test_profile.py
--rw-r--r--   0 runner    (1001) docker     (121)     2943 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/tests/test_utils.py
--rw-r--r--   0 runner    (1001) docker     (121)     7472 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/estimators/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.334033 gammapy-1.0rc2/gammapy/extern/
--rw-r--r--   0 runner    (1001) docker     (121)      429 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/extern/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    12232 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/extern/xmltodict.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.338033 gammapy-1.0rc2/gammapy/irf/
--rw-r--r--   0 runner    (1001) docker     (121)     1327 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    13237 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/background.py
--rw-r--r--   0 runner    (1001) docker     (121)    29768 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/core.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.338033 gammapy-1.0rc2/gammapy/irf/edisp/
--rw-r--r--   0 runner    (1001) docker     (121)      209 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/edisp/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     8680 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/edisp/core.py
--rw-r--r--   0 runner    (1001) docker     (121)    19652 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/edisp/kernel.py
--rw-r--r--   0 runner    (1001) docker     (121)    16928 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/edisp/map.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.338033 gammapy-1.0rc2/gammapy/irf/edisp/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/edisp/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     4465 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/edisp/tests/test_core.py
--rw-r--r--   0 runner    (1001) docker     (121)     3753 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/edisp/tests/test_kernel.py
--rw-r--r--   0 runner    (1001) docker     (121)    10935 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/edisp/tests/test_map.py
--rw-r--r--   0 runner    (1001) docker     (121)     7806 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/effective_area.py
--rw-r--r--   0 runner    (1001) docker     (121)     7751 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/io.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.338033 gammapy-1.0rc2/gammapy/irf/psf/
--rw-r--r--   0 runner    (1001) docker     (121)      317 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/psf/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     8532 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/psf/core.py
--rw-r--r--   0 runner    (1001) docker     (121)     8460 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/psf/kernel.py
--rw-r--r--   0 runner    (1001) docker     (121)    21653 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/psf/map.py
--rw-r--r--   0 runner    (1001) docker     (121)    12422 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/psf/parametric.py
--rw-r--r--   0 runner    (1001) docker     (121)      736 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/psf/table.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.338033 gammapy-1.0rc2/gammapy/irf/psf/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/psf/tests/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.338033 gammapy-1.0rc2/gammapy/irf/psf/tests/data/
--rw-r--r--   0 runner    (1001) docker     (121)      566 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/psf/tests/data/psf_info.txt
--rw-r--r--   0 runner    (1001) docker     (121)     2776 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/psf/tests/test_kernel.py
--rw-r--r--   0 runner    (1001) docker     (121)    19222 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/psf/tests/test_map.py
--rw-r--r--   0 runner    (1001) docker     (121)     5934 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/psf/tests/test_parametric.py
--rw-r--r--   0 runner    (1001) docker     (121)     3080 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/psf/tests/test_table.py
--rw-r--r--   0 runner    (1001) docker     (121)     3652 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/rad_max.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.342033 gammapy-1.0rc2/gammapy/irf/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    11926 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/tests/test_background.py
--rw-r--r--   0 runner    (1001) docker     (121)     2349 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/tests/test_core.py
--rw-r--r--   0 runner    (1001) docker     (121)     5012 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/tests/test_effective_area.py
--rw-r--r--   0 runner    (1001) docker     (121)     4026 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/tests/test_gadf.py
--rw-r--r--   0 runner    (1001) docker     (121)    10592 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/tests/test_io.py
--rw-r--r--   0 runner    (1001) docker     (121)     3148 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/irf/tests/test_rad_max.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.342033 gammapy-1.0rc2/gammapy/makers/
--rw-r--r--   0 runner    (1001) docker     (121)     1183 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/makers/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.342033 gammapy-1.0rc2/gammapy/makers/background/
--rw-r--r--   0 runner    (1001) docker     (121)      527 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/makers/background/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     9017 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/makers/background/fov.py
--rw-r--r--   0 runner    (1001) docker     (121)     4028 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/makers/background/phase.py
--rw-r--r--   0 runner    (1001) docker     (121)    20513 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/makers/background/reflected.py
--rw-r--r--   0 runner    (1001) docker     (121)    11103 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/makers/background/ring.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.342033 gammapy-1.0rc2/gammapy/makers/background/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/makers/background/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    12429 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/makers/background/tests/test_fov.py
--rw-r--r--   0 runner    (1001) docker     (121)     2245 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/makers/background/tests/test_phase.py
--rw-r--r--   0 runner    (1001) docker     (121)    15438 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/makers/background/tests/test_reflected.py
--rw-r--r--   0 runner    (1001) docker     (121)     4915 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/makers/background/tests/test_ring.py
--rw-r--r--   0 runner    (1001) docker     (121)      762 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/makers/core.py
--rw-r--r--   0 runner    (1001) docker     (121)    13471 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/makers/map.py
--rw-r--r--   0 runner    (1001) docker     (121)     6544 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/makers/reduce.py
--rw-r--r--   0 runner    (1001) docker     (121)    11897 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/makers/safe.py
--rw-r--r--   0 runner    (1001) docker     (121)     3136 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/makers/spectrum.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.346033 gammapy-1.0rc2/gammapy/makers/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/makers/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)      113 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/makers/tests/test_core.py
--rw-r--r--   0 runner    (1001) docker     (121)    18462 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/makers/tests/test_map.py
--rw-r--r--   0 runner    (1001) docker     (121)    12871 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/makers/tests/test_reduce.py
--rw-r--r--   0 runner    (1001) docker     (121)     8664 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/makers/tests/test_safe.py
--rw-r--r--   0 runner    (1001) docker     (121)    12765 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/makers/tests/test_spectrum.py
--rw-r--r--   0 runner    (1001) docker     (121)    14933 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/makers/tests/test_utils.py
--rw-r--r--   0 runner    (1001) docker     (121)    17461 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/makers/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.346033 gammapy-1.0rc2/gammapy/maps/
--rw-r--r--   0 runner    (1001) docker     (121)      630 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    93896 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/axes.py
--rw-r--r--   0 runner    (1001) docker     (121)     9845 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/coord.py
--rw-r--r--   0 runner    (1001) docker     (121)    63360 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/core.py
--rw-r--r--   0 runner    (1001) docker     (121)    17825 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/geom.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.346033 gammapy-1.0rc2/gammapy/maps/hpx/
--rw-r--r--   0 runner    (1001) docker     (121)      139 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/hpx/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    10417 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/hpx/core.py
--rw-r--r--   0 runner    (1001) docker     (121)    46682 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/hpx/geom.py
--rw-r--r--   0 runner    (1001) docker     (121)     3444 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/hpx/io.py
--rw-r--r--   0 runner    (1001) docker     (121)    38867 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/hpx/ndmap.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.346033 gammapy-1.0rc2/gammapy/maps/hpx/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/hpx/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    27107 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/hpx/tests/test_geom.py
--rw-r--r--   0 runner    (1001) docker     (121)    20992 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/hpx/tests/test_ndmap.py
--rw-r--r--   0 runner    (1001) docker     (121)    13353 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/hpx/utils.py
--rw-r--r--   0 runner    (1001) docker     (121)     2244 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/io.py
--rw-r--r--   0 runner    (1001) docker     (121)     5174 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/maps.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.346033 gammapy-1.0rc2/gammapy/maps/region/
--rw-r--r--   0 runner    (1001) docker     (121)      112 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/region/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    26888 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/region/geom.py
--rw-r--r--   0 runner    (1001) docker     (121)    25724 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/region/ndmap.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.350033 gammapy-1.0rc2/gammapy/maps/region/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/region/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    13324 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/region/tests/test_geom.py
--rw-r--r--   0 runner    (1001) docker     (121)    14564 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/region/tests/test_ndmap.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.350033 gammapy-1.0rc2/gammapy/maps/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    23868 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/tests/test_axes.py
--rw-r--r--   0 runner    (1001) docker     (121)     5131 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/tests/test_coord.py
--rw-r--r--   0 runner    (1001) docker     (121)    24904 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/tests/test_core.py
--rw-r--r--   0 runner    (1001) docker     (121)     1982 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/tests/test_counts.py
--rw-r--r--   0 runner    (1001) docker     (121)     2570 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/tests/test_maps.py
--rw-r--r--   0 runner    (1001) docker     (121)     2606 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.350033 gammapy-1.0rc2/gammapy/maps/wcs/
--rw-r--r--   0 runner    (1001) docker     (121)      139 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/wcs/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    10152 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/wcs/core.py
--rw-r--r--   0 runner    (1001) docker     (121)    40402 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/wcs/geom.py
--rw-r--r--   0 runner    (1001) docker     (121)      294 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/wcs/io.py
--rw-r--r--   0 runner    (1001) docker     (121)    30397 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/wcs/ndmap.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.350033 gammapy-1.0rc2/gammapy/maps/wcs/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/wcs/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    20449 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/wcs/tests/test_geom.py
--rw-r--r--   0 runner    (1001) docker     (121)    30561 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/maps/wcs/tests/test_ndmap.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.354033 gammapy-1.0rc2/gammapy/modeling/
--rw-r--r--   0 runner    (1001) docker     (121)      270 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     6037 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/covariance.py
--rw-r--r--   0 runner    (1001) docker     (121)    21714 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/fit.py
--rw-r--r--   0 runner    (1001) docker     (121)     6560 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/iminuit.py
--rw-r--r--   0 runner    (1001) docker     (121)     1455 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/likelihood.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.354033 gammapy-1.0rc2/gammapy/modeling/models/
--rw-r--r--   0 runner    (1001) docker     (121)     5467 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    33926 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/models/core.py
--rw-r--r--   0 runner    (1001) docker     (121)    32844 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/models/cube.py
--rw-r--r--   0 runner    (1001) docker     (121)    38600 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/models/spatial.py
--rw-r--r--   0 runner    (1001) docker     (121)    74337 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/models/spectral.py
--rw-r--r--   0 runner    (1001) docker     (121)     3215 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/models/spectral_cosmic_ray.py
--rw-r--r--   0 runner    (1001) docker     (121)     4243 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/models/spectral_crab.py
--rw-r--r--   0 runner    (1001) docker     (121)    30941 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/models/temporal.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.354033 gammapy-1.0rc2/gammapy/modeling/models/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/models/tests/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.358033 gammapy-1.0rc2/gammapy/modeling/models/tests/data/
--rw-r--r--   0 runner    (1001) docker     (121)     1499 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/models/tests/data/example2.yaml
--rw-r--r--   0 runner    (1001) docker     (121)     3413 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/models/tests/data/examples.yaml
--rw-r--r--   0 runner    (1001) docker     (121)     3245 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/models/tests/data/make.py
--rw-r--r--   0 runner    (1001) docker     (121)     6503 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/models/tests/test_core.py
--rw-r--r--   0 runner    (1001) docker     (121)    23517 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/models/tests/test_cube.py
--rw-r--r--   0 runner    (1001) docker     (121)    13762 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/models/tests/test_io.py
--rw-r--r--   0 runner    (1001) docker     (121)    12641 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/models/tests/test_management.py
--rw-r--r--   0 runner    (1001) docker     (121)    15858 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/models/tests/test_spatial.py
--rw-r--r--   0 runner    (1001) docker     (121)    40132 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/models/tests/test_spectral.py
--rw-r--r--   0 runner    (1001) docker     (121)     1256 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/models/tests/test_spectral_cosmic_ray.py
--rw-r--r--   0 runner    (1001) docker     (121)     2046 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/models/tests/test_spectral_crab.py
--rw-r--r--   0 runner    (1001) docker     (121)    12365 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/models/tests/test_temporal.py
--rw-r--r--   0 runner    (1001) docker     (121)    21807 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/parameter.py
--rw-r--r--   0 runner    (1001) docker     (121)     5118 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/scipy.py
--rw-r--r--   0 runner    (1001) docker     (121)     2091 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/sherpa.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.358033 gammapy-1.0rc2/gammapy/modeling/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     1902 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/tests/test_covariance.py
--rw-r--r--   0 runner    (1001) docker     (121)    10213 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/tests/test_fit.py
--rw-r--r--   0 runner    (1001) docker     (121)     4046 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/tests/test_iminuit.py
--rw-r--r--   0 runner    (1001) docker     (121)     6960 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/tests/test_parameter.py
--rw-r--r--   0 runner    (1001) docker     (121)     3061 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/tests/test_scipy.py
--rw-r--r--   0 runner    (1001) docker     (121)     2264 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/modeling/tests/test_sherpa.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.358033 gammapy-1.0rc2/gammapy/scripts/
--rw-r--r--   0 runner    (1001) docker     (121)      112 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/scripts/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     1482 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/scripts/analysis.py
--rw-r--r--   0 runner    (1001) docker     (121)      739 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/scripts/check.py
--rw-r--r--   0 runner    (1001) docker     (121)     5150 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/scripts/download.py
--rw-r--r--   0 runner    (1001) docker     (121)     2977 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/scripts/info.py
--rw-r--r--   0 runner    (1001) docker     (121)     3447 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/scripts/main.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.358033 gammapy-1.0rc2/gammapy/scripts/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/scripts/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)      838 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/scripts/tests/test_analysis.py
--rw-r--r--   0 runner    (1001) docker     (121)     1827 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/scripts/tests/test_download.py
--rw-r--r--   0 runner    (1001) docker     (121)      550 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/scripts/tests/test_info.py
--rw-r--r--   0 runner    (1001) docker     (121)      642 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/scripts/tests/test_main.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.362033 gammapy-1.0rc2/gammapy/stats/
--rw-r--r--   0 runner    (1001) docker     (121)      582 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/stats/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    10799 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/stats/counts_statistic.py
--rw-r--r--   0 runner    (1001) docker     (121)     7422 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/stats/fit_statistics.py
--rw-r--r--   0 runner    (1001) docker     (121)     3492 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/stats/fit_statistics_cython.pyx
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.362033 gammapy-1.0rc2/gammapy/stats/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/stats/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     7148 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/stats/tests/test_counts_statistic.py
--rw-r--r--   0 runner    (1001) docker     (121)     4678 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/stats/tests/test_fit_statistics.py
--rw-r--r--   0 runner    (1001) docker     (121)     1526 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/stats/tests/test_variability.py
--rw-r--r--   0 runner    (1001) docker     (121)     2213 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/stats/variability.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.362033 gammapy-1.0rc2/gammapy/tests/
--rw-r--r--   0 runner    (1001) docker     (121)      222 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/tests/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.366033 gammapy-1.0rc2/gammapy/utils/
--rw-r--r--   0 runner    (1001) docker     (121)      315 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     4073 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/array.py
--rw-r--r--   0 runner    (1001) docker     (121)      805 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/check.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.366033 gammapy-1.0rc2/gammapy/utils/coordinates/
--rw-r--r--   0 runner    (1001) docker     (121)      424 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/coordinates/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     2122 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/coordinates/fov.py
--rw-r--r--   0 runner    (1001) docker     (121)     2891 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/coordinates/other.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.366033 gammapy-1.0rc2/gammapy/utils/coordinates/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/coordinates/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     2553 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/coordinates/tests/test_fov.py
--rw-r--r--   0 runner    (1001) docker     (121)      371 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/coordinates/tests/test_other.py
--rw-r--r--   0 runner    (1001) docker     (121)     6476 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/docs.py
--rw-r--r--   0 runner    (1001) docker     (121)     4930 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/fits.py
--rw-r--r--   0 runner    (1001) docker     (121)     9221 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/gauss.py
--rw-r--r--   0 runner    (1001) docker     (121)     1367 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/integrate.py
--rw-r--r--   0 runner    (1001) docker     (121)     7470 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/interpolation.py
--rw-r--r--   0 runner    (1001) docker     (121)     1060 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/pbar.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.366033 gammapy-1.0rc2/gammapy/utils/random/
--rw-r--r--   0 runner    (1001) docker     (121)      453 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/random/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     2649 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/random/inverse_cdf.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.366033 gammapy-1.0rc2/gammapy/utils/random/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/random/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     1745 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/random/tests/test_inverse_cdf.py
--rw-r--r--   0 runner    (1001) docker     (121)     5654 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/random/tests/test_random.py
--rw-r--r--   0 runner    (1001) docker     (121)     8774 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/random/utils.py
--rw-r--r--   0 runner    (1001) docker     (121)     6700 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/regions.py
--rw-r--r--   0 runner    (1001) docker     (121)      684 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/registry.py
--rw-r--r--   0 runner    (1001) docker     (121)     4577 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/roots.py
--rw-r--r--   0 runner    (1001) docker     (121)     3647 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/scripts.py
--rw-r--r--   0 runner    (1001) docker     (121)     2844 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/table.py
--rw-r--r--   0 runner    (1001) docker     (121)     6684 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/testing.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.370033 gammapy-1.0rc2/gammapy/utils/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)      555 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/tests/test_array.py
--rw-r--r--   0 runner    (1001) docker     (121)     1508 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/tests/test_fits.py
--rw-r--r--   0 runner    (1001) docker     (121)     3045 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/tests/test_gauss.py
--rw-r--r--   0 runner    (1001) docker     (121)      525 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/tests/test_integrate.py
--rw-r--r--   0 runner    (1001) docker     (121)      530 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/tests/test_interpolation.py
--rw-r--r--   0 runner    (1001) docker     (121)     2650 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/tests/test_regions.py
--rw-r--r--   0 runner    (1001) docker     (121)     1439 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/tests/test_roots.py
--rw-r--r--   0 runner    (1001) docker     (121)      577 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/tests/test_scripts.py
--rw-r--r--   0 runner    (1001) docker     (121)     1331 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/tests/test_table.py
--rw-r--r--   0 runner    (1001) docker     (121)     1483 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/tests/test_time.py
--rw-r--r--   0 runner    (1001) docker     (121)     1282 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/tests/test_units.py
--rw-r--r--   0 runner    (1001) docker     (121)     2469 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/time.py
--rw-r--r--   0 runner    (1001) docker     (121)     2595 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/utils/units.py
--rw-r--r--   0 runner    (1001) docker     (121)      338 2022-11-06 22:04:42.000000 gammapy-1.0rc2/gammapy/version.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.370033 gammapy-1.0rc2/gammapy/visualization/
--rw-r--r--   0 runner    (1001) docker     (121)      479 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/visualization/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     4574 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/visualization/cmap.py
--rw-r--r--   0 runner    (1001) docker     (121)     4398 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/visualization/heatmap.py
--rw-r--r--   0 runner    (1001) docker     (121)     3536 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/visualization/panel.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.370033 gammapy-1.0rc2/gammapy/visualization/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/visualization/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     1327 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/visualization/tests/test_cmap.py
--rw-r--r--   0 runner    (1001) docker     (121)      553 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/visualization/tests/test_panel.py
--rw-r--r--   0 runner    (1001) docker     (121)     2294 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/visualization/tests/test_utils.py
--rw-r--r--   0 runner    (1001) docker     (121)     7241 2022-11-06 22:04:17.000000 gammapy-1.0rc2/gammapy/visualization/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-11-06 22:04:43.314032 gammapy-1.0rc2/gammapy.egg-info/
--rw-r--r--   0 runner    (1001) docker     (121)     1342 2022-11-06 22:04:43.000000 gammapy-1.0rc2/gammapy.egg-info/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (121)    22651 2022-11-06 22:04:43.000000 gammapy-1.0rc2/gammapy.egg-info/SOURCES.txt
--rw-r--r--   0 runner    (1001) docker     (121)        1 2022-11-06 22:04:43.000000 gammapy-1.0rc2/gammapy.egg-info/dependency_links.txt
--rw-r--r--   0 runner    (1001) docker     (121)       53 2022-11-06 22:04:43.000000 gammapy-1.0rc2/gammapy.egg-info/entry_points.txt
--rw-r--r--   0 runner    (1001) docker     (121)        1 2022-11-06 22:04:43.000000 gammapy-1.0rc2/gammapy.egg-info/not-zip-safe
--rw-r--r--   0 runner    (1001) docker     (121)      401 2022-11-06 22:04:43.000000 gammapy-1.0rc2/gammapy.egg-info/requires.txt
--rw-r--r--   0 runner    (1001) docker     (121)        8 2022-11-06 22:04:43.000000 gammapy-1.0rc2/gammapy.egg-info/top_level.txt
--rw-r--r--   0 runner    (1001) docker     (121)      340 2022-11-06 22:04:17.000000 gammapy-1.0rc2/lgtm.yml
--rw-r--r--   0 runner    (1001) docker     (121)      436 2022-11-06 22:04:17.000000 gammapy-1.0rc2/pyproject.toml
--rw-r--r--   0 runner    (1001) docker     (121)     3454 2022-11-06 22:04:43.374033 gammapy-1.0rc2/setup.cfg
--rwxr-xr-x   0 runner    (1001) docker     (121)     2040 2022-11-06 22:04:17.000000 gammapy-1.0rc2/setup.py
--rw-r--r--   0 runner    (1001) docker     (121)     3232 2022-11-06 22:04:17.000000 gammapy-1.0rc2/tox.ini
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.624921 gammapy-1.1rc1/
+-rw-r--r--   0 runner    (1001) docker     (123)       60 2023-06-02 16:41:53.000000 gammapy-1.1rc1/.codacy.yml
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.532920 gammapy-1.1rc1/.github/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.532920 gammapy-1.1rc1/.github/ISSUE_TEMPLATE/
+-rw-r--r--   0 runner    (1001) docker     (123)     1339 2023-06-02 16:41:53.000000 gammapy-1.1rc1/.github/ISSUE_TEMPLATE/bug_report.md
+-rw-r--r--   0 runner    (1001) docker     (123)      615 2023-06-02 16:41:53.000000 gammapy-1.1rc1/.github/ISSUE_TEMPLATE/feature_request.md
+-rw-r--r--   0 runner    (1001) docker     (123)     1027 2023-06-02 16:41:53.000000 gammapy-1.1rc1/.github/PULL_REQUEST_TEMPLATE.md
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.532920 gammapy-1.1rc1/.github/workflows/
+-rw-r--r--   0 runner    (1001) docker     (123)     1225 2023-06-02 16:41:53.000000 gammapy-1.1rc1/.github/workflows/cffconvert.yml
+-rw-r--r--   0 runner    (1001) docker     (123)     5088 2023-06-02 16:41:53.000000 gammapy-1.1rc1/.github/workflows/ci.yml
+-rw-r--r--   0 runner    (1001) docker     (123)      358 2023-06-02 16:41:53.000000 gammapy-1.1rc1/.github/workflows/dispatch.yml
+-rw-r--r--   0 runner    (1001) docker     (123)      562 2023-06-02 16:41:53.000000 gammapy-1.1rc1/.github/workflows/dispatch_benchmark.yml
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-02 16:41:53.000000 gammapy-1.1rc1/.github/workflows/greetings.yml
+-rw-r--r--   0 runner    (1001) docker     (123)     2051 2023-06-02 16:41:53.000000 gammapy-1.1rc1/.github/workflows/release.yml
+-rw-r--r--   0 runner    (1001) docker     (123)     1448 2023-06-02 16:41:53.000000 gammapy-1.1rc1/.gitignore
+-rw-r--r--   0 runner    (1001) docker     (123)     9465 2023-06-02 16:41:53.000000 gammapy-1.1rc1/.mailmap
+-rw-r--r--   0 runner    (1001) docker     (123)      650 2023-06-02 16:41:53.000000 gammapy-1.1rc1/.pre-commit-config.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)     1814 2023-06-02 16:41:53.000000 gammapy-1.1rc1/CITATION
+-rw-r--r--   0 runner    (1001) docker     (123)     4224 2023-06-02 16:41:53.000000 gammapy-1.1rc1/CITATION.cff
+-rw-r--r--   0 runner    (1001) docker     (123)      123 2023-06-02 16:41:53.000000 gammapy-1.1rc1/CODE_OF_CONDUCT.md
+-rw-r--r--   0 runner    (1001) docker     (123)     4167 2023-06-02 16:41:53.000000 gammapy-1.1rc1/CONTRIBUTING.md
+-rw-r--r--   0 runner    (1001) docker     (123)     1491 2023-06-02 16:41:53.000000 gammapy-1.1rc1/LICENSE.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      390 2023-06-02 16:41:53.000000 gammapy-1.1rc1/LONG_DESCRIPTION.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      252 2023-06-02 16:41:53.000000 gammapy-1.1rc1/MANIFEST.in
+-rw-r--r--   0 runner    (1001) docker     (123)     4688 2023-06-02 16:41:53.000000 gammapy-1.1rc1/Makefile
+-rw-r--r--   0 runner    (1001) docker     (123)     1362 2023-06-02 16:42:15.624921 gammapy-1.1rc1/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)     6533 2023-06-02 16:41:53.000000 gammapy-1.1rc1/README.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     7674 2023-06-02 16:41:53.000000 gammapy-1.1rc1/codemeta.json
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.536920 gammapy-1.1rc1/dev/
+-rw-r--r--   0 runner    (1001) docker     (123)      167 2023-06-02 16:41:53.000000 gammapy-1.1rc1/dev/README.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     2790 2023-06-02 16:41:53.000000 gammapy-1.1rc1/dev/authors.py
+-rw-r--r--   0 runner    (1001) docker     (123)      648 2023-06-02 16:41:53.000000 gammapy-1.1rc1/dev/codemeta.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.536920 gammapy-1.1rc1/dev/codespell/
+-rw-r--r--   0 runner    (1001) docker     (123)       40 2023-06-02 16:41:53.000000 gammapy-1.1rc1/dev/codespell/exclude-file.txt
+-rw-r--r--   0 runner    (1001) docker     (123)       56 2023-06-02 16:41:53.000000 gammapy-1.1rc1/dev/codespell/ignore-words.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     7576 2023-06-02 16:41:53.000000 gammapy-1.1rc1/dev/github_summary.py
+-rw-r--r--   0 runner    (1001) docker     (123)      794 2023-06-02 16:41:53.000000 gammapy-1.1rc1/dev/prepare-release.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.536920 gammapy-1.1rc1/docs/
+-rw-r--r--   0 runner    (1001) docker     (123)     4581 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/Makefile
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.540920 gammapy-1.1rc1/docs/_static/
+-rw-r--r--   0 runner    (1001) docker     (123)   173823 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/1d-analysis-image.png
+-rw-r--r--   0 runner    (1001) docker     (123)   251116 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/2d-analysis-image.png
+-rw-r--r--   0 runner    (1001) docker     (123)   285342 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/3d-analysis-image.png
+-rw-r--r--   0 runner    (1001) docker     (123)   185375 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/DC1_3d.png
+-rw-r--r--   0 runner    (1001) docker     (123)    25253 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/atom.png
+-rw-r--r--   0 runner    (1001) docker     (123)    12024 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/box.png
+-rw-r--r--   0 runner    (1001) docker     (123)   268580 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/data-flow-gammapy.png
+-rw-r--r--   0 runner    (1001) docker     (123)    11218 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/galleryicon.png
+-rw-r--r--   0 runner    (1001) docker     (123)     5911 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/gammapy.css
+-rw-r--r--   0 runner    (1001) docker     (123)    78429 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/gammapy_banner.png
+-rw-r--r--   0 runner    (1001) docker     (123)     3527 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/gammapy_logo.ico
+-rw-r--r--   0 runner    (1001) docker     (123)    27023 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/gammapy_logo.png
+-rw-r--r--   0 runner    (1001) docker     (123)    21439 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/gammapy_logo_nav.png
+-rw-r--r--   0 runner    (1001) docker     (123)   255027 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/gammapy_maps.png
+-rw-r--r--   0 runner    (1001) docker     (123)    19482 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/gears.png
+-rw-r--r--   0 runner    (1001) docker     (123)    24809 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/glossaryicon.png
+-rw-r--r--   0 runner    (1001) docker     (123)   286752 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/hgps_map_background_estimation.png
+-rw-r--r--   0 runner    (1001) docker     (123)   274950 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/hgps_spectrum_background_estimation.png
+-rw-r--r--   0 runner    (1001) docker     (123)     3519 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/index_api.svg
+-rw-r--r--   0 runner    (1001) docker     (123)     2528 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/index_contribute.svg
+-rw-r--r--   0 runner    (1001) docker     (123)     3977 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/index_getting_started.svg
+-rw-r--r--   0 runner    (1001) docker     (123)     6429 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/index_user_guide.svg
+-rw-r--r--   0 runner    (1001) docker     (123)    19367 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/install.png
+-rw-r--r--   0 runner    (1001) docker     (123)    19104 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/upgrade.png
+-rw-r--r--   0 runner    (1001) docker     (123)     9257 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_static/using.png
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.520919 gammapy-1.1rc1/docs/_templates/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.540920 gammapy-1.1rc1/docs/_templates/autosummary/
+-rw-r--r--   0 runner    (1001) docker     (123)      250 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_templates/autosummary/base.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      251 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_templates/autosummary/class.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      252 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/_templates/autosummary/module.rst
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.544920 gammapy-1.1rc1/docs/api-reference/
+-rw-r--r--   0 runner    (1001) docker     (123)      241 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/api-reference/analysis.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      400 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/api-reference/astro.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      220 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/api-reference/catalog.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      232 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/api-reference/data.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      229 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/api-reference/datasets.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      385 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/api-reference/estimators.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      411 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/api-reference/index.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      238 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/api-reference/irf.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      269 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/api-reference/makers.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      181 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/api-reference/maps.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      363 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/api-reference/modeling.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      209 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/api-reference/scripts.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      193 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/api-reference/stats.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     1171 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/api-reference/utils.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      294 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/api-reference/visualization.rst
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.544920 gammapy-1.1rc1/docs/binder/
+-rw-r--r--   0 runner    (1001) docker     (123)      126 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/binder/requirements.txt
+-rw-r--r--   0 runner    (1001) docker     (123)       10 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/binder/runtime.txt
+-rw-r--r--   0 runner    (1001) docker     (123)    12160 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/conf.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.544920 gammapy-1.1rc1/docs/development/
+-rw-r--r--   0 runner    (1001) docker     (123)     2280 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/dependencies.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    33975 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/dev_howto.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    10793 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/doc_howto.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      865 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/index.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    13344 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/intro.rst
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.548920 gammapy-1.1rc1/docs/development/pigs/
+-rw-r--r--   0 runner    (1001) docker     (123)      860 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/index.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    10348 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-001.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     9973 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-002.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     7229 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-003.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     8538 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-004.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     8470 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-005.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    93165 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-006-class-diagram.png
+-rw-r--r--   0 runner    (1001) docker     (123)    11244 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-006.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    18677 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-007.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    19998 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-008.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    12942 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-009.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    26320 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-010.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    11310 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-011.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    17401 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-012.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    12911 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-013.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     9474 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-014.rst
+-rw-r--r--   0 runner    (1001) docker     (123)   118034 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-016-gammapy-package-organisation-proposal.png
+-rw-r--r--   0 runner    (1001) docker     (123)   120184 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-016-gammapy-package-organisation-status.png
+-rw-r--r--   0 runner    (1001) docker     (123)    10097 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-016.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    16069 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-018.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     7874 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-019.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     5987 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-020.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    11481 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-021.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    15219 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-022.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     5954 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-023.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    18073 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/pigs/pig-024.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     6879 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/release.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    10102 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/development/setup.rst
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.548920 gammapy-1.1rc1/docs/getting-started/
+-rw-r--r--   0 runner    (1001) docker     (123)     2457 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/getting-started/environments.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     6383 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/getting-started/index.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     4312 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/getting-started/install.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     2642 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/getting-started/quickstart.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     1684 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/getting-started/troubleshooting.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     4538 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/getting-started/usage.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     2936 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/index.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     4549 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/make.bat
+-rw-r--r--   0 runner    (1001) docker     (123)      439 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/nitpick-exceptions
+-rw-r--r--   0 runner    (1001) docker     (123)     7677 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/references.txt
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.552920 gammapy-1.1rc1/docs/release-notes/
+-rw-r--r--   0 runner    (1001) docker     (123)     1836 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/index.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     2967 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v0.1.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     3216 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v0.10.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     5907 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v0.11.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     4787 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v0.12.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     5088 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v0.13.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     5401 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v0.14.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     9750 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v0.15.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     5661 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v0.16.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     8210 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v0.17.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      695 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v0.18.1.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      730 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v0.18.2.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    10000 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v0.18.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    15018 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v0.19.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     2060 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v0.2.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     2433 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v0.20.1.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     6692 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v0.20.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     2418 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v0.3.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     4583 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v0.4.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     5428 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v0.5.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     7359 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v0.6.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    11532 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v0.7.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    11529 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v0.8.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     5258 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v0.9.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     1988 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v1.0.1.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     7198 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v1.0.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    11889 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/release-notes/v1.1.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      852 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/serve.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.556920 gammapy-1.1rc1/docs/user-guide/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.556920 gammapy-1.1rc1/docs/user-guide/astro/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.556920 gammapy-1.1rc1/docs/user-guide/astro/darkmatter/
+-rw-r--r--   0 runner    (1001) docker     (123)     5802 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/astro/darkmatter/index.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      984 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/astro/index.rst
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.556920 gammapy-1.1rc1/docs/user-guide/astro/population/
+-rw-r--r--   0 runner    (1001) docker     (123)     2037 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/astro/population/index.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      799 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/astro/population/plot_radial_distributions.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1594 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/astro/population/plot_spiral_arm_models.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2278 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/astro/population/plot_spiral_arms.py
+-rw-r--r--   0 runner    (1001) docker     (123)      926 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/astro/population/plot_velocity_distributions.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.556920 gammapy-1.1rc1/docs/user-guide/astro/source/
+-rw-r--r--   0 runner    (1001) docker     (123)      492 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/astro/source/index.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      426 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/astro/source/plot_pulsar_spindown.py
+-rw-r--r--   0 runner    (1001) docker     (123)      724 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/astro/source/plot_pwn_evolution.py
+-rw-r--r--   0 runner    (1001) docker     (123)      774 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/astro/source/plot_snr_brightness_evolution.py
+-rw-r--r--   0 runner    (1001) docker     (123)      752 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/astro/source/plot_snr_radius_evolution.py
+-rw-r--r--   0 runner    (1001) docker     (123)      194 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/astro/source/pulsar.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      213 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/astro/source/pwn.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      367 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/astro/source/snr.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     1617 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/catalog.rst
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.556920 gammapy-1.1rc1/docs/user-guide/datasets/
+-rw-r--r--   0 runner    (1001) docker     (123)     9876 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/datasets/index.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     2482 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/datasets/plot_stack.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5987 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/dl3.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     8536 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/estimators.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      779 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/hli.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    12882 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/howto.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     1744 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/index.rst
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.560920 gammapy-1.1rc1/docs/user-guide/irf/
+-rw-r--r--   0 runner    (1001) docker     (123)      758 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/irf/aeff.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     1257 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/irf/bkg.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     3540 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/irf/edisp.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     5198 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/irf/index.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      299 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/irf/plot_aeff.py
+-rw-r--r--   0 runner    (1001) docker     (123)      432 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/irf/plot_aeff_param.py
+-rw-r--r--   0 runner    (1001) docker     (123)      282 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/irf/plot_bkg_3d.py
+-rw-r--r--   0 runner    (1001) docker     (123)      301 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/irf/plot_edisp.py
+-rw-r--r--   0 runner    (1001) docker     (123)      469 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/irf/plot_edisp_kernel.py
+-rw-r--r--   0 runner    (1001) docker     (123)      497 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/irf/plot_edisp_kernel_param.py
+-rw-r--r--   0 runner    (1001) docker     (123)      478 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/irf/plot_fermi_psf.py
+-rw-r--r--   0 runner    (1001) docker     (123)      254 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/irf/plot_psf.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1367 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/irf/psf.rst
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.560920 gammapy-1.1rc1/docs/user-guide/makers/
+-rw-r--r--   0 runner    (1001) docker     (123)     1225 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/makers/create_region.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2384 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/makers/fov.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      869 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/makers/index.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     1735 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/makers/make_rectangular_reflected_background.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2258 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/makers/make_reflected_regions.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4611 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/makers/reflected.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     2891 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/makers/ring.rst
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.560920 gammapy-1.1rc1/docs/user-guide/maps/
+-rw-r--r--   0 runner    (1001) docker     (123)     1947 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/maps/hpxmap.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    11201 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/maps/index.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    19094 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/maps/regionmap.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     2343 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/modeling.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     3813 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/package.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     9560 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/references.rst
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.560920 gammapy-1.1rc1/docs/user-guide/scripts/
+-rw-r--r--   0 runner    (1001) docker     (123)    12703 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/scripts/index.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      953 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/scripts/significance.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.560920 gammapy-1.1rc1/docs/user-guide/stats/
+-rw-r--r--   0 runner    (1001) docker     (123)     5858 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/stats/fit_statistics.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    11561 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/stats/index.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     1741 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/stats/plot_cash_errors.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1350 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/stats/plot_cash_significance.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1740 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/stats/plot_wstat_errors.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1349 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/stats/plot_wstat_significance.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6544 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/stats/wstat_derivation.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     3703 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/utils.rst
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.560920 gammapy-1.1rc1/docs/user-guide/visualization/
+-rw-r--r--   0 runner    (1001) docker     (123)     1077 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/visualization/colormap_example.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1358 2023-06-02 16:41:53.000000 gammapy-1.1rc1/docs/user-guide/visualization/index.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     1289 2023-06-02 16:41:53.000000 gammapy-1.1rc1/environment-dev.yml
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.560920 gammapy-1.1rc1/examples/
+-rw-r--r--   0 runner    (1001) docker     (123)      666 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/README.rst
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.560920 gammapy-1.1rc1/examples/models/
+-rw-r--r--   0 runner    (1001) docker     (123)      613 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/README.txt
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.564920 gammapy-1.1rc1/examples/models/spatial/
+-rw-r--r--   0 runner    (1001) docker     (123)       59 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spatial/README.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      792 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spatial/plot_constant.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3606 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spatial/plot_disk.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3337 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spatial/plot_gauss.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2772 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spatial/plot_gen_gauss.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1045 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spatial/plot_piecewise_norm_spatial.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1270 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spatial/plot_point.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1519 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spatial/plot_shell.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2332 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spatial/plot_shell2.py
+-rw-r--r--   0 runner    (1001) docker     (123)      928 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spatial/plot_template.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.564920 gammapy-1.1rc1/examples/models/spectral/
+-rw-r--r--   0 runner    (1001) docker     (123)       62 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spectral/README.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     3218 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spectral/plot_absorbed.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1147 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spectral/plot_broken_powerlaw.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1063 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spectral/plot_compound.py
+-rw-r--r--   0 runner    (1001) docker     (123)      742 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spectral/plot_constant_spectral.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1037 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spectral/plot_exp_cutoff_powerlaw.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1115 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spectral/plot_exp_cutoff_powerlaw_3fgl.py
+-rw-r--r--   0 runner    (1001) docker     (123)      911 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spectral/plot_gauss_spectral.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1533 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spectral/plot_logparabola.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2629 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spectral/plot_naima.py
+-rw-r--r--   0 runner    (1001) docker     (123)      953 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spectral/plot_piecewise_norm_spectral.py
+-rw-r--r--   0 runner    (1001) docker     (123)      878 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spectral/plot_powerlaw.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1084 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spectral/plot_powerlaw2.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1099 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spectral/plot_smooth_broken_powerlaw.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1306 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spectral/plot_super_exp_cutoff_powerlaw_3fgl.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1613 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spectral/plot_super_exp_cutoff_powerlaw_4fgl.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1333 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spectral/plot_super_exp_cutoff_powerlaw_4fgl_dr1.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1584 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/spectral/plot_template_spectral.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.568920 gammapy-1.1rc1/examples/models/temporal/
+-rw-r--r--   0 runner    (1001) docker     (123)       62 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/temporal/README.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      874 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/temporal/plot_constant_temporal.py
+-rw-r--r--   0 runner    (1001) docker     (123)      970 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/temporal/plot_expdecay_temporal.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1022 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/temporal/plot_gaussian_temporal.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1457 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/temporal/plot_generalized_gaussian_temporal.py
+-rw-r--r--   0 runner    (1001) docker     (123)      955 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/temporal/plot_linear_temporal.py
+-rw-r--r--   0 runner    (1001) docker     (123)      966 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/temporal/plot_powerlaw_temporal.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1016 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/temporal/plot_sine_temporal.py
+-rw-r--r--   0 runner    (1001) docker     (123)      953 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/temporal/plot_template_phase_temporal.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1364 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/models/temporal/plot_template_temporal.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.568920 gammapy-1.1rc1/examples/tutorials/
+-rw-r--r--   0 runner    (1001) docker     (123)      904 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/README.rst
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.568920 gammapy-1.1rc1/examples/tutorials/analysis-1d/
+-rw-r--r--   0 runner    (1001) docker     (123)      310 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-1d/README.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     7694 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-1d/cta_sensitivity.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10514 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-1d/extended_source_spectral_analysis.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7647 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-1d/sed_fitting.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16573 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-1d/spectral_analysis.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13740 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-1d/spectral_analysis_hli.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13447 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-1d/spectral_analysis_rad_max.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8185 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-1d/spectrum_simulation.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.568920 gammapy-1.1rc1/examples/tutorials/analysis-2d/
+-rw-r--r--   0 runner    (1001) docker     (123)       17 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-2d/README.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     7927 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-2d/detect.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5745 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-2d/modeling_2D.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9125 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-2d/ring_background.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.568920 gammapy-1.1rc1/examples/tutorials/analysis-3d/
+-rw-r--r--   0 runner    (1001) docker     (123)       15 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-3d/README.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    14714 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-3d/analysis_3d.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8572 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-3d/analysis_mwl.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11379 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-3d/cta_data_analysis.py
+-rw-r--r--   0 runner    (1001) docker     (123)    18184 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-3d/event_sampling.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12460 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-3d/event_sampling_nrg_depend_models.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8818 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-3d/flux_profiles.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6907 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-3d/simulate_3d.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.568920 gammapy-1.1rc1/examples/tutorials/analysis-time/
+-rw-r--r--   0 runner    (1001) docker     (123)        9 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-time/README.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    11897 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-time/light_curve.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9388 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-time/light_curve_flare.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11242 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-time/light_curve_simulation.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14457 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/analysis-time/pulsar_analysis.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.572920 gammapy-1.1rc1/examples/tutorials/api/
+-rw-r--r--   0 runner    (1001) docker     (123)      155 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/api/README.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     5851 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/api/astro_dark_matter.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12926 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/api/catalog.py
+-rw-r--r--   0 runner    (1001) docker     (123)    18018 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/api/datasets.py
+-rw-r--r--   0 runner    (1001) docker     (123)    19019 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/api/fitting.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13415 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/api/makers.py
+-rw-r--r--   0 runner    (1001) docker     (123)    30606 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/api/maps.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15719 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/api/mask_maps.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15229 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/api/model_management.py
+-rw-r--r--   0 runner    (1001) docker     (123)    26915 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/api/models.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.572920 gammapy-1.1rc1/examples/tutorials/data/
+-rw-r--r--   0 runner    (1001) docker     (123)      367 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/data/README.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    14359 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/data/cta.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14598 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/data/fermi_lat.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9755 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/data/hawc.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7005 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/data/hess.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.572920 gammapy-1.1rc1/examples/tutorials/scripts/
+-rw-r--r--   0 runner    (1001) docker     (123)      320 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/scripts/README.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      726 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/scripts/survey_map.py
+-rw-r--r--   0 runner    (1001) docker     (123)      256 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/scripts/survey_map.rst
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.572920 gammapy-1.1rc1/examples/tutorials/starting/
+-rw-r--r--   0 runner    (1001) docker     (123)      644 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/starting/README.rst
+-rw-r--r--   0 runner    (1001) docker     (123)    13667 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/starting/analysis_1.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12713 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/starting/analysis_2.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14945 2023-06-02 16:41:53.000000 gammapy-1.1rc1/examples/tutorials/starting/overview.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.572920 gammapy-1.1rc1/gammapy/
+-rw-r--r--   0 runner    (1001) docker     (123)     2227 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      358 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/__main__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      356 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/_astropy_init.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2720 2023-06-02 16:42:15.000000 gammapy-1.1rc1/gammapy/_compiler.c
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.576920 gammapy-1.1rc1/gammapy/analysis/
+-rw-r--r--   0 runner    (1001) docker     (123)      226 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/analysis/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.576920 gammapy-1.1rc1/gammapy/analysis/config/
+-rw-r--r--   0 runner    (1001) docker     (123)     2277 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/analysis/config/docs.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)      512 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/analysis/config/example-1d.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)     1064 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/analysis/config/example-3d.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)      563 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/analysis/config/model-1d.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)     1011 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/analysis/config/model.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)     9054 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/analysis/config.py
+-rw-r--r--   0 runner    (1001) docker     (123)    22511 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/analysis/core.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.576920 gammapy-1.1rc1/gammapy/analysis/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/analysis/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15229 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/analysis/tests/test_analysis.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5046 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/analysis/tests/test_config.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.576920 gammapy-1.1rc1/gammapy/astro/
+-rw-r--r--   0 runner    (1001) docker     (123)      114 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.576920 gammapy-1.1rc1/gammapy/astro/darkmatter/
+-rw-r--r--   0 runner    (1001) docker     (123)      302 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/darkmatter/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8253 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/darkmatter/profiles.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7409 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/darkmatter/spectra.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.576920 gammapy-1.1rc1/gammapy/astro/darkmatter/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/darkmatter/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      579 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/darkmatter/tests/test_profiles.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1941 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/darkmatter/tests/test_spectra.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1115 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/darkmatter/tests/test_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2256 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/darkmatter/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.576920 gammapy-1.1rc1/gammapy/astro/population/
+-rw-r--r--   0 runner    (1001) docker     (123)     1386 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/population/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14942 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/population/simulate.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16181 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/population/spatial.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.576920 gammapy-1.1rc1/gammapy/astro/population/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/population/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7119 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/population/tests/test_simulate.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1458 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/population/tests/test_spatial.py
+-rw-r--r--   0 runner    (1001) docker     (123)      849 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/population/tests/test_velocity.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3732 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/population/velocity.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.580920 gammapy-1.1rc1/gammapy/astro/source/
+-rw-r--r--   0 runner    (1001) docker     (123)      295 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/source/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5189 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/source/pulsar.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3916 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/source/pwn.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10627 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/source/snr.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.580920 gammapy-1.1rc1/gammapy/astro/source/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/source/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3383 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/source/tests/test_pulsar.py
+-rw-r--r--   0 runner    (1001) docker     (123)      675 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/source/tests/test_pwn.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1345 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/astro/source/tests/test_snr.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.580920 gammapy-1.1rc1/gammapy/catalog/
+-rw-r--r--   0 runner    (1001) docker     (123)     1688 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8676 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/core.py
+-rw-r--r--   0 runner    (1001) docker     (123)    49484 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/fermi.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13985 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/gammacat.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10522 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/hawc.py
+-rw-r--r--   0 runner    (1001) docker     (123)    38312 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/hess.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.580920 gammapy-1.1rc1/gammapy/catalog/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.584921 gammapy-1.1rc1/gammapy/catalog/tests/data/
+-rw-r--r--   0 runner    (1001) docker     (123)     1402 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/data/2fhl_j0822.6-4250e.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     1202 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/data/2fhl_j1445.1-0329.txt
+-rw-r--r--   0 runner    (1001) docker     (123)      370 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/data/2hwc_j0534+220.txt
+-rw-r--r--   0 runner    (1001) docker     (123)      458 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/data/2hwc_j0631+169.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     2537 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/data/3fgl_J0000.1+6545.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     2877 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/data/3fgl_J0001.4+2120.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     2618 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/data/3fgl_J0023.4+0923.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     2685 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/data/3fgl_J0835.3-4510.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     2552 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/data/3fhl_j2301.9+5855e.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     2872 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/data/4fgl_J0000.3-7355.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     3264 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/data/4fgl_J0001.5+2113.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     3081 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/data/4fgl_J0002.8+6217.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     3273 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/data/4fgl_J1409.1-6121e.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     2425 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/data/gammacat_hess_j1813-178.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     2299 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/data/gammacat_hess_j1848-018.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     2993 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/data/gammacat_vela_x.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     6496 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/data/hess_j1713-397.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     5272 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/data/hess_j1825-137.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     4634 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/data/hess_j1930+188.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     1664 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/data/make.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2941 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/test_core.py
+-rw-r--r--   0 runner    (1001) docker     (123)    23714 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/test_fermi.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6271 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/test_gammacat.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6704 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/test_hawc.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12470 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/catalog/tests/test_hess.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3423 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/conftest.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.584921 gammapy-1.1rc1/gammapy/data/
+-rw-r--r--   0 runner    (1001) docker     (123)      740 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/data/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    26341 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/data/data_store.py
+-rw-r--r--   0 runner    (1001) docker     (123)    34519 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/data/event_list.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3199 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/data/filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14182 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/data/gti.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6274 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/data/hdu_index_table.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14105 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/data/obs_table.py
+-rw-r--r--   0 runner    (1001) docker     (123)    27545 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/data/observations.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4099 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/data/observers.py
+-rw-r--r--   0 runner    (1001) docker     (123)    25104 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/data/pointing.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.588920 gammapy-1.1rc1/gammapy/data/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/data/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11422 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/data/tests/test_data_store.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9503 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/data/tests/test_event_list.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2592 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/data/tests/test_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6300 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/data/tests/test_gti.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4472 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/data/tests/test_hdu_index_table.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12481 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/data/tests/test_obs_table.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15916 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/data/tests/test_observations.py
+-rw-r--r--   0 runner    (1001) docker     (123)      494 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/data/tests/test_observers.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13580 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/data/tests/test_pointing.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4124 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/data/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.588920 gammapy-1.1rc1/gammapy/datasets/
+-rw-r--r--   0 runner    (1001) docker     (123)      869 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/datasets/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16920 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/datasets/core.py
+-rw-r--r--   0 runner    (1001) docker     (123)    19385 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/datasets/evaluator.py
+-rw-r--r--   0 runner    (1001) docker     (123)    17024 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/datasets/flux_points.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12055 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/datasets/io.py
+-rw-r--r--   0 runner    (1001) docker     (123)    95061 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/datasets/map.py
+-rw-r--r--   0 runner    (1001) docker     (123)    18283 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/datasets/simulate.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14646 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/datasets/spectrum.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.588920 gammapy-1.1rc1/gammapy/datasets/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/datasets/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2630 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/datasets/tests/test_datasets.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8109 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/datasets/tests/test_evaluator.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6864 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/datasets/tests/test_flux_points.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3646 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/datasets/tests/test_io.py
+-rw-r--r--   0 runner    (1001) docker     (123)    65336 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/datasets/tests/test_map.py
+-rw-r--r--   0 runner    (1001) docker     (123)    24782 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/datasets/tests/test_simulate.py
+-rw-r--r--   0 runner    (1001) docker     (123)    41695 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/datasets/tests/test_spectrum.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1109 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/datasets/tests/test_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2218 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/datasets/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.588920 gammapy-1.1rc1/gammapy/estimators/
+-rw-r--r--   0 runner    (1001) docker     (123)     1056 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2732 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/core.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6449 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/flux.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.592921 gammapy-1.1rc1/gammapy/estimators/map/
+-rw-r--r--   0 runner    (1001) docker     (123)      244 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/map/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9315 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/map/asmooth.py
+-rw-r--r--   0 runner    (1001) docker     (123)    33806 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/map/core.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11679 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/map/excess.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.592921 gammapy-1.1rc1/gammapy/estimators/map/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/map/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3877 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/map/tests/test_asmooth.py
+-rw-r--r--   0 runner    (1001) docker     (123)    17276 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/map/tests/test_core.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12671 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/map/tests/test_excess.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13105 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/map/tests/test_ts.py
+-rw-r--r--   0 runner    (1001) docker     (123)    26374 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/map/ts.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9985 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/parameter.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.592921 gammapy-1.1rc1/gammapy/estimators/points/
+-rw-r--r--   0 runner    (1001) docker     (123)      341 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/points/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    24520 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/points/core.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7086 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/points/lightcurve.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5144 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/points/profile.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7792 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/points/sed.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6415 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/points/sensitivity.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.592921 gammapy-1.1rc1/gammapy/estimators/points/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/points/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10494 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/points/tests/test_core.py
+-rw-r--r--   0 runner    (1001) docker     (123)    25458 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/points/tests/test_lightcurve.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6355 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/points/tests/test_profile.py
+-rw-r--r--   0 runner    (1001) docker     (123)    19691 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/points/tests/test_sed.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3824 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/points/tests/test_sensitivity.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13402 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/profile.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.592921 gammapy-1.1rc1/gammapy/estimators/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      197 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/tests/test_core.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7809 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/tests/test_flux.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3472 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/tests/test_parameter_estimator.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4726 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/tests/test_profile.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2943 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/tests/test_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7487 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/estimators/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.592921 gammapy-1.1rc1/gammapy/extern/
+-rw-r--r--   0 runner    (1001) docker     (123)      429 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/extern/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12232 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/extern/xmltodict.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.596921 gammapy-1.1rc1/gammapy/irf/
+-rw-r--r--   0 runner    (1001) docker     (123)     1327 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13654 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/background.py
+-rw-r--r--   0 runner    (1001) docker     (123)    30257 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/core.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.596921 gammapy-1.1rc1/gammapy/irf/edisp/
+-rw-r--r--   0 runner    (1001) docker     (123)      209 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/edisp/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8935 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/edisp/core.py
+-rw-r--r--   0 runner    (1001) docker     (123)    19744 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/edisp/kernel.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16959 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/edisp/map.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.596921 gammapy-1.1rc1/gammapy/irf/edisp/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/edisp/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4465 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/edisp/tests/test_core.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3760 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/edisp/tests/test_kernel.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10938 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/edisp/tests/test_map.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8038 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/effective_area.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9026 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/io.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.596921 gammapy-1.1rc1/gammapy/irf/psf/
+-rw-r--r--   0 runner    (1001) docker     (123)      317 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/psf/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8663 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/psf/core.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8472 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/psf/kernel.py
+-rw-r--r--   0 runner    (1001) docker     (123)    21923 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/psf/map.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12422 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/psf/parametric.py
+-rw-r--r--   0 runner    (1001) docker     (123)      736 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/psf/table.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.596921 gammapy-1.1rc1/gammapy/irf/psf/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/psf/tests/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.596921 gammapy-1.1rc1/gammapy/irf/psf/tests/data/
+-rw-r--r--   0 runner    (1001) docker     (123)      566 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/psf/tests/data/psf_info.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     2776 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/psf/tests/test_kernel.py
+-rw-r--r--   0 runner    (1001) docker     (123)    19915 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/psf/tests/test_map.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5934 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/psf/tests/test_parametric.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3080 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/psf/tests/test_table.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3683 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/rad_max.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.600921 gammapy-1.1rc1/gammapy/irf/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12661 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/tests/test_background.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2349 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/tests/test_core.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5052 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/tests/test_effective_area.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4026 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/tests/test_gadf.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11425 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/tests/test_io.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3148 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/irf/tests/test_rad_max.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.600921 gammapy-1.1rc1/gammapy/makers/
+-rw-r--r--   0 runner    (1001) docker     (123)     1183 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/makers/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.600921 gammapy-1.1rc1/gammapy/makers/background/
+-rw-r--r--   0 runner    (1001) docker     (123)      527 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/makers/background/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9017 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/makers/background/fov.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4769 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/makers/background/phase.py
+-rw-r--r--   0 runner    (1001) docker     (123)    20584 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/makers/background/reflected.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11103 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/makers/background/ring.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.600921 gammapy-1.1rc1/gammapy/makers/background/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/makers/background/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12450 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/makers/background/tests/test_fov.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5536 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/makers/background/tests/test_phase.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15438 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/makers/background/tests/test_reflected.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4955 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/makers/background/tests/test_ring.py
+-rw-r--r--   0 runner    (1001) docker     (123)      762 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/makers/core.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13231 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/makers/map.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6162 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/makers/reduce.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12010 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/makers/safe.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3157 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/makers/spectrum.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.600921 gammapy-1.1rc1/gammapy/makers/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/makers/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      113 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/makers/tests/test_core.py
+-rw-r--r--   0 runner    (1001) docker     (123)    18595 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/makers/tests/test_map.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13491 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/makers/tests/test_reduce.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10198 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/makers/tests/test_safe.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12743 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/makers/tests/test_spectrum.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16905 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/makers/tests/test_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)    18340 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/makers/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.604921 gammapy-1.1rc1/gammapy/maps/
+-rw-r--r--   0 runner    (1001) docker     (123)      630 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    97953 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/axes.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9845 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/coord.py
+-rw-r--r--   0 runner    (1001) docker     (123)    67721 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/core.py
+-rw-r--r--   0 runner    (1001) docker     (123)    17905 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/geom.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.604921 gammapy-1.1rc1/gammapy/maps/hpx/
+-rw-r--r--   0 runner    (1001) docker     (123)      139 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/hpx/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10417 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/hpx/core.py
+-rw-r--r--   0 runner    (1001) docker     (123)    46682 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/hpx/geom.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3444 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/hpx/io.py
+-rw-r--r--   0 runner    (1001) docker     (123)    38805 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/hpx/ndmap.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.604921 gammapy-1.1rc1/gammapy/maps/hpx/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/hpx/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    27107 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/hpx/tests/test_geom.py
+-rw-r--r--   0 runner    (1001) docker     (123)    20992 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/hpx/tests/test_ndmap.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13353 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/hpx/utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2244 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/io.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5174 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/maps.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.604921 gammapy-1.1rc1/gammapy/maps/region/
+-rw-r--r--   0 runner    (1001) docker     (123)      112 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/region/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    27023 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/region/geom.py
+-rw-r--r--   0 runner    (1001) docker     (123)    25789 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/region/ndmap.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.604921 gammapy-1.1rc1/gammapy/maps/region/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/region/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13351 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/region/tests/test_geom.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14588 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/region/tests/test_ndmap.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.604921 gammapy-1.1rc1/gammapy/maps/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    27867 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/tests/test_axes.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5131 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/tests/test_coord.py
+-rw-r--r--   0 runner    (1001) docker     (123)    28097 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/tests/test_core.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2316 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/tests/test_counts.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2567 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/tests/test_maps.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2606 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.608921 gammapy-1.1rc1/gammapy/maps/wcs/
+-rw-r--r--   0 runner    (1001) docker     (123)      139 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/wcs/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10152 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/wcs/core.py
+-rw-r--r--   0 runner    (1001) docker     (123)    40709 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/wcs/geom.py
+-rw-r--r--   0 runner    (1001) docker     (123)      294 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/wcs/io.py
+-rw-r--r--   0 runner    (1001) docker     (123)    35017 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/wcs/ndmap.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.608921 gammapy-1.1rc1/gammapy/maps/wcs/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/wcs/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    20756 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/wcs/tests/test_geom.py
+-rw-r--r--   0 runner    (1001) docker     (123)    32374 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/maps/wcs/tests/test_ndmap.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.608921 gammapy-1.1rc1/gammapy/modeling/
+-rw-r--r--   0 runner    (1001) docker     (123)      270 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5992 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/covariance.py
+-rw-r--r--   0 runner    (1001) docker     (123)    22542 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/fit.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6709 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/iminuit.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1455 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/likelihood.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.608921 gammapy-1.1rc1/gammapy/modeling/models/
+-rw-r--r--   0 runner    (1001) docker     (123)     5566 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    34686 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/models/core.py
+-rw-r--r--   0 runner    (1001) docker     (123)    35945 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/models/cube.py
+-rw-r--r--   0 runner    (1001) docker     (123)    45413 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/models/spatial.py
+-rw-r--r--   0 runner    (1001) docker     (123)    77123 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/models/spectral.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3215 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/models/spectral_cosmic_ray.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4243 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/models/spectral_crab.py
+-rw-r--r--   0 runner    (1001) docker     (123)    36611 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/models/temporal.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.612921 gammapy-1.1rc1/gammapy/modeling/models/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/models/tests/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.612921 gammapy-1.1rc1/gammapy/modeling/models/tests/data/
+-rw-r--r--   0 runner    (1001) docker     (123)     1499 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/models/tests/data/example2.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)     3475 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/models/tests/data/examples.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)     3245 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/models/tests/data/make.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6503 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/models/tests/test_core.py
+-rw-r--r--   0 runner    (1001) docker     (123)    27693 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/models/tests/test_cube.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16990 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/models/tests/test_io.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12641 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/models/tests/test_management.py
+-rw-r--r--   0 runner    (1001) docker     (123)    19464 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/models/tests/test_spatial.py
+-rw-r--r--   0 runner    (1001) docker     (123)    41814 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/models/tests/test_spectral.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1256 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/models/tests/test_spectral_cosmic_ray.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2046 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/models/tests/test_spectral_crab.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15489 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/models/tests/test_temporal.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1017 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/models/tests/test_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1888 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/models/utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)    21943 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/parameter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5118 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/scipy.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6217 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/selection.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2091 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/sherpa.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.612921 gammapy-1.1rc1/gammapy/modeling/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1902 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/tests/test_covariance.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10248 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/tests/test_fit.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4051 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/tests/test_iminuit.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6986 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/tests/test_parameter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3066 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/tests/test_scipy.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1631 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/tests/test_selection.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2269 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/modeling/tests/test_sherpa.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.612921 gammapy-1.1rc1/gammapy/scripts/
+-rw-r--r--   0 runner    (1001) docker     (123)      112 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/scripts/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1482 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/scripts/analysis.py
+-rw-r--r--   0 runner    (1001) docker     (123)      739 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/scripts/check.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5150 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/scripts/download.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2988 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/scripts/info.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3447 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/scripts/main.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.612921 gammapy-1.1rc1/gammapy/scripts/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/scripts/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      838 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/scripts/tests/test_analysis.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1827 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/scripts/tests/test_download.py
+-rw-r--r--   0 runner    (1001) docker     (123)      550 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/scripts/tests/test_info.py
+-rw-r--r--   0 runner    (1001) docker     (123)      642 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/scripts/tests/test_main.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.616921 gammapy-1.1rc1/gammapy/stats/
+-rw-r--r--   0 runner    (1001) docker     (123)      607 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/stats/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13266 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/stats/counts_statistic.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7422 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/stats/fit_statistics.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3492 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/stats/fit_statistics_cython.pyx
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.616921 gammapy-1.1rc1/gammapy/stats/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/stats/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8230 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/stats/tests/test_counts_statistic.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4678 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/stats/tests/test_fit_statistics.py
+-rw-r--r--   0 runner    (1001) docker     (123)      549 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/stats/tests/test_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1526 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/stats/tests/test_variability.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1395 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/stats/utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2213 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/stats/variability.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.616921 gammapy-1.1rc1/gammapy/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)      222 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/tests/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.616921 gammapy-1.1rc1/gammapy/utils/
+-rw-r--r--   0 runner    (1001) docker     (123)      315 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4073 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/array.py
+-rw-r--r--   0 runner    (1001) docker     (123)      809 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/check.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2290 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/cluster.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.616921 gammapy-1.1rc1/gammapy/utils/coordinates/
+-rw-r--r--   0 runner    (1001) docker     (123)      424 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/coordinates/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2122 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/coordinates/fov.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2891 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/coordinates/other.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.620921 gammapy-1.1rc1/gammapy/utils/coordinates/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/coordinates/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2553 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/coordinates/tests/test_fov.py
+-rw-r--r--   0 runner    (1001) docker     (123)      371 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/coordinates/tests/test_other.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1553 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/deprecation.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6476 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/docs.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5141 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/fits.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9221 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/gauss.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1367 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/integrate.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7470 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/interpolation.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6116 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/parallel.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1037 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/pbar.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.620921 gammapy-1.1rc1/gammapy/utils/random/
+-rw-r--r--   0 runner    (1001) docker     (123)      453 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/random/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2649 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/random/inverse_cdf.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.620921 gammapy-1.1rc1/gammapy/utils/random/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/random/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1745 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/random/tests/test_inverse_cdf.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5654 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/random/tests/test_random.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8774 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/random/utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7753 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/regions.py
+-rw-r--r--   0 runner    (1001) docker     (123)      684 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/registry.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4577 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/roots.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3647 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/scripts.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2936 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/table.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7218 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/testing.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.620921 gammapy-1.1rc1/gammapy/utils/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      555 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/tests/test_array.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2048 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/tests/test_deprecation.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1508 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/tests/test_fits.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3052 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/tests/test_gauss.py
+-rw-r--r--   0 runner    (1001) docker     (123)      525 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/tests/test_integrate.py
+-rw-r--r--   0 runner    (1001) docker     (123)      530 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/tests/test_interpolation.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2616 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/tests/test_parallel.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3491 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/tests/test_regions.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1439 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/tests/test_roots.py
+-rw-r--r--   0 runner    (1001) docker     (123)      577 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/tests/test_scripts.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1451 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/tests/test_table.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1955 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/tests/test_time.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1282 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/tests/test_units.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5693 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/time.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2595 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/utils/units.py
+-rw-r--r--   0 runner    (1001) docker     (123)      338 2023-06-02 16:42:15.000000 gammapy-1.1rc1/gammapy/version.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.624921 gammapy-1.1rc1/gammapy/visualization/
+-rw-r--r--   0 runner    (1001) docker     (123)      561 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/visualization/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4574 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/visualization/cmap.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5951 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/visualization/datasets.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4398 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/visualization/heatmap.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3539 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/visualization/panel.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.624921 gammapy-1.1rc1/gammapy/visualization/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/visualization/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1327 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/visualization/tests/test_cmap.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2697 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/visualization/tests/test_datasets.py
+-rw-r--r--   0 runner    (1001) docker     (123)      553 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/visualization/tests/test_panel.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1878 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/visualization/tests/test_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5233 2023-06-02 16:41:53.000000 gammapy-1.1rc1/gammapy/visualization/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-02 16:42:15.576920 gammapy-1.1rc1/gammapy.egg-info/
+-rw-r--r--   0 runner    (1001) docker     (123)     1362 2023-06-02 16:42:15.000000 gammapy-1.1rc1/gammapy.egg-info/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)    23442 2023-06-02 16:42:15.000000 gammapy-1.1rc1/gammapy.egg-info/SOURCES.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        1 2023-06-02 16:42:15.000000 gammapy-1.1rc1/gammapy.egg-info/dependency_links.txt
+-rw-r--r--   0 runner    (1001) docker     (123)       53 2023-06-02 16:42:15.000000 gammapy-1.1rc1/gammapy.egg-info/entry_points.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        1 2023-06-02 16:42:15.000000 gammapy-1.1rc1/gammapy.egg-info/not-zip-safe
+-rw-r--r--   0 runner    (1001) docker     (123)      530 2023-06-02 16:42:15.000000 gammapy-1.1rc1/gammapy.egg-info/requires.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        8 2023-06-02 16:42:15.000000 gammapy-1.1rc1/gammapy.egg-info/top_level.txt
+-rw-r--r--   0 runner    (1001) docker     (123)      340 2023-06-02 16:41:53.000000 gammapy-1.1rc1/lgtm.yml
+-rw-r--r--   0 runner    (1001) docker     (123)      662 2023-06-02 16:41:53.000000 gammapy-1.1rc1/pyproject.toml
+-rw-r--r--   0 runner    (1001) docker     (123)     3615 2023-06-02 16:42:15.624921 gammapy-1.1rc1/setup.cfg
+-rwxr-xr-x   0 runner    (1001) docker     (123)     2040 2023-06-02 16:41:53.000000 gammapy-1.1rc1/setup.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3359 2023-06-02 16:41:53.000000 gammapy-1.1rc1/tox.ini
```

### Comparing `gammapy-1.0rc2/.github/ISSUE_TEMPLATE/bug_report.md` & `gammapy-1.1rc1/.github/ISSUE_TEMPLATE/bug_report.md`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/.github/ISSUE_TEMPLATE/feature_request.md` & `gammapy-1.1rc1/.github/ISSUE_TEMPLATE/feature_request.md`

 * *Files 20% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 ---
 name: Feature request
 about: Suggest an idea to make Gammapy better!
 title: ''
-labels: feature
+labels: feature-request
 assignees: ''
 
 ---
 
 **Is your feature request related to a problem? Please describe.**
 A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]
```

### Comparing `gammapy-1.0rc2/.github/PULL_REQUEST_TEMPLATE.md` & `gammapy-1.1rc1/.github/PULL_REQUEST_TEMPLATE.md`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/.github/workflows/cffconvert.yml` & `gammapy-1.1rc1/.github/workflows/cffconvert.yml`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/.github/workflows/ci.yml` & `gammapy-1.1rc1/.github/workflows/ci.yml`

 * *Files 18% similar despite different names*

```diff
@@ -1,72 +1,75 @@
 name: CI
-on:
-  push:
-    branches:
-    - v1.0.x
-  pull_request:
-    branches:
-    - v1.0.x
+on: [push, pull_request]
 
 jobs:
   lint:
     name: Black check
     runs-on: ubuntu-latest
     steps:
-      - uses: actions/checkout@v2
+      - uses: actions/checkout@v3
       - uses: psf/black@stable
+        with:
+          version: "22.6.0"
   ci-runs:
     name: ${{ matrix.os }}, ${{ matrix.tox_env }}
     runs-on: ${{ matrix.os }}
+    continue-on-error: ${{ matrix.allowed_fail }}
     env:
       PYTEST_ADDOPTS: --color=yes -n auto --dist=loadscope
     strategy:
       fail-fast: true
       matrix:
         include:
           - os: ubuntu-latest
-            python: '3.8'
-            tox_env: 'py38-test-alldeps'
-          - os: ubuntu-latest
             python: '3.9'
-            tox_env: 'py39-test-alldeps-cov'
+            tox_env: 'py39-test-alldeps'
+            allowed_fail: false
+          - os: ubuntu-latest
+            python: '3.10'
+            tox_env: 'py310-test-alldeps-cov'
             gammapy_data_path: /home/runner/work/gammapy/gammapy/gammapy-datasets/dev
+            allowed_fail: false
           - os: macos-latest
-            python: '3.9'
-            tox_env: 'py39-test'
+            python: '3.10'
+            tox_env: 'py310-test'
             gammapy_data_path: /Users/runner/work/gammapy/gammapy/gammapy-datasets/dev
+            allowed_fail: false
           - os: windows-latest
-            python: '3.9'
-            tox_env: 'py39-test-alldeps'
-            gammapy_data_path:  D:\a\gammapy\gammapy\gammapy-datasets\dev
-          - os: ubuntu-latest
             python: '3.10'
             tox_env: 'py310-test-alldeps'
+            gammapy_data_path:  D:\a\gammapy\gammapy\gammapy-datasets\dev
+            allowed_fail: false
           - os: ubuntu-latest
-            python: '3.9'
-            tox_env: 'py39-test'
+            python: '3.10'
+            tox_env: 'py310-test'
+            allowed_fail: false
           - os: ubuntu-latest
-            python: '3.9'
+            python: '3.10'
             tox_env: 'codestyle'
+            allowed_fail: false
           - os: ubuntu-latest
-            python: '3.8'
-            tox_env: 'py38-test-alldeps-astropylts-numpy120'
+            python: '3.9'
+            tox_env: 'py39-test-alldeps-astropylts-numpy121'
+            allowed_fail: false
           - os: ubuntu-latest
-            python: '3.8'
+            python: '3.9'
             tox_env: 'oldestdeps'
+            allowed_fail: false
           - os: ubuntu-latest
-            python: '3.8'
+            python: '3.9'
             tox_env: 'devdeps'
+            allowed_fail: true
     steps:
       - name: Check out repository
         uses: actions/checkout@v3
         with:
           fetch-depth: 0
       - name: Set up Python ${{ matrix.python }}
-        uses: actions/setup-python@v3
+        uses: actions/setup-python@v4
         with:
           python-version: ${{ matrix.python }}
       - name: Install base dependencies
         run: |
           python -m pip install --upgrade pip
           python -m pip install tox
       - name: download datasets
@@ -92,29 +95,29 @@
       - name: Upload coverage to codecov
         if: "contains(matrix.tox_env, '-cov')"
         uses: codecov/codecov-action@v3
         with:
           file: ./coverage.xml
           verbose: true
   sphinx:
-    name: Linux python 3.8 sphinx all-deps
+    name: Linux python 3.9 sphinx all-deps
     runs-on: ubuntu-latest
     defaults:
       run:
         shell: bash -l {0}
     env:
       PYTEST_ADDOPTS: --color=yes -n auto --dist=loadscope
       GAMMAPY_DATA: /home/runner/work/gammapy/gammapy/gammapy-datasets/dev
     steps:
       - name: Check out repository
         uses: actions/checkout@v3
         with:
           fetch-depth: 0
       - name: Set up Python ${{ matrix.python }}
-        uses: actions/setup-python@v3
+        uses: actions/setup-python@v4
         with:
           python-version: ${{ matrix.python }}
       - name: Install base dependencies
         run: |
           python -m pip install --upgrade pip
           python -m pip install tox
       - name: download datasets
@@ -126,22 +129,22 @@
         run: |
           tox -e build_docs -- -j auto
       - name: check links
         continue-on-error: true
         run: |
           tox -e linkcheck -- -j auto  
   conda-build:
-    name: Linux python 3.8 conda-build all-deps
+    name: Linux python 3.9 conda-build all-deps
     runs-on: ubuntu-latest
     defaults:
       run:
         shell: bash -l {0}
     steps:
       - name: checkout repo
-        uses: actions/checkout@v2
+        uses: actions/checkout@v3
       - name: create and activate env
         uses: mamba-org/provision-with-micromamba@main
         with:
           environment-file: environment-dev.yml
       - name: install gammapy
         run: |
           pip install -e .
```

### Comparing `gammapy-1.0rc2/.github/workflows/release.yml` & `gammapy-1.1rc1/.github/workflows/release.yml`

 * *Files 19% similar despite different names*

```diff
@@ -3,14 +3,15 @@
 on:
   push:
     tags-ignore:
       - 'v*.dev'
 
 jobs:
   release-pypi:
+    if: github.repository_owner == 'gammapy'
     runs-on: ubuntu-latest
     steps:
       - name: Checkout
         uses: actions/checkout@v2
       - name: Update tags
         run: git fetch --tags --force
       - name: Set up Python
@@ -23,38 +24,43 @@
           pip install -U build
           python -m build --sdist
       - name: Publish package
         uses: pypa/gh-action-pypi-publish@release/v1
         with:
           user: __token__
           password: ${{ secrets.PYPI_TOKEN }}
+
   release-github:
+    if: github.repository_owner == 'gammapy' && !contains(github.ref_name, 'rc')
     needs: release-pypi
     runs-on: ubuntu-latest
-    if:  ${{ !contains(github.ref_name, 'rc') }}
     steps:
       - name: Checkout
         uses: actions/checkout@v2
       - name: Release
         uses: softprops/action-gh-release@v1
         with:
           body: |
             Gammapy is a Python package for gamma-ray astronomy. See [changelog for this release](https://github.com/gammapy/gammapy/blob/main/docs/release-notes/${{ github.ref_name }}.rst).
+
   dispatch-docs:
+    if: github.repository_owner == 'gammapy'
     needs: release-pypi
     runs-on: ubuntu-latest
     steps:
       - name: Dispatch Gammapy Docs
         uses: peter-evans/repository-dispatch@v2
         with:
           token: ${{ secrets.REMOTE_DISPATCH }}
           repository: gammapy/gammapy-docs
           event-type: release
           client-payload: '{"release": "${{ github.ref_name }}"}'
+
   dispatch-webpage:
+    if: github.repository_owner == 'gammapy'
     needs: release-github
     runs-on: ubuntu-latest
     steps:
       - name: Dispatch Gammapy Webpage
         uses: peter-evans/repository-dispatch@v2
         with:
           token: ${{ secrets.REMOTE_DISPATCH }}
```

### Comparing `gammapy-1.0rc2/.gitignore` & `gammapy-1.1rc1/.gitignore`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/.mailmap` & `gammapy-1.1rc1/.mailmap`

 * *Files 4% similar despite different names*

```diff
@@ -2,20 +2,22 @@
 
 Alexis de Almeida Coutinho <alexis.almeida98@usp.br> Alexis de Almeida Coutinho <alexis.almeida98@yahoo.com.br>
 
 Anne Lemière <alemiere@apc.in2p3.fr> Anne Lemière <alemiere@apcdhcp62.in2p3.fr>
 Anne Lemière <alemiere@apc.in2p3.fr> Anne Lemière <alemiere@eduroam-prg-bw-1-26-17.net.univ-paris-diderot.fr>
 Anne Lemière <alemiere@apc.in2p3.fr> Anne Lemière <alemiere@MacBook-Pro-de-Anne.local>
 
-Andrew W. Chen <andrew.w.chen@gmail.com> mealworm <andrew.w.chen@gmail.com>
+Andrew Chen <andrew.w.chen@gmail.com> mealworm <andrew.w.chen@gmail.com>
 
-Arnau Aguasca Cabot <arnauaguasca@gmail.com> aaguasca <arnauaguasca@gmail.com>
+Arnau Aguasca-Cabot <arnauaguasca@gmail.com> aaguasca <arnauaguasca@gmail.com>
 
 Arjun Voruganti <arjun.voruganti@gmail.com> vorugantia <arjun.voruganti@gmail.com>
 
+Mathieu de Bony de Lavergne <lavergne@lapp.in2p3.fr> Mathieu de Bony <lavergne@lapp.in2p3.fr>
+
 Atreyee Sinha <asinha@ucm.es> Atreyee SINHA <asinha@sinfos-MacBook-Pro.local>
 Atreyee Sinha <asinha@ucm.es> AtreyeeS <asinha@sinfos-MacBook-Pro.local>
 Atreyee Sinha <asinha@ucm.es> Atreyee Sinha <32677370+AtreyeeS@users.noreply.github.com>
 Atreyee Sinha <asinha@ucm.es> Atreyee Sinha <atreyee.sinha@apc.in2p3.fr>
 Atreyee Sinha <asinha@ucm.es> Atreyee Sinha <atreyee.sinha@gmail.com>
 Atreyee Sinha <asinha@ucm.es> AtreyeeS <atreyee.sinha@gmail.com>
 Atreyee Sinha <asinha@ucm.es> AtreyeeS <asinha@sinfos-mbp.home>
@@ -27,32 +29,33 @@
 Axel Donath <axel.donath@cfa.harvard.edu> Axel Donath <adonath@users.noreply.github.com>
 Axel Donath <axel.donath@cfa.harvard.edu> Axel Donath <donath@stud.uni-heidelberg.de>
 Axel Donath <axel.donath@cfa.harvard.edu> Axel Donath <axel.donath@mpi-hd.mpg.de>
 Axel Donath <axel.donath@cfa.harvard.edu> adonath <adonath@users.noreply.github.com>
 Axel Donath <axel.donath@cfa.harvard.edu> adonath <axel.donath@mpi-hd.mpg.de>
 Axel Donath <axel.donath@cfa.harvard.edu> adonath <donath@stud.uni-heidelberg.de>
 Axel Donath <axel.donath@cfa.harvard.edu> Axel Donath <axel.donath@mpi-hd.mpg.de>
+Axel Donath <axel.donath@cfa.harvard.edu> axel <axel.donath@mpi-hd.mpg.de>
 
-Brigitta Sipőcz <bsipocz@gmail.com> Brigitta Sipocz <b.sipocz@gmail.com>
-Brigitta Sipőcz <bsipocz@gmail.com> Brigitta Sipocz <bsipocz@gmail.com>
+Brigitta M Sipőcz <bsipocz@gmail.com> Brigitta Sipocz <b.sipocz@gmail.com>
+Brigitta M Sipőcz <bsipocz@gmail.com> Brigitta Sipocz <bsipocz@gmail.com>
 
 Bruno Khélifi <khelifi@in2p3.fr> Bruno Khelifi <khelifi@in2p3.fr>
 Bruno Khélifi <khelifi@in2p3.fr> Bruno Khelifi <khelifi@khelifi@apc.in2p3.fr>
 Bruno Khélifi <khelifi@in2p3.fr> khelifi <khelifi@in2p3.fr>
 Bruno Khélifi <khelifi@in2p3.fr> Bruno KHÉLIFI <khelifi@in2p3.fr>
 Bruno Khélifi <khelifi@in2p3.fr> Bruno KHÉLIFI <khelifi@apc.in2p3.fr>
 
 Cosimo Nigro <cosimo.nigro@ifae.es> cosimoNigro <cosimonigro2@gmail.com>
 Cosimo Nigro <cosimo.nigro@ifae.es> cnigro <cosimo.nigro@ifae.es>
 
 José Enrique Ruiz <jer@iaa.es> Bultako <jer@iaa.es>
 José Enrique Ruiz <jer@iaa.es> Jose Enrique Ruiz <jer@iaa.es>
 
-David Fidalgo <dfidalgo@gae.ucm.es> David Fidalgo <davidc.fidalgo@gmail.com>
-David Fidalgo <dfidalgo@gae.ucm.es> dcfidalgo <dfidalgo@gae.ucm.es>
+David Carreto Fidalgo <dfidalgo@gae.ucm.es> David Fidalgo <davidc.fidalgo@gmail.com>
+David Carreto Fidalgo <dfidalgo@gae.ucm.es> dcfidalgo <dfidalgo@gae.ucm.es>
 
 Debanjan Bose <debaice@hotmail.com> debaice <debaice@hotmail.com>
 
 Dirk Lennarz <dirk.lennarz@pa.msu.edu> Dirk Lennarz <dev-intel14-phi.i>
 Dirk Lennarz <dirk.lennarz@pa.msu.edu> Dirk Lennarz <dirk.lennarz@gatech.edu>
 Dirk Lennarz <dirk.lennarz@pa.msu.edu> Dirk Lennarz <dirk.lennarz@pa.msu.edu>
 Dirk Lennarz <dirk.lennarz@pa.msu.edu> Dirk Lennarz <dirk.lennarz@web.de>
@@ -84,33 +87,37 @@
 
 Johannes King <johannes.king@mpi-hd.mpg.de> Johannes King <johannes.king@sqlnet.ai>
 Johannes King <johannes.king@mpi-hd.mpg.de> kingj90 <johannes.king@mpi-hd.mpg.de>
 Johannes King <johannes.king@mpi-hd.mpg.de> kingj90 <kingj90@users.noreply.github.com>
 
 Jonathan D. Harris <jonharris24@gmail.com> JonathanDHarris <jonharris24@gmail.com>
 
-José Luis Contreras <jlcontreras@fis.ucm.es> contrera <jlcontreras@fis.ucm.es>
+José Luis Contreras Gonzalez <jlcontreras@fis.ucm.es> contrera <jlcontreras@fis.ucm.es>
 
 Julien Lefaucheur <julien.lefaucheur@obspm.fr> hijlk <julien.lefaucheur@obspm.fr>
 Julien Lefaucheur <julien.lefaucheur@obspm.fr> Julien Lefaucheur <jjlk@users.noreply.github.com>
 Julien Lefaucheur <julien.lefaucheur@obspm.fr> hijlk <julien.lefaucheur@obspm.fr>
 Julien Lefaucheur <julien.lefaucheur@obspm.fr> jlk <julien.lefaucheur@obspm.fr>
 
+Maximilian Linhoff <maximilian.noethe@tu-dortmund.de> Maximilian Nöthe <maximilian.noethe@tu-dortmund.de>
+
 Kai Brügge <kai.bruegge@tu-dortmund.de> Kai B <kai.bruegge@tu-dortmund.de>
 Kai Brügge <kai.bruegge@tu-dortmund.de> Kai Bruegge <kai.bruegge@tu-dortmund.de>
 
 Lars Mohrmann <lars.mohrmann@mpi-hd.mpg.de> Lars <lars.mohrmann@fau.de>
 Lars Mohrmann <lars.mohrmann@mpi-hd.mpg.de> Lars Mohrmann <lars.mohrmann@fau.de>
 
 Larry Bradley <larry.bradley@gmail.com> larrybradley <larry.bradley@gmail.com>
 
 Laura Olivera-Nieto <laura.olivera-nieto@mpi-hd.mpg.de> lauraolivera <laura.olivera-nieto@mpi-hd.mpg.de>
 Laura Olivera-Nieto <laura.olivera-nieto@mpi-hd.mpg.de> LauraOlivera <lauraoliverant@gmail.com>
 Laura Olivera-Nieto <laura.olivera-nieto@mpi-hd.mpg.de> Laura Olivera <lauraoliverant@gmail.com>
 
+Dimitri Papadopoulos Orfanos <3234522+DimitriPapadopoulos@users.noreply.github.com> Dimitri Papadopoulos <3234522+DimitriPapadopoulos@users.noreply.github.com>
+
 Léa Jouvin <lea.jouvin@apc.in2p3.fr> Lea Jouvin <lea.jouvin@gmail.com>
 Léa Jouvin <lea.jouvin@apc.in2p3.fr> Jouvin <lea.jouvin@apc.in2p3.fr>
 Léa Jouvin <lea.jouvin@apc.in2p3.fr> JouvinLea <lea.jouvin@apc.in2p3.fr>
 
 Luca Giunti <giunti@apc.in2p3.fr> luca-giunti <giunti@apc.in2p3.fr>
 Luca Giunti <giunti@apc.in2p3.fr> luca-giunti <47325742+luca-giunti@users.noreply.github.com>
 
@@ -154,8 +161,8 @@
 
 Ellis Owen <ellis.owen@mpi-hd.mpg.de> eowen <ellis.owen@mpi-hd.mpg.de>
 Ellis Owen <ellis.owen@mpi-hd.mpg.de> ellisowen <ellis.owen@mpi-hd.mpg.de>
 
 Roberta Zanin <roberta.zanin@cta-observatory.org> robertazanin <Roberta.Zanin@mpi-hd.mpg.de>
 Roberta Zanin <roberta.zanin@cta-observatory.org> robertazanin <robertazanin@gmail.com>
 
-Zé Vinicius <jvmirca@gmail.com> Ze Vinicius <jvmirca@gmail.com>
+José Vinícius de Miranda Cardoso <jvmirca@gmail.com> Ze Vinicius <jvmirca@gmail.com>
```

### Comparing `gammapy-1.0rc2/.pre-commit-config.yaml` & `gammapy-1.1rc1/.pre-commit-config.yaml`

 * *Files 20% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 repos:
   # https://pycqa.github.io/isort/docs/configuration/black_compatibility.html#integration-with-pre-commit
   - repo: https://github.com/pycqa/isort
-    rev: 5.6.4
+    rev: 5.12.0
     hooks:
       - id: isort
         args: ["--profile", "black", "--filter-files"]
   - repo: https://github.com/psf/black
     rev: 22.6.0
     hooks:
       - id: black
```

### Comparing `gammapy-1.0rc2/CITATION` & `gammapy-1.1rc1/CITATION`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/LICENSE.rst` & `gammapy-1.1rc1/LICENSE.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/Makefile` & `gammapy-1.1rc1/Makefile`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/PKG-INFO` & `gammapy-1.1rc1/PKG-INFO`

 * *Files 6% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: gammapy
-Version: 1.0rc2
+Version: 1.1rc1
 Summary: A Python package for gamma-ray astronomy
 Home-page: https://gammapy.org
 Author: The Gammapy developers
 Author-email: gammapy-coordination-l@in2p3.fr
 License: BSD 3-Clause
 Platform: any
 Classifier: Intended Audience :: Science/Research
@@ -14,17 +14,18 @@
 Classifier: Programming Language :: Cython
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: Implementation :: CPython
 Classifier: Topic :: Scientific/Engineering :: Astronomy
-Requires-Python: >=3.8
+Requires-Python: >=3.9
 Description-Content-Type: text/x-rst
 Provides-Extra: all
+Provides-Extra: cov
 Provides-Extra: test
 Provides-Extra: docs
 License-File: LICENSE.rst
 
 
 * Webpage: https://gammapy.org
 * Documentation: https://docs.gammapy.org
```

### Comparing `gammapy-1.0rc2/dev/authors.py` & `gammapy-1.1rc1/dev/authors.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/dev/codemeta.py` & `gammapy-1.1rc1/dev/codemeta.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/dev/prepare-release.py` & `gammapy-1.1rc1/dev/prepare-release.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/Makefile` & `gammapy-1.1rc1/docs/Makefile`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/1d-analysis-image.png` & `gammapy-1.1rc1/docs/_static/1d-analysis-image.png`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/2d-analysis-image.png` & `gammapy-1.1rc1/docs/_static/2d-analysis-image.png`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/3d-analysis-image.png` & `gammapy-1.1rc1/docs/_static/3d-analysis-image.png`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/DC1_3d.png` & `gammapy-1.1rc1/docs/_static/DC1_3d.png`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/atom.png` & `gammapy-1.1rc1/docs/_static/atom.png`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/box.png` & `gammapy-1.1rc1/docs/_static/box.png`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/data-flow-gammapy.png` & `gammapy-1.1rc1/docs/_static/data-flow-gammapy.png`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/galleryicon.png` & `gammapy-1.1rc1/docs/_static/galleryicon.png`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/gammapy.css` & `gammapy-1.1rc1/docs/_static/gammapy.css`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/gammapy_banner.png` & `gammapy-1.1rc1/docs/_static/gammapy_banner.png`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/gammapy_logo.ico` & `gammapy-1.1rc1/docs/_static/gammapy_logo.ico`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/gammapy_logo.png` & `gammapy-1.1rc1/docs/_static/gammapy_logo.png`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/gammapy_logo_nav.png` & `gammapy-1.1rc1/docs/_static/gammapy_logo_nav.png`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/gammapy_maps.png` & `gammapy-1.1rc1/docs/_static/gammapy_maps.png`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/gears.png` & `gammapy-1.1rc1/docs/_static/gears.png`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/glossaryicon.png` & `gammapy-1.1rc1/docs/_static/glossaryicon.png`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/hgps_map_background_estimation.png` & `gammapy-1.1rc1/docs/_static/hgps_map_background_estimation.png`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/hgps_spectrum_background_estimation.png` & `gammapy-1.1rc1/docs/_static/hgps_spectrum_background_estimation.png`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/index_api.svg` & `gammapy-1.1rc1/docs/_static/index_api.svg`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/index_contribute.svg` & `gammapy-1.1rc1/docs/_static/index_contribute.svg`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/index_getting_started.svg` & `gammapy-1.1rc1/docs/_static/index_getting_started.svg`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/index_user_guide.svg` & `gammapy-1.1rc1/docs/_static/index_user_guide.svg`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/install.png` & `gammapy-1.1rc1/docs/_static/install.png`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/upgrade.png` & `gammapy-1.1rc1/docs/_static/upgrade.png`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/_static/using.png` & `gammapy-1.1rc1/docs/_static/using.png`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/api-reference/utils.rst` & `gammapy-1.1rc1/docs/api-reference/utils.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/conf.py` & `gammapy-1.1rc1/docs/conf.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/dependencies.rst` & `gammapy-1.1rc1/docs/development/dependencies.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/dev_howto.rst` & `gammapy-1.1rc1/docs/development/dev_howto.rst`

 * *Files 5% similar despite different names*

```diff
@@ -337,18 +337,14 @@
 
         log.info('Writing {}'.format(outfile))
 
 
 You should never log messages from the module level (i.e. on import) or configure the log
 level or format in Gammapy, that should be left to callers ... except from command line tools ...
 
-There is also the rare case of functions or classes with the main job to check
-and log things. For these you can optionally let the caller pass a logger when
-constructing the class to make it easier to configure the logging.
-See the `~gammapy.data.EventListDatasetChecker` as an example.
 
 Interpolation and extrapolation
 -------------------------------
 
 In Gammapy, we use interpolation a lot, e.g. to evaluate instrument response functions (IRFs) on
 data grids, or to reproject diffuse models on data grids.
 
@@ -550,14 +546,110 @@
 We've had some pain due to merge conflicts in the releases notes and having to wait
 until the contributor rebases (and having to explain git rebase to new contributors).
 
 So our recommendation is that releases entries are not added in pull requests,
 but that the core developer adds a releases notes entry after right after having
 merged a pull request (you can add ``[skip ci]`` on this commit).
 
+How to handle API breaking changes?
+-----------------------------------
+
+As stated in PIG 23, API breaking changes can be introduced in feature and LTS releases.
+This changes must be clearly identified in the release notes. To avoid abruptly changing
+the API between consecutive version, forecoming API changes and deprecation must be announced
+in the previous release, in particular, in the form of a deprecation warning to warn users of
+future changes affecting their code.
+
+The deprecation warning must be present in the next feature or LTS release after the change was
+made. The feature can be removed in the following release.
+
+We use a deprecation warning system based on decorators derived from the one implemented in Astropy.
+Adding a decorator will raise a warning if the deprecated feature is called and it will also add a
+message to its docstring.
+
+Deprecating a function or a class
++++++++++++++++++++++++++++++++++
+
+To deprecate a function or a class, use the ``@deprecate`` decorator, indicating the first release
+following the change:
+
+.. testcode::
+
+    from gammapy.utils.deprecation import deprecated
+
+    @deprecated("1.1")
+    def deprecated_function(a, b):
+        return a + b
+
+If you want to indicate a new implementation to use instead, use the `alternative` argument:
+
+.. testcode::
+
+    from gammapy.utils.deprecation import deprecated
+
+    @deprecated("1.1", alternative="new_function")
+    def deprecated_function(a, b):
+        return a + b
+
+
+Renaming an argument
+++++++++++++++++++++
+
+If you change the name of an argument, you can use the ``deprecated_renamed_argument`` decorator.
+It will replace the old argument with the new one in a call to the function and will raise the
+``GammapyDeprecationWarning``. You can change several arguments at once.
+
+.. testcode::
+
+    from gammapy.utils.deprecation import deprecated_renamed_argument
+
+    @deprecated_renamed_argument(["a", "b"], ["x", "y"], ["1.1", "1.1"])
+    def deprecated_argument_function(x, y):
+        return x + y
+
+    print(deprecated_argument_function(a=1, b=2))
+
+If you rename a `kwarg` you simply need to set the `arg_in_kwargs` argument to `True`:
+
+.. testcode::
+
+    from gammapy.utils.deprecation import deprecated_renamed_argument
+
+    @deprecated_renamed_argument("old", "new", "1.1", arg_in_kwargs=True)
+    def deprecated_argument_function_kwarg(new=1):
+        return new
+
+    print(deprecated_argument_function_kwarg(old=3))
+
+Removing an attribute
++++++++++++++++++++++
+
+You can also remove an attribute from a class using the ``deprecated_attribute`` decorator.
+If you have a alternative attribute to use instead, pass its name in the `alternative` argument.
+
+.. testcode::
+
+    from gammapy.utils.deprecation import deprecated_attribute
+
+    class some_class:
+        old_attribute = deprecated_attribute(
+            "old_attribute", "1.1", alternative="new_attribute"
+        )
+
+        def __init__(self, value):
+            self._old_attribute = value
+            self._new_attribute = value
+
+        @property
+        def new_attribute(self):
+            return self._new_attribute
+
+    print(some_class(10).old_attribute)
+
+
 Others
 ------
 
 Command line tools using click
 ++++++++++++++++++++++++++++++
 
 Command line tools that use the `click <https://click.palletsprojects.com/en/8.0.x/>`__ module should disable
```

### Comparing `gammapy-1.0rc2/docs/development/doc_howto.rst` & `gammapy-1.1rc1/docs/development/pigs/pig-022.rst`

 * *Files 24% similar despite different names*

```diff
@@ -1,415 +1,362 @@
-.. include:: ../references.txt
+.. include:: ../../references.txt
 
-.. _doc_howto:
+.. _pig-022:
 
-********************
-Documentation How To
-********************
-
-Documentation building
-----------------------
-
-Generating the HTML docs for Gammapy is straight-forward::
-
-    make docs-all
-    make docs-show
-
-Generating the PDF docs is more complex.
-This should work::
-
-    # build the notebooks
-    python -m gammapy.utils.notebooks_process
-    # build the latex file
-    cd docs
-    python -m sphinx . _build/latex -b latex -j auto
-    # first generation of pdf file
-    cd _build/latex
-    pdflatex -interaction=nonstopmode gammapy.tex
-    # final generation of pdf file
-    pdflatex -interaction=nonstopmode gammapy.tex
-    # clean the git repo
-    git reset --hard
-    # open the pdf file
-    open gammapy.pdf
-
-You need a bunch or LaTeX stuff, specifically ``texlive-fonts-extra`` is needed.
-
-Jupyter notebooks present in ``docs/tutorials`` folder have stripped output cells.
-Although notebooks are code clean formatted, tested, and filled during the process of documentation
-building, where they are also converted to Sphinx formatted HTML files and ``.py`` scripts, 
-**you must always use stripped and clean formatted notebooks in your pull requests**.
-See :ref:`common-taks-notebooks` for the commands used for these tasks.
-
-The Sphinx formatted versions of the notebooks provide links to the raw ``.ipynb`` Jupyter
-files and ``.py`` script versions stored in ``docs/_static/notebooks`` folder, as well as
-a link pointing to its specific Binder space in the
-`gammapy-webpage <https://github.com/gammapy/gammapy-webpage>`__ repository (not for
-the deve version of the docs). Since notebooks are evolving with Gammapy features and documentation, 
-the different versions of the notebooks are linked to versioned Binder environments.
-
-Once the documentation is built you can optimize the speed of eventual re-building,
-for example in case you are modifying or adding new text, and you would like to check
-these changes are displayed nicely. For that purpose, you may run ``make docs-sphinx`` so
-that notebooks are not executed during the docs build.
-
-In the case one single notebook is modified or added to the documentation, you can
-execute the build doc process with the ``src`` parameter with value the name of the
-considered notebook. i.e. ``make docs-all src=docs/tutorials/my-notebook.ipynb``
+************************************
+PIG 22 - Unified flux estimators API
+************************************
 
-Check Python code
------------------
-
-Code in RST files
-+++++++++++++++++
-
-Most of the documentation of Gammapy is present in RST files that are converted into HTML pages using
-Sphinx during the build documentation process. You may include snippets of Python code in these RST files
-within blocks labelled with ``.. code-block:: python`` Sphinx directive. However, this code could not be
-tested, and it will not be possible to know if it fails in following versions of Gammapy. That's why we
-recommend using the ``.. testcode::`` directive to enclose code that will be tested against the results
-present in a block labelled with ``.. testoutput::`` directive. If not ``.. testoutput::`` directive is provided,
-only execution tests will be performed.
-
-For example, we could check that the code below does not fail, since it does not provide any output.
+* Author: Régis Terrier and Axel Donath
+* Created: Nov 11, 2020
+* Withdrawn: Nov 14th, 2021
+* Status: withdrawn
+* Discussion: `GH 3075`_
 
-.. code-block:: text
+Abstract
+========
+This pig proposes a uniform API for flux ``Estimator`` results. We discuss the
+introduction of a general ``FluxEstimate`` object that would allow flux type
+conversions and that would serve as a base class for ``FluxPoints`` and
+``FluxMap`` class. The latter would allow easier handling of ``TSMapEstimator`` results,
+in particular regarding serialization and flux conversion.
 
-    .. testcode::
 
-        from gammapy.astro import source
-        from gammapy.astro import population
-        from gammapy.astro import darkmatter
+Introduction
+============
 
-On the contrary, we could check the execution of the following code as well as the output values produced.
+Flux estimation is performed by ``Estimators`` in gammapy.  Some perform forward-
+folding methods to compute flux, ts, significance and errors at various positions
+or energy. This is the case of the ``FluxPointsEstimator``, the ``LightCurveEstimator``
+and the ``TSMapEstimator``. Other perform backward folding methods to compute similar
+quantities (they compute excesses and associated ts and errors and divide by the exposure
+in reco energy to deduce flux quantities). This is the case of ``ExcessMapEstimator``
+and ``ExcessProfileEstimator``.
 
-.. code-block:: text
+So far, the output of all these estimators is diverse and rely on different conventions
+for the definition of flux. There are four types of SED flux estimates described in the
+gamma astro data format. They are;
 
-    .. testcode::
+- ``dnde`` differential flux which is defined at a given ``e_ref``
+- ``e2dnde`` differential energy flux which is defined at a given ``e_ref``
+- ``flux`` integral flux defined between ``e_min`` and ``e_max``
+- ``eflux`` integral energy flux defined between ``e_min`` and ``e_max``
 
-        from astropy.time import Time
-        time = Time(['1999-01-01T00:00:00.123456789', '2010-01-01T00:00:00'])
-        print(time.mjd)
 
-    .. testoutput::
+To convert between these flux types, an assumption must be made on the spectral model.
 
-        [51179.00000143 55197.        ]
+Besides these, a useful SED type is the so-called ``likelihood`` type introduced by fermipy
+to represent SEDs and described in the gamma astro data format (ref). It uses reference
+fluxes expressed in the above flux types and a ``norm`` value that is used to derive the
+actual fluxes. Associated quantities are denoted ``norm_err``, ``norm_ul`` etc.
 
-In order to perform tests of these snippets of code present in RST files, you may run the following command.
+What we have
+============
 
-.. code-block:: bash
+So far, the only API in gammapy handling these different flux types is the ``FluxPoints``
+object. It contains a ``Table`` representing one given format above and utility functions
+allow to convert the table into another format with e.g.:
 
-    pytest --doctest-glob="*.rst" docs/
+.. code::
 
-Code in docstrings in Python files
-++++++++++++++++++++++++++++++++++
+    fp_dnde = fp.to_sed_type("dnde")
+    fp_energy_flux = fp.to_sed_type("eflux", model=PowerLawSpectralModel(index=3))
 
-It is also advisable to add code snippets within the docstrings of the classes and functions present in Python files.
-These snippets show how to use the function or class that is documented, and are written in the docstrings using the
-following syntax.
+The conversion is not possible in all directions.
 
-.. code-block:: text
+The various estimators implemented so far return different objects.
 
-        Examples
-        --------
-        >>> from astropy.units import Quantity
-        >>> from gammapy.data import EventList
-        >>> event_list = EventList.read('events.fits') # doctest: +SKIP
+- Map estimators return a dictionary of ``Map`` objects which are defined as ``flux`` types. Beyond the
+  fixed flux type, there is no easy API to allow the user to serialize all the ``Maps`` at once.
+- ``FluxPointsEstimator`` returns a ``FluxPoints`` object using the ``likelihood`` normalization scheme.
+- ``LightCurveEstimator`` relies on the ``FluxPointsEstimator`` in each time interval but converts the output
+  into a ``Table`` with one row per time interval and flux points stored as an array in each row.
+- ``ExcessProfileEstimator`` computes an integral flux (``flux`` type) in a list of regions and a list of energies.
+  It returns a ``Table`` with one region per row, and energy dependent fluxes stored as an array in each row.
 
-In the case above, we could check the execution of the first two lines importing the ``Quantity`` and ``EventList``
-modules, whilst the third line will be skipped. On the contrary, in the example below we could check the execution of
-the code as well as the output value produced.
 
-.. code-block:: text
+This diversity of output formats and flux types could be simplified with better design for flux quantities in gammapy.
+We propose below a generalized flux points API.
 
-        Examples
-        --------
-        >>> from regions import Regions
-        >>> regions = Regions.parse("galactic;circle(10,20,3)", format="ds9")
-        >>> print(regions[0])
-        Region: CircleSkyRegion
-        center: <SkyCoord (Galactic): (l, b) in deg
-            (10., 20.)>
-        radius: 3.0 deg
 
-In order to perform tests of these snippets of code present in the docstrings of the Python files, you may run the
-following command.
+Proposal of API for flux estimate results
+=========================================
 
-.. code-block:: bash
+Introduce a FluxEstimate base class
+-----------------------------------
 
-    pytest --doctest-modules --ignore-glob=*/tests gammapy
+First we propose that all ``Estimators`` compute quantities following a SED type inspired by
+the ``likelihood`` SED type. It would basically rely on the ``norm`` value and reference model
+to obtain fluxes in various formats. This is the basic ingredient of the current likelihood format
+described in the gadf but without the likelihood scan.
 
-If you get a zsh error try using putting to ignore block inside quotes 
+Using such a format, beyond the uniform behavior,  has the advantage of making flux type
+conversion easier.
 
-.. code-block:: bash
+To limit code duplication (e.g. for flux conversions), we propose a common base class to
+describe the format and contain the required quantities.
 
-    pytest --doctest-modules "--ignore-glob=*/tests" gammapy
+.. code::
 
-Sphinx gallery extension
-------------------------
+    class FluxEstimate:
+        """General likelihood sed conversion class
 
-The documentation built-in process uses the `sphinx-gallery <https://sphinx-gallery.github.io/stable/>`__
-extension to build galleries of illustrated examples on how to use Gammapy (i.e.
-:ref:`model-gallery`). The Python scripts used to produce the model gallery are placed in
-``examples/models`` and the configuration of the ``sphinx-gallery`` module is done in ``docs/conf.py``.
+        Converts norm values into dnde, flux, etc.
 
-Working with notebooks
-----------------------
-
-.. _common-taks-notebooks:
-
-Common tasks
-++++++++++++
+        Parameters
+        ----------
+        data : dict of `Map` or `Table`
+            Mappable containing the sed likelihood data
+        spectral_model : `SpectralModel`
+            Reference spectral model
+        energy_axis : `MapAxis`
+            Reference energy axis
+        """
+        def __init__(self, data, spectral_model, energy_axis=None):
+            self._data = data
+            self.spectral_model = spectral_model
+            self.energy_axis = energy_axis
 
-    * test with tutorials env: ``gammapy jupyter --src mynotebook.ipynb test --tutor``
-    * strip the output cells: ``gammapy jupyter --src mynotebook.ipynb strip``
-    * clean format code cells: ``gammapy jupyter --src mynotebook.ipynb  black``
-    * diff stripped notebooks: ``git diff mynotbook.pynb``
-  
+        @property
+        def dnde_ref(self):
+            """Reference differential flux""
+			energy = self.energy_axis.center
+            return = self.spectral_model(energy)
 
-Add a notebook into a folder other than tutorials folder
-++++++++++++++++++++++++++++++++++++++++++++++++++++++++
+        @property
+        def dnde(self):
+            """Differential flux"""
+            return self._data["norm"] * self.dnde_ref
 
-Most of the Gammapy notebooks are placed in the ``tutorials`` folder, and are displayed in a
-:ref:`tutorials` Gallery. However, we can choose to place a notebook in a different folder of the
-documentation folder structure. In this way we can write some parts of the documentation as notebooks
-instead of RST files. Once we have placed the notebook in the folder we choose we can link it from the
-``index.rst`` file using the name of the notebook filename **without the extension** and the Sphinx
-``toctree`` directive as shown below.
+        @property
+        def flux(self):
+            """Integral flux"""
+            energy = self.energy_axis.edges
+            flux_ref = self.spectral_model.integral(energy[:-1], energy[1:])
+            return self._data["norm"] * flux_ref
 
-.. code-block:: text
 
-    .. toctree::
+Practically, this allows easy manipulation of flux quantities between formats:
 
-        mynotebook
+.. code::
 
+    fpe = FluxPointsEtimator()
+    fp = fpe.run(datasets)
 
-.. _skip-nb-execution:
+    print(fp.dnde)
+    print(fp.eflux_err)
 
-Skip notebooks from being executed
-++++++++++++++++++++++++++++++++++
+    # but also get excess number estimate
+    fp.excess
 
-You may choose if a notebook is not executed during the documentation building process, and hence
-it will be published without the output cells in its static HTML version. To do this you may add
-the following code to the notebook metadata:
 
-.. code-block:: javascript
+TODO: what to do with counts based quantities? Introduce an `ExcessEstimate`?
 
-  "gammapy": {
-    "skip_run": true
-  }
+Introduce a FluxMap API
+-----------------------
 
-Choose a thumbnail and tooltip for the tutorial gallery
-+++++++++++++++++++++++++++++++++++++++++++++++++++++++
+Handling a simple dictionary of ``Maps`` is not very convenient. It is complex to
+perform flux transform, it is more complex to provide standard plotting functions
+for instance. More importantly, there is no way to serialize the maps with their
+associated quantities and other information. It could be useful to export the
+``GTI`` table of the ``Dataset`` that was used to extract the map or its ``meta``
+table. Some information on the way the flux was obtained could be kept as well
+(e.g. spatial model assumed or correlation radius used).
 
-The Gammapy :ref:`tutorials` are Jupyter notebooks that are displayed as a gallery with picture thumbnails and tooltips.
-You can choose the thumbnail for the tutorial and add the tooltip editing the metadata of the code cell that produces
-the picture that you've chosen. You can open the notebook in a text editor, and edit the internal code there. It may
-sound risky, but it is much simpler. Then, find the code cell that produces the figure that you would like for the
-gallery, and then replace the ``"metadata": {},`` bit above the code cell with the snippet below:
+The ``FluxMap`` would inherit from the general likelihood SED class discussed above
+and could include the possibility to export the resulting maps (in particular the
+``norm_scan`` maps) after sparsification according to the format definition from
+fermipy and presented in gamma astro data format.
 
-.. code-block:: javascript
+In addition, utilities to extract flux points at various positions could be provided.
 
-    "metadata": {
-     "nbsphinx-thumbnail": {
-      "tooltip": "Learn how to do perform a Fit in gammapy."
-     }},
+Typical usage would be:
 
-Note that you may write whatever you like after "tooltip".
+.. code::
 
-Dealing with links
-------------------
+    model = SkyModel(PointSpatialModel(), PowerLawSpectralModel(index=2.5))
 
-All Jupyter notebooks in Gammpay documentation are converted to HTML files using
-`nb_sphinx <http://nbsphinx.readthedocs.io/>`__ Sphinx extension which provides a source parser
-for ``.ipynb`` files.
+    estimator = TSMapEstimator(model, energy_edges=[0.2, 1.0, 10.0]*u.TeV)
 
-Links to notebooks
-++++++++++++++++++
+    flux_maps = estimator.run(dataset)
 
-From docstrings and RST documentation files in Gammapy you can link to the built fixed-text HTML formatted
-versions of the notebooks and subsections providing its filename with the ``.ipynb`` file extension
-and the relative path to the folder where they are placed::
+    # plot differential flux map in each energy band
+    flux_maps.dnde.plot_grid()
 
-    `Maps section in Gammapy overview tutorial <../tutorials/overview.ipynb#Maps>`__
+    # plot energy flux map in each energy band
+    flux_maps.eflux.plot_grid()
 
-Links within notebooks
-++++++++++++++++++++++
+    # one can access other quantities
+    flux_maps.sqrt_ts.plot_grid()
+    flux_maps.excess.plot_grid()
 
+    # Extract flux points at selected positions
+    positions = SkyCoord([225.31, 200.4], [35.65, 25.3], unit="deg", frame="icrs")
+    fp = flux_maps.get_flux_points(positions)
+    fp.plot()
 
-From MD cells in notebooks you can link to other notebooks, as well as to RST documentation files,
-and subsections using the Markdown syntax to declare links to resources, as shown in the examples below:
+    # Save to disk as a fits file
+    flux_maps.write("my_flux_maps.fits", overwrite=True)
 
-.. code-block:: rst
+    # Read from disk
+    new_flux_maps = FluxMap.read("my_flux_maps.fits")
 
-    - [Maps section in Gammapy overview tutorial](overview.ipynb#Maps)
-    - [Help!](../getting-started.rst#help)
 
-You can also link to the Gammapy API reference documentation using the same Sphinx syntax that is used
-when writing RST files. All links to the API reference classes and methods should start with ``~gammapy.``
-and enclosed within quotation marks. This syntax will be translated into relative links to the API in the
-HTML formatted versions of the notebooks, and to absolute links pointing to the online Gammapy documentation
-in the ``.ipynb`` notebook files available to download. During the documentation building process a warning
-will be raised for each detected broken link to the API.
 
-Examples:
+Introduce a FluxPointsCollection API
+------------------------------------
 
-- `gammapy.maps`
-- `gammapy.maps.Geom`
-- `gammapy.maps.Geom.is_image`
-- `gammapy.maps.Geom.is_image()`
+Several estimators return a set of ``FluxPoints`` . It is the case of the ``LightCurveEstimator``,
+a light curve being a time ordered list of fluxes. It is also the case of the ``ExcessProfileEstimator``
+which return a list of flux points ordered along a direction or radially. In the current implementation,
+they produce an ``~astropy.Table`` where each row contain an array of fluxes representing flux points at a
+given time or position.
 
-The example links above could be created within MD cells in notebooks with the syntax below:
+This solution is not ideal. It introduces a different container logic than the ``FluxPoints`` for which
+one row represents one energy.
 
-.. code-block:: rst
+A dedicated API could be introduced to support these objects. In order to keep the logic used in
+``FluxPoints``, a flat table ``Table`` could be used to store the various fluxes, where each row
+would represent the flux at a given energy, time, position etc.
 
-    - `~gammapy.maps`
-    - `~gammapy.maps.Geom`
-    - `~gammapy.maps.Geom.is_image`
-    - `~gammapy.maps.Geom.is_image()`
+Astropy provides a mechanism to group table rows according to column entries. It is then possible
+to extract the relevant ``FluxPoints`` object, representing the simple flux points or the lightcurve.
 
-When building the documentation of a release, the links declared in the MD cells as absolute links pointing
-to the ``dev`` version of the online Gammapy documentation will be transformed to relative links in the built
-HTML formatted notebooks and to absolute links pointing to that specific released version of the online docs
-in the downloadable ``.ipynb`` files.
+A possible implementation could follow the following lines:
 
-.. _dev-check_html_links:
+.. code::
 
-Check broken links
-++++++++++++++++++
+    energy_columns = ["e_min", "e_max", "e_ref"]
+    time_columns = ["t_min", "t_max"]
 
-To check for broken external links from the Sphinx documentation:
+    class FluxPointsCollection:
+        def __init__(self, table):
+            self.table = table
 
-.. code-block:: bash
+            if all(_ in self.table.keys() for _ in energy_columns ):
+                self._energy_table = self.table.group_by(energy_columns)
+            else:
+                raise TypeError("Table does not describe a flux point. Missing energy columns.")
 
-   $ cd docs; make linkcheck
+            self._time_groups = None
+            if all(_ in self.table.keys() for _ in time_columns):
+                self._time_table = self.table.group_by(time_columns)
 
-You may also use `brök <https://github.com/smallhadroncollider/brok>`__ software, which will also check
-the links present in the notebooks files.
 
-.. code-block:: bash
+       def flux_points_at_time(self, time):
+            if self._time_table is None:
+                raise KeyError("No time information")
 
-   $ brok docs/tutorials/*.ipynb | grep "Failed|Could"
+            index = np.where((time - self.t_min) <= 0)[0][0]
+            return self.__class__(self._time_table.groups[index])
 
+        def lightcurve_at_energy(self, energy):
+            if self._time_table is None:
+                raise KeyError("No time information")
 
-Include png files as images
-----------------------------
+            index = np.where((energy - self.e_min) <= 0)[0][0]
+            return self.__class__(self._energy_table.groups[index])
 
-In Jupyter notebooks
-++++++++++++++++++++
 
-You may include static images in notebooks using the following markdown directive:
+Keeping dedicated classes for specific types is an open question. While it might not be needed,
+it also provides a more explicit API for the user as well as specific functionalities. In particular,
+plotting is specific to each type. So will be I/O once specific data formats have been introduced.
 
-.. code-block:: rst
+We also note that ``FluxPointsDataset`` rely on ``FluxPoints`` object for now. An important missing
+feature is the ability of using these for temporal model evaluation.  ``TemporalModel`` might requires
+a ``GTI``.
 
-    ![](images/my_static_image.png)
 
-Please note that your images should be placed inside a `images` folder, accessed with that relative
-path from your notebook.
+Unification of flux estimators?
+===============================
 
-In the RST files
-++++++++++++++++
+Most estimators actually do the same thing: `LightCurveEstimator`` is simply grouping datasets in time
+intervals and applies ``FluxPointsEstimator`` in each interval. Similarly, the ``ExcessProfileEstimator``
+is performing a similar thing in different regions. The necessity of a specific estimator for all
+these tasks is then questionable. Currently, the responsibility of an estimator is to group and reproject
+datasets in the relevant intervals or group of data and then to apply a general flux or excess estimate.
 
-Gammapy has a ``gp-image`` directive to include an image from ``$GAMMAPY_DATA/figures/``,
-use the ``gp-image`` directive instead of the usual Sphinx ``image`` directive like this:
+In practice there are two different types of estimators. We can distinguish these:
 
-.. code-block:: rst
+- Flux estimators perform a fit of all individual counts inside the requested range
+  (energy-bin and/or spatial box) to obtain a flux given a certain physical model. Because
+  it relies on a fit of the complete model,this approach allows to take into account fluctuations
+  of other parameters by performing re-optimization.
 
-    .. gp-image:: detect/fermi_ts_image.png
-        :scale: 100%
+- Excess estimators sum all counts inside the requested range and estimate the corresponding excess
+  counts taking into account background and other signal contributions from other sources. No explicit
+  fit is actually performed, since we rely on ``CountsStatistics`` classes. The flux is then deduced
+  computing the ratio of measured excess to total ``npred`` in a given model assumption.
 
-More info on the `image directive <http://www.sphinx-doc.org/en/stable/rest.html#images>`__.
 
-Documentation guidelines
-------------------------
+Currently, the ``FluxPointsEstimator`` and the ``LightCurveEstimator`` belong to the first category.
+The ``TSMapEstimator`` a priori belongs there as well although our current implementation does not
+allow for other parameters re-optimization. A more general implementation could also rely on
+``FluxPointsEstimator``.
 
-Like almost all Python projects, the Gammapy documentation is written in a format called
-`restructured text (RST)`_ and built using `Sphinx`_.
-We mostly follow the :ref:`Astropy documentation guidelines <astropy:documentation-guidelines>`,
-which are based on the `Numpy docstring standard`_,
-which is what most scientific Python packages use.
+The ``ExcessMapEstimator`` and ``ExcessProfileEstimator`` are following the second approach (as
+their name suggest), but they still provide flux estimates through the excess/npred ratio. We note
+that flux points and light curve can also be estimated through this approach to provide rapid estimates.
 
-.. _restructured text (RST): http://sphinx-doc.org/rest.html
-.. _Sphinx: http://sphinx-doc.org/
-.. _Numpy docstring standard: https://numpydoc.readthedocs.io/en/latest/format.html#docstring-standard
+So we propose to introduce the following simplified estimator API:
 
-There's a few details that are not easy to figure out by browsing the Numpy or Astropy
-documentation guidelines, or that we actually do differently in Gammapy.
-These are listed here so that Gammapy developers have a reference.
+- `FluxPointsEstimator`, which handles multiple sources, time intervals and energy bins, using "forward folding"
+- `FluxMapEstimator`, which handles multiple energy bins, using "forward folding"
+- `ExcessPointsEstimator`, which handles multiple regions, time intervals and energy bins, using "backward folding"
+- `ExcessMapEstimator`, which handles multiple energy bins, using "backward folding"
 
-Usually the quickest way to figure out how something should be done is to browse the Astropy
-or Gammapy code a bit (either locally with your editor or online on GitHub or via the HTML docs),
-or search the Numpy or Astropy documentation guidelines mentioned above.
-If that doesn't quickly turn up something useful, please ask by putting a comment on the issue or
-pull request you're working on GitHub, or email the Gammapy mailing list.
 
-Functions or class methods that return a single object
-++++++++++++++++++++++++++++++++++++++++++++++++++++++
+Excess estimators
+-----------------
 
-For functions or class methods that return a single object, following the
-Numpy docstring standard and adding a *Returns* section usually means
-that you duplicate the one-line description and repeat the function name as
-return variable name.
-See `~astropy.cosmology.LambdaCDM.w` or `~astropy.time.Time.sidereal_time`
-as examples in the Astropy codebase. Here's a simple example:
+We can unify and clarify the general approach by introducing estimators following
+each of the methods.
 
-.. testcode::
+A general flux estimator already exists, it is the ``FluxEstimator``. It is the base of the
+``FluxPointsEstimator``.
 
-    def circle_area(radius):
-        """Circle area.
+An equivalent ``ExcessEstimator`` could be added. Technically, it would mostly encapsulate
+functionalities provided by the ``CountsStatistics``.
 
-        Parameters
-        ----------
-        radius : `~astropy.units.Quantity`
-            Circle radius
 
-        Returns
-        -------
-        area : `~astropy.units.Quantity`
-            Circle area
-        """
-        return 3.14 * (radius ** 2)
+Generalist estimators
+---------------------
 
-In these cases, the following shorter format omitting the *Returns* section is recommended:
+It is possible to create a generalist ``FluxPointsEstimator`` that could return a general
+``FluxPointsCollection`` without knowing a priori what type of grouping is applied to the
+datasets. This would allow to perform lightcurve or region-based flux estimates with the same
+API. This would allow a direct generalization of the ``FluxPointsEstimator`` to cover other problematic
+e.g. flux estimation in phase to build phase curves, flux estimation in different observation condition or
+instrument states to study systematic effects.
 
-.. testcode::
+The main change required for this is to move dataset grouping to the ``Datasets`` level.
 
-    def circle_area(radius):
-        """Circle area (`~astropy.units.Quantity`).
+Outlook
+-------
+Selection by time is already possible on ``Datasets`` thanks to the ``select_time(t_min, t_max)``
+method. This functionality could be extended to other quantities characterizing the datasets.
 
-        Parameters
-        ----------
-        radius : `~astropy.units.Quantity`
-            Circle radius
-        """
-        return 3.14 * (radius ** 2)
+So in future we could add more general grouping functionality on the ``Datasets``. It could
+internally rely on the grouping of the meta table: ``Datasets.meta_table.group_by``. It would
+require the table to be present in memory and be recomputed each time the ``Datasets`` object
+is updated. Then retrieving a set of datasets could be done by ``Datasets.get_group_by_idx()``.
 
-Usually the parameter description doesn't fit on the one line, so it's
-recommended to always keep this in the *Parameters* section.
+.. code::
 
-A common case where the short format is appropriate are class properties,
-because they always return a single object.
-As an example see `~gammapy.data.EventList.radec`, which is reproduced here:
+    # group datasets according to phase
+    phase_axis = MapAxis.from_bounds(0., 1., 10, name="phase", unit="")
+    datasets.group_by_axis(phase_axis)
+    datasets_in_phase_bin_3 = datasets.get_group_by_idx(3)
 
-.. testcode::
 
-    @property
-    def radec(self):
-        """Event RA / DEC sky coordinates (`~astropy.coordinates.SkyCoord`)."""
-        lon, lat = self['RA'], self['DEC']
-        return SkyCoord(lon, lat, unit='deg', frame='icrs')
 
+Alternative
+===========
 
-Class attributes
-++++++++++++++++
 
-Class attributes (data members) and properties are currently a bit of a mess.
-Attributes are listed in an *Attributes* section because I've listed them in a class-level
-docstring attributes section as recommended
-`here <https://numpydoc.readthedocs.io/en/latest/format.html#docstring-standard>`__.
-Properties are listed in separate *Attributes summary* and *Attributes Documentation*
-sections, which is confusing to users ("what's the difference between attributes and properties?").
 
-One solution is to always use properties, but that can get very verbose if we have to write
-so many getters and setters. We could start using descriptors.
+Decision
+========
+The authors have decided to withdraw the PIG. Most of the proposed changes have been
+implemented independently with review and discussions on individuals PRs.
 
-TODO: make a decision on this and describe the issue / solution here.
+.. _GH 3075: https://github.com/gammapy/gammapy/pull/3075
```

### Comparing `gammapy-1.0rc2/docs/development/index.rst` & `gammapy-1.1rc1/docs/development/index.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/intro.rst` & `gammapy-1.1rc1/docs/development/intro.rst`

 * *Files 14% similar despite different names*

```diff
@@ -33,14 +33,49 @@
 the process and technical steps how to contribute a code or documentation change via a
 **pull request** against the Gammapy repository.
 
 So let's assume you've used Gammapy for a while, and now you'd like to fix or
 add something to the Gammapy code, tests or docs. Here are the steps and commands
 to do it ...
 
+Acceptation of the Developer Certificate of Origin (DCO)
+========================================================
+As described in the `PIG 24 <https://github.com/gammapy/gammapy/blob/master/docs/development/pigs/pig-024.rst>`_ and
+the `README.rst <https://github.com/gammapy/gammapy/blob/master/README.rst>`_ file, each contributor shall accept the
+DCO based stored in the file `DeveloperCertificate.rst <https://github.com/gammapy/gammapy/blob/master/DeveloperCertificate.rst>`_:
+this is a binding statement that asserts that you are the creator of your contribution, and that you wish to allow
+Gammapy to use your work to cite you as contributor.
+
+**If you are willing to agree to these terms, the following agreement line should be added to every commit message:**
+
+``Signed-off-by: Random J Developer <random@developer.example.org>``
+
+Four solutions exist:
+
+1. You add this message by hand into each of your commit messages (not recommended)
+
+2. You can sign each of your commits with the command: "``git commit -s``".
+
+If you have authored a commit that is missing its ‘Signed-off-by’ line, you can amend your commits and push them to
+GitHub: "``git commit --amend --no-edit --signoff``"
+(see also this `How To <https://github.com/src-d/guide/blob/master/developer-community/fix-DCO.md#how-to-add-sign-offs-retroactively>`_).
+
+3. You can make an alias of the command "``git commit -s``", e.g.
+
+``alias gcs 'git commit -s'``
+
+4. You can create a so-called `git hooks` allowing to automatically sign all your commits (recommended option). This
+method is described in detail `here <https://github.com/src-d/guide/blob/master/developer-community/fix-DCO.md#how-to-prevent-missing-sign-offs-in-the-future>`_.
+
+For each of these solutions, it is **mandatory** to correctly set your `user.name` and `user.email` as part of your git
+configuration (see `this page <https://docs.github.com/en/account-and-profile/setting-up-and-managing-your-personal-account-on-github/managing-email-preferences/setting-your-commit-email-address>`_ to configure it).
+You have to use **your real name** (i.e., pseudonyms or anonymous contributions cannot be made) when using git. This is
+because the DCO is a binding document, granting the Gammapy project to be an open source project.
+
+
 Get in touch early
 ==================
 
 **Usually the first step, before doing any work, is to get in touch with the
 Gammapy developers!**
 
 Especially if you're new to the project, and don't have an overview of ongoing
@@ -152,15 +187,15 @@
 ``$ git remote -v`` to list all your configured remotes.
 
 In case you are working with the development version environment and you want to update this
 environment with the content present in `environment-dev.yml` see below:
 
 .. code-block:: bash
 
-    $ conda env update environment-dev.yml --prune
+    $ conda env update --file environment-dev.yml --prune
 
 
 When developing Gammapy you never want to work on the ``master`` branch, but
 always on a dedicated feature branch.
 
 .. code-block:: bash
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `gammapy-1.0rc2/docs/development/pigs/index.rst` & `gammapy-1.1rc1/docs/development/pigs/index.rst`

 * *Files 2% similar despite different names*

```diff
@@ -34,9 +34,10 @@
     pig-016
     pig-018
     pig-019
     pig-020
     pig-021
     pig-022
     pig-023
+    pig-024
 
 .. _pull requests with the "pig" label: https://github.com/gammapy/gammapy/issues?q=label%3Apig
```

### Comparing `gammapy-1.0rc2/docs/development/pigs/pig-001.rst` & `gammapy-1.1rc1/docs/development/pigs/pig-001.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/pigs/pig-002.rst` & `gammapy-1.1rc1/docs/development/pigs/pig-002.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/pigs/pig-003.rst` & `gammapy-1.1rc1/docs/development/pigs/pig-003.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/pigs/pig-004.rst` & `gammapy-1.1rc1/docs/development/pigs/pig-004.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/pigs/pig-005.rst` & `gammapy-1.1rc1/docs/development/pigs/pig-005.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/pigs/pig-006-class-diagram.png` & `gammapy-1.1rc1/docs/development/pigs/pig-006-class-diagram.png`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/pigs/pig-006.rst` & `gammapy-1.1rc1/docs/development/pigs/pig-006.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/pigs/pig-007.rst` & `gammapy-1.1rc1/docs/development/pigs/pig-007.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/pigs/pig-008.rst` & `gammapy-1.1rc1/docs/development/pigs/pig-008.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/pigs/pig-009.rst` & `gammapy-1.1rc1/docs/development/pigs/pig-009.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/pigs/pig-010.rst` & `gammapy-1.1rc1/docs/development/pigs/pig-010.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/pigs/pig-011.rst` & `gammapy-1.1rc1/docs/development/pigs/pig-011.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/pigs/pig-012.rst` & `gammapy-1.1rc1/docs/development/pigs/pig-012.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/pigs/pig-013.rst` & `gammapy-1.1rc1/docs/development/pigs/pig-013.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/pigs/pig-014.rst` & `gammapy-1.1rc1/docs/development/pigs/pig-014.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/pigs/pig-016-gammapy-package-organisation-proposal.png` & `gammapy-1.1rc1/docs/development/pigs/pig-016-gammapy-package-organisation-proposal.png`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/pigs/pig-016-gammapy-package-organisation-status.png` & `gammapy-1.1rc1/docs/development/pigs/pig-016-gammapy-package-organisation-status.png`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/pigs/pig-016.rst` & `gammapy-1.1rc1/docs/development/pigs/pig-016.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/pigs/pig-018.rst` & `gammapy-1.1rc1/docs/development/pigs/pig-018.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/pigs/pig-019.rst` & `gammapy-1.1rc1/docs/development/pigs/pig-019.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/pigs/pig-020.rst` & `gammapy-1.1rc1/docs/development/pigs/pig-020.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/pigs/pig-021.rst` & `gammapy-1.1rc1/docs/development/pigs/pig-021.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/pigs/pig-023.rst` & `gammapy-1.1rc1/docs/development/pigs/pig-023.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/development/pigs/pig-024.rst` & `gammapy-1.1rc1/docs/development/pigs/pig-024.rst`

 * *Files 0% similar despite different names*

```diff
@@ -15,16 +15,14 @@
 Abstract
 ========
 
 Given that the Gammapy library is more widely used by the community, a proper citation of the project including
 a policy about the authorship is necessary. This PIG addresses this issue by setting an authorship policy for the
 Gammapy project for each type of products (releases, papers and conferences).
 
-.. contents:: Table of Contents
-   :depth: 2
 
 Introduction
 ============
 
 Gammapy started in 2013 and is now widely used in scientific publications. A proper citation scheme with correct authorship allows:
 
 - a proper citation of the used Gammapy release,
@@ -320,7 +318,9 @@
 These requests to the Astropy community and CTAO for recommendations and preferences either remained
 un-responded or did not lead to objections at the current time.
 
 Decision
 ========
 After the addition of comments and proposals, the PIG is accepted by the dev team and the CC.
 The choice of practical implementation of such scheme will be made in dedicated pull requests.
+
+.. _GH 3970: https://github.com/gammapy/gammapy/pull/3970
```

### Comparing `gammapy-1.0rc2/docs/development/release.rst` & `gammapy-1.1rc1/docs/development/release.rst`

 * *Files 2% similar despite different names*

```diff
@@ -112,8 +112,8 @@
 ---------------------
 
 #. Add an entry for the bug-fix release like `v1.0.1` or `v1.1.2` in the ``download/index.json`` file in the `gammapy-web repo <https://github.com/gammapy/gammapy-webpage>`__.
    The ``datasets`` entry should point to last stable version, like `v1.0` or `v1.1`. We do not provide bug-fix release for data. 
 
 #. Follow the  `Astropy bug fix release instructions https://docs.astropy.org/en/latest/development/releasing.html#maintaining-bug-fix-releases`__.
 
-#. Follow the instructions for a major release for the modifications in the `gammapy-docs` and `gammapy-webpage` repo as well as the conda builds.
+#. Follow the instructions for a major release for the updates of CITATION.cff, the modifications in the `gammapy-docs` and `gammapy-webpage` repo as well as the conda builds.
```

### Comparing `gammapy-1.0rc2/docs/development/setup.rst` & `gammapy-1.1rc1/docs/development/setup.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/getting-started/environments.rst` & `gammapy-1.1rc1/docs/getting-started/environments.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/getting-started/index.rst` & `gammapy-1.1rc1/docs/getting-started/index.rst`

 * *Files 4% similar despite different names*

```diff
@@ -80,31 +80,31 @@
 :link-badge:`../tutorials/data/fermi_lat.html,"Fermi-LAT data tutorial",cls=badge-primary text-white`
 
 .. accordion-footer::
 
 .. accordion-header::
     :id: collapseTwo
     :title: How to compute a 1D spectrum
-    :link: ../tutorials/analysis/1D/spectral_analysis.html
+    :link: ../tutorials/analysis-1d/spectral_analysis.html
 
 Gammapy lets you create a 1D spectrum by defining an analysis region in
 the sky and energy binning using  `~gammapy.maps.RegionGeom` object.
 The **events and instrument response are binned** into `~gammapy.maps.RegionNDMap`
 and `~gammapy.irf.IRFMap` objects. In addition you can choose to estimate
 the background from data using e.g. a **reflected regions method**.
 Flux points can be computed using the `~gammapy.estimators.FluxPointsEstimator`.
 
 .. image:: ../_static/1d-analysis-image.png
     :width: 100%
 
 |
 
-:link-badge:`../tutorials/analysis/1D/spectral_analysis.html,"1D analysis tutorial",cls=badge-primary text-white`
-:link-badge:`../tutorials/analysis/1D/spectral_analysis_rad_max.html,"1D analysis tutorial with point-like IRFs",cls=badge-primary text-white`
-:link-badge:`../tutorials/analysis/1D/extended_source_spectral_analysis.html,"1D analysis tutorial of extended sources",cls=badge-primary text-white`
+:link-badge:`../tutorials/analysis-1d/spectral_analysis.html,"1D analysis tutorial",cls=badge-primary text-white`
+:link-badge:`../tutorials/analysis-1d/spectral_analysis_rad_max.html,"1D analysis tutorial with point-like IRFs",cls=badge-primary text-white`
+:link-badge:`../tutorials/analysis-1d/extended_source_spectral_analysis.html,"1D analysis tutorial of extended sources",cls=badge-primary text-white`
 
 .. accordion-footer::
 
 .. accordion-header::
     :id: collapseThree
     :title: How to compute a 2D image
     :link: ../tutorials/index.html#d-image
@@ -114,71 +114,71 @@
 fixed spectral index, or following the classical ring background estimation.
 
 .. image:: ../_static/2d-analysis-image.png
     :width: 100%
 
 |
 
-:link-badge:`../tutorials/analysis/2D/modeling_2D.html,"2D analysis tutorial",cls=badge-primary text-white`
-:link-badge:`../tutorials/analysis/2D/ring_background.html,"2D analysis tutorial with ring background",cls=badge-primary text-white`
+:link-badge:`../tutorials/analysis-2d/modeling_2D.html,"2D analysis tutorial",cls=badge-primary text-white`
+:link-badge:`../tutorials/analysis-2d/ring_background.html,"2D analysis tutorial with ring background",cls=badge-primary text-white`
 
 .. accordion-footer::
 
 .. accordion-header::
     :id: collapseFour
     :title: How to compute a 3D cube
-    :link: ../tutorials/analysis/3D/analysis_3d.html
+    :link: ../tutorials/analysis-3d/analysis_3d.html
 
 Gammapy lets you perform a combined spectral and spatial analysis as well.
 This is sometimes called in jargon a "cube analysis". Based on the 3D data reduction
 Gammapy can also simulate events. Flux points can be computed using the
 `~gammapy.estimators.FluxPointsEstimator`.
 
 .. image:: ../_static/3d-analysis-image.png
     :width: 100%
 
 |
 
-:link-badge:`../tutorials/analysis/3D/analysis_3d.html,"3D analysis tutorial",cls=badge-primary text-white`
-:link-badge:`../tutorials/analysis/3D/event_sampling.html,"3D analysis tutorial with event sampling",cls=badge-primary text-white`
+:link-badge:`../tutorials/analysis-3d/analysis_3d.html,"3D analysis tutorial",cls=badge-primary text-white`
+:link-badge:`../tutorials/analysis-3d/event_sampling.html,"3D analysis tutorial with event sampling",cls=badge-primary text-white`
 
 
 .. accordion-footer::
 
 
 .. accordion-header::
     :id: collapseFive
     :title: How to compute a lightcurve
-    :link: ../tutorials/analysis/time/light_curve.html
+    :link: ../tutorials/analysis-time/light_curve.html
 
 Gammapy allows you to compute light curves in various ways. Light curves
 can be computed for a **1D or 3D analysis scenario** (see above) by either
 grouping or splitting the DL3 data into multiple time intervals. Grouping
 mutiple observations allows for computing e.g. a **monthly or nightly light curves**,
 while splitting of a single observation allows to compute **light curves for flares**.
 You can also compute light curves in multiple energy bands. In all cases the light
 curve is computed using the `~gammapy.estimators.LightCurveEstimator`.
 
 
-:link-badge:`../tutorials/analysis/time/light_curve.html,"Light curve tutorial",cls=badge-primary text-white`
-:link-badge:`../tutorials/analysis/time/light_curve_flare.html,"Light curve tutorial for flares",cls=badge-primary text-white`
+:link-badge:`../tutorials/analysis-time/light_curve.html,"Light curve tutorial",cls=badge-primary text-white`
+:link-badge:`../tutorials/analysis-time/light_curve_flare.html,"Light curve tutorial for flares",cls=badge-primary text-white`
 
 
 .. accordion-footer::
 
 
 .. accordion-header::
     :id: collapseSix
     :title: How to combine data from multiple instruments
-    :link: ../tutorials/analysis/3D/analysis_mwl.html
+    :link: ../tutorials/analysis-3d/analysis_mwl.html
 
 Gammapy offers the possibility to **combine data from multiple instruments**
 in a "joint-likelihood" fit. This can be done at **multiple data levels** and
 independent dimensionality of the data. Gammapy can handle 1D and 3D datasets
 at the same time and can also include e.g. flux points in a combined likelihood fit.
 
-:link-badge:`../tutorials/analysis/3D/analysis_mwl.html,"Combined 1D / 3D analysis tutorial",cls=badge-primary text-white`
-:link-badge:`../tutorials/analysis/1D/sed_fitting.html,"SED fitting tutorial",cls=badge-primary text-white`
+:link-badge:`../tutorials/analysis-3d/analysis_mwl.html,"Combined 1D / 3D analysis tutorial",cls=badge-primary text-white`
+:link-badge:`../tutorials/analysis-1d/sed_fitting.html,"SED fitting tutorial",cls=badge-primary text-white`
 
 
 .. accordion-footer::
```

### Comparing `gammapy-1.0rc2/docs/getting-started/install.rst` & `gammapy-1.1rc1/docs/getting-started/install.rst`

 * *Files 2% similar despite different names*

```diff
@@ -81,19 +81,14 @@
     
 To install Gammapy with all optional dependencies, you can specify:
 
 .. code-block:: bash
 
    $ python -m pip install gammapy[all]
 
-Or on windows:
-
-.. code-block:: bash
-
-   $ python -m pip install gammapy[all-windows]
 
 To update an existing installation you can use:
 
 .. code-block:: bash
 
    $ python -m pip install gammapy --upgrade
```

### Comparing `gammapy-1.0rc2/docs/getting-started/quickstart.rst` & `gammapy-1.1rc1/docs/getting-started/quickstart.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/getting-started/troubleshooting.rst` & `gammapy-1.1rc1/docs/getting-started/troubleshooting.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/getting-started/usage.rst` & `gammapy-1.1rc1/docs/getting-started/usage.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/index.rst` & `gammapy-1.1rc1/docs/index.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/make.bat` & `gammapy-1.1rc1/docs/make.bat`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/references.txt` & `gammapy-1.1rc1/docs/references.txt`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/release-notes/index.rst` & `gammapy-1.1rc1/docs/release-notes/index.rst`

 * *Files 2% similar despite different names*

```diff
@@ -1,17 +1,25 @@
 .. _release_notes:
 
 =============
 Release notes
 =============
 
 This is the list of changes to Gammapy between each release. For full details,
-see the `commit logs <https://github.com/gammapy/gammapy/commits/master>`_.
+see the `commit logs <https://github.com/gammapy/gammapy/commits/main>`_.
 A complete list of Gammapy contributors is at https://gammapy.org/team.html
 
+Version 1.0.1
+-------------
+
+.. toctree::
+   :maxdepth: 2
+
+   v1.0.1
+
 Version 1.0
 -----------
 
 .. toctree::
    :maxdepth: 2
 
    v1.0
```

### Comparing `gammapy-1.0rc2/docs/release-notes/v0.1.rst` & `gammapy-1.1rc1/docs/release-notes/v0.1.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/release-notes/v0.10.rst` & `gammapy-1.1rc1/docs/release-notes/v0.10.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/release-notes/v0.11.rst` & `gammapy-1.1rc1/docs/release-notes/v0.11.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/release-notes/v0.12.rst` & `gammapy-1.1rc1/docs/release-notes/v0.12.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/release-notes/v0.13.rst` & `gammapy-1.1rc1/docs/release-notes/v0.13.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/release-notes/v0.14.rst` & `gammapy-1.1rc1/docs/release-notes/v0.14.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/release-notes/v0.15.rst` & `gammapy-1.1rc1/docs/release-notes/v0.15.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/release-notes/v0.16.rst` & `gammapy-1.1rc1/docs/release-notes/v0.16.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/release-notes/v0.17.rst` & `gammapy-1.1rc1/docs/release-notes/v0.17.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/release-notes/v0.18.1.rst` & `gammapy-1.1rc1/docs/release-notes/v0.18.1.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/release-notes/v0.18.2.rst` & `gammapy-1.1rc1/docs/release-notes/v0.18.2.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/release-notes/v0.18.rst` & `gammapy-1.1rc1/docs/release-notes/v0.18.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/release-notes/v0.19.rst` & `gammapy-1.1rc1/docs/release-notes/v0.19.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/release-notes/v0.2.rst` & `gammapy-1.1rc1/docs/release-notes/v0.2.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/release-notes/v0.20.1.rst` & `gammapy-1.1rc1/docs/release-notes/v0.20.1.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/release-notes/v0.20.rst` & `gammapy-1.1rc1/docs/release-notes/v0.20.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/release-notes/v0.3.rst` & `gammapy-1.1rc1/docs/release-notes/v0.3.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/release-notes/v0.4.rst` & `gammapy-1.1rc1/docs/release-notes/v0.4.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/release-notes/v0.5.rst` & `gammapy-1.1rc1/docs/release-notes/v0.5.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/release-notes/v0.6.rst` & `gammapy-1.1rc1/docs/release-notes/v0.6.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/release-notes/v0.7.rst` & `gammapy-1.1rc1/docs/release-notes/v0.7.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/release-notes/v0.8.rst` & `gammapy-1.1rc1/docs/release-notes/v0.8.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/release-notes/v0.9.rst` & `gammapy-1.1rc1/docs/release-notes/v0.9.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/release-notes/v1.0.rst` & `gammapy-1.1rc1/docs/release-notes/v1.0.rst`

 * *Files 2% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 .. include:: ../references.txt
 
 .. _gammapy_1p0_release:
 
-1.0 (November 9th, 2022)
------------------------
+1.0 (November 10th, 2022)
+-------------------------
 
 Summary
 ~~~~~~~
 
-- Released Nov 9th, 2022
+- Released Nov 10th, 2022
 - 12 contributors
-- 106 pull requests since v0.20.1 (not all listed below)
+- 103 pull requests since v0.20.1 (not all listed below)
 
 New features
 ~~~~~~~~~~~~
 
 This new release is the Long Term Stable (LTS) version 1.0. Most of the changes are in the package
 infrastructure. A number of improvements and bug corrections have been implemented since v0.20.1.
 Gammapy v1.0 adds support for the latest version 0.3 of `gadf`_.
@@ -68,15 +68,15 @@
 - The dataset name is now serialized with the Dataset as the `NAME` keyword in the primary HDU.
 - A `peek` method is now available for the `~gammapy.datasets.MapEvaluator` to help debugging issues
   with model evaluation on a `~gammapy.datasets.Dataset`.
 
 *gammapy.irf*
 
 - The interpolation scheme of the energy axis was incorrectly set to "linear" by default for the
-`~gammapy.irf.Background2D`. It is now set to "log".
+ `~gammapy.irf.Background2D`. It is now set to "log".
 
 *gammapy.makers*
 
 - Adapt the `~gammapy.makers.MapDatasetMaker` to handle the DL3 format introduced in g.a.d.f. v0.3 for drifting
   instruments.
 
 *gammapy.maps*
```

### Comparing `gammapy-1.0rc2/docs/serve.py` & `gammapy-1.1rc1/docs/serve.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/astro/darkmatter/index.rst` & `gammapy-1.1rc1/docs/user-guide/astro/darkmatter/index.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/astro/index.rst` & `gammapy-1.1rc1/docs/user-guide/astro/index.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/astro/population/index.rst` & `gammapy-1.1rc1/docs/user-guide/astro/population/index.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/astro/population/plot_radial_distributions.py` & `gammapy-1.1rc1/docs/user-guide/astro/population/plot_radial_distributions.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/astro/population/plot_spiral_arm_models.py` & `gammapy-1.1rc1/docs/user-guide/astro/population/plot_spiral_arm_models.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 """Plot Milky Way spiral arm models."""
 import numpy as np
 from astropy.units import Quantity
 import matplotlib.pyplot as plt
 from gammapy.astro.population.spatial import FaucherSpiral, ValleeSpiral
+from gammapy.maps.axes import UNIT_STRING_FORMAT
 
 fig = plt.figure(figsize=(7, 8))
 rect = [0.12, 0.12, 0.85, 0.85]
 ax_cartesian = fig.add_axes(rect)
 ax_cartesian.set_aspect("equal")
 
 vallee_spiral = ValleeSpiral()
@@ -28,15 +29,15 @@
     # Plot Faucher spiral
     x, y = faucher_spiral.xy_position(radius=radius, spiralarm_index=spiralarm_index)
     name = faucher_spiral.spiralarms[spiralarm_index]
     ax_cartesian.plot(x, y, label="Faucher " + name, ls="-.", color=color)
 
 ax_cartesian.plot(vallee_spiral.bar["x"], vallee_spiral.bar["y"])
 
-ax_cartesian.set_xlabel("x (kpc)")
-ax_cartesian.set_ylabel("y (kpc)")
+ax_cartesian.set_xlabel(f"x [{radius.unit.to_string(UNIT_STRING_FORMAT)}]")
+ax_cartesian.set_ylabel(f"y [{radius.unit.to_string(UNIT_STRING_FORMAT)}]")
 ax_cartesian.set_xlim(-12, 12)
 ax_cartesian.set_ylim(-15, 12)
 ax_cartesian.legend(ncol=2, loc="lower right")
 
 plt.grid()
 plt.show()
```

### Comparing `gammapy-1.0rc2/docs/user-guide/astro/population/plot_spiral_arms.py` & `gammapy-1.1rc1/docs/user-guide/astro/population/plot_spiral_arms.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 """Plot Milky Way spiral arms."""
 import numpy as np
 from astropy.units import Quantity
 import matplotlib.pyplot as plt
 from gammapy.astro.population import FaucherSpiral, simulate
+from gammapy.maps.axes import UNIT_STRING_FORMAT
 from gammapy.utils.coordinates import cartesian, polar
 
 catalog = simulate.make_base_catalog_galactic(
     n_sources=int(1e4), rad_dis="YK04", vel_dis="H05", max_age=Quantity(1e6, "yr")
 )
 
 spiral = FaucherSpiral()
@@ -27,16 +28,16 @@
     linestyle="none",
     markersize=5,
     alpha=0.3,
     fillstyle="full",
 )
 ax_cartesian.set_xlim(-20, 20)
 ax_cartesian.set_ylim(-20, 20)
-ax_cartesian.set_xlabel("x [kpc]", labelpad=2)
-ax_cartesian.set_ylabel("y [kpc]", labelpad=-4)
+ax_cartesian.set_xlabel(f"x [{u.kpc.to_string(UNIT_STRING_FORMAT)}]", labelpad=2)
+ax_cartesian.set_ylabel(f"y [{u.kpc.to_string(UNIT_STRING_FORMAT)}]", labelpad=-4)
 ax_cartesian.plot(
     0, 8, color="k", markersize=10, fillstyle="none", marker="*", linewidth=2
 )
 ax_cartesian.annotate(
     "Sun",
     xy=(0, 8),
     xycoords="data",
```

### Comparing `gammapy-1.0rc2/docs/user-guide/astro/source/plot_pwn_evolution.py` & `gammapy-1.1rc1/docs/user-guide/astro/source/plot_pwn_evolution.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/astro/source/plot_snr_brightness_evolution.py` & `gammapy-1.1rc1/docs/user-guide/astro/source/plot_snr_brightness_evolution.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/astro/source/plot_snr_radius_evolution.py` & `gammapy-1.1rc1/docs/user-guide/astro/source/plot_snr_radius_evolution.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/catalog.rst` & `gammapy-1.1rc1/docs/user-guide/catalog.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/datasets/index.rst` & `gammapy-1.1rc1/docs/user-guide/datasets/index.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/datasets/plot_stack.py` & `gammapy-1.1rc1/docs/user-guide/datasets/plot_stack.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/dl3.rst` & `gammapy-1.1rc1/docs/user-guide/dl3.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/estimators.rst` & `gammapy-1.1rc1/docs/user-guide/estimators.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/hli.rst` & `gammapy-1.1rc1/docs/user-guide/hli.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/howto.rst` & `gammapy-1.1rc1/docs/user-guide/howto.rst`

 * *Files 5% similar despite different names*

```diff
@@ -26,37 +26,37 @@
 the english word "pie". You can listen to it `here <http://ipa-reader.xyz/?text=ˈ%C9%A1æməpaɪ&voice=Amy>`__.
 
 .. accordion-footer::
 
 .. accordion-header::
     :id: collapseHowToTwo
     :title: Select observations
-    :link: ../tutorials/starting/analysis_2.html#Defining-the-datastore-and-selecting-observations
+    :link: ../tutorials/starting/analysis_2.html#defining-the-datastore-and-selecting-observations
 
 The `~gammapy.data.DataStore` provides access to a summary table of all observations available.
 It can be used to select observations with various criterion. You can for instance apply a cone search
 or also select observations based on other information available using the `~gammapy.data.ObservationTable.select_observations` method.
 
 .. accordion-footer::
 
 .. accordion-header::
     :id: collapseHowToThree
     :title: Make an on-axis equivalent livetime map
-    :link: ../tutorials/data/hess.html#On-axis-equivalent-livetime
+    :link: ../tutorials/data/hess.html#on-axis-equivalent-livetime
 
 The `~gammapy.data.DataStore` provides access to a summary table of all observations available.
 It can be used to select observations with various criterion. You can for instance apply a cone search
 or also select observations based on other information available using the `~gammapy.data.ObservationTable.select_observations` method.
 
 .. accordion-footer::
 
 .. accordion-header::
     :id: collapseHowToFour
     :title: Check IRFs
-    :link: ../tutorials/data/cta.html#IRFs
+    :link: ../tutorials/data/cta.html#irfs
 
 Gammapy offers a number of methods to explore the content of the various IRFs
 contained in an observation. This is usually done thanks to their ``peek()``
 methods.
 
 .. accordion-footer::
 
@@ -100,68 +100,90 @@
 :ref:`datasets` for an overview of fit statistics used.
 
 .. accordion-footer::
 
 .. accordion-header::
     :id: collapseHowToSeven
     :title: Compute cumulative significance
-    :link: ../tutorials/analysis/1D/spectral_analysis.html#Source-statistic
+    :link: ../tutorials/analysis-1d/spectral_analysis.html#source-statistic
 
 A classical plot in gamma-ray astronomy is the cumulative significance of a
 source as a function of observing time. In Gammapy, you can produce it with 1D
 (spectral) analysis. Once datasets are produced for a given ON region, you can
 access the total statistics with the ``info_table(cumulative=True)`` method of
 `~gammapy.datasets.Datasets`.
 
 .. accordion-footer::
 
 .. accordion-header::
     :id: collapseHowToEight
     :title: Implement a custom model
-    :link: ../tutorials/api/models.html#Implementing-a-Custom-Model
+    :link: ../tutorials/api/models.html#implementing-a-custom-model
 
 Gammapy allows the flexibility of using user-defined models for analysis.
 
 .. accordion-footer::
 
 .. accordion-header::
     :id: collapseHowToNine
-    :title: Energy dependent spatial models
-    :link: ../tutorials/api/models.html#Models-with-energy-dependent-morphology
+    :title: Implement energy dependent spatial models
+    :link: ../tutorials/api/models.html#models-with-energy-dependent-morphology
 
 While Gammapy does not ship energy dependent spatial models, it is possible to define
 such models within the modeling framework.
 
 .. accordion-footer::
 
 .. accordion-header::
     :id: collapseHowToTen
-    :title: How to model astrophysical source spectra
+    :title: Model astrophysical source spectra
 
 It is possible to combine Gammapy with astrophysical modeling codes, if they
 provide a Python interface. Usually this requires some glue code to be written,
 e.g. `~gammapy.modeling.models.NaimaSpectralModel` is an example of a Gammapy
 wrapper class around the Naima spectral model and radiation classes, which then
 allows modeling and fitting of Naima models within Gammapy (e.g. using CTA,
 H.E.S.S. or Fermi-LAT data).
 
 .. accordion-footer::
 
 .. accordion-header::
     :id: collapseSHowToEleven
-    :title: How to model temporal profiles
-    :link: ../tutorials/analysis/time/light_curve_simulation.html#Fitting-temporal-models
+    :title: Model temporal profiles
+    :link: ../tutorials/analysis-time/light_curve_simulation.html#fitting-temporal-models
 
 Temporal models can be directly fit on available lightcurves,
 or on the reduced datasets. This is done through a joint fitting of the datasets,
 one for each time bin.
 
 .. accordion-footer::
 
 .. accordion-header::
+    :id: collapseHowToOne
+    :title: Improve fit convergence with constraints on the source position
+
+It happens that a 3D fit does not converge with warning messages indicating that the
+scanned positions of the model are outside the valid IRF map range. The type of warning message is:
+::
+
+    Position <SkyCoord (ICRS): (ra, dec) in deg
+      (329.71693826, -33.18392464)> is outside valid IRF map range, using nearest IRF defined within
+
+This issue might happen when the position of a model has no defined range. The minimizer
+might scan positions outside the spatial range in which the IRFs are computed and then it gets lost.
+
+The simple solution is to add a physically-motivated range on the model's position, e.g. within
+the field of view or around an excess position. Most of the time, this tip solves the issue.
+The documentation of the
+`models sub-package <https://docs.gammapy.org/1.0/tutorials/api/models.html#modifying-model-parameters>`_
+explains how to add a validity range of a model parameter.
+
+.. accordion-footer::
+
+.. accordion-header::
     :id: collapseHowToTwelve
     :title: Reduce memory budget for large datasets
 
 When dealing with surveys and large sky regions, the amount of memory required might become
 problematic, in particular because of the default settings of the IRF maps stored in the
 `~gammapy.datasets.MapDataset` used for the data reduction. Several options can be used to reduce
 the required memory:
@@ -187,15 +209,15 @@
 and build the associated observation and HDU tables.
 
 .. accordion-footer::
 
 .. accordion-header::
     :id: collapseHowToFourteen
     :title: Interpolate onto a different geometry
-    :link: ../tutorials/api/maps.html#Filling-maps-from-interpolation
+    :link: ../tutorials/api/maps.html#filling-maps-from-interpolation
 
 To interpolate maps onto a different geometry use `~gammapy.maps.Map.interp_to_geom`.
 
 .. accordion-footer::
 
 .. accordion-header::
     :id: collapseHowToFifteen
@@ -216,15 +238,15 @@
         warnings.simplefilter('ignore', VerifyWarning)
         # do stuff here
 
 .. accordion-footer::
 
 .. accordion-header::
     :id: collapseHowToSixteen
-    :title: Displaying a progress bar
+    :title: Display a progress bar
 
 Gammapy provides the possibility of displaying a
 progress bar to monitor the advancement of time-consuming processes. To activate this
 functionality, make sure that `tqdm` is installed and add the following code snippet
 to your code:
 
 .. testcode::
@@ -232,15 +254,15 @@
     from gammapy.utils import pbar
     pbar.SHOW_PROGRESS_BAR = True
 
 .. accordion-footer::
 
 .. accordion-header::
     :id: collapseHowToSeventeen
-    :title: Changing plotting style and color-blind friendly visualizations
+    :title: Change plotting style and color-blind friendly visualizations
 
 As the Gammapy visualisations are using the library `matplotlib` that provides color styles, it is possible to change the
 default colors map of the Gammapy plots. Using using the
 `style sheet of matplotlib <https://matplotlib.org/stable/gallery/style_sheets/style_sheets_reference.html>`_, you
 should add into your notebooks or scripts the following lines after the Gammapy imports:
 
 .. code::
```

### Comparing `gammapy-1.0rc2/docs/user-guide/index.rst` & `gammapy-1.1rc1/docs/user-guide/index.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/irf/aeff.rst` & `gammapy-1.1rc1/docs/user-guide/irf/aeff.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/irf/bkg.rst` & `gammapy-1.1rc1/docs/user-guide/irf/bkg.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/irf/edisp.rst` & `gammapy-1.1rc1/docs/user-guide/irf/edisp.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/irf/index.rst` & `gammapy-1.1rc1/docs/user-guide/irf/index.rst`

 * *Files 1% similar despite different names*

```diff
@@ -96,15 +96,15 @@
     :add-heading:
 
 
 .. minigallery:: gammapy.irf.EDispKernelMap
     :add-heading:
 
 
-.. minigallery:: gammapy.irf.load_cta_irfs
+.. minigallery:: gammapy.irf.load_irf_dict_from_file
     :add-heading:
 
 
 .. toctree::
     :maxdepth: 1
     :hidden:
```

### Comparing `gammapy-1.0rc2/docs/user-guide/irf/psf.rst` & `gammapy-1.1rc1/docs/user-guide/irf/psf.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/makers/create_region.py` & `gammapy-1.1rc1/docs/user-guide/makers/create_region.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/makers/fov.rst` & `gammapy-1.1rc1/docs/user-guide/makers/fov.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/makers/index.rst` & `gammapy-1.1rc1/docs/user-guide/makers/index.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/makers/make_rectangular_reflected_background.py` & `gammapy-1.1rc1/docs/user-guide/makers/make_rectangular_reflected_background.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/makers/make_reflected_regions.py` & `gammapy-1.1rc1/docs/user-guide/makers/make_reflected_regions.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/makers/reflected.rst` & `gammapy-1.1rc1/docs/user-guide/makers/reflected.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/makers/ring.rst` & `gammapy-1.1rc1/docs/user-guide/makers/ring.rst`

 * *Files 6% similar despite different names*

```diff
@@ -32,38 +32,39 @@
 classed. These classes can only be used for image based data.
 A given `MapDataset` has to be reduced to a single image by calling
 `MapDataset.to_image()`
 
 .. testcode::
 
 	from gammapy.makers import MapDatasetMaker, RingBackgroundMaker, SafeMaskMaker
-	from gammapy.datasets import MapDataset
+	from gammapy.datasets import MapDataset, MapDatasetOnOff
 	from gammapy.data import DataStore
 	from gammapy.maps import MapAxis, WcsGeom, Map
 	from regions import CircleSkyRegion
 	from astropy import units as u
 
 	data_store = DataStore.from_dir("$GAMMAPY_DATA/hess-dl3-dr1")
 	observations = data_store.get_observations([23592, 23559])
 
 	energy_axis = MapAxis.from_energy_bounds("1 TeV", "10 TeV", nbin=1)
 	energy_axis_true = MapAxis.from_energy_bounds("0.3 TeV", "30 TeV", nbin=20, per_decade=True, name="energy_true")
 
 	geom = WcsGeom.create(skydir=(83.63, 22.01), axes=[energy_axis], width=5, binsz=0.02)
 
-	stacked = MapDataset.create(geom, energy_axis_true=energy_axis_true)
+	empty = MapDataset.create(geom, energy_axis_true=energy_axis_true)
+	stacked = MapDatasetOnOff.create(geom, energy_axis_true=energy_axis_true)
 
 	maker = MapDatasetMaker()
 	safe_mask_maker = SafeMaskMaker(
 		methods=["aeff-default", "offset-max"], offset_max="2.5 deg"
 	)
 
 	circle = CircleSkyRegion(center=geom.center_skydir, radius=0.2 * u.deg)
 	exclusion_mask = geom.region_mask([circle], inside=False)
 
 	ring_bkg_maker = RingBackgroundMaker(r_in="0.3 deg", width="0.3 deg", exclusion_mask=exclusion_mask)
 
 	for obs in observations:
-		dataset = maker.run(stacked, obs)
+		dataset = maker.run(empty, obs)
 		dataset = safe_mask_maker.run(dataset, obs)
 		dataset_on_off = ring_bkg_maker.run(dataset)
 		stacked.stack(dataset_on_off)
```

### Comparing `gammapy-1.0rc2/docs/user-guide/maps/hpxmap.rst` & `gammapy-1.1rc1/docs/user-guide/maps/hpxmap.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/maps/index.rst` & `gammapy-1.1rc1/docs/user-guide/maps/index.rst`

 * *Files 4% similar despite different names*

```diff
@@ -38,33 +38,14 @@
 map uses WCS or HEALPix pixelization). For applications which do depend on the
 specific representation one can also work directly with the classes derived from
 `~Map`. In the following we review some of the basic methods for working with
 map objects, more details are given in the :doc:`/tutorials/api/maps`
 tutorial.
 
 
-.. _node_types:
-
-Differential and integral maps
-------------------------------
-
-`gammapy.maps` supports both differential and integral maps, representing
-differential values at specific coordinates, or integral values within bins.
-This is achieved by specifying the ``node_type`` of a `~gammapy.maps.MapAxis`. Quantities
-defined at bin centers should have a node_type of "center", and quantities
-integrated in bins should have node_type of ``edges``. Interpolation is defined
-only for differential quantities.
-
-For the specific case of the energy axis, conventionally, true energies are have
-node_type "center" (usually used for IRFs and exposure) whereas the
-reconstructed energy axis has node_type "edges" (usually used for counts and
-background). Model evaluations are first computed on differential bins, and then
-multiplied by the bin volumes to finally return integrated maps, so the output
-predicted counts maps are integral with node_type "edges".
-
 
 Accessor methods
 ----------------
 
 All map objects have a set of accessor methods provided through the abstract
 `~Map` class. These methods can be used to access or update the contents of the
 map irrespective of its underlying representation. Four types of accessor
```

### Comparing `gammapy-1.0rc2/docs/user-guide/maps/regionmap.rst` & `gammapy-1.1rc1/docs/user-guide/maps/regionmap.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/modeling.rst` & `gammapy-1.1rc1/docs/user-guide/modeling.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/package.rst` & `gammapy-1.1rc1/docs/user-guide/package.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/references.rst` & `gammapy-1.1rc1/docs/user-guide/references.rst`

 * *Files 1% similar despite different names*

```diff
@@ -13,15 +13,15 @@
 --------
 
 .. glossary::
 
     1D Analysis
       1D analysis or spectral analysis where data are reduced to a simple 1D
       geometry along the reconstructed energy axis. In Cherenkov astronomy,
-      this is classically performed with an OFF background measurement [Piron2001]_.
+      this is classically performed with an OFF background measurement, see WStat.
 
     3D Analysis
       3D analysis or cube analysis, where data are reduced to a 3D cube with
       spatial coordinates and energy axes [Stewart2009]_. In Gammapy, these cube are
       represented by `Map` objects (see :ref:`maps`) and contained in a `MapDataset` object.
 
     Aeff
@@ -29,16 +29,16 @@
       area. See :ref:`irf` and :ref:`irf-aeff`.
 
     Bkg
       Short for "background": it is the IRF representing the residual background rate
       per solid angle. See :ref:`irf` and :ref:`irf-bkg`.
 
     Cash
-      The cash statistic is a Poisson fit statistic usually used when signal and
-      background can be modeled [Cash1979]_. It is defined as :math:`2 \times log(L)`. See
+      The Cash statistic is a Poisson fit statistic usually used when signal and
+      background can be modeled. It is defined as :math:`2 \times log(L)`. See
       :ref:`cash` in :ref:`fit statistics <fit-statistics>`.
 
     Dataset
       In Gammapy a dataset bundles the data, IRFs, model and a likelihood function.
       Based on the model and IRFs the predicted number of counts are computed and
       compared to the measured counts using the likelihood. See :ref:`datasets`
```

### Comparing `gammapy-1.0rc2/docs/user-guide/scripts/index.rst` & `gammapy-1.1rc1/docs/user-guide/scripts/index.rst`

 * *Files 0% similar despite different names*

```diff
@@ -73,15 +73,14 @@
       -h, --help                      Show this message and exit.
 
       Commands:
       analysis  Automation of configuration driven data reduction process.
       check     Run checks for Gammapy
       download  Download datasets and notebooks
       info      Display information about Gammapy
-      jupyter   Perform actions on notebooks
 
 All CLI functionality for Gammapy is implemented as sub-commands of the main
 ``gammapy`` command. If a command has sub-commands, they are listed in the help
 output. E.g. the help output from ``gammapy`` above shows that there is a
 sub-command called ``gammapy analysis``. Actually, ``gammapy analysis`` itself isn't a
 command that does something, but another command group that is used to group
 sub-commands.
```

### Comparing `gammapy-1.0rc2/docs/user-guide/scripts/significance.py` & `gammapy-1.1rc1/docs/user-guide/scripts/significance.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/stats/fit_statistics.rst` & `gammapy-1.1rc1/docs/user-guide/stats/fit_statistics.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/stats/index.rst` & `gammapy-1.1rc1/docs/user-guide/stats/index.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/stats/plot_cash_errors.py` & `gammapy-1.1rc1/docs/user-guide/stats/plot_cash_errors.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/stats/plot_cash_significance.py` & `gammapy-1.1rc1/docs/user-guide/stats/plot_cash_significance.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/stats/plot_wstat_errors.py` & `gammapy-1.1rc1/docs/user-guide/stats/plot_wstat_errors.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/stats/plot_wstat_significance.py` & `gammapy-1.1rc1/docs/user-guide/stats/plot_wstat_significance.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/stats/wstat_derivation.rst` & `gammapy-1.1rc1/docs/user-guide/stats/wstat_derivation.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/utils.rst` & `gammapy-1.1rc1/docs/user-guide/utils.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/visualization/colormap_example.py` & `gammapy-1.1rc1/docs/user-guide/visualization/colormap_example.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/docs/user-guide/visualization/index.rst` & `gammapy-1.1rc1/docs/user-guide/visualization/index.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/environment-dev.yml` & `gammapy-1.1rc1/environment-dev.yml`

 * *Files 18% similar despite different names*

```diff
@@ -12,35 +12,34 @@
   - sherpa
 
 variables:
   PYTHONNOUSERSITE: "1"
 
 dependencies:
   # core dependencies
-  - python=3.8
+  - python=3.9
   - pip
   - astropy
   - click
   - cython
-  - numpy<1.23
+  - numpy>1.20
   - pydantic
   - pyyaml
   - regions>=0.5
   - matplotlib>=3.4
-  - scipy
+  - scipy!=1.10
   - iminuit>=2.8.0
   - extension-helpers
   # test dependencies
   - codecov
   - pytest=6
   - pytest-astropy
   - pytest-cov
   - pytest-xdist
-  - coverage=6.2
-  - pytest-xdist
+  - coverage
   - requests
   - tqdm
   # extra dependencies
   - healpy
   - ipython
   - jupyter
   - jupyterlab
@@ -49,30 +48,35 @@
   - reproject
   - sherpa
   # dev dependencies
   - black
   - codespell
   - flake8
   - isort
-  - jinja2=3.0
+  - jinja2
   - nbsphinx
   - numdifftools
   - pandoc
   - pydocstyle
   - pylint
   - setuptools_scm
   - sphinx
   - sphinx-astropy
   - sphinx-click
-  - sphinx-gallery
+  - sphinx-gallery<0.13
   - sphinx-panels
   - sphinx-copybutton
   - tox
   - pydata-sphinx-theme==0.8.1
   - pre-commit
   - twine
   - yamllint
   - nbformat
   - h5py
   - ruamel.yaml
+  - cffconvert
+  - pyinstrument
+  - memray
   - pip:
       - pytest-sphinx
+      - ray
+      - PyGithub
```

### Comparing `gammapy-1.0rc2/examples/README.rst` & `gammapy-1.1rc1/examples/README.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/README.txt` & `gammapy-1.1rc1/examples/models/README.txt`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/spatial/plot_constant.py` & `gammapy-1.1rc1/examples/models/spatial/plot_constant.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/spatial/plot_disk.py` & `gammapy-1.1rc1/examples/models/spatial/plot_disk.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/spatial/plot_gauss.py` & `gammapy-1.1rc1/examples/models/spatial/plot_gauss.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/spatial/plot_gen_gauss.py` & `gammapy-1.1rc1/examples/models/spatial/plot_gen_gauss.py`

 * *Files 8% similar despite different names*

```diff
@@ -19,15 +19,15 @@
 where :math:`\Gamma` is the gamma function.
 This analytical norm is approximated so it may not integrate to unity in extreme cases
 if ellipticity tend to one and radius is large or :math:`\eta` much larger than one (outside the default range).
 
 The effective radius is given by:
 
 .. math::
-    \r_{rm eff}(\text{lon}, \text{lat}) = \sqrt{
+    r_{rm eff}(\text{lon}, \text{lat}) = \sqrt{
         (r_M \sin(\Delta \phi))^2 +
         (r_m \cos(\Delta \phi))^2
     }.
 
 where :math:`r_M` (:math:`r_m`) is the major (minor) semiaxis, and
 :math:`\Delta \phi` is the difference between `phi`, the position angle of the model, and the
 position angle of the evaluation point.
```

### Comparing `gammapy-1.0rc2/examples/models/spatial/plot_point.py` & `gammapy-1.1rc1/examples/models/spatial/plot_point.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/spatial/plot_shell.py` & `gammapy-1.1rc1/examples/models/spatial/plot_shell.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/spatial/plot_shell2.py` & `gammapy-1.1rc1/examples/models/spatial/plot_shell2.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/spatial/plot_template.py` & `gammapy-1.1rc1/examples/models/spatial/plot_template.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/spectral/plot_absorbed.py` & `gammapy-1.1rc1/examples/models/spectral/plot_absorbed.py`

 * *Files 11% similar despite different names*

```diff
@@ -11,14 +11,16 @@
 .. math::
     \exp{ \left ( -\alpha \times \tau(E, z) \right )}
 
 where :math:`\tau(E, z)` is the optical depth predicted by the model
 (`~gammapy.modeling.models.EBLAbsorptionNormSpectralModel`), which depends on the energy of the gamma-rays and the
 redshift z of the source, and :math:`\alpha` is a scale factor
 (default: 1) for the optical depth.
+
+The available EBL models are defined in `~gammapy.modeling.models.spectral.EBL_DATA_BUILTIN`.
 """
 
 # %%
 # Example plot
 # ------------
 # Here is an example plot of the model:
 
@@ -26,35 +28,47 @@
 import matplotlib.pyplot as plt
 from gammapy.modeling.models import (
     EBLAbsorptionNormSpectralModel,
     Models,
     PowerLawSpectralModel,
     SkyModel,
 )
+from gammapy.modeling.models.spectral import EBL_DATA_BUILTIN
+
+# Print the available EBL models
+print(EBL_DATA_BUILTIN.keys())
 
 # Here we illustrate how to create and plot EBL absorption models for a redshift of 0.5
 # sphinx_gallery_thumbnail_number = 1
 
 redshift = 0.5
 dominguez = EBLAbsorptionNormSpectralModel.read_builtin("dominguez", redshift=redshift)
 franceschini = EBLAbsorptionNormSpectralModel.read_builtin(
     "franceschini", redshift=redshift
 )
 finke = EBLAbsorptionNormSpectralModel.read_builtin("finke", redshift=redshift)
+franceschini17 = EBLAbsorptionNormSpectralModel.read_builtin(
+    "franceschini17", redshift=redshift
+)
+saldana21 = EBLAbsorptionNormSpectralModel.read_builtin(
+    "saldana-lopez21", redshift=redshift
+)
 
 fig, (ax_ebl, ax_model) = plt.subplots(
     nrows=1, ncols=2, figsize=(10, 4), gridspec_kw={"left": 0.08, "right": 0.96}
 )
 
 energy_bounds = [0.08, 3] * u.TeV
 opts = dict(energy_bounds=energy_bounds, xunits=u.TeV)
 
 franceschini.plot(ax=ax_ebl, label="Franceschini 2008", **opts)
 finke.plot(ax=ax_ebl, label="Finke 2010", **opts)
 dominguez.plot(ax=ax_ebl, label="Dominguez 2011", **opts)
+franceschini17.plot(ax=ax_ebl, label="Franceschni 2017", **opts)
+saldana21.plot(ax=ax_ebl, label="Saldana-Lopez 2021", **opts)
 
 ax_ebl.set_ylabel(r"Absorption coefficient [$\exp{(-\tau(E))}$]")
 ax_ebl.set_xlim(energy_bounds.value)
 ax_ebl.set_ylim(1e-4, 2)
 ax_ebl.set_title(f"EBL models (z={redshift})")
 ax_ebl.grid(which="both")
 ax_ebl.legend(loc="best")
```

### Comparing `gammapy-1.0rc2/examples/models/spectral/plot_broken_powerlaw.py` & `gammapy-1.1rc1/examples/models/spectral/plot_broken_powerlaw.py`

 * *Files 8% similar despite different names*

```diff
@@ -5,15 +5,15 @@
 ===============================
 
 This model parametrises a broken power law spectrum.
 
 It is defined by the following equation:
 
 .. math::
-    \phi(E) = phi_0 \cdot \begin{cases}
+    \phi(E) = \phi_0 \cdot \begin{cases}
                           \left( \frac{E}{E_{break}} \right)^{-\Gamma1} & \text{if } E < E_{break} \\
                           \left( \frac{E}{E_{break}} \right)^{-\Gamma2} & \text{otherwise}
                          \end{cases}
     """
 
 # %%
 # Example plot
```

### Comparing `gammapy-1.0rc2/examples/models/spectral/plot_compound.py` & `gammapy-1.1rc1/examples/models/spectral/plot_compound.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/spectral/plot_constant_spectral.py` & `gammapy-1.1rc1/examples/models/spectral/plot_constant_spectral.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/spectral/plot_exp_cutoff_powerlaw.py` & `gammapy-1.1rc1/examples/models/spectral/plot_exp_cutoff_powerlaw.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/spectral/plot_exp_cutoff_powerlaw_3fgl.py` & `gammapy-1.1rc1/examples/models/spectral/plot_exp_cutoff_powerlaw_3fgl.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/spectral/plot_gauss_spectral.py` & `gammapy-1.1rc1/examples/models/spectral/plot_gauss_spectral.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/spectral/plot_logparabola.py` & `gammapy-1.1rc1/examples/models/spectral/plot_logparabola.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/spectral/plot_naima.py` & `gammapy-1.1rc1/examples/models/spectral/plot_naima.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/spectral/plot_piecewise_norm_spectral.py` & `gammapy-1.1rc1/examples/models/spectral/plot_piecewise_norm_spectral.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/spectral/plot_powerlaw.py` & `gammapy-1.1rc1/examples/models/spectral/plot_powerlaw.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/spectral/plot_powerlaw2.py` & `gammapy-1.1rc1/examples/models/spectral/plot_powerlaw2.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/spectral/plot_smooth_broken_powerlaw.py` & `gammapy-1.1rc1/examples/models/spectral/plot_smooth_broken_powerlaw.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/spectral/plot_super_exp_cutoff_powerlaw_3fgl.py` & `gammapy-1.1rc1/examples/models/spectral/plot_super_exp_cutoff_powerlaw_3fgl.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/spectral/plot_super_exp_cutoff_powerlaw_4fgl.py` & `gammapy-1.1rc1/examples/models/spectral/plot_super_exp_cutoff_powerlaw_4fgl_dr1.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,48 +1,41 @@
 r"""
-.. _super-exp-cutoff-powerlaw-4fgl-dr3-spectral-model:
+.. _super-exp-cutoff-powerlaw-4fgl-spectral-model:
 
-Super Exponential Cutoff Power Law Model used for 4FGL-DR3
-==========================================================
+Super Exponential Cutoff Power Law Model used for 4FGL-DR1 (and DR2)
+====================================================================
 
 This model parametrises super exponential cutoff power-law model spectrum used for 4FGL.
 
 It is defined by the following equation:
 
 .. math::
+    \phi(E) = \phi_0 \cdot \left(\frac{E}{E_0}\right)^{-\Gamma_1}
+              \exp \left(
+                  a \left( E_0 ^{\Gamma_2} - E^{\Gamma_2} \right)
+              \right)
 
-
-    \phi(e) =
-            \begin{cases}
-                \phi_0 \cdot \left(\frac{E}{E_0}\right)^{\frac{\a}{\Gamma_2} -\Gamma_1} \cdot \exp \left(
-                  \frac{\a}{\Gamma_2^2} \left( 1 - \left(\frac{E}{E_0}\right)^{\frac{\a}{\Gamma_2} \right)
-              \right)&
-                              \\
-                \phi_0 \cdot \left(\frac{E}{E_0}\right)^{ -\Gamma_1 - \frac{\a}{2} \ln \frac{E}{E_0} - \frac{\a \Gamma_2}{6} \ln^2 \frac{E}{E_0} - \frac{\a \Gamma_2^2}{24} \ln^3 \frac{E}{E_0}}\\
-                0 & \text{for } \left| \Gamma_2 \ln \frac{E}{E_0}  \right|
-            \end{cases}
-
-See Equation (2) and (3) in https://arxiv.org/pdf/2201.11184.pdf
+See Equation (4) in https://arxiv.org/pdf/1902.10045.pdf
 """
 
 # %%
 # Example plot
 # ------------
 # Here is an example plot of the model:
 
 from astropy import units as u
 import matplotlib.pyplot as plt
 from gammapy.modeling.models import (
     Models,
     SkyModel,
-    SuperExpCutoffPowerLaw4FGLDR3SpectralModel,
+    SuperExpCutoffPowerLaw4FGLSpectralModel,
 )
 
 energy_range = [0.1, 100] * u.TeV
-model = SuperExpCutoffPowerLaw4FGLDR3SpectralModel(
+model = SuperExpCutoffPowerLaw4FGLSpectralModel(
     index_1=1,
     index_2=2,
     amplitude="1e-12 TeV-1 cm-2 s-1",
     reference="1 TeV",
     expfactor=1e-2,
 )
 model.plot(energy_range)
@@ -50,11 +43,11 @@
 plt.ylim(1e-24, 1e-10)
 
 # %%
 # YAML representation
 # -------------------
 # Here is an example YAML file using the model:
 
-model = SkyModel(spectral_model=model, name="super-exp-cutoff-power-law-4fgl-dr3-model")
+model = SkyModel(spectral_model=model, name="super-exp-cutoff-power-law-4fgl-model")
 models = Models([model])
 
 print(models.to_yaml())
```

### Comparing `gammapy-1.0rc2/examples/models/spectral/plot_super_exp_cutoff_powerlaw_4fgl_dr1.py` & `gammapy-1.1rc1/examples/models/spectral/plot_super_exp_cutoff_powerlaw_4fgl.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,41 +1,39 @@
 r"""
-.. _super-exp-cutoff-powerlaw-4fgl-spectral-model:
+.. _super-exp-cutoff-powerlaw-4fgl-dr3-spectral-model:
 
-Super Exponential Cutoff Power Law Model used for 4FGL-DR1 (and DR2)
-====================================================================
+Super Exponential Cutoff Power Law Model used for 4FGL-DR3
+==========================================================
 
 This model parametrises super exponential cutoff power-law model spectrum used for 4FGL.
 
 It is defined by the following equation:
 
 .. math::
-    \phi(E) = \phi_0 \cdot \left(\frac{E}{E_0}\right)^{-\Gamma_1}
-              \exp \left(
-                  a \left( E_0 ^{\Gamma_2} - E^{\Gamma_2} \right)
-              \right)
 
-See Equation (4) in https://arxiv.org/pdf/1902.10045.pdf
+    \phi(E) = \begin{cases} \phi_0 \cdot \left(\frac{E}{E_0}\right)^{\frac{a}{\Gamma_2} -\Gamma_1} \cdot \exp \left( \frac{a}{\Gamma_2^2}\left( 1 - \left(\frac{E}{E_0}\right)^{\Gamma_2} \right) \right) \\ \phi_0 \cdot \left(\frac{E}{E_0}\right)^{ -\Gamma_1 - \frac{a}{2} \ln \frac{E}{E_0} - \frac{a \Gamma_2}{6} \ln^2 \frac{E}{E_0} - \frac{a \Gamma_2^2}{24} \ln^3 \frac{E}{E_0}} & \text{for } \left| \Gamma_2 \ln \frac{E}{E_0} \right| < 10^{-2} \end{cases}
+
+See Equation (2) and (3) in https://arxiv.org/pdf/2201.11184.pdf
 """
 
 # %%
 # Example plot
 # ------------
 # Here is an example plot of the model:
 
 from astropy import units as u
 import matplotlib.pyplot as plt
 from gammapy.modeling.models import (
     Models,
     SkyModel,
-    SuperExpCutoffPowerLaw4FGLSpectralModel,
+    SuperExpCutoffPowerLaw4FGLDR3SpectralModel,
 )
 
 energy_range = [0.1, 100] * u.TeV
-model = SuperExpCutoffPowerLaw4FGLSpectralModel(
+model = SuperExpCutoffPowerLaw4FGLDR3SpectralModel(
     index_1=1,
     index_2=2,
     amplitude="1e-12 TeV-1 cm-2 s-1",
     reference="1 TeV",
     expfactor=1e-2,
 )
 model.plot(energy_range)
@@ -43,11 +41,11 @@
 plt.ylim(1e-24, 1e-10)
 
 # %%
 # YAML representation
 # -------------------
 # Here is an example YAML file using the model:
 
-model = SkyModel(spectral_model=model, name="super-exp-cutoff-power-law-4fgl-model")
+model = SkyModel(spectral_model=model, name="super-exp-cutoff-power-law-4fgl-dr3-model")
 models = Models([model])
 
 print(models.to_yaml())
```

### Comparing `gammapy-1.0rc2/examples/models/spectral/plot_template_spectral.py` & `gammapy-1.1rc1/examples/models/spectral/plot_template_spectral.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/temporal/plot_constant_temporal.py` & `gammapy-1.1rc1/examples/models/temporal/plot_constant_temporal.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/temporal/plot_expdecay_temporal.py` & `gammapy-1.1rc1/examples/models/temporal/plot_expdecay_temporal.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/temporal/plot_gaussian_temporal.py` & `gammapy-1.1rc1/examples/models/temporal/plot_gaussian_temporal.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/temporal/plot_generalized_gaussian_temporal.py` & `gammapy-1.1rc1/examples/models/temporal/plot_generalized_gaussian_temporal.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/temporal/plot_linear_temporal.py` & `gammapy-1.1rc1/examples/models/temporal/plot_linear_temporal.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/temporal/plot_powerlaw_temporal.py` & `gammapy-1.1rc1/examples/models/temporal/plot_powerlaw_temporal.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/temporal/plot_sine_temporal.py` & `gammapy-1.1rc1/examples/models/temporal/plot_sine_temporal.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/models/temporal/plot_template_phase_temporal.py` & `gammapy-1.1rc1/examples/models/temporal/plot_template_phase_temporal.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/tutorials/README.rst` & `gammapy-1.1rc1/examples/tutorials/README.rst`

 * *Files 23% similar despite different names*

```diff
@@ -2,14 +2,18 @@
 
 .. _tutorials:
 
 =========
 Tutorials
 =========
 
+**Notice :** it is
+advised to first read :ref:`package_structure` of the User Guide before using the
+tutorials.
+
 This page lists the Gammapy tutorials that are available as `Jupyter`_ notebooks.
 You can read them here, or execute them using a temporary cloud server in Binder.
 
 To execute them locally, you have to first install Gammapy locally (see
 :ref:`installation`) and download the tutorial notebooks and example datasets (see
 :ref:`getting-started`). Once Gammapy is installed, remember that you can always
 use ``gammapy info`` to check your setup.
```

### Comparing `gammapy-1.0rc2/examples/tutorials/analysis-1d/cta_sensitivity.py` & `gammapy-1.1rc1/examples/tutorials/analysis-1d/cta_sensitivity.py`

 * *Files 16% similar despite different names*

```diff
@@ -35,18 +35,19 @@
 # -----
 #
 # As usual, we’ll start with some setup …
 #
 from IPython.display import display
 from gammapy.data import Observation, observatory_locations
 from gammapy.datasets import SpectrumDataset, SpectrumDatasetOnOff
-from gammapy.estimators import SensitivityEstimator
-from gammapy.irf import load_cta_irfs
+from gammapy.estimators import FluxPoints, SensitivityEstimator
+from gammapy.irf import load_irf_dict_from_file
 from gammapy.makers import SpectrumDatasetMaker
 from gammapy.maps import MapAxis, RegionGeom
+from gammapy.maps.axes import UNIT_STRING_FORMAT
 
 ######################################################################
 # Check setup
 # -----------
 from gammapy.utils.check import check_tutorials_setup
 
 check_tutorials_setup()
@@ -74,21 +75,22 @@
 ######################################################################
 # Load IRFs and prepare dataset
 # -----------------------------
 #
 # We extract the 1D IRFs from the full 3D IRFs provided by CTA.
 #
 
-irfs = load_cta_irfs(
+irfs = load_irf_dict_from_file(
     "$GAMMAPY_DATA/cta-1dc/caldb/data/cta/1dc/bcf/South_z20_50h/irf_file.fits"
 )
 location = observatory_locations["cta_south"]
 pointing = SkyCoord("0 deg", "0 deg")
+livetime = 5.0 * u.h
 obs = Observation.create(
-    pointing=pointing, irfs=irfs, livetime="5 h", location=location
+    pointing=pointing, irfs=irfs, livetime=livetime, location=location
 )
 
 spectrum_maker = SpectrumDatasetMaker(selection=["exposure", "edisp", "background"])
 dataset = spectrum_maker.run(empty_dataset, obs)
 
 
 ######################################################################
@@ -152,60 +154,91 @@
 # Plot the sensitivity curve
 t = sensitivity_table
 
 is_s = t["criterion"] == "significance"
 
 fig, ax = plt.subplots()
 ax.plot(
-    t["energy"][is_s],
+    t["e_ref"][is_s],
     t["e2dnde"][is_s],
     "s-",
     color="red",
     label="significance",
 )
 
 is_g = t["criterion"] == "gamma"
-ax.plot(t["energy"][is_g], t["e2dnde"][is_g], "*-", color="blue", label="gamma")
+ax.plot(t["e_ref"][is_g], t["e2dnde"][is_g], "*-", color="blue", label="gamma")
 is_bkg_syst = t["criterion"] == "bkg"
 ax.plot(
-    t["energy"][is_bkg_syst],
+    t["e_ref"][is_bkg_syst],
     t["e2dnde"][is_bkg_syst],
     "v-",
     color="green",
     label="bkg syst",
 )
 
 ax.loglog()
-ax.set_xlabel(f"Energy ({t['energy'].unit})")
-ax.set_ylabel(f"Sensitivity ({t['e2dnde'].unit})")
+ax.set_xlabel(f"Energy [{t['e_ref'].unit.to_string(UNIT_STRING_FORMAT)}]")
+ax.set_ylabel(f"Sensitivity [{t['e2dnde'].unit.to_string(UNIT_STRING_FORMAT)}]")
 ax.legend()
+plt.show()
 
 
 ######################################################################
 # We add some control plots showing the expected number of background
 # counts per bin and the ON region size cut (here the 68% containment
 # radius of the PSF).
 #
 
 # Plot expected number of counts for signal and background
 fig, ax1 = plt.subplots()
-# ax1.plot( t["energy"], t["excess"],"o-", color="red", label="signal")
-ax1.plot(t["energy"], t["background"], "o-", color="black", label="blackground")
+# ax1.plot( t["e_ref"], t["excess"],"o-", color="red", label="signal")
+ax1.plot(t["e_ref"], t["background"], "o-", color="black", label="blackground")
 
 ax1.loglog()
-ax1.set_xlabel(f"Energy ({t['energy'].unit})")
+ax1.set_xlabel(f"Energy [{t['e_ref'].unit.to_string(UNIT_STRING_FORMAT)}]")
 ax1.set_ylabel("Expected number of bkg counts")
 
 ax2 = ax1.twinx()
-ax2.set_ylabel(f"ON region radius ({on_radii.unit})", color="red")
-ax2.semilogy(t["energy"], on_radii, color="red", label="PSF68")
+ax2.set_ylabel(
+    f"ON region radius [{on_radii.unit.to_string(UNIT_STRING_FORMAT)}]", color="red"
+)
+ax2.semilogy(t["e_ref"], on_radii, color="red", label="PSF68")
 ax2.tick_params(axis="y", labelcolor="red")
 ax2.set_ylim(0.01, 0.5)
 plt.show()
 
+######################################################################
+# Obtaining an integral flux sensitivity
+# --------------------------------------
+#
+# It is often useful to obtain the integral sensitivity above a certain
+# threshold. In this case, it is simplest to use a dataset with one energy bin
+# while setting the high energy edge to a very large value.
+# Here, we simply squash the previously created dataset into one with a single
+# energy
+#
+
+dataset_on_off1 = dataset_on_off.to_image()
+sensitivity_estimator = SensitivityEstimator(
+    gamma_min=5, n_sigma=3, bkg_syst_fraction=0.10
+)
+sensitivity_table = sensitivity_estimator.run(dataset_on_off1)
+print(sensitivity_table)
+
+# To get the integral flux, we convert to a `FluxPoints` object that does the conversion
+# internally
+
+flux_points = FluxPoints.from_table(
+    sensitivity_table, sed_type="e2dnde", reference_model=sensitivity_estimator.spectrum
+)
+print(
+    f"Integral sensitivity in {livetime:.2f} above {energy_axis.edges[0]:.2e} "
+    f"is {np.squeeze(flux_points.flux.quantity):.2e}"
+)
 
 ######################################################################
 # Exercises
 # ---------
 #
 # -  Also compute the sensitivity for a 20 hour observation
 # -  Compare how the sensitivity differs between 5 and 20 hours by
```

### Comparing `gammapy-1.0rc2/examples/tutorials/analysis-1d/extended_source_spectral_analysis.py` & `gammapy-1.1rc1/examples/tutorials/analysis-1d/extended_source_spectral_analysis.py`

 * *Files 2% similar despite different names*

```diff
@@ -6,26 +6,24 @@
 
 Prerequisites
 -------------
 
 -  Understanding of spectral analysis techniques in classical Cherenkov
    astronomy.
 -  Understanding the basic data reduction and modeling/fitting processes
-   with the gammapy library API as shown in the `first gammapy analysis
-   with the gammapy library API
-   tutorial :doc:`/tutorials/starting/analysis_2`
+   with the gammapy library API as shown in the tutorial :doc:`/tutorials/starting/analysis_2`
 
 Context
 -------
 
 Many VHE sources in the Galaxy are extended. Studying them with a 1D
 spectral analysis is more complex than studying point sources. One often
-has to use complex (i.e. non circular) regions and more importantly, one
-has to take into account the fact that the instrument response is non
-uniform over the selectred region. A typical example is given by the
+has to use complex (i.e. non-circular) regions and more importantly, one
+has to take into account the fact that the instrument response is non-uniform
+over the selected region. A typical example is given by the
 supernova remnant RX J1713-3935 which is nearly 1 degree in diameter.
 See the `following
 article <https://ui.adsabs.harvard.edu/abs/2018A%26A...612A...6H/abstract>`__.
 
 **Objective: Measure the spectrum of RX J1713-3945 in a 1 degree region
 fully enclosing it.**
 
@@ -34,31 +32,31 @@
 
 We have seen in the general presentation of the spectrum extraction for
 point sources (see :doc:`/tutorials/analysis-1d/spectral_analysis`
 tutorial) that Gammapy uses specific
 datasets makers to first produce reduced spectral data and then to
 extract OFF measurements with reflected background techniques: the
 `~gammapy.makers.SpectrumDatasetMaker` and the
-`~gammapy.makers.ReflectedRegionsBackgroundMaker`. However if the flag
+`~gammapy.makers.ReflectedRegionsBackgroundMaker`. However, if the flag
 `use_region_center` is not set to `False`, the former simply
 computes the reduced IRFs at the center of the ON region (assumed to be
 circular).
 
 This is no longer valid for extended sources. To be able to compute
 average responses in the ON region, we can set
 `use_region_center=False` with the
 `~gammapy.makers.SpectrumDatasetMaker`, in which case the values of
 the IRFs are averaged over the entire region.
 
-In summary we have to:
+In summary, we have to:
 
 -  Define an ON region (a `~regions.SkyRegion`) fully enclosing the
    source we want to study.
 -  Define a `~gammapy.maps.RegionGeom` with the ON region and the
-   required energy range (beware in particular, the true energy range).
+   required energy range (in particular, beware of the true energy range).
 -  Create the necessary makers :
 
    -  the spectrum dataset maker :
       `~gammapy.makers.SpectrumDatasetMaker` with
       `use_region_center=False`
    -  the OFF background maker, here a
       `~gammapy.makers.ReflectedRegionsBackgroundMaker`
@@ -244,14 +242,15 @@
 # Explore the results
 # -------------------
 #
 # We can peek at the content of the spectrum datasets
 #
 
 datasets[0].peek()
+plt.show()
 
 
 ######################################################################
 # Cumulative excess and signficance
 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 #
 # Finally, we can look at cumulative significance and number of excesses.
@@ -283,14 +282,15 @@
     marker="o",
     ls="none",
 )
 
 ax_sqrt_ts.set_title("Sqrt(TS)")
 ax_sqrt_ts.set_xlabel("Livetime [h]")
 ax_sqrt_ts.set_ylabel("Sqrt(TS)")
+plt.show()
 
 
 ######################################################################
 # Perform spectral model fitting
 # ------------------------------
 #
 # Here we perform a joint fit.
@@ -330,15 +330,15 @@
 # Then plot the fit result to compare measured and expected counts. Rather
 # than plotting them for each individual dataset, we stack all datasets
 # and plot the fit result on the result.
 #
 
 # First stack them all
 reduced = datasets.stack_reduce()
+
 # Assign the fitted model
 reduced.models = model
-# Plot the result
 
-plt.figure()
+# Plot the result
 ax_spectrum, ax_residuals = reduced.plot_fit()
 reduced.plot_masks(ax=ax_spectrum)
 plt.show()
```

### Comparing `gammapy-1.0rc2/examples/tutorials/analysis-1d/sed_fitting.py` & `gammapy-1.1rc1/examples/tutorials/analysis-1d/sed_fitting.py`

 * *Files 0% similar despite different names*

```diff
@@ -25,15 +25,15 @@
 points.**
 
 Proposed approach
 -----------------
 
 Here we will load, the spectral points from Fermi-LAT and TeV catalogs
 and fit them with various spectral models to find the best
-representation of the wide band spectrum.
+representation of the wide-band spectrum.
 
 The central class we’re going to use for this example analysis is:
 
 -  `~gammapy.datasets.FluxPointsDataset`
 
 In addition we will work with the following data classes:
```

### Comparing `gammapy-1.0rc2/examples/tutorials/analysis-1d/spectral_analysis.py` & `gammapy-1.1rc1/examples/tutorials/analysis-1d/spectral_analysis.py`

 * *Files 6% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 
 Prerequisites
 -------------
 
 -  Understanding how spectral extraction is performed in Cherenkov
    astronomy, in particular regarding OFF background measurements.
 -  Understanding the basics data reduction and modeling/fitting process
-   with the gammapy library API as shown in the `doc:`/tutorials/starting/analysis_2`
+   with the gammapy library API as shown in the :doc:`/tutorials/starting/analysis_2`
    tutorial.
 
 Context
 -------
 
 While 3D analyses allow in principle to consider complex field of views
 containing overlapping gamma-ray sources, in many cases we might have an
@@ -57,33 +57,43 @@
 We can then proceed with data reduction with a loop over all selected
 observations to produce datasets in the relevant geometry.
 
 We can then explore the resulting datasets and look at the cumulative
 signal and significance of our source. We finally proceed with model
 fitting.
 
-In practice, we have to: - Create a `~gammapy.data.DataStore` poiting
-to the relevant data - Apply an observation selection to produce a list
-of observations, a `~gammapy.data.Observations` object. - Define a
-geometry of the spectrum we want to produce: - Create a
-`~regions.CircleSkyRegion` for the ON extraction region - Create a
-`~gammapy.maps.MapAxis` for the energy binnings: one for the
-reconstructed (i.e. measured) energy, the other for the true energy
-(i.e. the one used by IRFs and models) - Create the necessary makers : -
-the spectrum dataset maker : `~gammapy.makers.SpectrumDatasetMaker` -
-the OFF background maker, here a
-`~gammapy.makers.ReflectedRegionsBackgroundMaker` - and the safe range
-maker : `~gammapy.makers.SafeMaskMaker` - Perform the data reduction
-loop. And for every observation: - Apply the makers sequentially to
-produce a `~gammapy.datasets.SpectrumDatasetOnOff` - Append it to list
-of datasets - Define the `~gammapy.modeling.models.SkyModel` to apply
-to the dataset. - Create a `~gammapy.modeling.Fit` object and run it
-to fit the model parameters - Apply a
-`~gammapy.estimators.FluxPointsEstimator` to compute flux points for
-the spectral part of the fit.
+In practice, we have to:
+
+- Create a `~gammapy.data.DataStore` pointing to the relevant data
+- Apply an observation selection to produce a list of observations,
+  a `~gammapy.data.Observations` object.
+- Define a geometry of the spectrum we want to produce:
+
+  - Create a `~regions.CircleSkyRegion` for the ON extraction region
+  - Create a `~gammapy.maps.MapAxis` for the energy binnings: one for the
+    reconstructed (i.e.measured) energy, the other for the true energy
+    (i.e.the one used by IRFs and models)
+
+- Create the necessary makers :
+
+  - the spectrum dataset maker : `~gammapy.makers.SpectrumDatasetMaker` -
+    the OFF background maker, here a `~gammapy.makers.ReflectedRegionsBackgroundMaker`
+  - and the safe range maker : `~gammapy.makers.SafeMaskMaker`
+
+- Perform the data reduction loop. And for every observation:
+
+  - Apply the makers sequentially to produce a `~gammapy.datasets.SpectrumDatasetOnOff`
+  - Append it to list of datasets
+
+- Define the `~gammapy.modeling.models.SkyModel` to apply to the dataset.
+- Create a `~gammapy.modeling.Fit` object and run it to fit the model parameters
+- Apply a `~gammapy.estimators.FluxPointsEstimator` to compute flux points for
+  the spectral part of the fit.
+
+
 """
 
 from pathlib import Path
 
 # Check package versions
 import numpy as np
 import astropy.units as u
@@ -134,15 +144,15 @@
 # Load Data
 # ---------
 #
 # First, we select and load some H.E.S.S. observations of the Crab nebula
 # (simulated events for now).
 #
 # We will access the events, effective area, energy dispersion, livetime
-# and PSF for containement correction.
+# and PSF for containment correction.
 #
 
 datastore = DataStore.from_dir("$GAMMAPY_DATA/hess-dl3-dr1/")
 obs_ids = [23523, 23526, 23559, 23592]
 observations = datastore.get_observations(obs_ids)
 
 
@@ -182,14 +192,15 @@
 skydir = target_position.galactic
 geom = WcsGeom.create(
     npix=(150, 150), binsz=0.05, skydir=skydir, proj="TAN", frame="icrs"
 )
 
 exclusion_mask = ~geom.region_mask([exclusion_region])
 exclusion_mask.plot()
+plt.show()
 
 
 ######################################################################
 # Run data reduction chain
 # ------------------------
 #
 # We begin with the configuration of the maker classes:
@@ -227,14 +238,15 @@
 # ----------------
 #
 
 plt.figure()
 ax = exclusion_mask.plot()
 on_region.to_pixel(ax.wcs).plot(ax=ax, edgecolor="k")
 plot_spectrum_datasets_off_regions(ax=ax, datasets=datasets)
+plt.show()
 
 
 ######################################################################
 # Source statistic
 # ----------------
 #
 # Next we’re going to look at the overall source statistics in our signal
@@ -242,15 +254,15 @@
 #
 
 info_table = datasets.info_table(cumulative=True)
 
 display(info_table)
 
 ######################################################################
-# And make the correpsonding plots
+# And make the corresponding plots
 
 fig, (ax_excess, ax_sqrt_ts) = plt.subplots(figsize=(10, 4), ncols=2, nrows=1)
 ax_excess.plot(
     info_table["livetime"].to("h"),
     info_table["excess"],
     marker="o",
     ls="none",
@@ -266,14 +278,15 @@
     marker="o",
     ls="none",
 )
 
 ax_sqrt_ts.set_title("Sqrt(TS)")
 ax_sqrt_ts.set_xlabel("Livetime [h]")
 ax_sqrt_ts.set_ylabel("Sqrt(TS)")
+plt.show()
 
 
 ######################################################################
 # Finally you can write the extracted datasets to disk using the OGIP
 # format (PHA, ARF, RMF, BKG, see
 # `here <https://gamma-astro-data-formats.readthedocs.io/en/latest/spectra/ogip/index.html>`__
 # for details):
@@ -345,23 +358,23 @@
 
 
 ######################################################################
 # A simple way to inspect the model residuals is using the function
 # `~SpectrumDataset.plot_fit()`
 #
 
-plt.figure()
 ax_spectrum, ax_residuals = datasets[0].plot_fit()
 ax_spectrum.set_ylim(0.1, 40)
 datasets[0].plot_masks(ax=ax_spectrum)
+plt.show()
 
 
 ######################################################################
 # For more ways of assessing fit quality, please refer to the dedicated
-# doc:`/tutorials/api/fitting` tutorial.
+# :doc:`/tutorials/api/fitting` tutorial.
 #
 
 
 ######################################################################
 # Compute Flux Points
 # -------------------
 #
@@ -397,30 +410,32 @@
 # Now we plot the flux points and their likelihood profiles. For the
 # plotting of upper limits we choose a threshold of TS < 4.
 #
 
 fig, ax = plt.subplots()
 flux_points.plot(ax=ax, sed_type="e2dnde", color="darkorange")
 flux_points.plot_ts_profiles(ax=ax, sed_type="e2dnde")
+plt.show()
 
 
 ######################################################################
 # The final plot with the best fit model, flux points and residuals can be
 # quickly made like this:
 #
 
 flux_points_dataset = FluxPointsDataset(data=flux_points, models=model_best_joint)
 flux_points_dataset.plot_fit()
+plt.show()
 
 
 ######################################################################
 # Stack observations
 # ------------------
 #
-# And alternative approach to fitting the spectrum is stacking all
+# An alternative approach to fitting the spectrum is stacking all
 # observations first and the fitting a model. For this we first stack the
 # individual datasets:
 #
 
 dataset_stacked = Datasets(datasets).stack_reduce()
 
 
@@ -474,14 +489,15 @@
 create_crab_spectral_model("hess_ecpl").plot(
     **plot_kwargs,
     label="Crab reference",
 )
 ax.legend()
 plt.show()
 
+# sphinx_gallery_thumbnail_number = 5
 
 ######################################################################
 # Exercises
 # ---------
 #
 # Now you have learned the basics of a spectral analysis with Gammapy. To
 # practice you can continue with the following exercises:
@@ -502,10 +518,10 @@
 # ----------
 #
 # The methods shown in this tutorial is valid for point-like or midly
 # extended sources where we can assume that the IRF taken at the region
 # center is valid over the whole region. If one wants to extract the 1D
 # spectrum of a large source and properly average the response over the
 # extraction region, one has to use a different approach explained in
-# the doc:`/tutorials/analysis-1d/extended_source_spectral_analysis`
+# the :doc:`/tutorials/analysis-1d/extended_source_spectral_analysis`
 # tutorial.
 #
```

### Comparing `gammapy-1.0rc2/examples/tutorials/analysis-1d/spectral_analysis_hli.py` & `gammapy-1.1rc1/examples/tutorials/analysis-1d/spectral_analysis_hli.py`

 * *Files 1% similar despite different names*

```diff
@@ -86,15 +86,15 @@
 
 ######################################################################
 # Analysis configuration
 # ----------------------
 #
 # For configuration of the analysis we use the
 # `YAML <https://en.wikipedia.org/wiki/YAML>`__ data format. YAML is a
-# machine readable serialisation format, that is also friendly for humans
+# machine-readable serialisation format, that is also friendly for humans
 # to read. In this tutorial we will write the configuration file just
 # using Python strings, but of course the file can be created and modified
 # with any text editor of your choice.
 #
 # Here is what the configuration for our analysis looks like:
 #
 
@@ -147,15 +147,15 @@
 
 ######################################################################
 # Here, we want to use Crab runs from the H.E.S.S. DL3-DR1. We have
 # defined the datastore and a cone search of observations pointing with 5
 # degrees of the Crab nebula. Parameters can be set directly or as a
 # python dict.
 #
-# PS: do not forget to setup your environment variable *$GAMMAPY_DATA* to
+# PS: do not forget to set up your environment variable *$GAMMAPY_DATA* to
 # your local directory containing the H.E.S.S. DL3-DR1 as described in
 # :ref:`quickstart-setup`.
 #
 
 
 ######################################################################
 # Setting the exclusion mask
@@ -393,14 +393,15 @@
 #
 
 ax_spectrum, ax_residuals = analysis.datasets[0].plot_fit()
 ax_spectrum.set_ylim(0.1, 200)
 ax_spectrum.set_xlim(0.2, 60)
 ax_residuals.set_xlim(0.2, 60)
 analysis.datasets[0].plot_masks(ax=ax_spectrum)
+plt.show()
 
 
 ######################################################################
 # Serialisation of the fit result
 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 #
 # This is how we can write the model back to file again:
@@ -435,14 +436,15 @@
 # Let’s plot the flux points with their likelihood profile
 #
 fig, ax_sed = plt.subplots()
 crab_fp.plot(ax=ax_sed, sed_type="e2dnde", color="darkorange")
 ax_sed.set_ylim(1.0e-12, 2.0e-10)
 ax_sed.set_xlim(0.5, 40)
 crab_fp.plot_ts_profiles(ax=ax_sed, sed_type="e2dnde")
+plt.show()
 
 
 ######################################################################
 # Serialisation of the results
 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 #
 # The flux points can be exported to a fits table following the format
@@ -473,10 +475,10 @@
 ######################################################################
 # What’s next?
 # ------------
 #
 # You can look at the same analysis without the high level interface in
 # :doc:`/tutorials/analysis-1d/spectral_analysis`
 #
-# As we can store the best model fit, you can overlaid the fit results of
-# both methods on an unique plot.
+# As we can store the best model fit, you can overlay the fit results of
+# both methods on a unique plot.
 #
```

### Comparing `gammapy-1.0rc2/examples/tutorials/analysis-1d/spectral_analysis_rad_max.py` & `gammapy-1.1rc1/examples/tutorials/analysis-1d/spectral_analysis_rad_max.py`

 * *Files 5% similar despite different names*

```diff
@@ -16,15 +16,15 @@
    `full-enclosure <https://gamma-astro-data-formats.readthedocs.io/en/latest/irfs/full_enclosure/index.html>`__
    IRF.
 
 Context
 -------
 
 As already explained in the :doc:`/tutorials/analysis-1d/spectral_analysis`
-tutorial, the background is estimated fromthe field of view of the observation.
+tutorial, the background is estimated from the field of view of the observation.
 In particular, the source and background events are counted within a circular 
 ON region enclosing the source. The background to be subtracted is then estimated
 from one or more OFF regions with an expected background rate similar to the one
 in the ON region (i.e. from regions with similar acceptance).
 
 *Full-containment* IRFs have no directional cut applied, when employed
 for a 1D analysis, it is required to apply a correction to the IRF
@@ -43,23 +43,23 @@
 `gamma-astro-data-format <https://gamma-astro-data-formats.readthedocs.io/en/latest/>`__
 specifications offer two different ways to store this information: \* if
 the same :math:`\\theta` cut is applied at all energies and offsets, `a
 `RAD_MAX`
 keyword <https://gamma-astro-data-formats.readthedocs.io/en/latest/irfs/point_like/#rad-max>`__
 is added to the header of the data units containing IRF components. This
 should be used to define the size of the ON and OFF regions; \* in case
-an energy- (and offset-) dependent :math:`\theta` cut is applied, its
+an energy- (and offset-) dependent :math:`\\theta` cut is applied, its
 values are stored in additional `FITS` data unit, named
 ``RAD_MAX_2D` <https://gamma-astro-data-formats.readthedocs.io/en/latest/irfs/point_like/#rad-max-2d>`__.
 
 `Gammapy` provides a class to automatically read these values,
 `~gammapy.irf.RadMax2D`, for both cases (fixed or energy-dependent
-:math:`\theta` cut). In this notebook we will focus on how to perform a
+:math:`\\theta` cut). In this notebook we will focus on how to perform a
 spectral extraction with a point-like IRF with an energy-dependent
-:math:`\theta` cut. We remark that in this case a
+:math:`\\theta` cut. We remark that in this case a
 `~regions.PointSkyRegion` (and not a `~regions.CircleSkyRegion`)
 should be used to define the ON region. If a geometry based on a
 `~regions.PointSkyRegion` is fed to the spectra and the background
 `Makers`, the latter will automatically use the values stored in the
 `RAD_MAX` keyword / table for defining the size of the ON and OFF
 regions.
 
@@ -72,22 +72,22 @@
 observations of MAGIC and fit the resulting datasets.**
 
 Introduction
 ------------
 
 We load two MAGIC observations in the
 `gammapy-data <https://github.com/gammapy/gammapy-data>`__ containing
-IRF component with a :math:`\theta` cut.
+IRF component with a :math:`\\theta` cut.
 
 We define the ON region, this time as a `~regions.PointSkyRegion` instead of a
 `CircleSkyRegion`, i.e. we specify only the center of our ON region.
 We create a `RegionGeom` adding to the region the estimated energy
 axis of the `~gammapy.datasets.SpectrumDataset` object we want to
 produce. The corresponding dataset maker will automatically use the
-:math:`\theta` values in `~gammapy.irf.RadMax2D` to set the
+:math:`\\theta` values in `~gammapy.irf.RadMax2D` to set the
 appropriate ON region sizes (based on the offset on the observation and
 on the estimated energy binning).
 
 In order to define the OFF regions it is recommended to use a
 `~gammapy.makers.WobbleRegionsFinder`, that uses fixed positions for
 the OFF regions. In the different estimated energy bins we will have OFF
 regions centered at the same positions, but with changing size. As for
@@ -164,14 +164,15 @@
 
 ######################################################################
 # We can also plot the rad max value against the energy:
 #
 
 fig, ax = plt.subplots()
 rad_max.plot_rad_max_vs_energy(ax=ax)
+plt.show()
 
 
 ######################################################################
 # Define the ON region
 # --------------------
 #
 # To use the `RAD_MAX_2D` values to define the sizes of the ON and OFF
@@ -216,15 +217,15 @@
 # the number of OFF regions to be considered.
 #
 
 dataset_maker = SpectrumDatasetMaker(
     containment_correction=False, selection=["counts", "exposure", "edisp"]
 )
 
-# tell the background maker to use the WobbleRegionsFinder, let us use 1 off
+# tell the background maker to use the WobbleRegionsFinder, let us use 3 off
 region_finder = WobbleRegionsFinder(n_off_regions=3)
 bkg_maker = ReflectedRegionsBackgroundMaker(region_finder=region_finder)
 
 # use the energy threshold specified in the DL3 files
 safe_mask_masker = SafeMaskMaker(methods=["aeff-default"])
 
 # %%time
@@ -244,18 +245,18 @@
 
 
 ######################################################################
 # Now we can plot the off regions and target positions on top of the counts
 # map:
 #
 
-plt.figure()
 ax = counts.plot(cmap="viridis")
 geom.plot_region(ax=ax, kwargs_point={"color": "k", "marker": "*"})
 plot_spectrum_datasets_off_regions(ax=ax, datasets=datasets)
+plt.show()
 
 
 ######################################################################
 # Fit spectrum
 # ------------
 #
 # | We perform a joint likelihood fit of the two datasets.
@@ -308,14 +309,15 @@
 
 ######################################################################
 # A simple way to inspect the model residuals is using the function
 # `~SpectrumDataset.plot_fit()`
 #
 ax_spectrum, ax_residuals = datasets[0].plot_fit()
 ax_spectrum.set_ylim(0.1, 120)
+plt.show()
 
 
 ######################################################################
 # For more ways of assessing fit quality, please refer to the dedicated
 # `modeling and fitting tutorial :doc:`/tutorials/api/fitting` tutorial.
 #
 
@@ -344,7 +346,37 @@
 )
 best_fit_model.spectral_model.plot_error(facecolor="crimson", alpha=0.4, **plot_kwargs)
 crab_magic_lp.plot(ls="--", lw=1.5, color="k", label="MAGIC reference", **plot_kwargs)
 
 ax.legend()
 ax.set_ylim([1e-13, 1e-10])
 plt.show()
+
+
+######################################################################
+# Dataset simulations
+# -------------------
+#
+# A common way to check if a fit is biased is to simulate multiple datasets with
+# the obtained best fit model, and check the distribution of the fitted parameters.
+# Here, we show how to perform one such simulation assuming the measured off counts
+# provide a good distribution of the background.
+#
+
+dataset_simulated = datasets.stack_reduce().copy(name="simulated_ds")
+simulated_model = best_fit_model.copy(name="simulated")
+dataset_simulated.models = simulated_model
+dataset_simulated.fake(
+    npred_background=dataset_simulated.counts_off * dataset_simulated.alpha
+)
+dataset_simulated.peek()
+plt.show()
+
+# The important thing to note here is that while this samples the on-counts, the off counts are
+# not sampled. If you have multiple measurements of the off counts, they should be used.
+# Alternatively, you can try to create a parametric model of the background.
+
+result = fit.run(datasets=[dataset_simulated])
+print(result.models.to_parameters_table())
+
+
+# sphinx_gallery_thumbnail_number = 4
```

### Comparing `gammapy-1.0rc2/examples/tutorials/analysis-1d/spectrum_simulation.py` & `gammapy-1.1rc1/examples/tutorials/analysis-1d/spectrum_simulation.py`

 * *Files 4% similar despite different names*

```diff
@@ -5,16 +5,16 @@
 Simulate a number of spectral on-off observations of a source with a power-law spectral
 model using the CTA 1DC response and fit them with the assumed spectral model.
 
 Prerequisites
 -------------
 
 -  Knowledge of spectral extraction and datasets used in gammapy, see
-   for instance the `spectral analysis
-   tutorial <spectral_analysis.ipynb>`__
+   for instance the :doc:`spectral analysis
+   tutorial </tutorials/analysis-1d/spectral_analysis>`
 
 Context
 -------
 
 To simulate a specific observation, it is not always necessary to
 simulate the full photon list. For many uses cases, simulating directly
 a reduced binned dataset is enough: the IRFs reduced in the correct
@@ -33,19 +33,19 @@
 source with a power-law spectral model with CTA using the CTA 1DC
 response, fit them with the assumed spectral model and check that the
 distribution of fitted parameters is consistent with the input values.**
 
 Proposed approach
 -----------------
 
-We will use the following classes:
+We will use the following classes and functions:
 
 -  `~gammapy.datasets.SpectrumDatasetOnOff`
 -  `~gammapy.datasets.SpectrumDataset`
--  `~gammapy.irf.load_cta_irfs`
+-  `~gammapy.irf.load_irf_dict_from_file`
 -  `~gammapy.modeling.models.PowerLawSpectralModel`
 
 """
 
 
 import numpy as np
 import astropy.units as u
@@ -58,15 +58,15 @@
 ######################################################################
 # Setup
 # -----
 #
 from IPython.display import display
 from gammapy.data import Observation, observatory_locations
 from gammapy.datasets import Datasets, SpectrumDataset, SpectrumDatasetOnOff
-from gammapy.irf import load_cta_irfs
+from gammapy.irf import load_irf_dict_from_file
 from gammapy.makers import SpectrumDatasetMaker
 from gammapy.maps import MapAxis, RegionGeom
 from gammapy.modeling import Fit
 from gammapy.modeling.models import PowerLawSpectralModel, SkyModel
 
 ######################################################################
 # Check setup
@@ -80,15 +80,15 @@
 # Simulation of a single spectrum
 # -------------------------------
 #
 # To do a simulation, we need to define the observational parameters like
 # the livetime, the offset, the assumed integration radius, the energy
 # range to perform the simulation for and the choice of spectral model. We
 # then use an in-memory observation which is convolved with the IRFs to
-# get the predicted number of counts. This is Poission fluctuated using
+# get the predicted number of counts. This is Poisson fluctuated using
 # the `fake()` to get the simulated counts for each observation.
 #
 
 # Define simulation parameters parameters
 livetime = 1 * u.h
 
 pointing = SkyCoord(0, 0, unit="deg", frame="galactic")
@@ -115,16 +115,16 @@
 )
 print(model_simu)
 # we set the sky model used in the dataset
 model = SkyModel(spectral_model=model_simu, name="source")
 
 ######################################################################
 # Load the IRFs
-# In this simulation, we use the CTA-1DC irfs shipped with gammapy.
-irfs = load_cta_irfs(
+# In this simulation, we use the CTA-1DC IRFs shipped with Gammapy.
+irfs = load_irf_dict_from_file(
     "$GAMMAPY_DATA/cta-1dc/caldb/data/cta/1dc/bcf/South_z20_50h/irf_file.fits"
 )
 
 location = observatory_locations["cta_south"]
 obs = Observation.create(
     pointing=pointing,
     livetime=livetime,
@@ -160,15 +160,18 @@
 
 ######################################################################
 # On-Off analysis
 # ~~~~~~~~~~~~~~~
 #
 # To do an on off spectral analysis, which is the usual science case, the
 # standard would be to use `SpectrumDatasetOnOff`, which uses the
-# acceptance to fake off-counts
+# acceptance to fake off-counts. Please also refer to :doc:`simulations in
+# the absence of a background model
+# <spectral_analysis_rad_max.html#dataset-simulations>`
+# for simulations based on observations of real off counts.
 #
 
 dataset_on_off = SpectrumDatasetOnOff.from_spectrum_dataset(
     dataset=dataset, acceptance=1, acceptance_off=5
 )
 dataset_on_off.fake(npred_background=dataset.npred_background())
 print(dataset_on_off)
@@ -202,14 +205,15 @@
 fix, axes = plt.subplots(1, 3, figsize=(12, 4))
 axes[0].hist(table["counts"])
 axes[0].set_xlabel("Counts")
 axes[1].hist(table["counts_off"])
 axes[1].set_xlabel("Counts Off")
 axes[2].hist(table["excess"])
 axes[2].set_xlabel("excess")
+plt.show()
 
 
 ######################################################################
 # Now, we fit each simulated spectrum individually
 #
 
 # %%time
```

### Comparing `gammapy-1.0rc2/examples/tutorials/analysis-2d/detect.py` & `gammapy-1.1rc1/examples/tutorials/analysis-2d/detect.py`

 * *Files 2% similar despite different names*

```diff
@@ -120,14 +120,15 @@
 # %%time
 scales = u.Quantity(np.arange(0.05, 1, 0.05), unit="deg")
 smooth = ASmoothMapEstimator(threshold=3, scales=scales, energy_edges=[10, 500] * u.GeV)
 images = smooth.run(dataset)
 
 plt.figure(figsize=(9, 5))
 images["flux"].plot(add_cbar=True, stretch="asinh")
+plt.show()
 
 
 ######################################################################
 # TS map estimation
 # -----------------
 #
 # The Test Statistic, TS = 2 ∆ log L (`Mattox et
@@ -173,14 +174,15 @@
 
 maps["sqrt_ts"].plot(ax=ax1, add_cbar=True)
 ax1.set_title("Significance map")
 maps["flux"].plot(ax=ax2, add_cbar=True, stretch="sqrt", vmin=0)
 ax2.set_title("Flux map")
 maps["niter"].plot(ax=ax3, add_cbar=True)
 ax3.set_title("Iteration map")
+plt.show()
 
 ######################################################################
 # Source candidates
 # -----------------
 #
 # Let’s run a peak finder on the `sqrt_ts` image to get a list of
 # point-sources candidates (positions and peak `sqrt_ts` values). The
@@ -205,14 +207,15 @@
     edgecolor="w",
     marker="o",
     s=600,
     lw=1.5,
 )
 plt.show()
 
+# sphinx_gallery_thumbnail_number = 3
 
 ######################################################################
 # Note that we used the instrument point-spread-function (PSF) as kernel,
 # so the hypothesis we test is the presence of a point source. In order to
 # test for extended sources we would have to use as kernel an extended
 # template convolved by the PSF. Alternatively, we can compute the
 # significance of an extended excess using the Li & Ma formalism, which is
@@ -233,12 +236,12 @@
 # -  Look how background estimation is performed for IACTs with and
 #    without the high level interface in
 #    :doc:`/tutorials/starting/analysis_1` and
 #    :doc:`/tutorials/starting/analysis_2` notebooks,
 #    respectively
 # -  Learn about 2D model fitting in the :doc:`/tutorials/analysis-2d/modeling_2D` notebook
 # -  Find more about Fermi-LAT data analysis in the
-#    `:doc:`/tutorials/data/fermi_lat` notebook
+#    :doc:`/tutorials/data/fermi_lat` notebook
 # -  Use source candidates to build a model and perform a 3D fitting (see
 #    :doc:`/tutorials/analysis-3d/analysis_3d`,
 #    :doc:`/tutorials/analysis-3d/analysis_mwl` notebooks for some hints)
 #
```

### Comparing `gammapy-1.0rc2/examples/tutorials/analysis-2d/modeling_2D.py` & `gammapy-1.1rc1/examples/tutorials/analysis-2d/modeling_2D.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 ==============
 
 Source modelling and fitting in stacked observations using the high level interface.
 
 Prerequisites
 -------------
 
--  To understand how a generel modelling and fiiting works in gammapy,
+-  To understand how a general modelling and fitting works in gammapy,
    please refer to the :doc:`/tutorials/analysis-3d/analysis_3d` tutorial.
 
 Context
 -------
 
 We often want the determine the position and morphology of an object. To
 do so, we don’t necessarily have to resort to a full 3D fitting but can
@@ -72,15 +72,15 @@
 # Selecting the observations
 config.observations.datastore = "$GAMMAPY_DATA/cta-1dc/index/gps/"
 config.observations.obs_ids = [110380, 111140, 111159]
 
 
 ######################################################################
 # Technically, gammapy implements 2D analysis as a special case of 3D
-# analysis (one one bin in energy). So, we must specify the type of
+# analysis (one bin in energy). So, we must specify the type of
 # analysis as *3D*, and define the geometry of the analysis.
 #
 
 config.datasets.type = "3d"
 config.datasets.geom.wcs.skydir = {
     "lon": "0 deg",
     "lat": "0 deg",
@@ -140,14 +140,15 @@
 
 
 ######################################################################
 # We can have a quick look of these maps in the following way:
 #
 
 analysis.datasets["stacked"].counts.reduce_over_axes().plot(vmax=10, add_cbar=True)
+plt.show()
 
 
 ######################################################################
 # Modelling
 # ---------
 #
 # Now, we define a model to be fitted to the dataset. **The important
@@ -200,8 +201,7 @@
 analysis.datasets["stacked"].background_model.parameters["tilt"].frozen = True
 
 # To run the fit
 analysis.run_fit()
 
 # To see the best fit values along with the errors
 display(analysis.models.to_parameters_table())
-plt.show()
```

### Comparing `gammapy-1.0rc2/examples/tutorials/analysis-2d/ring_background.py` & `gammapy-1.1rc1/examples/tutorials/analysis-2d/ring_background.py`

 * *Files 1% similar despite different names*

```diff
@@ -146,15 +146,15 @@
 
 
 ######################################################################
 # Extracting the ring background
 # ------------------------------
 #
 # Since the ring background is extracted from real off events, we need to
-# use the wstat statistics in this case. For this, we will use the
+# use the Wstat statistics in this case. For this, we will use the
 # `MapDatasetOnOFF` and the `RingBackgroundMaker` classes.
 #
 
 
 ######################################################################
 # Create exclusion mask
 # ~~~~~~~~~~~~~~~~~~~~~
@@ -169,14 +169,15 @@
 energy_axis = analysis.datasets[0].counts.geom.axes["energy"]
 geom_image = geom.to_image().to_cube([energy_axis.squash()])
 
 # Make the exclusion mask
 regions = CircleSkyRegion(center=source_pos, radius=0.3 * u.deg)
 exclusion_mask = ~geom_image.region_mask([regions])
 exclusion_mask.sum_over_axes().plot()
+plt.show()
 
 
 ######################################################################
 # For the present analysis, we use a ring with an inner radius of 0.5 deg
 # and width of 0.3 deg.
 #
 
@@ -240,18 +241,19 @@
 )
 
 ax1.set_title("Significance map")
 significance_map.plot(ax=ax1, add_cbar=True)
 
 ax2.set_title("Excess map")
 excess_map.plot(ax=ax2, add_cbar=True)
+plt.show()
 
 
 ######################################################################
-# It is often important to look at the signficance distribution outside
+# It is often important to look at the significance distribution outside
 # the exclusion region to check that the background estimation is not
 # contaminated by gamma-ray events. This can be the case when exclusion
 # regions are not large enough. Typically, we expect the off distribution
 # to be a standard normal distribution.
 #
 
 # create a 2D mask for the images
@@ -288,7 +290,9 @@
 ax.set_yscale("log")
 ax.set_ylim(1e-5, 1)
 xmin, xmax = np.min(significance_all), np.max(significance_all)
 ax.set_xlim(xmin, xmax)
 
 print(f"Fit results: mu = {mu:.2f}, std = {std:.2f}")
 plt.show()
+
+# sphinx_gallery_thumbnail_number = 2
```

### Comparing `gammapy-1.0rc2/examples/tutorials/analysis-3d/analysis_3d.py` & `gammapy-1.1rc1/examples/tutorials/analysis-3d/analysis_3d.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """
 3D detailed analysis
 ====================
 
 Perform detailed 3D stacked and joint analysis.
 
-This tutorial does a 3D map based analsis on the galactic center, using
+This tutorial does a 3D map based analysis on the galactic center, using
 simulated observations from the CTA-1DC. We will use the high level
 interface for the data reduction, and then do a detailed modelling. This
 will be done in two different ways:
 
 -  stacking all the maps together and fitting the stacked maps
 -  handling all the observations separately and doing a joint fitting on
    all the maps
@@ -144,40 +144,44 @@
 print(dataset_stacked)
 
 ######################################################################
 # To plot a smooth counts map
 #
 
 dataset_stacked.counts.smooth(0.02 * u.deg).plot_interactive(add_cbar=True)
+plt.show()
 
 ######################################################################
 # And the background map
 #
 
 dataset_stacked.background.plot_interactive(add_cbar=True)
+plt.show()
 
 ######################################################################
 # We can quickly check the PSF
 #
 
 dataset_stacked.psf.peek()
+plt.show()
 
 ######################################################################
 # And the energy dispersion in the center of the map
 #
 
 dataset_stacked.edisp.peek()
+plt.show()
 
 ######################################################################
 # You can also get an excess image with a few lines of code:
 #
 
 excess = dataset_stacked.excess.sum_over_axes()
 excess.smooth("0.06 deg").plot(stretch="sqrt", add_cbar=True)
-
+plt.show()
 
 ######################################################################
 # Modeling and fitting
 # ~~~~~~~~~~~~~~~~~~~~
 #
 # Now comes the interesting part of the analysis - choosing appropriate
 # models for our source and fitting them.
@@ -192,15 +196,15 @@
 # specific *mask*. On the dataset, the `mask_fit` is a `Map` sharing
 # the same geometry as the `MapDataset` and containing boolean data.
 #
 # To create a mask to limit the fit within a restricted energy range, one
 # can rely on the `~gammapy.maps.Geom.energy_mask()` method.
 #
 # For more details on masks and the techniques to create them in gammapy,
-# please checkou the dedicated :doc:`/tutorials/api/mask_maps` tutorial.
+# please checkout the dedicated :doc:`/tutorials/api/mask_maps` tutorial.
 #
 
 dataset_stacked.mask_fit = dataset_stacked.counts.geom.energy_mask(
     energy_min=0.3 * u.TeV, energy_max=None
 )
 
 spatial_model = PointSpatialModel(
@@ -255,26 +259,28 @@
 # A quick way to inspect the model residuals is using the function
 # `~MapDataset.plot_residuals_spatial()`. This function computes and
 # plots a residual image (by default, the smoothing radius is `0.1 deg`
 # and `method=diff`, which corresponds to a simple `data - model`
 # plot):
 #
 dataset_stacked.plot_residuals_spatial(method="diff/sqrt(model)", vmin=-1, vmax=1)
+plt.show()
 
 
 ######################################################################
 # The more general function `~MapDataset.plot_residuals()` can also
 # extract and display spectral residuals in a region:
 #
 
 region = CircleSkyRegion(spatial_model.position, radius=0.15 * u.deg)
 dataset_stacked.plot_residuals(
     kwargs_spatial=dict(method="diff/sqrt(model)", vmin=-1, vmax=1),
     kwargs_spectral=dict(region=region),
 )
+plt.show()
 
 
 ######################################################################
 # This way of accessing residuals is quick and handy, but comes with
 # limitations. For example: - In case a fitting energy range was defined
 # using a `MapDataset.mask_fit`, it won’t be taken into account.
 # Residuals will be summed up over the whole reconstructed energy range -
@@ -290,14 +296,15 @@
     energy_edges=[0.1, 1, 10] * u.TeV,
 )
 
 result = estimator.run(dataset_stacked)
 result["sqrt_ts"].plot_grid(
     figsize=(12, 4), cmap="coolwarm", add_cbar=True, vmin=-5, vmax=5, ncols=2
 )
+plt.show()
 
 
 ######################################################################
 # Distribution of residuals significance in the full map geometry:
 #
 significance_data = result["sqrt_ts"].data
 
@@ -318,14 +325,22 @@
     p,
     lw=2,
     color="black",
     label=r"$\mu$ = {:.2f}, $\sigma$ = {:.2f}".format(mu, std),
 )
 ax.legend(fontsize=17)
 ax.set_xlim(-5, 5)
+plt.show()
+
+
+######################################################################
+# Here we can plot the number of predicted counts for each model and
+# for the background in our dataset by using the
+# `~gammapy.visualization.plot_npred_signal` function.
+#
 
 
 ######################################################################
 # Joint analysis
 # --------------
 #
 # In this section, we perform a joint analysis of the same data. Of
```

### Comparing `gammapy-1.0rc2/examples/tutorials/analysis-3d/analysis_mwl.py` & `gammapy-1.1rc1/examples/tutorials/analysis-3d/analysis_mwl.py`

 * *Files 1% similar despite different names*

```diff
@@ -5,17 +5,17 @@
 Joint 3D analysis using 3D Fermi datasets, a H.E.S.S. reduced spectrum and HAWC flux points.
 
 Prerequisites
 -------------
 
 -  Handling of Fermi-LAT data with Gammapy see the :doc:`/tutorials/data/fermi_lat` tutorial.
 -  Knowledge of spectral analysis to produce 1D On-Off datasets, see
-   the following doc:`/tutorials/analysis-1d/spectral_analysis` tutorial.
+   the following :doc:`/tutorials/analysis-1d/spectral_analysis` tutorial.
 -  Using flux points to directly fit a model (without forward-folding) from the 
-   doc:`/tutorials/analysis-1d/sed_fitting` tutorial.
+   :doc:`/tutorials/analysis-1d/sed_fitting` tutorial.
 
 Context
 -------
 
 Some science studies require to combine heterogeneous data from various
 instruments to extract physical information. In particular, it is often
 useful to add flux measurements of a source at different energies to an
@@ -70,15 +70,15 @@
 
 
 ######################################################################
 # Data and models files
 # ---------------------
 #
 # The datasets serialization produce YAML files listing the datasets and
-# models. In the following cells we show an example containning only the
+# models. In the following cells we show an example containing only the
 # Fermi-LAT dataset and the Crab model.
 #
 # Fermi-LAT-3FHL_datasets.yaml:
 #
 
 path = make_path("$GAMMAPY_DATA/fermi-3fhl-crab/Fermi-LAT-3FHL_datasets.yaml")
 
@@ -240,15 +240,15 @@
 
 flux_points_hess = FluxPointsEstimator(
     energy_edges=energy_edges, source="Crab Nebula", selection_optional=["ul"]
 ).run([datasets["HESS"]])
 
 
 ######################################################################
-# Now, Let’s plot the Crab spectrum fitted and the flux points of each
+# Now, let’s plot the Crab spectrum fitted and the flux points of each
 # instrument.
 #
 
 # display spectrum and flux points
 fig, ax = plt.subplots(figsize=(8, 6))
 
 energy_bounds = [0.01, 300] * u.TeV
```

### Comparing `gammapy-1.0rc2/examples/tutorials/analysis-3d/cta_data_analysis.py` & `gammapy-1.1rc1/examples/tutorials/analysis-3d/cta_data_analysis.py`

 * *Files 5% similar despite different names*

```diff
@@ -49,15 +49,15 @@
 from gammapy.maps import MapAxis, RegionGeom, WcsGeom
 from gammapy.modeling import Fit
 from gammapy.modeling.models import (
     GaussianSpatialModel,
     PowerLawSpectralModel,
     SkyModel,
 )
-from gammapy.visualization import plot_spectrum_datasets_off_regions
+from gammapy.visualization import plot_npred_signal, plot_spectrum_datasets_off_regions
 
 logging.basicConfig()
 log = logging.getLogger("gammapy.spectrum")
 log.setLevel(logging.ERROR)
 
 ######################################################################
 # Check setup
@@ -125,15 +125,15 @@
 # %%time
 stacked = MapDataset.create(geom=geom)
 stacked.edisp = None
 maker = MapDatasetMaker(selection=["counts", "background", "exposure", "psf"])
 maker_safe_mask = SafeMaskMaker(methods=["offset-max"], offset_max=2.5 * u.deg)
 
 for obs in observations:
-    cutout = stacked.cutout(obs.pointing_radec, width="5 deg")
+    cutout = stacked.cutout(obs.get_pointing_icrs(obs.tmid), width="5 deg")
     dataset = maker.run(cutout, obs)
     dataset = maker_safe_mask.run(dataset, obs)
     stacked.stack(dataset)
 
 #
 # The maps are cubes, with an energy axis.
 # Let's also make some images:
@@ -160,14 +160,15 @@
 dataset_image.counts.smooth(2).plot(ax=ax1, vmax=5)
 
 ax2.set_title("Background map")
 dataset_image.background.plot(ax=ax2, vmax=5)
 
 ax3.set_title("Excess map")
 dataset_image.excess.smooth(3).plot(ax=ax3, vmax=2)
+plt.show()
 
 
 ######################################################################
 # Source Detection
 # ----------------
 #
 # Use the class `~gammapy.estimators.TSMapEstimator` and function
@@ -216,14 +217,15 @@
     transform=ax.get_transform("icrs"),
     color="none",
     edgecolor="white",
     marker="o",
     s=200,
     lw=1.5,
 )
+plt.show()
 
 
 ######################################################################
 # Spatial analysis
 # ----------------
 #
 # See other notebooks for how to run a 3D cube or 2D image based analysis.
@@ -240,16 +242,16 @@
 #
 
 target_position = SkyCoord(0, 0, unit="deg", frame="galactic")
 on_radius = 0.2 * u.deg
 on_region = CircleSkyRegion(center=target_position, radius=on_radius)
 
 exclusion_mask = ~geom.to_image().region_mask([on_region])
-plt.figure()
 exclusion_mask.plot()
+plt.show()
 
 ######################################################################
 # Configure spectral analysis
 
 energy_axis = MapAxis.from_energy_bounds(0.1, 40, 40, unit="TeV", name="energy")
 energy_axis_true = MapAxis.from_energy_bounds(
     0.05, 100, 200, unit="TeV", name="energy_true"
@@ -282,21 +284,22 @@
 # Plot results
 
 plt.figure(figsize=(8, 6))
 ax = dataset_image.counts.smooth("0.03 deg").plot(vmax=8)
 
 on_region.to_pixel(ax.wcs).plot(ax=ax, edgecolor="white")
 plot_spectrum_datasets_off_regions(datasets, ax=ax)
+plt.show()
 
 
 ######################################################################
 # Model fit
 # ~~~~~~~~~
 #
-# The next step is to fit a spectral model, using all data (i.e. a
+# The next step is to fit a spectral model, using all data (i.e. a
 # “global” fit, using all energies).
 #
 
 # %%time
 spectral_model = PowerLawSpectralModel(
     index=2, amplitude=1e-11 * u.Unit("cm-2 s-1 TeV-1"), reference=1 * u.TeV
 )
@@ -307,31 +310,50 @@
 
 fit = Fit()
 result = fit.run(datasets=datasets)
 print(result)
 
 
 ######################################################################
+# Here we can plot the predicted number of counts for each model and
+# for the background in the dataset. This is especially useful when
+# studying complex field with a lot a sources. There is a function
+# in the visualization sub-package of gammapy that does this automatically.
+#
+# First we need to stack our datasets.
+
+
+stacked_dataset = datasets.stack_reduce(name="stacked")
+stacked_dataset.models = model
+
+print(stacked_dataset)
+
+
+######################################################################
+# Call `plot_npred_signal` to plot the predicted counts.
+#
+
+
+plot_npred_signal(stacked_dataset)
+plt.show()
+
+
+######################################################################
 # Spectral points
 # ~~~~~~~~~~~~~~~
 #
 # Finally, let’s compute spectral points. The method used is to first
 # choose an energy binning, and then to do a 1-dim likelihood fit /
 # profile to compute the flux and flux error.
 #
 
-# Flux points are computed on stacked observation
-stacked_dataset = datasets.stack_reduce(name="stacked")
-
-print(stacked_dataset)
 
+# Flux points are computed on stacked datasets
 energy_edges = MapAxis.from_energy_bounds("1 TeV", "30 TeV", nbin=5).edges
 
-stacked_dataset.models = model
-
 fpe = FluxPointsEstimator(energy_edges=energy_edges, source="source-gc")
 flux_points = fpe.run(datasets=[stacked_dataset])
 flux_points.to_table(sed_type="dnde", formatted=True)
 
 
 ######################################################################
 # Plot
@@ -371,9 +393,9 @@
 
 ######################################################################
 # What next?
 # ----------
 #
 # -  This notebook showed an example of a first CTA analysis with Gammapy,
 #    using simulated 1DC data.
-# -  Let us know if you have any question or issues!
+# -  Let us know if you have any questions or issues!
 #
```

### Comparing `gammapy-1.0rc2/examples/tutorials/analysis-3d/event_sampling.py` & `gammapy-1.1rc1/examples/tutorials/analysis-3d/event_sampling.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,71 +3,71 @@
 ==============
 
 Learn to sampling events from a given sky model and IRFs.
 
 Prerequisites
 -------------
 
-To understand how to generate a model and a `MapDataset` and how to fit
+To understand how to generate a model and a `~gammapy.datasets.MapDataset` and how to fit
 the data, please refer to the `~gammapy.modeling.models.SkyModel` and
 :doc:`/tutorials/analysis-3d/simulate_3d` tutorial.
 
 Context
 -------
 
 This tutorial describes how to sample events from an observation of a
 one (or more) gamma-ray source(s). The main aim of the tutorial will be
 to set the minimal configuration needed to deal with the Gammapy
 event-sampler and how to obtain an output photon event list.
 
 The core of the event sampling lies into the Gammapy
 `~gammapy.datasets.MapDatasetEventSampler` class, which is based on
 the inverse cumulative distribution function `(Inverse
-CDF) <https://en.wikipedia.org/wiki/Cumulative_distribution_function#Inverse_distribution_function_(quantile_function)>`__.  # noqa: E501
+CDF) <https://en.wikipedia.org/wiki/Cumulative_distribution_function#Inverse_distribution_function_(quantile_function)>`__. 
 
 The `~gammapy.datasets.MapDatasetEventSampler` takes in input a
 `~gammapy.datasets.Dataset` object containing the spectral, spatial
 and temporal properties of the source(s) of interest.
 
 The `~gammapy.datasets.MapDatasetEventSampler` class evaluates the map
 of predicted counts (`npred`) per bin of the given Sky model, and the
 `npred` map is then used to sample the events. In particular, the
 output of the event-sampler will be a set of events having information
 about their true coordinates, true energies and times of arrival.
 
 To these events, IRF corrections (i.e. PSF and energy dispersion) can
-also further applied in order to obtain reconstructed coordinates and
+also further be applied in order to obtain reconstructed coordinates and
 energies of the sampled events.
 
 At the end of this process, you will obtain an event-list in FITS
 format.
 
 
 Objective
 ---------
 
 Describe the process of sampling events from a given Sky model and
-obtaining an output event-list.
+obtain an output event-list.
 
 
 Proposed approach
 -----------------
 
-In this section, we will show how to define an observation and to create
+In this section, we will show how to define an observation and create
 a Dataset object. These are both necessary for the event sampling. Then,
 we will define the Sky model from which we sample events.
 
 In this tutorial, we propose examples for sampling events of:
 
 -  `a point-like source <#sampling-the-source-and-background-events>`__
 -  `a time variable point-like
    source <#time-variable-source-using-a-lightcurve>`__
 -  `an extended source using a template
    map <#extended-source-using-a-template>`__
--  `a set of observations <#simulate-mutiple-event-lists>`__
+-  `a set of observations <#simulate-multiple-event-lists>`__
 
 We will work with the following functions and classes:
 
 -  `~gammapy.data.Observations`
 -  `~gammapy.datasets.Dataset`
 -  `~gammapy.modeling.models.SkyModel`
 -  `~gammapy.datasets.MapDatasetEventSampler`
@@ -91,15 +91,15 @@
 from regions import CircleSkyRegion
 import matplotlib.pyplot as plt
 
 # %matplotlib inline
 from IPython.display import display
 from gammapy.data import DataStore, Observation, observatory_locations
 from gammapy.datasets import MapDataset, MapDatasetEventSampler
-from gammapy.irf import load_cta_irfs
+from gammapy.irf import load_irf_dict_from_file
 from gammapy.makers import MapDatasetMaker
 from gammapy.maps import Map, MapAxis, WcsGeom
 from gammapy.modeling import Fit
 from gammapy.modeling.models import (
     ExpDecayTemporalModel,
     FoVBackgroundModel,
     Models,
@@ -140,15 +140,15 @@
 livetime = 1 * u.hr
 
 
 ######################################################################
 # Now you can create the observation:
 #
 
-irfs = load_cta_irfs(path / irf_filename)
+irfs = load_irf_dict_from_file(path / irf_filename)
 location = observatory_locations["cta_south"]
 
 observation = Observation.create(
     obs_id=1001,
     pointing=pointing,
     livetime=livetime,
     irfs=irfs,
@@ -159,19 +159,19 @@
 ######################################################################
 # Define the MapDataset
 # ~~~~~~~~~~~~~~~~~~~~~
 #
 # Let’s generate the `~gammapy.datasets.Dataset` object (for more info
 # on `~gammapy.datasets.Dataset` objects, please checkout
 # :doc:`/tutorials/api/datasets` tutorial):
-# we define the energy axes (true and reconstruncted), the migration axis
+# we define the energy axes (true and reconstructed), the migration axis
 # and the geometry of the observation.
 #
 # *This is a crucial point for the correct configuration of the event
-# sampler. Indeed the spatial and energetic binning should be treaten
+# sampler. Indeed, the spatial and energetic binning should be treated
 # carefully and… the finer the better. For this reason, we suggest to
 # define the energy axes (true and reconstructed) by setting a minimum
 # binning of least 10-20 bins per decade for all the sources of interest.
 # The spatial binning may instead be different from source to source and,
 # at first order, it should be adopted a binning significantly smaller
 # than the expected source size.*
 #
@@ -258,15 +258,15 @@
 print(dataset.models)
 
 
 ######################################################################
 # The next step shows how to sample the events with the
 # `~gammapy.datasets.MapDatasetEventSampler` class. The class requests a
 # random number seed generator (that we set with `random_state=0`), the
-# `~gammapy.datasets.Dataset` and the `gammapy.data.Observations`
+# `~gammapy.datasets.Dataset` and the `~gammapy.data.Observations`
 # object. From the latter, the
 # `~gammapy.datasets.MapDatasetEventSampler` class takes all the meta
 # data information.
 #
 
 # %%time
 sampler = MapDatasetEventSampler(random_state=0)
@@ -287,14 +287,15 @@
 
 
 ######################################################################
 # We can inspect the properties of the simulated events as follows:
 #
 
 events.select_offset([0, 1] * u.deg).peek()
+plt.show()
 
 
 ######################################################################
 # By default, the `~gammapy.datasets.MapDatasetEventSampler` fills the
 # metadata keyword `OBJECT` in the event list using the first model of
 # the SkyModel object. You can change it with the following commands:
 #
@@ -319,16 +320,16 @@
 # ~~~~~~~~~~~~~~~~~
 #
 # A skymap of the simulated events can be obtained with:
 #
 
 counts = Map.from_geom(geom)
 counts.fill_events(events)
-plt.figure()
 counts.sum_over_axes().plot(add_cbar=True)
+plt.show()
 
 
 ######################################################################
 # Fit the simulated data
 # ~~~~~~~~~~~~~~~~~~~~~~
 #
 # We can now check the sake of the event sampling by fitting the data.
@@ -379,15 +380,15 @@
 expdecay_model = ExpDecayTemporalModel(t_ref=t_ref.mjd * u.d, t0=t0)
 
 
 ######################################################################
 # where we defined the time axis starting from the reference time
 # `t_ref` up to the requested exposure (`livetime`). The bin size of
 # the time-axis is quite arbitrary but, as above for spatial and energy
-# binnings, the finer the better.
+# binning, the finer the better.
 #
 
 
 ######################################################################
 # Then, we can create the sky model. Just for the sake of the example,
 # let’s boost the flux of the simulated source of an order of magnitude:
 #
@@ -445,14 +446,15 @@
 
 
 ######################################################################
 # Then we can have a quick look to the data with the `peek` function:
 #
 
 src_events.peek()
+plt.show()
 
 
 ######################################################################
 # In the right figure of the bottom panel, it is shown the source
 # lightcurve that follows a decay trend as expected.
 #
 
@@ -490,23 +492,24 @@
 print(dataset.models)
 
 # %%time
 sampler = MapDatasetEventSampler(random_state=0)
 events = sampler.run(dataset, observation)
 
 events.select_offset([0, 1] * u.deg).peek()
+plt.show()
 
 
 ######################################################################
 # Simulate multiple event lists
 # -----------------------------
 #
 # In some user case, you may want to sample events from a number of
 # observations. In this section, we show how to simulate a set of event
-# lists. For simplicity we consider only one point-like source, observed
+# lists. For simplicity, we consider only one point-like source, observed
 # three times for 1 hr and assuming the same pointing position.
 #
 # Let’s firstly define the time start and the livetime of each
 # observation:
 #
 
 tstarts = Time("2020-01-01 00:00:00") + [1, 5, 7] * u.hr
@@ -514,15 +517,15 @@
 
 # %%time
 n_obs = len(tstarts)
 irf_paths = [path / irf_filename] * n_obs
 events_paths = []
 
 for idx, tstart in enumerate(tstarts):
-    irfs = load_cta_irfs(irf_paths[idx])
+    irfs = load_irf_dict_from_file(irf_paths[idx])
     observation = Observation.create(
         obs_id=idx,
         pointing=pointing,
         tstart=tstart,
         livetime=livetimes[idx],
         irfs=irfs,
         location=location,
@@ -546,22 +549,21 @@
 path = Path("./event_sampling/")
 events_paths = list(path.rglob("events*.fits"))
 data_store = DataStore.from_events_files(events_paths, irf_paths)
 display(data_store.obs_table)
 
 
 ######################################################################
-# Then you can create the obervations from the data store and make your own
+# Then you can create the observations from the data store and make your own
 # analysis following the instructions in the
 # :doc:`/tutorials/starting/analysis_2` tutorial.
 #
 
 observations = data_store.get_observations()
 observations[0].peek()
-
 plt.show()
 
 
 ######################################################################
 # Exercises
 # ---------
 #
```

### Comparing `gammapy-1.0rc2/examples/tutorials/analysis-3d/flux_profiles.py` & `gammapy-1.1rc1/examples/tutorials/analysis-3d/flux_profiles.py`

 * *Files 5% similar despite different names*

```diff
@@ -9,16 +9,16 @@
 
 Knowledge of 3D data reduction and datasets used in Gammapy, see for
 instance the first analysis tutorial.
 
 Context
 -------
 
-A useful tool to study and compare the saptial distribution of flux in
-images and data cubes is the measurement of flxu profiles. Flux profiles
+A useful tool to study and compare the spatial distribution of flux in
+images and data cubes is the measurement of flux profiles. Flux profiles
 can show spatial correlations of gamma-ray data with e.g. gas maps or
 other type of gamma-ray data. Most commonly flux profiles are measured
 along some preferred coordinate axis, either radially distance from a
 source of interest, along longitude and latitude coordinate axes or
 along the path defined by two spatial coordinates.
 
 Proposed Approach
@@ -27,15 +27,15 @@
 Flux profile estimation essentially works by estimating flux points for
 a set of predefined spatially connected regions. For radial flux
 profiles the shape of the regions are annuli with a common center, for
 linear profiles it’s typically a rectangular shape.
 
 We will work on a pre-computed `~gammapy.datasets.MapDataset` of Fermi-LAT data, use
 `~regions.SkyRegion` to define the structure of the bins of the flux profile and
-run the actually profile extraction using the `~gammapy.estimators.FluxProfileEstimator`
+run the flux profile extraction using the `~gammapy.estimators.FluxProfileEstimator`
 
 """
 
 
 import numpy as np
 from astropy import units as u
 from astropy.coordinates import SkyCoord
@@ -76,14 +76,15 @@
 
 
 ######################################################################
 # This is what the counts image we will work with looks like:
 #
 counts_image = dataset.counts.sum_over_axes()
 counts_image.smooth("0.1 deg").plot(stretch="sqrt")
+plt.show()
 
 
 ######################################################################
 # There are 400x200 pixels in the dataset and 11 energy bins between 10
 # GeV and 2 TeV:
 #
 
@@ -97,15 +98,15 @@
 # Configuration
 # ~~~~~~~~~~~~~
 #
 # We start by defining a list of spatially connected regions along the
 # galactic longitude axis. For this there is a helper function
 # `~gammapy.utils.regions.make_orthogonal_rectangle_sky_regions`. The individual region bins
 # for the profile have a height of 3 deg and in total there are 31 bins.
-# The starts from lon = 10 deg tand goes to lon = 350 deg. In addition we
+# Its starts from lon = 10 deg and goes to lon = 350 deg. In addition, we
 # have to specify the `wcs` to take into account possible projections
 # effects on the region definition:
 #
 
 regions = make_orthogonal_rectangle_sky_regions(
     start_pos=SkyCoord("10d", "0d", frame="galactic"),
     end_pos=SkyCoord("350d", "0d", frame="galactic"),
@@ -116,18 +117,18 @@
 
 
 ######################################################################
 # We can use the `~gammapy.maps.RegionGeom` object to illustrate the regions on top of
 # the counts image:
 #
 
-plt.figure()
 geom = RegionGeom.create(region=regions)
 ax = counts_image.smooth("0.1 deg").plot(stretch="sqrt")
 geom.plot_region(ax=ax, color="w")
+plt.show()
 
 
 ######################################################################
 # Next we create the `~gammapy.estimators.FluxProfileEstimator`. For the estimation of the
 # flux profile we assume a spectral model with a power-law shape and an
 # index of 2.3
 #
@@ -166,30 +167,31 @@
 # profile is measured along. The `lon` and `lat` axes can be ignored.
 #
 # Plotting Results
 # ~~~~~~~~~~~~~~~~
 #
 # Let us directly plot the result using `~gammapy.estimators.FluxPoints.plot`:
 #
-plt.figure()
 ax = profile.plot(sed_type="dnde")
 ax.set_yscale("linear")
+plt.show()
 
 
 ######################################################################
 # Based on the spectral model we specified above we can also plot in any
 # other sed type, e.g. energy flux and define a different threshold when
 # to plot upper limits:
 #
 
 profile.sqrt_ts_threshold_ul = 2
 
 plt.figure()
 ax = profile.plot(sed_type="eflux")
 ax.set_yscale("linear")
+plt.show()
 
 
 ######################################################################
 # We can also plot any other quantity of interest, that is defined on the
 # `~gammapy.estimators.FluxPoints` result object. E.g. the predicted total counts,
 # background counts and excess counts:
 #
@@ -197,15 +199,16 @@
 quantities = ["npred", "npred_excess", "npred_background"]
 
 fig, ax = plt.subplots()
 
 for quantity in quantities:
     profile[quantity].plot(ax=ax, label=quantity.title())
 
-ax.set_ylabel("Counts ")
+ax.set_ylabel("Counts")
+plt.show()
 
 
 ######################################################################
 # Serialisation and I/O
 # ~~~~~~~~~~~~~~~~~~~~~
 #
 # The profile can be serialised using `~gammapy.estimators.FluxPoints.write`, given a
@@ -217,17 +220,17 @@
     format="profile",
     overwrite=True,
     sed_type="dnde",
 )
 
 profile_new = FluxPoints.read(filename="flux_profile_fermi.fits", format="profile")
 
-fig = plt.figure()
 ax = profile_new.plot()
 ax.set_yscale("linear")
+plt.show()
 
 
 ######################################################################
 # The profile can be serialised to a `~astropy.table.Table` object
 # using:
 #
 
@@ -246,21 +249,21 @@
     nbin=11,
 )
 
 
 ######################################################################
 # Again we first illustrate the regions:
 #
-plt.figure()
 geom = RegionGeom.create(region=regions)
 gc_image = counts_image.cutout(
     position=SkyCoord("0d", "0d", frame="galactic"), width=3 * u.deg
 )
 ax = gc_image.smooth("0.1 deg").plot(stretch="sqrt")
 geom.plot_region(ax=ax, color="w")
+plt.show()
 
 
 ######################################################################
 # This time we define two energy bins and include the fit statistic
 # profile in the computation:
 #
 
@@ -275,30 +278,31 @@
 profile = flux_profile_estimator.run(datasets=dataset)
 
 
 ######################################################################
 # We can directly plot the result:
 #
 
-plt.figure()
 profile.plot(axis_name="projected-distance", sed_type="flux")
+plt.show()
 
 
 ######################################################################
 # However because of the powerlaw spectrum the flux at high energies is
 # much lower. To extract the profile at high energies only we can use:
 #
 
 profile_high = profile.slice_by_idx({"energy": slice(1, 2)})
+plt.show()
 
 
 ######################################################################
 # And now plot the points together with the likelihood profiles:
 #
 
 fig, ax = plt.subplots()
 profile_high.plot(ax=ax, sed_type="eflux", color="tab:orange")
 profile_high.plot_ts_profiles(ax=ax, sed_type="eflux")
 ax.set_yscale("linear")
-
-
 plt.show()
+
+# sphinx_gallery_thumbnail_number = 2
```

### Comparing `gammapy-1.0rc2/examples/tutorials/analysis-3d/simulate_3d.py` & `gammapy-1.1rc1/examples/tutorials/analysis-3d/simulate_3d.py`

 * *Files 6% similar despite different names*

```diff
@@ -32,15 +32,15 @@
 
 Proposed approach
 -----------------
 
 Here we can’t use the regular observation objects that are connected to
 a `DataStore`. Instead we will create a fake
 `~gammapy.data.Observation` that contain some pointing information and
-the CTA 1DC IRFs (that are loaded with `~gammapy.irf.load_cta_irfs`).
+the CTA 1DC IRFs (that are loaded with `~gammapy.irf.load_irf_dict_from_file`).
 
 Then we will create a `~gammapy.datasets.MapDataset` geometry and
 create it with the `~gammapy.makers.MapDatasetMaker`.
 
 Then we will be able to define a model consisting of a
 `~gammapy.modeling.models.PowerLawSpectralModel` and a
 `~gammapy.modeling.models.GaussianSpatialModel`. We will assign it to
@@ -59,15 +59,15 @@
 from astropy.coordinates import SkyCoord
 import matplotlib.pyplot as plt
 
 # %matplotlib inline
 from IPython.display import display
 from gammapy.data import Observation, observatory_locations
 from gammapy.datasets import MapDataset
-from gammapy.irf import load_cta_irfs
+from gammapy.irf import load_irf_dict_from_file
 from gammapy.makers import MapDatasetMaker, SafeMaskMaker
 from gammapy.maps import MapAxis, WcsGeom
 from gammapy.modeling import Fit
 from gammapy.modeling.models import (
     FoVBackgroundModel,
     GaussianSpatialModel,
     Models,
@@ -78,22 +78,19 @@
 ######################################################################
 # Simulation
 # ----------
 #
 
 
 ######################################################################
-# We will simulate using the CTA-1DC IRFs shipped with gammapy. Note that
-# for dedictaed CTA simulations, you can simply use
-# ``Observation.from_caldb()` <>`__ without having to externally load
-# the IRFs
+# We will simulate using the CTA-1DC IRFs shipped with gammapy
 #
 
 # Loading IRFs
-irfs = load_cta_irfs(
+irfs = load_irf_dict_from_file(
     "$GAMMAPY_DATA/cta-1dc/caldb/data/cta/1dc/bcf/South_z20_50h/irf_file.fits"
 )
 
 # Define the observation parameters (typically the observation duration and the pointing position):
 livetime = 2.0 * u.hr
 pointing = SkyCoord(0, 0, unit="deg", frame="galactic")
 
@@ -134,15 +131,15 @@
 models = Models([model_simu, bkg_model])
 print(models)
 
 
 ######################################################################
 # Now, comes the main part of dataset simulation. We create an in-memory
 # observation and an empty dataset. We then predict the number of counts
-# for the given model, and Poission fluctuate it using `fake()` to make
+# for the given model, and Poisson fluctuate it using `fake()` to make
 # a simulated counts maps. Keep in mind that it is important to specify
 # the `selection` of the maps that you want to produce
 #
 
 # Create an in-memory observation
 location = observatory_locations["cta_south"]
 obs = Observation.create(
@@ -155,31 +152,31 @@
 
 maker_safe_mask = SafeMaskMaker(methods=["offset-max"], offset_max=4.0 * u.deg)
 
 dataset = maker.run(empty, obs)
 dataset = maker_safe_mask.run(dataset, obs)
 print(dataset)
 
-# Add the model on the dataset and Poission fluctuate
+# Add the model on the dataset and Poisson fluctuate
 dataset.models = models
 dataset.fake()
 # Do a print on the dataset - there is now a counts maps
 print(dataset)
 
 
 ######################################################################
 # Now use this dataset as you would in all standard analysis. You can plot
 # the maps, or proceed with your custom analysis. In the next section, we
 # show the standard 3D fitting as in :doc:`/tutorials/analysis-3d/analysis_3d`
 # tutorial.
 #
 
 # To plot, eg, counts:
-plt.figure()
 dataset.counts.smooth(0.05 * u.deg).plot_interactive(add_cbar=True, stretch="linear")
+plt.show()
 
 
 ######################################################################
 # Fit
 # ---
 #
 # In this section, we do a usual 3D fit with the same model used to
@@ -196,16 +193,17 @@
 
 dataset.models = models_fit
 print(dataset.models)
 
 # %%time
 fit = Fit(optimize_opts={"print_level": 1})
 result = fit.run(datasets=[dataset])
-plt.figure()
+
 dataset.plot_residuals_spatial(method="diff/sqrt(model)", vmin=-0.5, vmax=0.5)
+plt.show()
 
 
 ######################################################################
 # Compare the injected and fitted models:
 #
 
 print(
@@ -217,9 +215,7 @@
 
 
 ######################################################################
 # Get the errors on the fitted parameters from the parameter table
 #
 
 display(result.parameters.to_table())
-
-plt.show()
```

### Comparing `gammapy-1.0rc2/examples/tutorials/analysis-time/light_curve.py` & `gammapy-1.1rc1/examples/tutorials/analysis-time/light_curve.py`

 * *Files 1% similar despite different names*

```diff
@@ -15,15 +15,15 @@
 
 This tutorial presents how light curve extraction is performed in
 gammapy, i.e. how to measure the flux of a source in different time
 bins.
 
 Cherenkov telescopes usually work with observing runs and distribute
 data according to this basic time interval. A typical use case is to
-look for variability of a source on various time binnings: observation
+look for variability of a source on various time bins: observation
 run-wise binning, nightly, weekly etc.
 
 **Objective: The Crab nebula is not known to be variable at TeV
 energies, so we expect constant brightness within statistical and
 systematic errors. Compute per-observation and nightly fluxes of the
 four Crab nebula observations from the H.E.S.S. first public test data
 release**\ `o <https://www.mpi-hd.mpg.de/hfm/HESS/pages/dl3-dr1/>`__\ **to
@@ -215,14 +215,15 @@
 # (points vs upper limits), even if this has no effect with this data set.
 fig, ax = plt.subplots(
     figsize=(8, 6),
     gridspec_kw={"left": 0.16, "bottom": 0.2, "top": 0.98, "right": 0.98},
 )
 lc_3d.sqrt_ts_threshold_ul = 5
 lc_3d.plot(ax=ax, axis_name="time")
+plt.show()
 
 table = lc_3d.to_table(format="lightcurve", sed_type="flux")
 display(table["time_min", "time_max", "e_min", "e_max", "flux", "flux_err"])
 
 
 ######################################################################
 # Running the light curve extraction in 1D
@@ -337,14 +338,15 @@
 fig, ax = plt.subplots(
     figsize=(8, 6),
     gridspec_kw={"left": 0.16, "bottom": 0.2, "top": 0.98, "right": 0.98},
 )
 lc_1d.plot(ax=ax, marker="o", label="1D")
 lc_3d.plot(ax=ax, marker="o", label="3D")
 plt.legend()
+plt.show()
 
 
 ######################################################################
 # Night-wise LC estimation
 # ------------------------
 #
 # Here we want to extract a night curve per night. We define the time
```

### Comparing `gammapy-1.0rc2/examples/tutorials/analysis-time/light_curve_flare.py` & `gammapy-1.1rc1/examples/tutorials/analysis-time/light_curve_flare.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,39 +1,39 @@
 """
 Light curves for flares
 =======================
 
-Compute the light curve of a PKS 2155-304 flare on 5 minutes time intervals.
+Compute the light curve of a PKS 2155-304 flare on 10 minutes time intervals.
 
 Prerequisites
 -------------
 
 -  Understanding of how the light curve estimator works, please refer to
-   the `light curve notebook <light_curve.ipynb>`__.
+   the :doc:`light curve notebook </tutorials/analysis-time/light_curve>`.
 
 Context
 -------
 
 Frequently, especially when studying flares of bright sources, it is
 necessary to explore the time behaviour of a source on short time
 scales, in particular on time scales shorter than observing runs.
 
 A typical example is given by the flare of PKS 2155-304 during the night
 from July 29 to 30 2006. See the `following
 article <https://ui.adsabs.harvard.edu/abs/2009A%26A...502..749A/abstract>`__.
 
 **Objective: Compute the light curve of a PKS 2155-304 flare on 5
-minutes time intervals, i.e. smaller than the duration of individual
+minutes time intervals, i.e. smaller than the duration of individual
 observations.**
 
 Proposed approach
 -----------------
 
 We have seen in the general presentation of the light curve estimator,
-see `light curve notebook <light_curve.ipynb>`__, Gammapy produces
+see the :doc:`light curve notebook </tutorials/analysis-time/light_curve>`, Gammapy produces
 datasets in a given time interval, by default that of the parent
 observation. To be able to produce datasets on smaller time steps, it is
 necessary to split the observations into the required time intervals.
 
 This is easily performed with the `~gammapy.data.Observations.select_time` method of
 `~gammapy.data.Observations`. If you pass it a list of time intervals
 it will produce a list of time filtered observations in a new
```

### Comparing `gammapy-1.0rc2/examples/tutorials/analysis-time/light_curve_simulation.py` & `gammapy-1.1rc1/examples/tutorials/analysis-time/light_curve_simulation.py`

 * *Files 1% similar despite different names*

```diff
@@ -79,15 +79,15 @@
 ######################################################################
 # And some gammapy specific imports
 #
 
 from gammapy.data import Observation, observatory_locations
 from gammapy.datasets import Datasets, FluxPointsDataset, SpectrumDataset
 from gammapy.estimators import LightCurveEstimator
-from gammapy.irf import load_cta_irfs
+from gammapy.irf import load_irf_dict_from_file
 from gammapy.makers import SpectrumDatasetMaker
 from gammapy.maps import MapAxis, RegionGeom, TimeMapAxis
 from gammapy.modeling import Fit
 from gammapy.modeling.models import (
     ExpDecayTemporalModel,
     PowerLawSpectralModel,
     SkyModel,
@@ -115,15 +115,15 @@
 # We will simulate 10 spectra between 300 GeV and 10 TeV using an
 # `PowerLawSpectralModel` and a `ExpDecayTemporalModel`. The important
 # thing to note here is how to attach a different `GTI` to each dataset.
 # Since we use spectrum datasets here, we will use a `RegionGeom`.
 #
 
 # Loading IRFs
-irfs = load_cta_irfs(
+irfs = load_irf_dict_from_file(
     "$GAMMAPY_DATA/cta-1dc/caldb/data/cta/1dc/bcf/South_z20_50h/irf_file.fits"
 )
 
 # Reconstructed and true energy axis
 energy_axis = MapAxis.from_edges(
     np.logspace(-0.5, 1.0, 10), unit="TeV", name="energy", interp="log"
 )
@@ -214,15 +214,15 @@
 # Extract the lightcurve
 # ----------------------
 #
 # This section uses standard light curve estimation tools for a 1D
 # extraction. Only a spectral model needs to be defined in this case.
 # Since the estimator returns the integrated flux separately for each time
 # bin, the temporal model need not be accounted for at this stage. We
-# extract the lightcurve in 3 energy binsç
+# extract the lightcurve in 3 energy bins.
 #
 
 # Define the model:
 spectral_model = PowerLawSpectralModel(
     index=3, amplitude="1e-11 cm-2 s-1 TeV-1", reference="1 TeV"
 )
 model_fit = SkyModel(spectral_model=spectral_model, name="model-fit")
@@ -239,14 +239,15 @@
 lc_1d = lc_maker_1d.run(datasets)
 
 fig, ax = plt.subplots(
     figsize=(8, 6),
     gridspec_kw={"left": 0.16, "bottom": 0.2, "top": 0.98, "right": 0.98},
 )
 lc_1d.plot(ax=ax, marker="o", axis_name="time", sed_type="flux")
+plt.show()
 
 
 ######################################################################
 # Fitting temporal models
 # -----------------------
 #
 # We have the reconstructed lightcurve at this point. Now we want to fit a
@@ -314,14 +315,15 @@
 lc_1TeV_10TeV.plot(ax=ax, sed_type="norm", axis_name="time")
 
 time_range = lc_1TeV_10TeV.geom.axes["time"].time_bounds
 temporal_model1.plot(ax=ax, time_range=time_range, label="Best fit model")
 
 ax.set_yscale("linear")
 ax.legend()
+plt.show()
 
 
 ######################################################################
 # Fit the datasets
 # ~~~~~~~~~~~~~~~~
 #
 # Here, we apply the models directly to the simulated datasets.
@@ -351,24 +353,23 @@
 # %%time
 # Do a joint fit
 fit = Fit()
 result = fit.run(datasets=datasets)
 
 display(result.parameters.to_table())
 
-plt.show()
 ######################################################################
 # We see that the fitted parameters are consistent between fitting flux
 # points and datasets, and match well with the simulated ones
 #
 
 
 ######################################################################
 # Exercises
 # ---------
 #
 # 1. Re-do the analysis with `MapDataset` instead of `SpectralDataset`
-# 2. Model the flare of PKS 2155-304 which you obtained using the
-#   :doc:`/tutorials/analysis-time/light_curve_flare` tutorial.
-#   Use a combination of a Gaussian and Exponential flare profiles.
+# 2. Model the flare of PKS 2155-304 which you obtained using
+#    the :doc:`/tutorials/analysis-time/light_curve_flare` tutorial.
+#    Use a combination of a Gaussian and Exponential flare profiles.
 # 3. Do a joint fitting of the datasets.
 #
```

### Comparing `gammapy-1.0rc2/examples/tutorials/analysis-time/pulsar_analysis.py` & `gammapy-1.1rc1/examples/tutorials/analysis-time/pulsar_analysis.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,349 +1,442 @@
 """
 Pulsar analysis
-===============
-
-Produce a phasogram, phased-resolved maps and spectra in pulsar analysis.
+---------------
 
+Produce a phasogram, phased-resolved maps and spectra for pulsar analysis.
+ 
 Introduction
 ------------
 
+This notebook shows how to do a simple pulsar analysis with Gammapy. We will produce a
+phasogram, a phase-resolved map and a phase-resolved spectrum of the Vela pulsar. In
+order to build these products, we will use the
+`~PhaseBackgroundMaker` which takes into account the on and off phase to compute a
+`~MapDatasetOnOff` and a `~SpectrumDatasetOnOff` in the phase space.
 
+This tutorial uses a simulated run of vel observation from the CTA DC1, which already contains a
+column for the pulsar phases. The phasing in itself is therefore not show here. It
+requires specific packages like Tempo2 or [PINT]((https://nanograv-pint.readthedocs.io). A gammapy
+recipe shows how to compute phases with PINT in the framework of Gammapy.
 
-This notebook shows how to do a pulsar analysis with Gammapy. It’s based
-on a Vela simulation file from the CTA DC1, which already contains a
-column of phases. We will produce a phasogram, a phase-resolved map and
-a phase-resolved spectrum of the Vela pulsar using the class
-PhaseBackgroundEstimator.
 
-The phasing in itself is not done here, and it requires specific
-packages like Tempo2 or `PINT <https://nanograv-pint.readthedocs.io>`__.
-"""
 
-######################################################################
-# Opening the data
-# ----------------
-#
+Opening the data
+----------------
 
+Let’s first do the imports and load the only observation containing Vela
+in the CTA 1DC dataset shipped with Gammapy.
+
+"""
 
-######################################################################
-# Let’s first do the imports and load the only observation containing Vela
-# in the CTA 1DC dataset shipped with Gammapy.
-#
 
+# Remove warnings
+import warnings
 import numpy as np
 import astropy.units as u
 from astropy.coordinates import SkyCoord
 import matplotlib.pyplot as plt
 
 # %matplotlib inline
 from IPython.display import display
 from gammapy.data import DataStore
-from gammapy.datasets import Datasets, FluxPointsDataset, SpectrumDataset
-from gammapy.estimators import FluxPointsEstimator
-from gammapy.makers import PhaseBackgroundMaker, SafeMaskMaker, SpectrumDatasetMaker
-from gammapy.maps import Map, MapAxis, RegionGeom, WcsGeom
+from gammapy.datasets import Datasets, FluxPointsDataset, MapDataset, SpectrumDataset
+from gammapy.estimators import ExcessMapEstimator, FluxPointsEstimator
+from gammapy.makers import (
+    MapDatasetMaker,
+    PhaseBackgroundMaker,
+    SafeMaskMaker,
+    SpectrumDatasetMaker,
+)
+from gammapy.maps import MapAxis, RegionGeom, WcsGeom
 from gammapy.modeling import Fit
 from gammapy.modeling.models import PowerLawSpectralModel, SkyModel
+from gammapy.stats import WStatCountsStatistic
+from gammapy.utils.regions import SphericalCircleSkyRegion
+
+warnings.filterwarnings("ignore")
+
 
 ######################################################################
 # Check setup
 # -----------
+
+
 from gammapy.utils.check import check_tutorials_setup
-from gammapy.utils.regions import SphericalCircleSkyRegion
 
 check_tutorials_setup()
 
 
 ######################################################################
 # Load the data store (which is a subset of CTA-DC1 data):
-#
+
 
 data_store = DataStore.from_dir("$GAMMAPY_DATA/cta-1dc/index/gps")
 
 
 ######################################################################
-# Define obsevation ID and print events:
-#
+# Define observation ID and print events:
+
 
 id_obs_vela = [111630]
 obs_list_vela = data_store.get_observations(id_obs_vela)
 print(obs_list_vela[0].events)
 
 
 ######################################################################
 # Now that we have our observation, let’s select the events in 0.2° radius
 # around the pulsar position.
-#
+
 
 pos_target = SkyCoord(ra=128.836 * u.deg, dec=-45.176 * u.deg, frame="icrs")
 on_radius = 0.2 * u.deg
 on_region = SphericalCircleSkyRegion(pos_target, on_radius)
 
 # Apply angular selection
 events_vela = obs_list_vela[0].events.select_region(on_region)
 print(events_vela)
 
 
 ######################################################################
 # Let’s load the phases of the selected events in a dedicated array.
-#
+
 
 phases = events_vela.table["PHASE"]
 
 # Let's take a look at the first 10 phases
 display(phases[:10])
 
 
 ######################################################################
 # Phasogram
 # ---------
 #
 # Once we have the phases, we can make a phasogram. A phasogram is a
-# histogram of phases and it works exactly like any other histogram (you
+# histogram of phases. It works exactly like any other histogram (you
 # can set the binning, evaluate the errors based on the counts in each
 # bin, etc).
-#
 
 nbins = 30
 phase_min, phase_max = (0, 1)
 values, bin_edges = np.histogram(phases, range=(phase_min, phase_max), bins=nbins)
 bin_width = (phase_max - phase_min) / nbins
 
 bin_center = (bin_edges[:-1] + bin_edges[1:]) / 2
 
-
 # Poissonian uncertainty on each bin
 values_err = np.sqrt(values)
 
 fig, ax = plt.subplots()
 ax.bar(
     x=bin_center,
     height=values,
     width=bin_width,
-    color="#d53d12",
-    alpha=0.8,
+    color="orangered",
+    alpha=0.7,
     edgecolor="black",
     yerr=values_err,
 )
 ax.set_xlim(0, 1)
 ax.set_xlabel("Phase")
 ax.set_ylabel("Counts")
 ax.set_title(f"Phasogram with angular cut of {on_radius}")
+plt.show()
+
+on_phase_range = (0.5, 0.6)
+off_phase_range = (0.7, 1)
 
 
 ######################################################################
 # Now let’s add some fancy additions to our phasogram: a patch on the ON-
 # and OFF-phase regions and one for the background level.
-#
 
 # Evaluate background level
-off_phase_range = (0.7, 1.0)
-on_phase_range = (0.5, 0.6)
-
 mask_off = (off_phase_range[0] < phases) & (phases < off_phase_range[1])
 
 count_bkg = mask_off.sum()
 print(f"Number of Off events: {count_bkg}")
 
 # bkg level normalized by the size of the OFF zone (0.3)
 bkg = count_bkg / nbins / (off_phase_range[1] - off_phase_range[0])
 
 # error on the background estimation
 bkg_err = np.sqrt(count_bkg) / nbins / (off_phase_range[1] - off_phase_range[0])
 
+######################################################################
 # Let's redo the same plot for the basis
-fig, ax = plt.subplots()
+
+fig, ax = plt.subplots(figsize=(10, 7))
 ax.bar(
     x=bin_center,
     height=values,
     width=bin_width,
-    color="#d53d12",
-    alpha=0.8,
+    color="orangered",
+    alpha=0.7,
     edgecolor="black",
     yerr=values_err,
 )
 
 # Plot background level
 x_bkg = np.linspace(0, 1, 50)
 
-kwargs = {"color": "black", "alpha": 0.5, "ls": "--", "lw": 2}
+kwargs = {"color": "black", "alpha": 0.7, "ls": "--", "lw": 2}
 
 ax.plot(x_bkg, (bkg - bkg_err) * np.ones_like(x_bkg), **kwargs)
 ax.plot(x_bkg, (bkg + bkg_err) * np.ones_like(x_bkg), **kwargs)
 
 ax.fill_between(
     x_bkg, bkg - bkg_err, bkg + bkg_err, facecolor="grey", alpha=0.5
 )  # grey area for the background level
 
 # Let's make patches for the on and off phase zones
 on_patch = ax.axvspan(
-    on_phase_range[0], on_phase_range[1], alpha=0.3, color="gray", ec="black"
+    on_phase_range[0], on_phase_range[1], alpha=0.5, color="royalblue", ec="black"
 )
 
 off_patch = ax.axvspan(
     off_phase_range[0],
     off_phase_range[1],
-    alpha=0.4,
+    alpha=0.25,
     color="white",
     hatch="x",
     ec="black",
 )
 
 # Legends "ON" and "OFF"
 ax.text(0.55, 5, "ON", color="black", fontsize=17, ha="center")
 ax.text(0.895, 5, "OFF", color="black", fontsize=17, ha="center")
 ax.set_xlabel("Phase")
 ax.set_ylabel("Counts")
 ax.set_xlim(0, 1)
 ax.set_title(f"Phasogram with angular cut of {on_radius}")
+plt.show()
+
+
+######################################################################
+# Make a Li&Ma test over the events
+# ---------------------------------
+#
+# Another thing that we want to do is to compute a Li&Ma test between the on-phase and the off-phase.
+
+# Calculate the ratio between the on-phase and the off-phase
+alpha = (on_phase_range[1] - on_phase_range[0]) / (
+    off_phase_range[1] - off_phase_range[0]
+)
+
+# Select events in the on region
+region_events = obs_list_vela[0].events.select_region(on_region)
+
+# Select events in phase space
+on_events = region_events.select_parameter("PHASE", band=on_phase_range)
+off_events = region_events.select_parameter("PHASE", band=off_phase_range)
+
+# Apply the WStat (Li&Ma statistic)
+pulse_stat = WStatCountsStatistic(
+    len(on_events.time), len(off_events.time), alpha=alpha
+)
+
+print(f"Number of excess counts: {pulse_stat.n_sig}")
+print(f"TS: {pulse_stat.ts}")
+print(f"Significance: {pulse_stat.sqrt_ts}")
 
 
 ######################################################################
 # Phase-resolved map
 # ------------------
-#
 
 
 ######################################################################
-# Now that the phases are computed, we want to do a phase-resolved sky map
+# Now that we have an overview of the phasogram of the pulsar, we can do a phase-resolved sky map
 # : a map of the ON-phase events minus alpha times the OFF-phase events.
 # Alpha is the ratio between the size of the ON-phase zone (here 0.1) and
-# the OFF-phase zone (0.3). It’s a map of the excess events in phase,
-# which are the pulsed events.
-#
+# the OFF-phase zone (0.3).
+
+e_true = MapAxis.from_energy_bounds(
+    0.003, 10, 6, per_decade=True, unit="TeV", name="energy_true"
+)
+e_reco = MapAxis.from_energy_bounds(
+    0.01, 10, 4, per_decade=True, unit="TeV", name="energy"
+)
 
-geom = WcsGeom.create(binsz=0.02 * u.deg, skydir=pos_target, width="5 deg")
+geom = WcsGeom.create(
+    binsz=0.02 * u.deg, skydir=pos_target, width="4 deg", axes=[e_reco]
+)
 
 
 ######################################################################
 # Let’s create an ON-map and an OFF-map:
-#
 
-on_map = Map.from_geom(geom)
-off_map = Map.from_geom(geom)
+map_dataset_empty = MapDataset.create(geom=geom, energy_axis_true=e_true)
 
-events_vela_on = events_vela.select_parameter("PHASE", on_phase_range)
-events_vela_off = events_vela.select_parameter("PHASE", off_phase_range)
+map_dataset_maker = MapDatasetMaker()
+phase_bkg_maker = PhaseBackgroundMaker(
+    on_phase=on_phase_range, off_phase=off_phase_range, phase_column_name="PHASE"
+)
 
-on_map.fill_events(events_vela_on)
-off_map.fill_events(events_vela_off)
+offset_max = 5 * u.deg
+safe_mask_maker = SafeMaskMaker(methods=["offset-max"], offset_max=offset_max)
 
-# Defining alpha as the ratio of the ON and OFF phase zones
-alpha = (on_phase_range[1] - on_phase_range[0]) / (
-    off_phase_range[1] - off_phase_range[0]
+map_datasets = Datasets()
+
+for obs in obs_list_vela:
+    map_dataset = map_dataset_maker.run(map_dataset_empty, obs)
+    map_dataset = safe_mask_maker.run(map_dataset, obs)
+    map_dataset_on_off = phase_bkg_maker.run(map_dataset, obs)
+    map_datasets.append(map_dataset_on_off)
+
+
+######################################################################
+# Once the data reduction is done, we can plot the map of the counts-ON (i.e. in the ON-phase)
+# and the map of the background (i.e. the counts-OFF, selected in the OFF-phase, multiplied by alpha).
+# If one wants to plot the counts-OFF instead, `~background` should be replaced by `~counts_off` in the following cell.
+
+counts = (
+    map_datasets[0].counts.smooth(kernel="gauss", width=0.1 * u.deg).sum_over_axes()
 )
+background = (
+    map_datasets[0].background.smooth(kernel="gauss", width=0.1 * u.deg).sum_over_axes()
+)
+
+fig, (ax1, ax2) = plt.subplots(
+    figsize=(11, 5), ncols=2, subplot_kw={"projection": counts.geom.wcs}
+)
+
+counts.plot(ax=ax1, add_cbar=True)
+ax1.set_title("Counts")
+
+background.plot(ax=ax2, add_cbar=True)
+ax2.set_title("Background")
 
-# Create and fill excess map
-# The pulsed events are the difference between the ON-phase count and alpha times the OFF-phase count
-excess_map = on_map - off_map * alpha
-
-# Plot excess map
-plt.figure()
-excess_map.smooth(kernel="gauss", width=0.2 * u.deg).plot(add_cbar=True)
+plt.show()
 
 
 ######################################################################
-# Phase-resolved spectrum
-# -----------------------
-#
+# Finally, we can run an `~gammapy.estimators.ExcessMapEstimator` to compute the excess and significance maps.
+
+excess_map_estimator = ExcessMapEstimator(
+    correlation_radius="0.2 deg", energy_edges=[50 * u.GeV, 10 * u.TeV]
+)
+estimator_results = excess_map_estimator.run(dataset=map_datasets[0])
+
+npred_excess = estimator_results.npred_excess
+sqrt_ts = estimator_results.sqrt_ts
+
+fig, (ax1, ax2) = plt.subplots(
+    figsize=(11, 5), ncols=2, subplot_kw={"projection": npred_excess.geom.wcs}
+)
+
+npred_excess.plot(ax=ax1, add_cbar=True)
+ax1.set_title("Excess counts")
+
+sqrt_ts.plot(ax=ax2, add_cbar=True)
+ax2.set_title("Significance")
+
+plt.show()
 
 
 ######################################################################
-# We can also do a phase-resolved spectrum. In order to do that, there is
-# the class PhaseBackgroundMaker. In a phase-resolved analysis, the
-# background is estimated in the same sky region but in the OFF-phase
-# zone.
+# Note that here we are lacking statistic because we only use one run of CTA.
+#
+# Phase-resolved spectrum
+# -----------------------
 #
+# We can also make a phase-resolved spectrum.
+# In order to do that, we are going to use the `~gammapy.makers.PhaseBackgroundMaker` to create a
+# `~gammapy.makers.SpectrumDatasetOnOff` with the ON and OFF taken in the phase space.
+# Note that this maker take the ON and OFF in the same spatial region.
+#
+# Here to create the `~gammapy.datasets.SpectrumDatasetOnOff`, we are going to redo the whole data reduction.
+# However, note that one can use the `to_spectrum_dataset()` method of `~gammapy.datasets.MapDatasetOnOff`
+# (with the `containment_correction` parameter set to True) if such a `~gammapy.datasets.MapDatasetOnOff`
+# has been created as shown above.
 
 e_true = MapAxis.from_energy_bounds(0.003, 10, 100, unit="TeV", name="energy_true")
 e_reco = MapAxis.from_energy_bounds(0.01, 10, 30, unit="TeV", name="energy")
 
 
 geom = RegionGeom.create(region=on_region, axes=[e_reco])
 
-dataset_empty = SpectrumDataset.create(geom=geom, energy_axis_true=e_true)
+spectrum_dataset_empty = SpectrumDataset.create(geom=geom, energy_axis_true=e_true)
 
-dataset_maker = SpectrumDatasetMaker()
+spectrum_dataset_maker = SpectrumDatasetMaker()
 phase_bkg_maker = PhaseBackgroundMaker(
-    on_phase=on_phase_range, off_phase=off_phase_range
+    on_phase=on_phase_range, off_phase=off_phase_range, phase_column_name="PHASE"
 )
-safe_mask_maker = SafeMaskMaker(methods=["aeff-default", "edisp-bias"], bias_percent=20)
 
-datasets = []
+offset_max = 5 * u.deg
+safe_mask_maker = SafeMaskMaker(methods=["offset-max"], offset_max=offset_max)
+
+spectrum_datasets = Datasets()
 
 for obs in obs_list_vela:
-    dataset = dataset_maker.run(dataset_empty, obs)
-    dataset_on_off = phase_bkg_maker.run(dataset, obs)
-    dataset_on_off = safe_mask_maker.run(dataset_on_off, obs)
-    datasets.append(dataset_on_off)
+    spectrum_dataset = spectrum_dataset_maker.run(spectrum_dataset_empty, obs)
+    spectrum_dataset = safe_mask_maker.run(spectrum_dataset, obs)
+    spectrum_dataset_on_off = phase_bkg_maker.run(spectrum_dataset, obs)
+    spectrum_datasets.append(spectrum_dataset_on_off)
 
 
 ######################################################################
-# Now let’s a look at the datasets we just created:
-#
+# Now let’s take a look at the datasets we just created:
 
-datasets[0].peek()
+spectrum_datasets[0].peek()
+plt.show()
 
 
 ######################################################################
-# Now we’ll fit a model to the spectrum with the `Fit` class. First we
+# Now we’ll fit a model to the spectrum with the `~gammapy.modeling.Fit` class. First we
 # load a power law model with an initial value for the index and the
 # amplitude and then wo do a likelihood fit. The fit results are printed
 # below.
-#
 
 spectral_model = PowerLawSpectralModel(
     index=4, amplitude="1.3e-9 cm-2 s-1 TeV-1", reference="0.02 TeV"
 )
 model = SkyModel(spectral_model=spectral_model, name="vela psr")
 emin_fit, emax_fit = (0.04 * u.TeV, 0.4 * u.TeV)
 
 mask_fit = geom.energy_mask(energy_min=emin_fit, energy_max=emax_fit)
 
-for dataset in datasets:
+for dataset in spectrum_datasets:
     dataset.models = model
     dataset.mask_fit = mask_fit
 
 joint_fit = Fit()
-joint_result = joint_fit.run(datasets=datasets)
+joint_result = joint_fit.run(datasets=spectrum_datasets)
 
 print(joint_result)
 
 
 ######################################################################
 # Now you might want to do the stacking here even if in our case there is
 # only one observation which makes it superfluous. We can compute flux
 # points by fitting the norm of the global model in energy bands.
-#
 
 energy_edges = np.logspace(np.log10(0.04), np.log10(0.4), 7) * u.TeV
 
-dataset = Datasets(datasets).stack_reduce()
+stack_dataset = spectrum_datasets.stack_reduce()
 
-dataset.models = model
+stack_dataset.models = model
 
 fpe = FluxPointsEstimator(
     energy_edges=energy_edges, source="vela psr", selection_optional="all"
 )
 
-flux_points = fpe.run(datasets=[dataset])
+flux_points = fpe.run(datasets=[stack_dataset])
 flux_points.meta["ts_threshold_ul"] = 1
 
 amplitude_ref = 0.57 * 19.4e-14 * u.Unit("1 / (cm2 s MeV)")
 spec_model_true = PowerLawSpectralModel(
     index=4.5, amplitude=amplitude_ref, reference="20 GeV"
 )
 
 flux_points_dataset = FluxPointsDataset(data=flux_points, models=model)
 
 
 ######################################################################
 # Now we can plot.
-#
 
 ax_spectrum, ax_residuals = flux_points_dataset.plot_fit()
 
 ax_spectrum.set_ylim([1e-14, 3e-11])
 ax_residuals.set_ylim([-1.7, 1.7])
 
 spec_model_true.plot(
@@ -360,8 +453,7 @@
 plt.show()
 
 ######################################################################
 # This tutorial suffers a bit from the lack of statistics: there were 9
 # Vela observations in the CTA DC1 while there is only one here. When done
 # on the 9 observations, the spectral analysis is much better agreement
 # between the input model and the gammapy fit.
-#
```

### Comparing `gammapy-1.0rc2/examples/tutorials/api/astro_dark_matter.py` & `gammapy-1.1rc1/examples/tutorials/api/astro_dark_matter.py`

 * *Files 15% similar despite different names*

```diff
@@ -26,15 +26,15 @@
 #
 # As always, we start with some setup for the notebook, and with imports.
 #
 
 import numpy as np
 import astropy.units as u
 from astropy.coordinates import SkyCoord
-from regions import CircleSkyRegion
+from regions import CircleSkyRegion, RectangleSkyRegion
 
 # %matplotlib inline
 import matplotlib.pyplot as plt
 from matplotlib.colors import LogNorm
 from gammapy.astro.darkmatter import (
     DarkMatterAnnihilationSpectralModel,
     JFactory,
@@ -59,39 +59,39 @@
 # can be scaled to a given density at a certain distance. These parameters
 # are controlled by `~gammapy.astro.darkmatter.profiles.DMProfile.LOCAL_DENSITY` and
 # `~gammapy.astro.darkmatter.profiles.DMProfile.DISTANCE_GC`
 #
 
 profiles.DMProfile.__subclasses__()
 
-plt.figure()
 for profile in profiles.DMProfile.__subclasses__():
     p = profile()
     p.scale_to_local_density()
     radii = np.logspace(-3, 2, 100) * u.kpc
     plt.plot(radii, p(radii), label=p.__class__.__name__)
 
 plt.loglog()
 plt.axvline(8.5, linestyle="dashed", color="black", label="local density")
 plt.legend()
+plt.show()
 
 print("LOCAL_DENSITY:", profiles.DMProfile.LOCAL_DENSITY)
 print("DISTANCE_GC:", profiles.DMProfile.DISTANCE_GC)
 
 
 ######################################################################
 # J Factors
 # ---------
 #
 # There are utilities to compute J-Factor maps that can serve as a basis
 # to compute J-Factors for certain regions. In the following we compute a
 # J-Factor map for the Galactic Centre region
 #
 
-profile = profiles.NFWProfile()
+profile = profiles.NFWProfile(r_s=20 * u.kpc)
 
 # Adopt standard values used in HESS
 profiles.DMProfile.DISTANCE_GC = 8.5 * u.kpc
 profiles.DMProfile.LOCAL_DENSITY = 0.39 * u.Unit("GeV / cm3")
 
 profile.scale_to_local_density()
 
@@ -102,28 +102,40 @@
 jfact = jfactory.compute_jfactor()
 
 jfact_map = WcsNDMap(geom=geom, data=jfact.value, unit=jfact.unit)
 plt.figure()
 ax = jfact_map.plot(cmap="viridis", norm=LogNorm(), add_cbar=True)
 plt.title(f"J-Factor [{jfact_map.unit}]")
 
-# 1 deg circle usually used in H.E.S.S. analyses
+# 1 deg circle usually used in H.E.S.S. analyses without the +/- 0.3 deg band around the plane
 sky_reg = CircleSkyRegion(center=position, radius=1 * u.deg)
 pix_reg = sky_reg.to_pixel(wcs=geom.wcs)
 pix_reg.plot(ax=ax, facecolor="none", edgecolor="red", label="1 deg circle")
+
+sky_reg_rec = RectangleSkyRegion(center=position, height=0.6 * u.deg, width=2 * u.deg)
+pix_reg_rec = sky_reg_rec.to_pixel(wcs=geom.wcs)
+pix_reg_rec.plot(ax=ax, facecolor="none", edgecolor="orange", label="+/- 0.3 deg band")
+
 plt.legend()
+plt.show()
 
-# NOTE: https://arxiv.org/abs/1607.08142 quote 2.67e21 without the +/- 0.3 deg band around the plane
-total_jfact = pix_reg.to_mask().multiply(jfact).sum()
+# NOTE: https://arxiv.org/abs/1607.08142 quote 2.67e21
+total_jfact = (
+    pix_reg.to_mask().multiply(jfact).sum()
+    - pix_reg_rec.to_mask().multiply(jfact).sum()
+)
+total_jfact = (
+    pix_reg.to_mask().multiply(jfact).sum()
+    - pix_reg_rec.to_mask().multiply(jfact).sum()
+)
 print(
-    "J-factor in 1 deg circle around GC assuming a "
+    "J-factor in 1 deg circle without the +/- 0.3 deg band around GC assuming a "
     f"{profile.__class__.__name__} is {total_jfact:.3g}"
 )
 
-
 ######################################################################
 # Gamma-ray spectra at production
 # -------------------------------
 #
 # The gamma-ray spectrum per annihilation is a further ingredient for a
 # dark matter analysis. The following annihilation channels are supported.
 # For more info see https://arxiv.org/pdf/1012.4515.pdf
@@ -148,14 +160,15 @@
             ax=ax,
             label=channel,
             yunits=u.Unit("1/GeV"),
         )
 
 axes[0].legend()
 plt.subplots_adjust(hspace=0.9)
+plt.show()
 
 
 ######################################################################
 # Flux maps
 # ---------
 #
 # Finally flux maps can be produced like this:
```

### Comparing `gammapy-1.0rc2/examples/tutorials/api/catalog.py` & `gammapy-1.1rc1/examples/tutorials/api/catalog.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,20 +4,20 @@
 
 Access and explore thew most common gamma-ray source catalogs.
 
 Introduction
 ------------
 
 `~gammapy.catalog` provides convenient access to common gamma-ray
-source catalogs. This module is mostly independent from the rest of
-Gammapy. Typically you use it to compare new analyses against catalog
-results, e.g. overplot the spectral model, or compare the source
+source catalogs. This module is mostly independent of the rest of
+Gammapy. Typically, you use it to compare new analyses against catalog
+results, e.g. overplot the spectral model, or compare the source
 position.
 
-Moreover as creating a source model and flux points for a given catalog
+Moreover, as creating a source model and flux points for a given catalog
 from the FITS table is tedious, `~gammapy.catalog` has this already
 implemented. So you can create initial source models for your analyses.
 This is very common for Fermi-LAT, to start with a catalog model. For
 TeV analysis, especially in crowded Galactic regions, using the HGPS,
 gamma-cat or 2HWC catalog in this way can also be useful.
 
 In this tutorial you will learn how to:
@@ -37,15 +37,15 @@
 -  `~gammapy.catalog.SourceCatalogHGPS`
 -  `~gammapy.catalog.SourceCatalogGammaCat`
 -  `~gammapy.catalog.SourceCatalog3FHL`
 -  `~gammapy.catalog.SourceCatalog4FGL`
 
 All catalog and source classes work the same, as long as some
 information is available. E.g. trying to access a lightcurve from a
-catalog and source that doesn’t have that information will return
+catalog and source that does not have that information will return
 `None`.
 
 Further information is available at `~gammapy.catalog`.
 
 """
 
 import numpy as np
@@ -294,19 +294,19 @@
 # %%
 print(model.spatial_model)
 
 # %%
 print(model.spectral_model)
 
 # %%
-plt.figure()
 energy_bounds = (100 * u.MeV, 100 * u.GeV)
 opts = dict(sed_type="e2dnde", yunits=u.Unit("TeV cm-2 s-1"))
 model.spectral_model.plot(energy_bounds, **opts)
 model.spectral_model.plot_error(energy_bounds, **opts)
+plt.show()
 
 
 ######################################################################
 # You can create initial source models for your analyses using the
 # `~gammapy.catalog.SourceCatalog.to_models()` method of the catalog objects. Here for example we
 # create a `~gammapy.modeling.models.Models` object from the 4FGL catalog subset we previously
 # defined:
@@ -372,16 +372,16 @@
 
 print(flux_points)
 
 # %%
 display(flux_points.to_table(sed_type="flux"))
 
 # %%
-plt.figure()
 flux_points.plot(sed_type="e2dnde")
+plt.show()
 
 
 ######################################################################
 # Lightcurves
 # -----------
 #
 # The Fermi catalogs contain lightcurves for each source. It is available
@@ -393,16 +393,16 @@
 
 print(lightcurve)
 
 # %%
 display(lightcurve.to_table(format="lightcurve", sed_type="flux"))
 
 # %%
-plt.figure()
 lightcurve.plot()
+plt.show()
 
 
 ######################################################################
 # Pretty-print source information
 # -------------------------------
 #
 # A source object has a nice string representation that you can print.
@@ -418,10 +418,7 @@
 # can learn about them using `help()`
 #
 
 help(source.info)
 
 # %%
 print(source.info("associations"))
-
-# %%
-plt.show()
```

### Comparing `gammapy-1.0rc2/examples/tutorials/api/datasets.py` & `gammapy-1.1rc1/examples/tutorials/api/datasets.py`

 * *Files 16% similar despite different names*

```diff
@@ -155,22 +155,23 @@
 print(dataset_cta.info_dict())
 
 ######################################################################
 # For a quick view, use
 #
 
 dataset_cta.peek()
-
+plt.show()
 
 ######################################################################
 # And access individual maps like:
 #
 plt.figure()
 counts_image = dataset_cta.counts.sum_over_axes()
 counts_image.smooth("0.1 deg").plot()
+plt.show()
 
 
 ######################################################################
 # Of course you can also access IRF related maps, e.g. the psf as
 # `~gammapy.irf.PSFMap`:
 #
 
@@ -181,17 +182,17 @@
 # And use any method on the `~gammapy.irf.PSFMap` object:
 #
 radius = dataset_cta.psf.containment_radius(energy_true=1 * u.TeV, fraction=0.95)
 print(radius)
 
 # %%
 
-plt.figure()
 edisp_kernel = dataset_cta.edisp.get_edisp_kernel()
 edisp_kernel.plot_matrix()
+plt.show()
 
 
 ######################################################################
 # The `~gammapy.datasets.MapDataset` typically also contains the information on the
 # residual hadronic background, stored in `~gammapy.datasets.MapDataset.background` as a
 # map:
 #
@@ -208,52 +209,51 @@
 model.spatial_model.position = SkyCoord("0d", "0d", frame="galactic")
 model_bkg = FoVBackgroundModel(dataset_name="dataset-cta")
 
 dataset_cta.models = [model, model_bkg]
 
 
 ######################################################################
-# Assigning models to datasets is covered in more detail in the
-#  :doc:`/tutorials/api/model_management`. Printing the dataset will now show
-# the mode components:
+# Assigning models to datasets is covered in more detail in :doc:`/tutorials/api/model_management`.
+# Printing the dataset will now show the model components:
 #
 
 print(dataset_cta)
 
 
 ######################################################################
 # Now we can use the `~gammapy.datasets.MapDataset.npred` method to get a map of the total predicted counts
 # of the model:
 #
 
-plt.figure()
 npred = dataset_cta.npred()
 npred.sum_over_axes().plot()
+plt.show()
 
 
 ######################################################################
 # To get the predicted counts from an individual model component we can
 # use:
 #
 
-plt.figure()
 npred_source = dataset_cta.npred_signal(model_name="gc")
 npred_source.sum_over_axes().plot()
+plt.show()
 
 
 ######################################################################
 # `~gammapy.datasets.MapDataset.background` contains the background map computed from the
 # IRF. Internally it will be combined with a `~gammapy.modeling.models.FoVBackgroundModel`, to
-# allow for adjusting the backgroun model during a fit. To get the model
+# allow for adjusting the background model during a fit. To get the model
 # corrected background, one can use `~gammapy.datasets.MapDataset.npred_background`.
 #
 
-plt.figure()
 npred_background = dataset_cta.npred_background()
 npred_background.sum_over_axes().plot()
+plt.show()
 
 
 ######################################################################
 # Using masks
 # ~~~~~~~~~~~
 #
 # There are two masks that can be set on a `~gammapy.datasets.MapDataset`, `~gammapy.datasets.MapDataset.mask_safe` and
@@ -265,37 +265,39 @@
 # -  During modelling and fitting, the user might want to additionally
 #    ignore some parts of a reduced dataset, e.g. to restrict the fit to a
 #    specific energy range or to ignore parts of the region of interest.
 #    This should be done by applying the `~gammapy.datasets.MapDataset.mask_fit`. To see details of
 #    applying masks, please refer to :ref:`masks-for-fitting`.
 #
 # Both the `~gammapy.datasets.MapDataset.mask_fit` and `~gammapy.datasets.MapDataset.mask_safe` must
-# have the same `~gammapy.maps.Map.geom` as the `~gammapy.datasets.MapDataset.counts` and `~gammapy.datasets.MapDataset.background` maps.
+# have the same `~gammapy.maps.Map.geom` as the `~gammapy.datasets.MapDataset.counts` and
+# `~gammapy.datasets.MapDataset.background` maps.
 #
 
 # eg: to see the safe data range
 
-# plt.figure()
 dataset_cta.mask_safe.plot_grid()
+plt.show()
 
 
 ######################################################################
 # In addition it is possible to define a custom `~gammapy.datasets.MapDataset.mask_fit`:
 #
 
-# To apply a mask fit - in enegy and space
+# To apply a mask fit - in energy and space
 
 region = CircleSkyRegion(SkyCoord("0d", "0d", frame="galactic"), 1.5 * u.deg)
 
 geom = dataset_cta.counts.geom
 
 mask_space = geom.region_mask([region])
 mask_energy = geom.energy_mask(0.3 * u.TeV, 8 * u.TeV)
 dataset_cta.mask_fit = mask_space & mask_energy
 dataset_cta.mask_fit.plot_grid(vmin=0, vmax=1, add_cbar=True)
+plt.show()
 
 
 ######################################################################
 # To access the energy range defined by the mask you can use:
 #
 # -`~gammapy.datasets.MapDataset.energy_range_safe` : energy range definedby the `~gammapy.datasets.MapDataset.mask_safe`
 # - `~gammapy.datasets.MapDataset.energy_range_fit` : energy range defined by the `~gammapy.datasets.MapDataset.mask_fit`
@@ -305,129 +307,135 @@
 # values at each spatial pixel
 #
 
 e_min, e_max = dataset_cta.energy_range
 
 # To see the low energy threshold at each point
 
-plt.figure()
 e_min.plot(add_cbar=True)
+plt.show()
 
 # To see the high energy threshold at each point
 
-plt.figure()
 e_max.plot(add_cbar=True)
+plt.show()
 
 
 ######################################################################
 # Just as for `~gammapy.maps.Map` objects it is possible to cutout a whole
 # `~gammapy.datasets.MapDataset`, which will perform the cutout for all maps in
 # parallel.Optionally one can provide a new name to the resulting dataset:
 #
 
 cutout = dataset_cta.cutout(
     position=SkyCoord("0d", "0d", frame="galactic"),
     width=2 * u.deg,
     name="cta-cutout",
 )
 
-plt.figure()
 cutout.counts.sum_over_axes().plot()
+plt.show()
 
 
 ######################################################################
 # It is also possible to slice a `~gammapy.datasets.MapDataset` in energy:
 #
 
 sliced = dataset_cta.slice_by_energy(
     energy_min=1 * u.TeV, energy_max=5 * u.TeV, name="slice-energy"
 )
 sliced.counts.plot_grid()
+plt.show()
 
 
 ######################################################################
 # The same operation will be applied to all other maps contained in the
 # datasets such as `~gammapy.datasets.MapDataset.mask_fit`:
 #
 
 sliced.mask_fit.plot_grid()
+plt.show()
 
 
 ######################################################################
 # Resampling datasets
 # ~~~~~~~~~~~~~~~~~~~
 #
 # It can often be useful to coarsely rebin an initially computed datasets
 # by a specified factor. This can be done in either spatial or energy
 # axes:
 #
 
 plt.figure()
 downsampled = dataset_cta.downsample(factor=8)
 downsampled.counts.sum_over_axes().plot()
+plt.show()
 
 
 ######################################################################
-# And the same downsampling process is possible along the energy axis:
+# And the same down-sampling process is possible along the energy axis:
 #
 
 downsampled_energy = dataset_cta.downsample(
     factor=5, axis_name="energy", name="downsampled-energy"
 )
 downsampled_energy.counts.plot_grid()
+plt.show()
 
 
 ######################################################################
 # In the printout one can see that the actual number of counts is
-# preserved during the downsampling:
+# preserved during the down-sampling:
 #
 
 print(downsampled_energy, dataset_cta)
 
 
 ######################################################################
 # We can also resample the finer binned datasets to an arbitrary coarser
 # energy binning using:
 #
 
 energy_axis_new = MapAxis.from_energy_edges([0.1, 0.3, 1, 3, 10] * u.TeV)
 resampled = dataset_cta.resample_energy_axis(energy_axis=energy_axis_new)
 resampled.counts.plot_grid(ncols=2)
+plt.show()
 
 
 ######################################################################
 # To squash the whole dataset into a single energy bin there is the
 # `~gammapy.datasets.MapDataset.to_image()` convenience method:
 #
 
-plt.figure()
 dataset_image = dataset_cta.to_image()
 dataset_image.counts.plot()
+plt.show()
 
 
 ######################################################################
 # SpectrumDataset
 # ---------------
 #
 # `~gammapy.datasets.SpectrumDataset` inherits from a `~gammapy.datasets.MapDataset`, and is specially
 # adapted for 1D spectral analysis, and uses a `RegionGeom` instead of a
-# `WcsGeom`. A `~gammapy.datasets.MapDatset` can be converted to a `~gammapy.datasets.SpectrumDataset`,
+# `WcsGeom`. A `~gammapy.datasets.MapDataset` can be converted to a `~gammapy.datasets.SpectrumDataset`,
 # by summing the `counts` and `background` inside the `on_region`,
 # which can then be used for classical spectral analysis. Containment
 # correction is feasible only for circular regions.
 #
 
 
 region = CircleSkyRegion(SkyCoord(0, 0, unit="deg", frame="galactic"), 0.5 * u.deg)
 spectrum_dataset = dataset_cta.to_spectrum_dataset(
     region, containment_correction=True, name="spectrum-dataset"
 )
 
 # For a quick look
 spectrum_dataset.peek()
+plt.show()
 
 
 ######################################################################
 # A `~gammapy.datasets.MapDataset` can also be integrated over the `on_region` to create
 # a `~gammapy.datasets.MapDataset` with a `~gammapy.maps.RegionGeom`. Complex regions can be handled
 # and since the full IRFs are used, containment correction is not
 # required.
@@ -438,84 +446,81 @@
 
 
 ######################################################################
 # FluxPointsDataset
 # -----------------
 #
 # `~gammapy.datasets.FluxPointsDataset` is a `~gammapy.datasets.Dataset` container for precomputed flux
-# points, which can be then used in fitting. `~gammapy.datasets.FluxPointsDataset` cannot
-# be read directly, but should be read through `FluxPoints`, with an
-# additional `~gammapy.modeling.models.SkyModel`. Similarly, `~gammapy.datasets.FluxPointsDataset.write` only
-# saves the `~gammapy.datasets.FluxPointsDataset,data` attribute to disk.
+# points, which can be then used in fitting.
 #
 
-plt.figure()
 flux_points = FluxPoints.read(
     "$GAMMAPY_DATA/tests/spectrum/flux_points/diff_flux_points.fits"
 )
 model = SkyModel(spectral_model=PowerLawSpectralModel(index=2.3))
 fp_dataset = FluxPointsDataset(data=flux_points, models=model)
 
 fp_dataset.plot_spectrum()
+plt.show()
 
 
 ######################################################################
 # The masks on `~gammapy.datasets.FluxPointsDataset` are `~numpy.ndarray` objects
 # and the data is a
-# `~gammapy.datasets.FluxPoints` object. The `~gammapy.datasets.FluxPointsDataset.mask_safe`, by default, masks the upper
-# limit points
+# `~gammapy.datasets.FluxPoints` object. The `~gammapy.datasets.FluxPointsDataset.mask_safe`,
+# by default, masks the upper limit points.
 #
 
 print(fp_dataset.mask_safe)  # Note: the mask here is simply a numpy array
 
 # %%
 
 print(fp_dataset.data)  # is a `FluxPoints` object
 
 # %%
 
 print(fp_dataset.data_shape())  # number of data points
 
 
 ######################################################################
-# For an example of fitting `~gammapy.estimators.FluxPoints`, see
-#  :doc:`/tutorials/analysis-1d/sed_fitting`, and can be used for
-# catalog objects, e.g. see :doc:`/tutorials/api/catalog`
+#
+# For an example of fitting `~gammapy.estimators.FluxPoints`, see :doc:`/tutorials/analysis-1d/sed_fitting`,
+# and for using source catalogs see :doc:`/tutorials/api/catalog`
 #
 
 
 ######################################################################
 # Datasets
 # --------
 #
 # `~gammapy.datasets.Datasets` are a collection of `~gammapy.datasets.Dataset` objects. They can be of the
-# same type, or of different types, eg: mix of `~gammapy.datasets.FluxPointDataset`,
+# same type, or of different types, eg: mix of `~gammapy.datasets.FluxPointsDataset`,
 # `~gammapy.datasets.MapDataset` and `~gammapy.datasets.SpectrumDataset`.
 #
 # For modelling and fitting of a list of `~gammapy.datasets.Dataset` objects, you can
-# either - Do a joint fitting of all the datasets together - Stack the
-# datasets together, and then fit them.
+# either:
+# (a) Do a joint fitting of all the datasets together OR
+# (b) Stack the datasets together, and then fit them.
 #
 # `~gammapy.datasets.Datasets` is a convenient tool to handle joint fitting of
-# simultaneous datasets. As an example, please see the
-#  :doc:`/tutorials/analysis-3d/analysis_mwl`
+# simultaneous datasets. As an example, please see :doc:`/tutorials/analysis-3d/analysis_mwl`
 #
 # To see how stacking is performed, please see :ref:`stack`.
 #
 # To create a `~gammapy.datasets.Datasets` object, pass a list of `~gammapy.datasets.Dataset` on init, eg
 #
 
 datasets = Datasets([dataset_empty, dataset_cta])
 
 print(datasets)
 
 
 ######################################################################
 # If all the datasets have the same type we can also print an info table,
-# collectiong all the information from the individual calls to
+# collecting all the information from the individual calls to
 # `~gammapy.datasets.Dataset.info_dict()`:
 #
 
 display(datasets.info_table())  # quick info of all datasets
 
 print(datasets.names)  # unique name of each dataset
 
@@ -576,12 +581,12 @@
 
 
 ######################################################################
 # Or slice all datasets by a given energy range:
 #
 
 datasets_sliced = datasets.slice_by_energy(energy_min="1 TeV", energy_max="10 TeV")
+plt.show()
+
 print(datasets_sliced.energy_ranges)
 
 # %%
-
-plt.show()
```

### Comparing `gammapy-1.0rc2/examples/tutorials/api/fitting.py` & `gammapy-1.1rc1/examples/tutorials/api/fitting.py`

 * *Files 1% similar despite different names*

```diff
@@ -15,23 +15,24 @@
 
 Proposed approach
 -----------------
 
 This is a hands-on tutorial to `~gammapy.modeling`, showing how to do
 perform a Fit in gammapy. The emphasis here is on interfacing the
 `Fit` class and inspecting the errors. To see an analysis example of
-how datasets and models interact, see the
-:doc:`/tutorials/api/model_management` tutorial. As an example, in this notebook,
-we are going to work with HESS data of the Crab Nebula and show in
-particular how to : - perform a spectral analysis - use different
-fitting backends - access covariance matrix information and parameter
-errors - compute likelihood profile - compute confidence contours
+how datasets and models interact, see the :doc:`/tutorials/api/model_management` tutorial.
+As an example, in this notebook, we are going to work with HESS data of the Crab Nebula and show in
+particular how to :
+
+- perform a spectral analysis
+- use different fitting backends
+- access covariance matrix information and parameter errors
+- compute likelihood profile - compute confidence contours
 
-See also: :doc:`/tutorials/api/models` and
-`docs/modeling/index.rst`.
+See also: :doc:`/tutorials/api/models` and :ref:`modeling`.
 
 The setup
 ---------
 
 """
 
 from itertools import combinations
@@ -191,15 +192,15 @@
 
 
 ######################################################################
 # If the fit is performed with minuit you can print detailed informations
 # to check the convergence
 #
 
-print(fit.minuit)
+print(result_minuit.minuit)
 
 
 ######################################################################
 # Check the trace of the fit e.g.  in case the fit did not converge
 # properly
 #
 
@@ -231,23 +232,24 @@
 
 for ax, par in zip(axes, datasets.parameters.free_parameters):
     par.scan_n_values = 17
     idx = datasets.parameters.index(par)
     name = datasets.models.parameters_unique_names[idx]
     profile = fit.stat_profile(datasets=datasets, parameter=par)
     ax.plot(profile[f"{name}_scan"], profile["stat_scan"] - total_stat)
-    ax.set_xlabel(f"{par.name} {par.unit}")
+    ax.set_xlabel(f"{par.name} [{par.unit}]")
     ax.set_ylabel("Delta TS")
     ax.set_title(f"{name}:\n {par.value:.1e} +- {par.error:.1e}")
+plt.show()
 
 
 ######################################################################
 # Inspect model residuals. Those can always be accessed using
 # `~gammapy.datasets.Dataset.residuals()`. For more details, we refer here to the dedicated
-#  :doc:`/tutorials/analysis-3d/analysis_3d` (for `~gammapy.datasets.MapDataset` fitting) and
+# :doc:`/tutorials/analysis-3d/analysis_3d` (for `~gammapy.datasets.MapDataset` fitting) and
 # :doc:`/tutorials/analysis-1d/spectral_analysis` (for `SpectrumDataset` fitting).
 #
 
 
 ######################################################################
 # Covariance and parameters errors
 # --------------------------------
@@ -259,32 +261,33 @@
 print(result_minuit.models.covariance)
 
 ######################################################################
 # And you can plot the total parameter correlation as well:
 #
 
 result_minuit.models.covariance.plot_correlation()
+plt.show()
 
 # The covariance information is also propagated to the individual models
 # Therefore, one can also get the error on a specific parameter by directly
 # accessing the `~gammapy.modeling.Parameter.error` attribute:
 #
 
 print(crab_model.spectral_model.alpha.error)
 
 
 ######################################################################
 # As an example, this step is needed to produce a butterfly plot showing
 # the envelope of the model taking into account parameter uncertainties.
 #
 
-plt.figure()
 energy_bounds = [1, 10] * u.TeV
 crab_spectrum.plot(energy_bounds=energy_bounds, energy_power=2)
 ax = crab_spectrum.plot_error(energy_bounds=energy_bounds, energy_power=2)
+plt.show()
 
 
 ######################################################################
 # Confidence contours
 # -------------------
 #
 # In most studies, one wishes to estimate parameters distribution using
@@ -513,15 +516,15 @@
 fig.colorbar(im, label="sqrt(TS)")
 ax.set_xlabel(f"{par_alpha.name}")
 ax.set_ylabel(f"{par_beta.name}")
 
 # We choose to plot 1 and 2 sigma confidence contours
 levels = [1, 2]
 contours = ax.contour(x_values, y_values, stat_surface, levels=levels, colors="white")
-ax.clabel(contours, fmt="%.0f, $\\sigma$", inline=3, fontsize=15)
+ax.clabel(contours, fmt="%.0f $\\sigma$", inline=3, fontsize=15)
 
 plt.show()
 
 ######################################################################
 # Note that, if computed with `reoptimize=True`, this plot would be
 # completely consistent with the third panel of the plot produced with
 # `~gammapy.modeling.Fit.stat_contour` (try!).
```

### Comparing `gammapy-1.0rc2/examples/tutorials/api/makers.py` & `gammapy-1.1rc1/examples/tutorials/api/makers.py`

 * *Files 1% similar despite different names*

```diff
@@ -67,27 +67,27 @@
 )
 dataset_empty = MapDataset.create(geom=geom)
 print(dataset_empty)
 
 
 ######################################################################
 # It is possible to compute the instrument response functions with
-# different spatial and energy binnings as compared to the counts and
+# different spatial and energy bins as compared to the counts and
 # background maps. For example, one can specify a true energy axis which
 # defines the energy binning of the IRFs:
 #
 
 energy_axis_true = MapAxis.from_bounds(
     0.3, 10, nbin=31, name="energy_true", unit="TeV", interp="log"
 )
 dataset_empty = MapDataset.create(geom=geom, energy_axis_true=energy_axis_true)
 
 
 ######################################################################
-# For the detail of the other options availables, you can always call the
+# For the detail of the other options available, you can always call the
 # help:
 #
 
 help(MapDataset.create)
 
 
 ######################################################################
@@ -99,25 +99,26 @@
 data_store = DataStore.from_dir("$GAMMAPY_DATA/hess-dl3-dr1")
 obs = data_store.get_observations([23592])[0]
 
 # fill dataset
 maker = MapDatasetMaker()
 dataset = maker.run(dataset_empty, obs)
 print(dataset)
-plt.figure()
+
 dataset.counts.sum_over_axes().plot(stretch="sqrt", add_cbar=True)
+plt.show()
 
 
 ######################################################################
 # The `~gammapy.makers.MapDatasetMaker` fills the corresponding `counts`,
 # `exposure`, `background`, `psf` and `edisp` map per observation.
 # The `~gammapy.makers.MapDatasetMaker` has a `selection` parameter, in case some of
 # the maps should not be computed. There is also a
 # `background_oversampling` parameter that defines the oversampling
-# factor in energy used to compute the bakcground (default is None).
+# factor in energy used to compute the background (default is None).
 #
 # Safe data range handling
 # ------------------------
 #
 # To exclude the data range from a `~gammapy.makers.MapDataset`, that is associated with
 # high systematics on instrument response functions, a `~gammapy.makers.MapDataset.mask_safe`
 # can be defined. The `~gammapy.makers.MapDataset.mask_safe` is a `~gammapy.maps.Map` object
@@ -140,28 +141,29 @@
 # -  bkg-peak, the energy threshold is defined as the upper edge of the
 #    energy bin with the highest predicted background rate. This method
 #    was introduced in the HESS DL3 validation paper:
 #    https://arxiv.org/pdf/1910.08088.pdf
 #
 # Note that currently some methods computing a safe energy range
 # ("aeff-default", "aeff-max" and "edisp-bias") determine a true energy range and
-#  apply it to reconstructed energy, effectively neglecting the energy dispersion.
+# apply it to reconstructed energy, effectively neglecting the energy dispersion.
 #
 # Multiple methods can be combined. Here is an example :
 #
 
 safe_mask_maker = SafeMaskMaker(
     methods=["aeff-default", "offset-max"], offset_max="3 deg"
 )
 
 dataset = maker.run(dataset_empty, obs)
 dataset = safe_mask_maker.run(dataset, obs)
 print(dataset.mask_safe)
-plt.figure()
+
 dataset.mask_safe.sum_over_axes().plot()
+plt.show()
 
 
 ######################################################################
 # The `~gammapy.makers.SafeMaskMaker` does not modify any data, but only defines the
 # `~gammapy.datasets.MapDataset.mask_safe` attribute. This means that the safe data range
 # can be defined and modified in between the data reduction and stacking
 # and fitting. For a joint-likelihood analysis of multiple observations
@@ -187,15 +189,15 @@
 # made possible thanks to the `~gammapy.makers.FoVBackgroundMaker`. This
 # technique is recommended in most 3D data reductions. For more details
 # and usage, see `fov_background <../../user-guide/makers/fov.rst>`__.
 #
 # Here we are going to use a `~gammapy.makers.FoVBackgroundMaker` that
 # will rescale the background model to the data excluding the region where
 # a known source is present. For more details on the way to create
-# exclusion masks see the `mask maps <mask_maps.ipynb>`__ notebook.
+# exclusion masks see the :doc:`mask maps </tutorials/api/mask_maps>` notebook.
 #
 
 circle = CircleSkyRegion(center=geom.center_skydir, radius=0.2 * u.deg)
 exclusion_mask = geom.region_mask([circle], inside=False)
 
 fov_bkg_maker = FoVBackgroundMaker(method="scale", exclusion_mask=exclusion_mask)
 dataset = fov_bkg_maker.run(dataset)
@@ -206,15 +208,15 @@
 #
 # Ring background
 # ~~~~~~~~~~~~~~~
 #
 # If the background model does not reproduce well the morphology, a
 # classical approach consists in applying local corrections by smoothing
 # the data with a ring kernel. This allows to build a set of OFF counts
-# taking into account the inperfect knowledge of the background. This is
+# taking into account the imperfect knowledge of the background. This is
 # implemented in the `~gammapy.makers.RingBackgroundMaker` which
 # transforms the Dataset in a `~gammapy.datasets.MapDatasetOnOff`. This technique is
 # mostly used for imaging, and should not be applied for 3D modeling and
 # fitting.
 #
 # For more details and usage, see
 # `ring_background <../../user-guide/makers/ring.rst>`__.
@@ -235,15 +237,15 @@
 # `reflected_background <../../user-guide/makers/reflected.rst>`__.
 #
 # Data reduction loop
 # -------------------
 #
 # The data reduction steps can be combined in a single loop to run a full
 # data reduction chain. For this the `MapDatasetMaker` is run first and
-# the output dataset is the passed on to the next maker step. Finally the
+# the output dataset is the passed on to the next maker step. Finally, the
 # dataset per observation is stacked into a larger map.
 #
 
 data_store = DataStore.from_dir("$GAMMAPY_DATA/hess-dl3-dr1")
 observations = data_store.get_observations([23523, 23592, 23526, 23559])
 
 energy_axis = MapAxis.from_bounds(
@@ -255,15 +257,15 @@
 safe_mask_maker = SafeMaskMaker(
     methods=["aeff-default", "offset-max"], offset_max="3 deg"
 )
 
 stacked = MapDataset.create(geom)
 
 for obs in observations:
-    local_dataset = stacked.cutout(obs.pointing_radec, width="6 deg")
+    local_dataset = stacked.cutout(obs.get_pointing_icrs(obs.tmid), width="6 deg")
     dataset = dataset_maker.run(local_dataset, obs)
     dataset = safe_mask_maker.run(dataset, obs)
     dataset = fov_bkg_maker.run(dataset)
     stacked.stack(dataset)
 
 print(stacked)
 
@@ -276,42 +278,42 @@
 #
 # Note that we stack the individual `~gammapy.datasets.MapDataset`, which are computed per
 # observation into a larger dataset. During the stacking the safe data
 # range mask (`~gammapy.datasets.MapDataset.mask_safe`) is applied by setting data outside
 # to zero, then data is added to the larger map dataset. To stack multiple
 # observations, the larger dataset must be created first.
 #
-# The data reduction loop shown above can be done throught the
+# The data reduction loop shown above can be done through the
 # `~gammapy.makers.DatasetsMaker` class that take as argument a list of makers. **Note
 # that the order of the makers list is important as it determines their
 # execution order.** Moreover the `stack_datasets` option offers the
-# possibily to stack or not the output datasets, and the `n_jobs` option
+# possibility to stack or not the output datasets, and the `n_jobs` option
 # allow to use multiple processes on run.
 #
 
 global_dataset = MapDataset.create(geom)
 makers = [dataset_maker, safe_mask_maker, fov_bkg_maker]  # the order matter
 datasets_maker = DatasetsMaker(makers, stack_datasets=False, n_jobs=1)
 datasets = datasets_maker.run(global_dataset, observations)
 print(datasets)
 
 
 ######################################################################
 # Spectrum dataset
 # ----------------
 #
-# The spectrum datasets represent 1D spectra along an energy axis whitin a
+# The spectrum datasets represent 1D spectra along an energy axis within a
 # given on region. The `~gammapy.datasets.SpectrumDataset` contains a counts spectrum, and
 # a background model. The `~gammapy.datasets.SpectrumDatasetOnOff` contains ON and OFF
 # count spectra, background is implicitly modeled via the OFF counts
 # spectrum.
 #
 # The `~gammapy.datasets.SpectrumDatasetMaker` make spectrum dataset for a single
 # observation. In that case the irfs and background are computed at a
-# single fixed offset, which is recommend only for point-sources.
+# single fixed offset, which is recommended only for point-sources.
 #
 # Here is an example of data reduction loop to create
 # `~gammapy.datasets.SpectrumDatasetOnOff` datasets:
 #
 
 # on region is given by the CircleSkyRegion previously defined
 geom = RegionGeom.create(region=circle, axes=[energy_axis])
```

### Comparing `gammapy-1.0rc2/examples/tutorials/api/maps.py` & `gammapy-1.1rc1/examples/tutorials/api/maps.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,16 +23,16 @@
 interpolation and reprojection to the arbitrary extra dimensions and
 makes working with (2 + N)-dimensional hypercubes as easy as working
 with a simple 2D image. Further information is also provided on the
 `~gammapy.maps` docs page.
 
 In the following introduction we will learn all the basics of working
 with WCS based maps. HEALPix based maps will be covered in a future
-tutorial. Make sure you have worked through the `Gammapy
-overview <../starting/overview.ipynb>`__, because a solid knowledge
+tutorial. Make sure you have worked through the :doc:`Gammapy
+overview </tutorials/starting/overview>`, because a solid knowledge
 about working with `SkyCoord` and `Quantity` objects as well as
 `Numpy <http://www.numpy.org/>`__ is required for this tutorial.
 
 This notebook is rather lengthy, but getting to know the `Map` data
 structure in detail is essential for working with Gammapy and will allow
 you to fulfill complex analysis tasks with very few and simple code in
 future!
@@ -145,16 +145,16 @@
 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 #
 # As we have seen in the first examples, the `~gammapy.maps.Map` object couples the
 # data (stored as a `~numpy.ndarray`) with a `~gammapy.maps.Geom` object. The
 # `~gammapy.maps.~Geom` object can be seen as a generalization of an
 # `astropy.wcs.WCS` object, providing the information on how the data
 # maps to physical coordinate systems. In some cases e.g. when creating
-# many maps with the same WCS geometry it can be advantegeous to first
-# create the map geometry independent of the map object itsself:
+# many maps with the same WCS geometry it can be advantageous to first
+# create the map geometry independent of the map object it-self:
 #
 
 wcs_geom = WcsGeom.create(binsz=0.02, width=(10, 5), skydir=(0, 0), frame="galactic")
 
 
 ######################################################################
 # And then create the map objects from the ``wcs_geom`` geometry
@@ -268,17 +268,17 @@
 
 
 ######################################################################
 # Reading and Writing
 # -------------------
 #
 # Gammapy `~gammapy.maps.Map` objects are serialized using the Flexible Image
-# Transport Format (FITS). Depending on the pixelisation scheme (HEALPix
+# Transport Format (FITS). Depending on the pixelization scheme (HEALPix
 # or WCS) and presence of non-spatial dimensions the actual convention to
-# write the FITS file is different. By default Gammpy uses a generic
+# write the FITS file is different. By default Gammapy uses a generic
 # convention named ``"gadf"``, which will support WCS and HEALPix formats as
 # well as an arbitrary number of non-spatial axes. The convention is
 # documented in detail on the `Gamma Astro Data
 # Formats <https://gamma-astro-data-formats.readthedocs.io/en/latest/skymaps/index.html>`__
 # page.
 #
 # Other conventions required by specific software (e.g. the Fermi Science
@@ -340,15 +340,15 @@
 print(Map.from_hdulist(hdulist=hdulist))
 
 
 ######################################################################
 # Writing Maps
 # ~~~~~~~~~~~~
 #
-# Writing FITS files is mainoy exposure via the `Map.write()` method.
+# Writing FITS files on disk via the `Map.write()` method.
 # Here is a first example:
 #
 
 m_cube.write("example_cube.fits", overwrite=True)
 
 
 ######################################################################
@@ -653,15 +653,15 @@
 
 
 ######################################################################
 # Filling maps from interpolation
 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 #
 # Maps support interpolation via the `~~gammapy.maps.Map.interp_by_coord` and
-# `~~gammapy.maps.Map.interp_by_pix` methods. Currently the following interpolation
+# `~~gammapy.maps.Map.interp_by_pix` methods. Currently, the following interpolation
 # methods are supported:
 #
 # -  ``"nearest"`` : Return value of nearest pixel (no interpolation).
 # -  ``"linear"`` : Interpolation with first order polynomial. This is the
 #    only interpolation method that is supported for all map types.
 # -  `quadratic` : Interpolation with second order polynomial.
 # -  `cubic` : Interpolation with third order polynomial.
@@ -752,37 +752,37 @@
 #
 
 iem_times_two = m_iem_10GeV * 2
 # iem_times_two = 2 * m_iem_10GeV # this won't work
 
 
 ######################################################################
-# The logic operators can also by applied on maps (the result is a map of
+# The logic operators can also be applied on maps (the result is a map of
 # boolean type):
 #
 
 is_null = iem_minus_iem == 0
 print(is_null)
 
 
 ######################################################################
-# Here we check that the result is `True` for all the well-defiend
+# Here we check that the result is `True` for all the well-defined
 # pixels (not `NaN`):
 #
 
 print(np.all(is_null.data[~np.isnan(iem_minus_iem)]))
 
 
 ######################################################################
 # Cutouts
 # ~~~~~~~
 #
 # The `WCSNDMap` objects features a `~gammapy.maps.Map.cutout()` method, which allows
 # you to cut out a smaller part of a larger map. This can be useful,
-# e.g. when working with allsky diffuse maps. Here is an example:
+# e.g. when working with all-sky diffuse maps. Here is an example:
 #
 
 position = SkyCoord(0, 0, frame="galactic", unit="deg")
 m_iem_cutout = m_iem_gc.cutout(position=position, width=(4 * u.deg, 2 * u.deg))
 
 
 ######################################################################
@@ -798,15 +798,15 @@
 # Visualizing and Plotting
 # ------------------------
 #
 # All map objects provide a `~gammapy.maps.Map.plot` method for generating a visualization
 # of a map. This method returns figure, axes, and image objects that can
 # be used to further tweak/customize the image. The `~gammapy.maps.Map.plot` method should
 # be used with 2D maps, while 3D maps can be displayed with the
-# `~gammapy.maps.Map.plot_interative()` or `~gammapy.maps.Map.plot_grid()` methods.
+# `~gammapy.maps.Map.plot_interactive()` or `~gammapy.maps.Map.plot_grid()` methods.
 #
 # Image Plotting
 # ~~~~~~~~~~~~~~
 #
 # For debugging and inspecting the map data it is useful to plot or
 # visualize the images planes contained in the map.
 #
@@ -816,62 +816,62 @@
 
 
 ######################################################################
 # After reading the map we can now plot it on the screen by calling the
 # ``.plot()`` method:
 #
 
-plt.figure()
 m_3fhl_gc.plot()
+plt.show()
 
 
 ######################################################################
 # We can easily improve the plot by calling `~gammapy.maps.Map.smooth()` first and
 # providing additional arguments to `~gammapy.maps.Map.plot()`. Most of them are passed
 # further to
 # `plt.imshow() <https://matplotlib.org/api/_as_gen/matplotlib.pyplot.imshow.html>`__:
 #
 
-plt.figure()
 smoothed = m_3fhl_gc.smooth(width=0.2 * u.deg, kernel="gauss")
 smoothed.plot(stretch="sqrt", add_cbar=True, vmax=4, cmap="inferno")
+plt.show()
 
 
 ######################################################################
 # We can use the
 # `plt.rc_context() <https://matplotlib.org/api/_as_gen/matplotlib.pyplot.rc_context.html>`__
 # context manager to further tweak the plot by adapting the figure and
 # font size:
 #
 
-plt.figure()
 rc_params = {"figure.figsize": (12, 5.4), "font.size": 12}
 with plt.rc_context(rc=rc_params):
     smoothed = m_3fhl_gc.smooth(width=0.2 * u.deg, kernel="gauss")
     smoothed.plot(stretch="sqrt", add_cbar=True, vmax=4)
+plt.show()
 
 
 ######################################################################
 # Cube plotting
 # ~~~~~~~~~~~~~
 #
 # For maps with non-spatial dimensions the `~gammapy.maps.Map` object features an
 # interactive plotting method, that works in jupyter notebooks only (Note:
 # it requires the package `ipywidgets` to be installed). We first read a
 # small example cutout from the Fermi Galactic diffuse model and display
 # the data cube by calling `~gammapy.maps.Map.plot_interactive()`:
 #
 
-plt.figure()
 rc_params = {
     "figure.figsize": (12, 5.4),
     "font.size": 12,
     "axes.formatter.limits": (2, -2),
 }
 m_iem_gc.plot_interactive(add_cbar=True, stretch="sqrt", rc_params=rc_params)
+plt.show()
 
 
 ######################################################################
 # Now you can use the interactive slider to select an energy range and the
 # corresponding image is displayed on the screen. You can also use the
 # radio buttons to select your preferred image stretching. We have passed
 # additional keywords using the `rc_params` argument to improve the
@@ -882,9 +882,8 @@
 # Additionally all the slices of a 3D `~gammapy.maps.Map` can be displayed using the
 # `~gammapy.maps.Map.plot_grid()` method. By default the colorbars bounds of the subplots
 # are not the same, we can make them consistent using the `vmin` and
 # `vmax` options:
 #
 
 counts_3d.plot_grid(ncols=4, figsize=(16, 12), vmin=0, vmax=100, stretch="log")
-
 plt.show()
```

### Comparing `gammapy-1.0rc2/examples/tutorials/api/mask_maps.py` & `gammapy-1.1rc1/examples/tutorials/api/mask_maps.py`

 * *Files 1% similar despite different names*

```diff
@@ -4,26 +4,26 @@
 
 Create and apply masks maps.
 
 Prerequisites
 -------------
 
 -  Understanding of basic analyses in 1D or 3D.
--  Usage of `~regions` and catalogs, see the `catalog
-   notebook <catalog.ipynb>`__.
+-  Usage of `~regions` and catalogs, see the :doc:`catalog
+   notebook </tutorials/api/catalog>`.
 
 Context
 -------
 
 There are two main categories of masks in Gammapy for different use
 cases. - Fitting often requires to ignore some parts of a reduced
-dataset, e.g. to restrict the fit to a specific energy range or to
+dataset, e.g. to restrict the fit to a specific energy range or to
 ignore parts of the region of interest that the user does not want to
 model, or both. Gammapy’s `Datasets` therefore contain a `mask_fit`
-sharing the same geometry as the data (i.e. `counts`). - During data
+sharing the same geometry as the data (i.e. `counts`). - During data
 reduction, some background makers will normalize the background model
 template on the data themselves. To limit contamination by real photons,
 one has to exclude parts of the field-of-view where signal is expected
 to be large. To do so, one needs to provide an exclusion mask. The
 latter can be provided in a different geometry as it will be reprojected
 by the `Makers`.
 
@@ -33,25 +33,25 @@
 ~~~~~~~~~~~~~~~~~
 
 The region of interest used for the fit can defined through the dataset
 `mask_fit` attribute. The `mask_fit` is a map containing boolean
 values where pixels used in the fit are stored as True.
 
 A spectral fit (1D or 3D) can be restricted to a specific energy range
-where e.g. the background is well estimated or where the number of
+where e.g. the background is well estimated or where the number of
 counts is large enough. Similarly, 2D and 3D analyses usually require to
 work with a wider map than the region of interest so sources laying
 outside but reconstructed inside because of the PSF are correctly taken
 into account. Then the `mask_fit` have to include a margin that take
 into account the PSF width. We will show an example in the boundary mask
 sub-section.
 
 The `mask_fit` also can be used to exclude sources or complex regions
 for which we don’t have good enough models. In that case the masking is
-an extra security, it is prefereable to include the available models
+an extra security, it is preferable to include the available models
 even if the sources are masked and frozen.
 
 Note that a dataset contains also a `mask_safe` attribute that is
 created and filled during data reduction. It is not to be modified
 directly by users. The `mask_safe` is defined only from the options
 passed to the `~gammapy.makers.SafeMaskMaker` (for more details see
 `Safe Data Range Handling`_).
@@ -171,15 +171,15 @@
 # `Geom`.
 #
 # In the following we restrict the fit region to a square around the Crab
 # nebula. **Note**: the dataset geometry is aligned on the galactic frame,
 # we use the same frame to define the box to ensure a correct alignment.
 # We can now create the map. We use the `WcsGeom.region_mask` method
 # putting all pixels outside the regions to False (because we only want to
-# consider pixels inside the region. For convenience we can directly pass
+# consider pixels inside the region. For convenience, we can directly pass
 # a ds9 region string to the method:
 #
 
 regions = "galactic;box(184.55, -5.78, 3.0, 3.0)"
 mask_map = dataset.counts.geom.region_mask(regions)
 
 
@@ -191,15 +191,16 @@
 dataset.mask_fit &= mask_map
 
 
 ######################################################################
 # Let’s check the result and plot the full mask.
 #
 
-_ = dataset.mask_fit.plot_grid(ncols=5, vmin=0, vmax=1, figsize=(14, 3))
+dataset.mask_fit.plot_grid(ncols=5, vmin=0, vmax=1, figsize=(14, 3))
+plt.show()
 
 
 ######################################################################
 # Creating a mask manually
 # ~~~~~~~~~~~~~~~~~~~~~~~~
 #
 # If you are more familiar with the `Geom` and `Map` API, you can also
@@ -227,15 +228,15 @@
 # build the geometry.
 #
 # Define the geometry
 # ~~~~~~~~~~~~~~~~~~~
 #
 # Masks are stored in `Map` objects. We must first define its geometry
 # and then we can determine which pixels to exclude. Here we consider a
-# region at the Galactic anticentre around the crab nebula.
+# region at the Galactic anti-centre around the crab nebula.
 #
 
 position = SkyCoord(83.633083, 22.0145, unit="deg", frame="icrs")
 geom = WcsGeom.create(skydir=position, width="5 deg", binsz=0.02, frame="galactic")
 
 
 ######################################################################
@@ -277,16 +278,16 @@
 #
 # We can now create the map. We use the `WcsGeom.region_mask` method
 # putting all pixels inside the regions to False.
 #
 
 # to define the exclusion mask we take the inverse
 mask_map = ~geom.region_mask(regions)
-plt.figure()
 mask_map.plot()
+plt.show()
 
 
 ######################################################################
 # Create the mask from a catalog of sources
 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 #
 # We can also build our list of regions from a list of catalog sources.
@@ -317,16 +318,16 @@
 
 
 ######################################################################
 # Now we can build the mask map the same way as above.
 #
 
 mask_map_catalog = ~geom.region_mask(regions)
-plt.figure()
 mask_map_catalog.plot()
+plt.show()
 
 
 ######################################################################
 # Create the mask from statistically significant pixels in a dataset
 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 #
 # Here we want to determine an exclusion from the data directly. We will
@@ -359,16 +360,16 @@
 # Because the `ExcessMapEstimator` returns NaN for masked pixels, we
 # need to put the NaN values to `True` to avoid incorrectly excluding
 # them.
 #
 
 invalid_pixels = np.isnan(result["sqrt_ts"].data)
 significance_mask.data[invalid_pixels] = True
-plt.figure()
 significance_mask.plot()
+plt.show()
 
 
 ######################################################################
 # This method frequently yields isolated pixels or weakly significant
 # features if one places the threshold too low.
 #
 # To overcome this issue, one can use
@@ -390,54 +391,54 @@
 # If two masks share the same geometry it is easy to combine them with
 # `Map` arithmetic.
 #
 # OR condition is represented by `|` operator :
 #
 
 mask = mask_map | mask_map_catalog
-plt.figure()
 mask.plot()
+plt.show()
 
 
 ######################################################################
 # AND condition is represented by `&` or `*` operators :
 #
 
 mask_map &= mask_map_catalog
-plt.figure()
 mask_map.plot()
+plt.show()
 
 
 ######################################################################
 # The NOT operator is represented by `~` symbol:
 #
 
 significance_mask_inv = ~significance_mask
-plt.figure()
 significance_mask_inv.plot()
+plt.show()
 
 
 ######################################################################
 # Mask modifications
 # ------------------
 #
 # Mask dilation and erosion
 # ~~~~~~~~~~~~~~~~~~~~~~~~~
 #
 # One can reduce or extend a mask using `binary_erode` and
 # `binary_dilate` methods, respectively.
 #
 
-plt.figure()
 mask = significance_mask_inv.binary_erode(width=0.2 * u.deg, kernel="disk")
 mask.plot()
+plt.show()
 
-plt.figure()
 mask = significance_mask_inv.binary_dilate(width=0.2 * u.deg)
 mask.plot()
+plt.show()
 
 
 ######################################################################
 # Boundary mask
 # ~~~~~~~~~~~~~
 #
 # In the following example we use the Fermi dataset previously loaded and
@@ -446,20 +447,20 @@
 # method of the psf object and the mask is created using the
 # `boundary_mask` method available on the geometry object.
 #
 
 # get PSF 95% containment radius
 energy_true = dataset.exposure.geom.axes[0].center
 psf_r95 = dataset.psf.containment_radius(fraction=0.95, energy_true=energy_true)
+plt.show()
+
 # create mask_fit with margin based on PSF
 mask_fit = dataset.counts.geom.boundary_mask(psf_r95.max())
 dataset.mask_fit = mask_fit
-plt.figure()
 dataset.mask_fit.sum_over_axes().plot()
-
 plt.show()
 
 ######################################################################
 # Reading and writing masks
 # -------------------------
 #
 # `gammapy.maps` can directly read/write maps with boolean content as
```

### Comparing `gammapy-1.0rc2/examples/tutorials/api/model_management.py` & `gammapy-1.1rc1/examples/tutorials/api/model_management.py`

 * *Files 2% similar despite different names*

```diff
@@ -110,14 +110,16 @@
     ax=ax1, stretch="sqrt", add_cbar=True
 )
 datasets[1].counts.sum_over_axes().smooth(0.05 * u.deg).plot(
     ax=ax2, stretch="sqrt", add_cbar=True
 )
 ax1.set_title("Fermi counts")
 ax2.set_title("CTA counts")
+plt.show()
+
 
 ######################################################################
 #
 
 display(datasets.info_table(cumulative=False))
 
 ######################################################################
@@ -272,15 +274,15 @@
 models_selected = models_3fhl.select_region(region)
 print(len(models_selected))
 
 
 ######################################################################
 # We now want to assign `models_3fhl` to the Fermi dataset, and
 # `models_selected` to both the CTA and Fermi datasets. For this, we
-# explicitlty mention the `datasets_names` to the former, and leave it
+# explicitly mention the `datasets_names` to the former, and leave it
 # `None` (default) for the latter.
 #
 
 for model in models_3fhl:
     if model not in models_selected:
         model.datasets_names = fermi_dataset.name
 
@@ -293,16 +295,16 @@
 #
 
 print("Fermi dataset models: ", datasets[0].models.names)
 print("\n CTA dataset models: ", datasets[1].models.names)
 
 
 ######################################################################
-# Combining two `Models`
-# ------------------------
+# Combining two Models
+# --------------------
 #
 
 
 ######################################################################
 # `Models` can be extended simply as as python lists
 #
```

### Comparing `gammapy-1.0rc2/examples/tutorials/api/models.py` & `gammapy-1.1rc1/examples/tutorials/api/models.py`

 * *Files 3% similar despite different names*

```diff
@@ -129,16 +129,16 @@
 
 
 ######################################################################
 # As a convenience you can also plot any spectral model in a given energy
 # range:
 #
 
-plt.figure()
 pwl.plot(energy_bounds=[1, 100] * u.TeV)
+plt.show()
 
 
 ######################################################################
 # Norm Spectral Models
 # ~~~~~~~~~~~~~~~~~~~~
 #
 
@@ -184,22 +184,22 @@
 # A typical use case of a norm model would be in applying spectral
 # correction to a `TemplateSpectralModel`. A template model is defined
 # by custom tabular values provided at initialization.
 #
 
 from gammapy.modeling.models import TemplateSpectralModel
 
-plt.figure()
 energy = [0.3, 1, 3, 10, 30] * u.TeV
 values = [40, 30, 20, 10, 1] * u.Unit("TeV-1 s-1 cm-2")
 template = TemplateSpectralModel(energy, values)
 template.plot(energy_bounds=[0.2, 50] * u.TeV, label="template model")
 normed_template = template * pwl_norm
 normed_template.plot(energy_bounds=[0.2, 50] * u.TeV, label="normed_template model")
 plt.legend()
+plt.show()
 
 
 ######################################################################
 # Compound Spectral Model
 # ~~~~~~~~~~~~~~~~~~~~~~~
 #
 # A `CompoundSpectralModel` is an arithmetic combination of two spectral
@@ -279,28 +279,28 @@
 # The returned quantity corresponds to a surface brightness. Spatial model
 # can be also evaluated using `~gammapy.maps.Map` and
 # `~gammapy.maps.Geom` objects:
 #
 
 m = Map.create(skydir=(0, 0), width=(1, 1), binsz=0.02, frame="galactic")
 m.quantity = gauss.evaluate_geom(m.geom)
-plt.figure()
 m.plot(add_cbar=True)
+plt.show()
 
 
 ######################################################################
 # Again for convenience the model can be plotted directly:
 #
-plt.figure()
 gauss.plot(add_cbar=True)
+plt.show()
 
 
 ######################################################################
 # All spatial models have an associated sky region to it e.g. to
-# illustrate the extend of the model on a sky image. The returned object
+# illustrate the extension of the model on a sky image. The returned object
 # is an `~regions.SkyRegion` object:
 #
 
 print(gauss.to_region())
 
 
 ######################################################################
@@ -314,14 +314,15 @@
 )
 ax = gauss_elongated.plot(add_cbar=True)
 
 # add region illustration
 region = gauss_elongated.to_region()
 region_pix = region.to_pixel(ax.wcs)
 ax.add_artist(region_pix.as_artist(ec="w", fc="None"))
+plt.show()
 
 
 ######################################################################
 # The `~gammapy.modeling.models.SpatialModel.to_region()` method can also be useful to write e.g. ds9 region
 # files using `write_ds9` from the `regions` package:
 #
 
@@ -379,14 +380,15 @@
 
 ######################################################################
 # As for other models, they can be plotted in a given time range
 #
 
 time = Time([59233.0, 59250], format="mjd")
 gauss_temp.plot(time)
+plt.show()
 
 
 ######################################################################
 # SkyModel
 # --------
 #
 
@@ -433,16 +435,16 @@
 print(model.temporal_model)
 
 
 ######################################################################
 # And can be used as you have seen already seen above:
 #
 
-plt.figure()
 model.spectral_model.plot(energy_bounds=[1, 10] * u.TeV)
+plt.show()
 
 
 ######################################################################
 # Note that the gammapy fitting can interface only with a `~gammapy.modeling.models.SkyModel` and
 # **not** its individual components. So, it is customary to work with
 # `~gammapy.modeling.models.SkyModel` even if you are not doing a 3D fit. Since the amplitude
 # parameter resides on the `~gammapy.modeling.models.SpectralModel`, specifying a spectral
@@ -504,15 +506,15 @@
 
 # Visualise the model as a table
 display(model.parameters.to_table())
 
 
 ######################################################################
 # You can use the interactive boxes to choose model parameters by name,
-# type or other attrributes mentioned in the column names.
+# type or other attributes mentioned in the column names.
 #
 
 
 ######################################################################
 # Model lists and serialisation
 # -----------------------------
 #
@@ -572,28 +574,28 @@
 # The structure of the yaml files follows the structure of the python
 # objects. The ``components`` listed correspond to the `SkyModel` and
 # components of the ``Models``. For each ``SkyModel``
 # we have information about its ``name``, ``type`` (corresponding to the
 # tag attribute) and sub-mobels (i.e ``spectral`` model and eventually
 # ``spatial`` model). Then the spatial and spectral models are defined by
 # their type and parameters. The ``parameters`` keys name/value/unit are
-# mandatory, while the keys min/max/frozen are optionnals (so you can
+# mandatory, while the keys min/max/frozen are optional (so you can
 # prepare shorter files).
 #
 # If you want to write this list of models to disk and read it back later
 # you can use:
 #
 
 models.write("models.yaml", overwrite=True)
 
 models_read = Models.read("models.yaml")
 
 
 ######################################################################
-# Additionally the models can exported and imported togeter with the data
+# Additionally the models can be exported and imported together with the data
 # using the ``Datasets.read()`` and ``Datasets.write()`` methods as shown
 # in the :doc:`/tutorials/analysis-3d/analysis_mwl`
 # notebook.
 #
 # Models with shared parameter
 # ----------------------------
 #
@@ -642,15 +644,15 @@
 #
 
 from gammapy.modeling import Parameter
 from gammapy.modeling.models import SpectralModel
 
 
 class MyCustomSpectralModel(SpectralModel):
-    """My custom spectral model, parametrising a power law plus a Gaussian spectral line.
+    """My custom spectral model, parametrizing a power law plus a Gaussian spectral line.
 
     Parameters
     ----------
     amplitude : `astropy.units.Quantity`
         Amplitude of the spectra model.
     index : `astropy.units.Quantity`
         Spectral index of the model.
@@ -680,35 +682,35 @@
         )
         gauss = amplitude * np.exp(-((energy - mean) ** 2) / (2 * width**2))
         return pwl + gauss
 
 
 ######################################################################
 # It is good practice to also implement a docstring for the model,
-# defining the parameters and also definig a ``.tag``, which specifies the
+# defining the parameters and also defining a ``.tag``, which specifies the
 # name of the model for serialisation. Also note that gammapy assumes that
 # all SpectralModel evaluate functions return a flux in unit of
 # `"cm-2 s-1 TeV-1"` (or equivalent dimensions).
 #
 # This model can now be used as any other spectral model in Gammapy:
 #
 
 my_custom_model = MyCustomSpectralModel(mean="3 TeV")
 print(my_custom_model)
 
 print(my_custom_model.integral(1 * u.TeV, 10 * u.TeV))
 
-plt.figure()
 my_custom_model.plot(energy_bounds=[1, 10] * u.TeV)
+plt.show()
 
 
 ######################################################################
 # As a next step we can also register the custom model in the
 # ``SPECTRAL_MODELS`` registry, so that it becomes available for
-# serilisation:
+# serialization:
 #
 
 SPECTRAL_MODEL_REGISTRY.append(MyCustomSpectralModel)
 
 model = SkyModel(spectral_model=my_custom_model, name="my-source")
 models = Models([model])
 models.write("my-custom-models.yaml", overwrite=True)
@@ -731,33 +733,34 @@
 # A common science case in the study of extended sources is to probe for
 # energy dependent morphology, eg: in Supernova Remnants or Pulsar Wind
 # Nebulae. Traditionally, this has been done by splitting the data into
 # energy bands and doing individual fits of the morphology in these energy
 # bands.
 #
 # `~gammapy.modeling.models.SkyModel` offers a natural framework to simultaneously model the
-# energy and morphology, e.g. spatial extent described by a parametric
+# energy and morphology, e.g. spatial extent described by a parametric
 # model expression with energy dependent parameters.
 #
 # The models shipped within gammapy use a “factorised” representation of
 # the source model, where the spatial (:math:`l,b`), energy (:math:`E`)
 # and time (:math:`t`) dependence are independent model components and not
 # correlated:
 #
-# :raw-latex:`\begin{align}f(l, b, E, t) = F(l, b) \cdot G(E) \cdot H(t)\end{align}`
+# .. math::
+#     \begin{align}f(l, b, E, t) = F(l, b) \cdot G(E) \cdot H(t)\end{align}
 #
-# To use full 3D models, ie $f(l, b, E) = F(l, b, E)
-# :raw-latex:`\cdot`\ G(E) $, you have to implement your own custom
+# To use full 3D models, ie :math:`f(l, b, E) = F(l, b, E) \cdot \ G(E)`,
+# you have to implement your own custom
 # `SpatialModel`. Note that it is still necessary to multiply by a
 # `SpectralModel`, :math:`G(E)` to be dimensionally consistent.
 #
 # In this example, we create Gaussian Spatial Model with the extension
-# varying with energy. For simplicity, we assume a linear dependence on
+# varying with energy. For simplicity, we assume a linear dependency on
 # energy and parameterize this by specifying the extension at 2 energies.
-# You can add more complex dependences, probably motivated by physical
+# You can add more complex dependencies, probably motivated by physical
 # models.
 #
 
 from astropy.coordinates.angle_utilities import angular_separation
 from gammapy.modeling.models import SpatialModel
```

### Comparing `gammapy-1.0rc2/examples/tutorials/data/cta.py` & `gammapy-1.1rc1/examples/tutorials/data/cta.py`

 * *Files 3% similar despite different names*

```diff
@@ -46,15 +46,15 @@
 At the end of the notebooks, we give several links to other tutorial
 notebooks that show how to simulate CTA data and how to evaluate CTA
 observability and sensitivity, or how to analyse CTA data.
 
 Note that the FITS data and IRF format currently used by CTA is the one
 documented at https://gamma-astro-data-formats.readthedocs.io/, and is
 also used by H.E.S.S. and other imaging atmospheric Cherenkov telescopes
-(IACTs). So if you see other Gammapy tutorials using e.g. H.E.S.S.
+(IACTs). So if you see other Gammapy tutorials using e.g. H.E.S.S.
 example data, know that they also apply to CTA, all you have to do is to
 change the loaded data or IRFs to CTA.
 
 Setup
 -----
 
 """
@@ -63,15 +63,15 @@
 from pathlib import Path
 from astropy import units as u
 
 # %matplotlib inline
 import matplotlib.pyplot as plt
 from IPython.display import display
 from gammapy.data import DataStore, EventList
-from gammapy.irf import EffectiveAreaTable2D, load_cta_irfs
+from gammapy.irf import EffectiveAreaTable2D, load_irf_dict_from_file
 
 ######################################################################
 # Check setup
 # -----------
 from gammapy.utils.check import check_tutorials_setup
 
 check_tutorials_setup()
@@ -95,15 +95,15 @@
 # After download, follow the instructions how to `untar` the files, and
 # set a `CTADATA` environment variable to point to the data.
 #
 # For convenience, since the 1DC data files are large, and not publicly
 # available to anyone, we have taken a tiny subset of the CTA 1DC data,
 # four observations with the southern array from the GPS survey, pointing
 # near the Galactic center, and included them at `$GAMMAPY_DATA/cta-1dc`
-# which you get via `gammapy download tutorials`.
+# which you get via `gammapy download datasets`.
 #
 # Files
 # ~~~~~
 #
 # Next we will show a quick overview of the files and how to load them,
 # and some quick look plots showing the shape of the CTA IRFs. How to do
 # CTA simulations and analyses is shown in other tutorials, see links at
@@ -196,15 +196,15 @@
 display(events.table[:5])
 
 ######################################################################
 # And show a summary plot:
 #
 
 events.peek()
-
+plt.show()
 
 ######################################################################
 # IRFs
 # ----
 #
 # The CTA instrument response functions (IRFs) are given as FITS files in
 # the `caldb` folder, the following IRFs are available:
@@ -235,90 +235,93 @@
 #
 
 print(observation.aeff)
 
 irf_filename = (
     "$GAMMAPY_DATA/cta-1dc/caldb/data/cta/1dc/bcf/South_z20_50h/irf_file.fits"
 )
-irfs = load_cta_irfs(irf_filename)
+irfs = load_irf_dict_from_file(irf_filename)
 print(irfs)
 
 
 ######################################################################
 # Effective area
 # ~~~~~~~~~~~~~~
 #
 
 # Equivalent alternative way to load IRFs directly
 aeff = EffectiveAreaTable2D.read(irf_filename, hdu="EFFECTIVE AREA")
 print(aeff)
 
 irfs["aeff"].peek()
+plt.show()
 
 # What is the on-axis effective area at 10 TeV?
 print(aeff.evaluate(energy_true="10 TeV", offset="0 deg").to("km2"))
 
 
 ######################################################################
 # Energy dispersion
 # ~~~~~~~~~~~~~~~~~
 #
 
 irfs["edisp"].peek()
+plt.show()
 
 
 ######################################################################
 # Point spread function
 # ~~~~~~~~~~~~~~~~~~~~~
 #
 
 irfs["psf"].peek()
+plt.show()
 
 # This is how for analysis you could slice out the PSF
 # at a given field of view offset
 irfs["psf"].plot_containment_radius_vs_energy(
     offset=[1] * u.deg, fraction=[0.68, 0.8, 0.95]
 )
-
+plt.show()
 
 ######################################################################
 # Background
 # ~~~~~~~~~~
 #
 # The background is given as a rate in units `MeV-1 s-1 sr-1`.
 #
 
 irfs["bkg"].peek()
+plt.show()
 
 print(irfs["bkg"].evaluate(energy="3 TeV", fov_lon="1 deg", fov_lat="0 deg"))
 
 
 ######################################################################
 # To visualise the background at particular energies:
 #
 
 irfs["bkg"].plot_at_energy(
     ["100 GeV", "500 GeV", "1 TeV", "3 TeV", "10 TeV", "100 TeV"]
 )
-
 plt.show()
 
 ######################################################################
 # Source models
 # -------------
 #
 # The 1DC sky model is distributed as a set of XML files, which in turn
 # link to a ton of other FITS and text files. Gammapy doesn’t support this
 # XML model file format. We are currently developing a YAML based format
 # that improves upon the XML format, to be easier to write and read, add
 # relevant information (units for physical quantities), and omit useless
-# information (e.g. parameter scales in addition to values).
+# information (e.g. parameter scales in addition to values).
 #
 # If you must or want to read the XML model files, you can use
-# e.g. `ElementTree <https://docs.python.org/3/library/xml.etree.elementtree.html>`__
+# e.g. `ElementTree <https://docs.python.org/3/library/xml.etree.elementtree.html>`__
 # from the Python standard library, or
 # `xmltodict <https://github.com/martinblech/xmltodict>`__ if you
 # `pip install xmltodict`. Here’s an example how to load the information
 # for a given source, and to convert it into the sky model format Gammapy
 # understands.
 #
 
@@ -364,29 +367,29 @@
 
 # !curl -O https://www.cta-observatory.org/wp-content/uploads/2019/04/CTA-Performance-prod3b-v2-FITS.tar.gz
 
 # !tar xf CTA-Performance-prod3b-v2-FITS.tar.gz
 
 # !ls caldb/data/cta/prod3b-v2/bcf
 
-# irfs1 = load_cta_irfs("caldb/data/cta/prod3b-v2/bcf/South_z20_50h/irf_file.fits")
+# irfs1 = load_irf_dict_from_file("caldb/data/cta/prod3b-v2/bcf/South_z20_50h/irf_file.fits")
 # irfs1["aeff"].plot_energy_dependence()
 
-# irfs2 = load_cta_irfs("caldb/data/cta/prod3b-v2/bcf/South_z40_50h/irf_file.fits")
+# irfs2 = load_irf_dict_from_file("caldb/data/cta/prod3b-v2/bcf/South_z40_50h/irf_file.fits")
 # irfs2["aeff"].plot_energy_dependence()
 
 
 ######################################################################
 # Exercises
 # ---------
 #
 # -  Load the EVENTS file for `obs_id=111159` as a
 #    `~gammapy.data.EventList` object.
 # -  Use `~gammapy.data.EventList.table` to find the energy, sky coordinate and time of
-#    the highest-energy envent.
+#    the highest-energy event.
 # -  Use `~gammapy.data.EventList.pointing_radec` to find the pointing position of this
 #    observation, and use `astropy.coordinates.SkyCoord` methods to find
 #    the field of view offset of the highest-energy event.
 # -  What is the effective area and PSF 68% containment radius of CTA at 1
 #    TeV for the `South_z20_50h` configuration used for the CTA 1DC
 #    simulation?
 # -  Get the latest CTA FITS performance files from
```

### Comparing `gammapy-1.0rc2/examples/tutorials/data/fermi_lat.py` & `gammapy-1.1rc1/examples/tutorials/data/fermi_lat.py`

 * *Files 2% similar despite different names*

```diff
@@ -153,17 +153,16 @@
 # We put this call into the same Jupyter cell as the Map.create
 # because otherwise we could accidentally fill the counts
 # multiple times when executing the `fill_by_coord` multiple times.
 counts.fill_events(events)
 
 print(counts.geom.axes[0])
 
-plt.figure()
 counts.sum_over_axes().smooth(2).plot(stretch="sqrt", vmax=30)
-
+plt.show()
 
 ######################################################################
 # Exposure
 # --------
 #
 # The Fermi-LAT dataset contains the energy-dependent exposure for the
 # whole sky as a HEALPix map computed with `gtexpcube2`. This format is
@@ -185,16 +184,16 @@
 # any energy axis for your exposure cube that you like.
 #
 
 exposure_hpx = Map.read("$GAMMAPY_DATA/fermi_3fhl/fermi_3fhl_exposure_cube_hpx.fits.gz")
 print(exposure_hpx.geom)
 print(exposure_hpx.geom.axes[0])
 
-plt.figure()
 exposure_hpx.plot()
+plt.show()
 
 ######################################################################
 # For exposure, we choose a geometry with node_type='center',
 axis = MapAxis.from_energy_bounds(
     "10 GeV",
     "2 TeV",
     nbin=10,
@@ -206,16 +205,16 @@
 exposure = exposure_hpx.interp_to_geom(geom)
 
 print(exposure.geom)
 print(exposure.geom.axes[0])
 
 ######################################################################
 # Exposure is almost constant across the field of view
-plt.figure()
 exposure.slice_by_idx({"energy_true": 0}).plot(add_cbar=True)
+plt.show()
 
 ######################################################################
 # Exposure varies very little with energy at these high energies
 energy = [10, 100, 1000] * u.GeV
 print(exposure.get_by_coord({"skycoord": gc_pos, "energy_true": energy}))
 
 
@@ -249,27 +248,27 @@
     name="diffuse-iem",
 )
 
 
 ######################################################################
 # Let’s look at the map of first energy band of the cube:
 #
-plt.figure()
 template_diffuse.map.slice_by_idx({"energy_true": 0}).plot(add_cbar=True)
+plt.show()
 
 
 ######################################################################
 # Here is the spectrum at the Galactic center:
 #
 
 dnde = template_diffuse.map.to_region_nd_map(region=gc_pos)
-plt.figure()
 dnde.plot()
 plt.xlabel("Energy (GeV)")
 plt.ylabel("Flux (cm-2 s-1 MeV-1 sr-1)")
+plt.show()
 
 
 ######################################################################
 # Isotropic diffuse background
 # ----------------------------
 #
 # To load the isotropic diffuse model with Gammapy, use the
@@ -283,17 +282,17 @@
     filename=filename, interp_kwargs={"fill_value": None}
 )
 
 
 ######################################################################
 # We can plot the model in the energy range between 50 GeV and 2000 GeV:
 #
-plt.figure()
 energy_bounds = [50, 2000] * u.GeV
 diffuse_iso.spectral_model.plot(energy_bounds, yunits=u.Unit("1 / (cm2 MeV s)"))
+plt.show()
 
 
 ######################################################################
 # PSF
 # ---
 #
 # Next we will tke a look at the PSF. It was computed using `gtpsf`, in
@@ -312,14 +311,15 @@
 # To get an idea of the size of the PSF we check how the containment radii
 # of the Fermi-LAT PSF vari with energy and different containment
 # fractions:
 #
 
 plt.figure(figsize=(8, 5))
 psf.plot_containment_radius_vs_energy()
+plt.show()
 
 
 ######################################################################
 # In addition we can check how the actual shape of the PSF varies with
 # energy and compare it against the mean PSF between 50 GeV and 2000 GeV:
 #
 
@@ -331,40 +331,41 @@
 spectrum = PowerLawSpectralModel(index=2.3)
 psf_mean = psf.to_image(spectrum=spectrum)
 psf_mean.plot_psf_vs_rad(c="k", ls="--", energy_true=[500] * u.GeV)
 
 plt.xlim(1e-3, 0.3)
 plt.ylim(1e3, 1e6)
 plt.legend()
+plt.show()
 
 ######################################################################
-# This is whaty the corresponding PSF kernel looks like:
+# This is what the corresponding PSF kernel looks like:
 #
 
 psf_kernel = psf.get_psf_kernel(
     position=geom.center_skydir, geom=geom, max_radius="1 deg"
 )
-plt.figure()
 psf_kernel.to_image().psf_kernel_map.plot(stretch="log", add_cbar=True)
+plt.show()
 
 
 ######################################################################
 # Energy Dispersion
 # ~~~~~~~~~~~~~~~~~
 #
 # For simplicity we assume a diagonal energy dispersion:
 #
 
 e_true = exposure.geom.axes["energy_true"]
 edisp = EDispKernelMap.from_diagonal_response(
     energy_axis_true=e_true, energy_axis=energy_axis
 )
 
-plt.figure()
 edisp.get_edisp_kernel().plot_matrix()
+plt.show()
 
 
 ######################################################################
 # Fit
 # ---
 #
 # Now, the big finale: let’s do a 3D map fit for the source at the
@@ -400,36 +401,36 @@
 
 print(result)
 
 print(models)
 
 residual = counts - dataset.npred()
 
-plt.figure()
 residual.sum_over_axes().smooth("0.1 deg").plot(
     cmap="coolwarm", vmin=-3, vmax=3, add_cbar=True
 )
+plt.show()
 
 ######################################################################
 # Serialisation
-# ---
+# -------------
 #
 # To serialise the created dataset, you must proceed through the
 # Datasets API
 #
 
 Datasets([dataset]).write(
     filename="fermi_dataset.yaml", filename_models="fermi_models.yaml", overwrite=True
 )
 datasets_read = Datasets.read(
     filename="fermi_dataset.yaml", filename_models="fermi_models.yaml"
 )
 print(datasets_read)
 
-plt.show()
+
 ######################################################################
 # Exercises
 # ---------
 #
 # -  Fit the position and spectrum of the source `SNR
 #    G0.9+0.1 <http://gamma-sky.net/#/cat/tev/110>`__.
 # -  Make maps and fit the position and spectrum of the `Crab
```

### Comparing `gammapy-1.0rc2/examples/tutorials/data/hess.py` & `gammapy-1.1rc1/examples/tutorials/data/hess.py`

 * *Files 3% similar despite different names*

```diff
@@ -36,14 +36,16 @@
 This is how to access data and IRFs from the H.E.S.S. data level 3, data
 release 1.
 
 """
 
 import astropy.units as u
 from astropy.coordinates import SkyCoord
+
+# %matplotlib inline
 import matplotlib.pyplot as plt
 from IPython.display import display
 from gammapy.data import DataStore
 from gammapy.makers import MapDatasetMaker
 from gammapy.makers.utils import make_theta_squared_table
 from gammapy.maps import Map, MapAxis, WcsGeom
 
@@ -70,15 +72,15 @@
 # Create and get info on the data store
 
 data_store = DataStore.from_dir("$GAMMAPY_DATA/hess-dl3-dr1")
 
 data_store.info()
 
 ######################################################################
-# Preview an excerpt from the observtaion table
+# Preview an excerpt from the observation table
 
 display(data_store.obs_table[:2][["OBS_ID", "DATE-OBS", "RA_PNT", "DEC_PNT", "OBJECT"]])
 
 ######################################################################
 # Get a single obervation
 
 obs = data_store.obs(23523)
@@ -100,17 +102,16 @@
 
 ######################################################################
 # Peek the psf
 obs.psf.peek()
 
 ######################################################################
 # Peek the background rate
-plt.figure()
 obs.bkg.to_2d().plot()
-
+plt.show()
 
 ######################################################################
 # Theta squared event distribution
 # --------------------------------
 #
 # As a quick look plot it can be helpful to plot the quadratic offset
 # (theta squared) distribution of the events.
@@ -124,15 +125,15 @@
     observations=observations,
     position=position,
     theta_squared_axis=theta2_axis,
 )
 
 plt.figure(figsize=(10, 5))
 plot_theta_squared_table(theta2_table)
-
+plt.show()
 
 ######################################################################
 # On-axis equivalent livetime
 # ---------------------------
 #
 # Since the acceptance of the H.E.S.S. camera varies within the field of
 # view, what is often interesting is not the simply the total number of
@@ -165,36 +166,37 @@
     proj="CAR",
     axes=[energy_axis_true],
 )
 
 # compute
 livetime = Map.from_geom(geom, unit=u.hr)
 for obs in observations:
-    geom_obs = geom.cutout(position=obs.pointing_radec, width=2.0 * offset_max)
+    geom_obs = geom.cutout(
+        position=obs.get_pointing_icrs(obs.tmid), width=2.0 * offset_max
+    )
     exposure = MapDatasetMaker.make_exposure(geom=geom_obs, observation=obs)
     on_axis = obs.aeff.evaluate(
         offset=0.0 * u.deg, energy_true=geom.axes["energy_true"].center
     )
     on_axis = on_axis.reshape((on_axis.shape[0], 1, 1))
     lv_obs = exposure / on_axis
     livetime.stack(lv_obs)
 
 # Plot
-plt.figure()
 ax = livetime.plot(add_cbar=True)
+plt.show()
 
 # Add the pointing position on top
 for obs in observations:
     ax.plot(
-        obs.pointing_radec.to_pixel(wcs=ax.wcs)[0],
-        obs.pointing_radec.to_pixel(wcs=ax.wcs)[1],
+        obs.get_pointing_icrs(obs.tmid).to_pixel(wcs=ax.wcs)[0],
+        obs.get_pointing_icrs(obs.tmid).to_pixel(wcs=ax.wcs)[1],
         "+",
         color="black",
     )
-
 plt.show()
 
 ######################################################################
 # Exercises
 # ---------
 #
 # -  Find the `OBS_ID` for the runs of the Crab nebula
```

### Comparing `gammapy-1.0rc2/examples/tutorials/scripts/survey_map.py` & `gammapy-1.1rc1/examples/tutorials/scripts/survey_map.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/tutorials/starting/README.rst` & `gammapy-1.1rc1/examples/tutorials/starting/README.rst`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/examples/tutorials/starting/analysis_1.py` & `gammapy-1.1rc1/examples/tutorials/starting/analysis_1.py`

 * *Files 3% similar despite different names*

```diff
@@ -56,27 +56,29 @@
    and run the different analysis steps
 
    -  Observation selection
    -  Data reduction
    -  Model fitting
    -  Estimating flux points
 
-Finally we will compare the results against a reference model.
+Finally, we will compare the results against a reference model.
 
 """
 
 
 ######################################################################
 # Setup
 # -----
 #
 
-# %matplotlib inline
 from pathlib import Path
 from astropy import units as u
+
+# %matplotlib inline
+import matplotlib.pyplot as plt
 from gammapy.analysis import Analysis, AnalysisConfig
 
 ######################################################################
 # Check setup
 # -----------
 from gammapy.utils.check import check_tutorials_setup
 
@@ -253,16 +255,16 @@
 #
 
 print(analysis.observations.ids)
 
 
 ######################################################################
 # To see how to explore observations, please refer to the following
-# notebook: `CTA with Gammapy <../data/cta.ipynb>`__ or `HESS with
-# Gammapy <../data/hess.ipynb>`__
+# notebook: :doc:`CTA with Gammapy </tutorials/data/cta>` or :doc:`HESS with
+# Gammapy </tutorials/data/hess>`
 #
 
 
 ######################################################################
 # Data reduction
 # --------------
 #
@@ -299,15 +301,15 @@
 # We can also compute the map of the sqrt_ts (significance) of the excess
 # counts above the background. The correlation radius to sum counts is
 # defined in the config file.
 #
 
 analysis.get_excess_map()
 analysis.excess_map["sqrt_ts"].plot(add_cbar=True)
-
+plt.show()
 
 ######################################################################
 # Save dataset to disk
 # --------------------
 #
 # It is common to run the preparation step independent of the likelihood
 # fit, because often the preparation of maps, PSF and energy dispersion is
@@ -411,38 +413,39 @@
 analysis.get_flux_points()
 
 # Example showing how to change just before plotting the threshold on the signal significance
 # (points vs upper limits), even if this has no effect with this data set.
 fp = analysis.flux_points.data
 fp.sqrt_ts_threshold_ul = 5
 ax_sed, ax_residuals = analysis.flux_points.plot_fit()
-
+plt.show()
 
 ######################################################################
 # The flux points can be exported to a fits table following the format
 # defined
-# `here <https://gamma-astro-data-formats.readthedocs.io/en/latest/spectra/flux_points/index.html>`__
+# `here <https://gamma-astro-data-formats.readthedocs.io/en/latest/spectra/flux_points/index.html>`_
 #
 
 filename = path / "flux-points.fits"
 analysis.flux_points.write(filename, overwrite=True)
 
 
 ######################################################################
 # To check the fit is correct, we compute the map of the sqrt_ts of the
 # excess counts above the current model.
 #
 
 analysis.get_excess_map()
 analysis.excess_map["sqrt_ts"].plot(add_cbar=True, cmap="RdBu", vmin=-5, vmax=5)
+plt.show()
 
 
 ######################################################################
 # What’s next
 # -----------
 #
 # You can look at the same analysis without the high level interface in
-# `analysis_2 <analysis_2.ipynb>`__
+# :doc:`/tutorials/starting/analysis_2`
 #
 # You can see how to perform a 1D spectral analysis of the same data in
-# `spectral analysis <../analysis-1d/spectral_analysis.ipynb>`__
+# :doc:`/tutorials/analysis-1d/spectral_analysis`
 #
```

### Comparing `gammapy-1.0rc2/examples/tutorials/starting/analysis_2.py` & `gammapy-1.1rc1/examples/tutorials/starting/analysis_2.py`

 * *Files 5% similar despite different names*

```diff
@@ -6,16 +6,16 @@
 
 Prerequisites
 -------------
 
 -  Understanding the gammapy data workflow, in particular what are DL3
    events and instrument response functions (IRF).
 -  Understanding of the data reduction and modeling fitting process as
-   shown in the `analysis with the high level interface
-   tutorial <analysis_1.ipynb>`__
+   shown in the analysis with the high level interface
+   tutorial :doc:`/tutorials/starting/analysis_1`
 
 Context
 -------
 
 This notebook is an introduction to gammapy analysis this time using the
 lower level classes and functions the library. This allows to understand
 what happens during two main gammapy analysis steps, data reduction and
@@ -32,15 +32,15 @@
 `~gammapy.data.DataStore`) to retrieve a list of selected observations
 (`~gammapy.data.Observations`). Then, we define the geometry of the
 `~gammapy.datasets.MapDataset` object we want to produce and the maker
 object that reduce an observation to a dataset.
 
 We can then proceed with data reduction with a loop over all selected
 observations to produce datasets in the relevant geometry and stack them
-together (i.e. sum them all).
+together (i.e.sum them all).
 
 In practice, we have to:
 
 - Create a `~gammapy.data.DataStore` poiting to the relevant data
 - Apply an observation selection to produce a list of observations,
   a `~gammapy.data.Observations` object.
 - Define a geometry of the Map we want to produce, with a sky projection
@@ -74,27 +74,29 @@
 from pathlib import Path
 from astropy import units as u
 from astropy.coordinates import SkyCoord
 from regions import CircleSkyRegion
 
 # %matplotlib inline
 import matplotlib.pyplot as plt
+from IPython.display import display
 from gammapy.data import DataStore
 from gammapy.datasets import MapDataset
 from gammapy.estimators import FluxPointsEstimator
 from gammapy.makers import FoVBackgroundMaker, MapDatasetMaker, SafeMaskMaker
 from gammapy.maps import MapAxis, WcsGeom
 from gammapy.modeling import Fit
 from gammapy.modeling.models import (
     FoVBackgroundModel,
     PointSpatialModel,
     PowerLawSpectralModel,
     SkyModel,
 )
 from gammapy.utils.check import check_tutorials_setup
+from gammapy.visualization import plot_npred_signal
 
 ######################################################################
 # Check setup
 # -----------
 
 check_tutorials_setup()
 
@@ -202,15 +204,15 @@
 #
 
 # %%time
 
 for obs in observations:
     # First a cutout of the target map is produced
     cutout = stacked.cutout(
-        obs.pointing_radec, width=2 * offset_max, name=f"obs-{obs.obs_id}"
+        obs.get_pointing_icrs(obs.tmid), width=2 * offset_max, name=f"obs-{obs.obs_id}"
     )
     # A MapDataset is filled in this cutout geometry
     dataset = maker.run(cutout, obs)
     # The data quality cut is applied
     dataset = maker_safe_mask.run(dataset, obs)
     # fit background model
     dataset = maker_fov.run(dataset)
@@ -225,14 +227,15 @@
 
 ######################################################################
 # Inspect the reduced dataset
 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~
 #
 
 stacked.counts.sum_over_axes().smooth(0.05 * u.deg).plot(stretch="sqrt", add_cbar=True)
+plt.show()
 
 
 ######################################################################
 # Save dataset to disk
 # --------------------
 #
 # It is common to run the preparation step independent of the likelihood
@@ -315,49 +318,61 @@
 # `~astropy.modeling.models.Models` object.
 #
 
 print(stacked.models.to_parameters_table())
 
 
 ######################################################################
+# Here we can plot the number of predicted counts for each model and
+# for the background in our dataset. In order to do this, we can use
+# the `~gammapy.visualization.plot_npred_signal` function.
+#
+
+plot_npred_signal(stacked)
+plt.show()
+
+
+######################################################################
 # Inspecting residuals
 # ~~~~~~~~~~~~~~~~~~~~
 #
 # For any fit it is useful to inspect the residual images. We have a few
 # options on the dataset object to handle this. First we can use
 # `~gammapy.datasets.MapDataset.plot_residuals_spatial` to plot a residual image, summed over all
 # energies:
 #
 
 stacked.plot_residuals_spatial(method="diff/sqrt(model)", vmin=-0.5, vmax=0.5)
+plt.show()
 
 
 ######################################################################
 # In addition, we can also specify a region in the map to show the
 # spectral residuals:
 #
 
 region = CircleSkyRegion(center=SkyCoord("83.63 deg", "22.14 deg"), radius=0.5 * u.deg)
 
 stacked.plot_residuals(
     kwargs_spatial=dict(method="diff/sqrt(model)", vmin=-0.5, vmax=0.5),
     kwargs_spectral=dict(region=region),
 )
+plt.show()
 
 
 ######################################################################
 # We can also directly access the ``.residuals()`` to get a map, that we
 # can plot interactively:
 #
 
 residuals = stacked.residuals(method="diff")
 residuals.smooth("0.08 deg").plot_interactive(
     cmap="coolwarm", vmin=-0.2, vmax=0.2, stretch="linear", add_cbar=True
 )
-
+plt.show()
 
 ######################################################################
 # Plot the fitted spectrum
 # ------------------------
 #
 
 
@@ -376,14 +391,15 @@
 ######################################################################
 # Now we can actually do the plot using the ``plot_error`` method:
 #
 
 energy_bounds = [1, 10] * u.TeV
 spec.plot(energy_bounds=energy_bounds, energy_power=2)
 ax = spec.plot_error(energy_bounds=energy_bounds, energy_power=2)
+plt.show()
 
 
 ######################################################################
 # Computing flux points
 # ~~~~~~~~~~~~~~~~~~~~~
 #
 # We can now compute some flux points using the
@@ -398,7 +414,8 @@
 fpe = FluxPointsEstimator(energy_edges=energy_edges, source="crab")
 
 # %%time
 flux_points = fpe.run(datasets=[stacked])
 
 ax = spec.plot_error(energy_bounds=energy_bounds, energy_power=2)
 flux_points.plot(ax=ax, energy_power=2)
+plt.show()
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `gammapy-1.0rc2/examples/tutorials/starting/overview.py` & `gammapy-1.1rc1/examples/tutorials/starting/overview.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,15 +5,15 @@
 Introduction to basic data structures handling.
 
 Introduction
 ------------
 
 This is a getting started tutorial for Gammapy.
 
-In this tutorial we will use the `Second Fermi-LAT Catalog of
+In this tutorial we will use the `Third Fermi-LAT Catalog of
 High-Energy Sources (3FHL)
 catalog <http://fermi.gsfc.nasa.gov/ssc/data/access/lat/3FHL/>`__,
 corresponding event list and images to learn how to work with some of
 the central Gammapy data structures.
 
 We will cover the following topics:
 
@@ -66,14 +66,15 @@
 # machine where the datasets needed are placed. To check whether your
 # setup is correct you can execute the following cell:
 #
 
 
 import astropy.units as u
 from astropy.coordinates import SkyCoord
+import matplotlib.pyplot as plt
 
 ######################################################################
 # Check setup
 # -----------
 from gammapy.utils.check import check_tutorials_setup
 
 # %matplotlib inline
@@ -140,78 +141,79 @@
 # basically calls
 # `plt.imshow <https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html>`__,
 # passing the ``gc_3fhl.data`` attribute but in addition handles axis with
 # world coordinates using
 # `astropy.visualization.wcsaxes <https://docs.astropy.org/en/stable/visualization/wcsaxes/>`__
 # and defines some defaults for nicer plots (e.g. the colormap ‘afmhot’):
 #
-
 gc_3fhl.plot(stretch="sqrt")
+plt.show()
 
 
 ######################################################################
 # To make the structures in the image more visible we will smooth the data
 # using a Gaussian kernel.
 #
 
 gc_3fhl_smoothed = gc_3fhl.smooth(kernel="gauss", width=0.2 * u.deg)
-
 gc_3fhl_smoothed.plot(stretch="sqrt")
+plt.show()
 
 
 ######################################################################
 # The smoothed plot already looks much nicer, but still the image is
 # rather large. As we are mostly interested in the inner part of the
 # image, we will cut out a quadratic region of the size 9 deg x 9 deg
 # around Vela. Therefore we use `~gammapy.maps.Map.cutout` to make a
 # cutout map:
 #
 
 # define center and size of the cutout region
 center = SkyCoord(0, 0, unit="deg", frame="galactic")
 gc_3fhl_cutout = gc_3fhl_smoothed.cutout(center, 9 * u.deg)
 gc_3fhl_cutout.plot(stretch="sqrt")
+plt.show()
 
 
 ######################################################################
 # For a more detailed introduction to `~gammapy.maps`, take a look a the
-# `maps.ipynb <../api/maps.ipynb>`__ notebook.
+# :doc:`/tutorials/api/maps` notebook.
 #
 # Exercises
 # ~~~~~~~~~
 #
-# -  Add a marker and circle at the position of ``Sag A*`` (you can find
+# -  Add a marker and circle at the position of ``Sgr A*`` (you can find
 #    examples in
 #    `astropy.visualization.wcsaxes <https://docs.astropy.org/en/stable/visualization/wcsaxes/>`__).
 #
 
 
 ######################################################################
 # Event lists
 # -----------
 #
 # Almost any high level gamma-ray data analysis starts with the raw
 # measured counts data, which is stored in event lists. In Gammapy event
-# lists are represented by the ``~gammapy.data.EventList`` class.
+# lists are represented by the `~gammapy.data.EventList` class.
 #
 # In this section we will learn how to:
 #
 # -  Read event lists from FITS files
 # -  Access and work with the ``EventList`` attributes such as ``.table``
 #    and ``.energy``
 # -  Filter events lists using convenience methods
 #
-# Let’s start with the import from the ``~gammapy.data`` submodule:
+# Let’s start with the import from the `~gammapy.data` submodule:
 #
 
 from gammapy.data import EventList
 
 ######################################################################
 # Very similar to the sky map class an event list can be created, by
-# passing a filename to the ``~gammapy.data.EventList.read()`` method:
+# passing a filename to the `~gammapy.data.EventList.read()` method:
 #
 
 events_3fhl = EventList.read("$GAMMAPY_DATA/fermi-3fhl-gc/fermi-3fhl-gc-events.fits.gz")
 
 
 ######################################################################
 # This time the actual data is stored as an
@@ -246,17 +248,19 @@
 # or
 # `~astropy.time.Time`
 # objects:
 #
 
 print(events_3fhl.energy.to("GeV"))
 
+# %%
 print(events_3fhl.galactic)
 # events_3fhl.radec
 
+# %%
 print(events_3fhl.time)
 
 
 ######################################################################
 # In addition ``EventList`` provides convenience methods to filter the
 # event lists. One possible use case is to find the highest energy event
 # within a radius of 0.5 deg around the vela position:
@@ -294,15 +298,15 @@
 # In this section we will learn how to:
 #
 # -  Load builtins catalogs from `~gammapy.catalog`
 # -  Sort and index the underlying Astropy tables
 # -  Access data from individual sources
 #
 # Let’s start with importing the 3FHL catalog object from the
-# ``~gammapy.catalog`` submodule:
+# `~gammapy.catalog` submodule:
 #
 
 from gammapy.catalog import SourceCatalog3FHL
 
 ######################################################################
 # First we initialize the Fermi-LAT 3FHL catalog and directly take a look
 # at the ``.table`` attribute:
@@ -386,14 +390,15 @@
 # parameter values and errors taken from the 3FHL catalog.
 #
 # Let’s plot the spectral model in the energy range between 10 GeV and
 # 2000 GeV:
 #
 
 ax_crab_3fhl = crab_3fhl_spec.plot(energy_bounds=[10, 2000] * u.GeV, energy_power=0)
+plt.show()
 
 
 ######################################################################
 # We assign the return axes object to variable called ``ax_crab_3fhl``,
 # because we will re-use it later to plot the flux points on top.
 #
 # To compute the differential flux at 100 GeV we can simply call the model
@@ -455,17 +460,17 @@
 
 ######################################################################
 # Finally let’s combine spectral model and flux points in a single plot
 # and scale with ``energy_power=2`` to obtain the spectral energy
 # distribution:
 #
 
-ax = crab_3fhl_spec.plot(energy_bounds=[10, 2000] * u.GeV, energy_power=2)
-crab_3fhl.flux_points.plot(ax=ax, sed_type="dnde", energy_power=2)
-
+ax = crab_3fhl_spec.plot(energy_bounds=[10, 2000] * u.GeV, sed_type="e2dnde")
+crab_3fhl.flux_points.plot(ax=ax, sed_type="e2dnde")
+plt.show()
 
 ######################################################################
 # Exercises
 # ~~~~~~~~~
 #
 # -  Plot the spectral model and flux points for PKS 2155-304 for the 3FGL
 #    and 2FHL catalogs. Try to plot the error of the model (aka
@@ -477,13 +482,13 @@
 # ----------
 #
 # This was a quick introduction to some of the high level classes in
 # Astropy and Gammapy.
 #
 # -  To learn more about those classes, go to the API docs (links are in
 #    the introduction at the top).
-# -  To learn more about other parts of Gammapy (e.g. Fermi-LAT and TeV
+# -  To learn more about other parts of Gammapy (e.g. Fermi-LAT and TeV
 #    data analysis), check out the other tutorial notebooks.
 # -  To see what’s available in Gammapy, browse the Gammapy docs or use
 #    the full-text search.
 # -  If you have any questions, ask on the mailing list.
 #
```

### Comparing `gammapy-1.0rc2/gammapy/__init__.py` & `gammapy-1.1rc1/gammapy/__init__.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/_compiler.c` & `gammapy-1.1rc1/gammapy/_compiler.c`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/analysis/config/docs.yaml` & `gammapy-1.1rc1/gammapy/analysis/config/docs.yaml`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/analysis/config/example-1d.yaml` & `gammapy-1.1rc1/gammapy/analysis/config/example-1d.yaml`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/analysis/config/example-3d.yaml` & `gammapy-1.1rc1/gammapy/analysis/config/example-3d.yaml`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/analysis/config/model-1d.yaml` & `gammapy-1.1rc1/gammapy/analysis/config/model-1d.yaml`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/analysis/config/model.yaml` & `gammapy-1.1rc1/gammapy/analysis/config/model.yaml`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/analysis/config.py` & `gammapy-1.1rc1/gammapy/analysis/config.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/analysis/core.py` & `gammapy-1.1rc1/gammapy/analysis/core.py`

 * *Files 1% similar despite different names*

```diff
@@ -305,14 +305,15 @@
         fp_settings = self.config.flux_points
         log.info("Calculating flux points.")
         energy_edges = self._make_energy_axis(fp_settings.energy).edges
         flux_point_estimator = FluxPointsEstimator(
             energy_edges=energy_edges,
             source=fp_settings.source,
             fit=self.fit,
+            n_jobs=self.config.general.n_jobs,
             **fp_settings.parameters,
         )
 
         fp = flux_point_estimator.run(datasets=self.datasets)
 
         self.flux_points = FluxPointsDataset(
             data=fp, models=self.models[fp_settings.source]
@@ -368,14 +369,15 @@
             ]
 
         light_curve_estimator = LightCurveEstimator(
             time_intervals=time_intervals,
             energy_edges=energy_edges,
             source=lc_settings.source,
             fit=self.fit,
+            n_jobs=self.config.general.n_jobs,
             **lc_settings.parameters,
         )
         lc = light_curve_estimator.run(datasets=self.datasets)
         self.light_curve = lc
         log.info(
             "\n{}".format(
                 self.light_curve.to_table(format="lightcurve", sed_type="flux")
@@ -540,15 +542,14 @@
             makers,
             stack_datasets=datasets_settings.stack,
             n_jobs=self.config.general.n_jobs,
             cutout_mode="trim",
             cutout_width=2 * offset_max,
         )
         self.datasets = datasets_maker.run(stacked, self.observations)
-        # TODO: move progress bar to DatasetsMaker but how with multiprocessing ?
 
     def _spectrum_extraction(self):
         """Run all steps for the spectrum extraction."""
         log.info("Reducing spectrum datasets.")
         datasets_settings = self.config.datasets
         dataset_maker = self._create_dataset_maker()
         safe_mask_maker = self._create_safe_mask_maker()
```

### Comparing `gammapy-1.0rc2/gammapy/analysis/tests/test_analysis.py` & `gammapy-1.1rc1/gammapy/analysis/tests/test_analysis.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/analysis/tests/test_config.py` & `gammapy-1.1rc1/gammapy/analysis/tests/test_config.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/astro/darkmatter/profiles.py` & `gammapy-1.1rc1/gammapy/astro/darkmatter/profiles.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 """Dark matter profiles."""
 import abc
 import numpy as np
 import astropy.units as u
 from gammapy.modeling import Parameter, Parameters
-from gammapy.modeling.models.spectral import integrate_spectrum
+from gammapy.utils.integrate import trapz_loglog
 
 __all__ = [
     "BurkertProfile",
     "DMProfile",
     "EinastoProfile",
     "IsothermalProfile",
     "MooreProfile",
@@ -30,34 +30,66 @@
         return self.evaluate(radius, **kwargs)
 
     def scale_to_local_density(self):
         """Scale to local density."""
         scale = (self.LOCAL_DENSITY / self(self.DISTANCE_GC)).to_value("")
         self.parameters["rho_s"].value *= scale
 
-    def _eval_squared(self, radius):
-        """Squared density at given radius."""
-        return self(radius) ** 2
+    def _eval_squared(self, radius, separation):
+        """Squared density at given radius together with the substitution part"""
+        return (
+            self(radius) ** 2
+            * radius
+            / np.sqrt(radius**2 - (self.DISTANCE_GC * np.sin(separation)) ** 2)
+        )
 
-    def integral(self, rmin, rmax, **kwargs):
+    def integral(self, rmin, rmax, separation, ndecade):
         r"""Integrate squared dark matter profile numerically.
 
         .. math::
             F(r_{min}, r_{max}) = \int_{r_{min}}^{r_{max}}\rho(r)^2 dr
 
         Parameters
         ----------
         rmin, rmax : `~astropy.units.Quantity`
             Lower and upper bound of integration range.
-        **kwargs : dict
-            Keyword arguments passed to :func:`~gammapy.utils.integrate.integrate_spectrum`
+        separation : `~numpy.ndarray`
+            Separation angle in rad
+        ndecade    : int, optional
+            Number of grid points per decade used for the integration.
+            Default : 10000
         """
-        integral = integrate_spectrum(self._eval_squared, rmin, rmax, **kwargs)
+        integral = self.integrate_spectrum_separation(
+            self._eval_squared, rmin, rmax, separation, ndecade
+        )
         return integral.to("GeV2 / cm5")
 
+    def integrate_spectrum_separation(self, func, xmin, xmax, separation, ndecade):
+        r"""Helper for the squared dark matter profile integral.
+
+        Parameters
+        ----------
+        xmin, xmax : `~astropy.units.Quantity`
+            Lower and upper bound of integration range.
+        separation : `~numpy.ndarray`
+            Separation angle in rad
+        ndecade    : int
+            Number of grid points per decade used for the integration.
+        """
+        unit = xmin.unit
+        xmin = xmin.value
+        xmax = xmax.to_value(unit)
+        logmin = np.log10(xmin)
+        logmax = np.log10(xmax)
+        n = np.int32((logmax - logmin) * ndecade)
+        x = np.logspace(logmin, logmax, n) * unit
+        y = func(x, separation)
+        val = trapz_loglog(y, x)
+        return val.sum()
+
 
 class NFWProfile(DMProfile):
     r"""NFW Profile.
 
     .. math::
         \rho(r) = \rho_s \frac{r_s}{r}\left(1 + \frac{r}{r_s}\right)^{-2}
```

### Comparing `gammapy-1.0rc2/gammapy/astro/darkmatter/spectra.py` & `gammapy-1.1rc1/gammapy/astro/darkmatter/spectra.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/astro/darkmatter/tests/test_profiles.py` & `gammapy-1.1rc1/gammapy/astro/darkmatter/tests/test_profiles.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/astro/darkmatter/tests/test_spectra.py` & `gammapy-1.1rc1/gammapy/astro/darkmatter/tests/test_spectra.py`

 * *Files 6% similar despite different names*

```diff
@@ -15,15 +15,15 @@
     primflux = PrimaryFlux(channel="W", mDM=1 * u.TeV)
     actual = primflux.table_model(500 * u.GeV)
     desired = 9.328234e-05 / u.GeV
     assert_quantity_allclose(actual, desired)
 
 
 @requires_data()
-def test_DMAnnihilation():
+def test_dm_annihilation_spectral_model(tmpdir):
     channel = "b"
     massDM = 5 * u.TeV
     jfactor = 3.41e19 * u.Unit("GeV2 cm-5")
     energy_min = 0.01 * u.TeV
     energy_max = 10 * u.TeV
 
     model = DarkMatterAnnihilationSpectralModel(
@@ -35,16 +35,17 @@
     differential_flux = model.evaluate(energy=1 * u.TeV, scale=1).to("cm-2 s-1 TeV-1")
 
     sky_model = SkyModel(
         spectral_model=model,
         name="skymodel",
     )
     models = Models([sky_model])
-    models.write("tmp.yaml", overwrite=True)
-    new_models = Models.read("tmp.yaml")
+    filename = tmpdir / "model.yaml"
+    models.write(filename, overwrite=True)
+    new_models = Models.read(filename)
 
     assert_quantity_allclose(integral_flux.value, 6.19575457e-14, rtol=1e-3)
     assert_quantity_allclose(differential_flux.value, 2.97506768e-16, rtol=1e-3)
 
     assert model.scale.is_norm
     assert new_models[0].spectral_model.channel == model.channel
     assert new_models[0].spectral_model.z == model.z
```

### Comparing `gammapy-1.0rc2/gammapy/astro/darkmatter/tests/test_utils.py` & `gammapy-1.1rc1/gammapy/astro/darkmatter/tests/test_utils.py`

 * *Files 6% similar despite different names*

```diff
@@ -13,15 +13,19 @@
 @pytest.fixture(scope="session")
 def geom():
     return WcsGeom.create(binsz=0.5, npix=10)
 
 
 @pytest.fixture(scope="session")
 def jfact(geom):
-    jfactory = JFactory(geom=geom, profile=profiles.NFWProfile(), distance=8 * u.kpc)
+    jfactory = JFactory(
+        geom=geom,
+        profile=profiles.NFWProfile(),
+        distance=profiles.DMProfile.DISTANCE_GC,
+    )
     return jfactory.compute_jfactor()
 
 
 @requires_data()
 def test_dmfluxmap(jfact):
     energy_min = 0.1 * u.TeV
     energy_max = 10 * u.TeV
@@ -29,9 +33,9 @@
     channel = "W"
 
     diff_flux = DarkMatterAnnihilationSpectralModel(mass=massDM, channel=channel)
     int_flux = (
         jfact * diff_flux.integral(energy_min=energy_min, energy_max=energy_max)
     ).to("cm-2 s-1")
     actual = int_flux[5, 5]
-    desired = 1.9483e-12 / u.cm**2 / u.s
+    desired = 5.94207e-12 / u.cm**2 / u.s
     assert_quantity_allclose(actual, desired, rtol=1e-3)
```

### Comparing `gammapy-1.0rc2/gammapy/astro/population/__init__.py` & `gammapy-1.1rc1/gammapy/astro/population/__init__.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/astro/population/simulate.py` & `gammapy-1.1rc1/gammapy/astro/population/simulate.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/astro/population/spatial.py` & `gammapy-1.1rc1/gammapy/astro/population/spatial.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/astro/population/tests/test_simulate.py` & `gammapy-1.1rc1/gammapy/astro/population/tests/test_simulate.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/astro/population/tests/test_spatial.py` & `gammapy-1.1rc1/gammapy/astro/population/tests/test_spatial.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/astro/population/tests/test_velocity.py` & `gammapy-1.1rc1/gammapy/astro/population/tests/test_velocity.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/astro/population/velocity.py` & `gammapy-1.1rc1/gammapy/astro/population/velocity.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/astro/source/pulsar.py` & `gammapy-1.1rc1/gammapy/astro/source/pulsar.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/astro/source/pwn.py` & `gammapy-1.1rc1/gammapy/astro/source/pwn.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/astro/source/snr.py` & `gammapy-1.1rc1/gammapy/astro/source/snr.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/astro/source/tests/test_pulsar.py` & `gammapy-1.1rc1/gammapy/astro/source/tests/test_pulsar.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/astro/source/tests/test_pwn.py` & `gammapy-1.1rc1/gammapy/astro/source/tests/test_pwn.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/astro/source/tests/test_snr.py` & `gammapy-1.1rc1/gammapy/astro/source/tests/test_snr.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/__init__.py` & `gammapy-1.1rc1/gammapy/catalog/__init__.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/core.py` & `gammapy-1.1rc1/gammapy/catalog/core.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,17 +2,18 @@
 """Source catalog and object base classes."""
 import abc
 import numbers
 from copy import deepcopy
 import numpy as np
 from astropy.coordinates import SkyCoord
 from astropy.utils import lazyproperty
+from astropy.table import Table
 from gammapy.maps import TimeMapAxis
 from gammapy.modeling.models import Models
-from gammapy.utils.table import table_from_row_data, table_row_to_dict
+from gammapy.utils.table import table_row_to_dict
 
 __all__ = ["SourceCatalog", "SourceCatalogObject"]
 
 
 # https://pydanny.blogspot.com/2011/11/loving-bunch-class.html
 class Bunch(dict):
     def __init__(self, **kw):
@@ -65,15 +66,15 @@
     def row_index(self):
         """Row index of source in catalog (int)"""
         return self.data[self._row_index_key]
 
     @property
     def position(self):
         """Source position (`~astropy.coordinates.SkyCoord`)."""
-        table = table_from_row_data([self.data])
+        table = Table([self.data])
         return _skycoord_from_table(table)[0]
 
 
 class SourceCatalog(abc.ABC):
     """Generic source catalog.
 
     This class can be used directly, but it is mostly used as a
```

### Comparing `gammapy-1.0rc2/gammapy/catalog/fermi.py` & `gammapy-1.1rc1/gammapy/catalog/fermi.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/gammacat.py` & `gammapy-1.1rc1/gammapy/catalog/gammacat.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/hawc.py` & `gammapy-1.1rc1/gammapy/catalog/hawc.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/hess.py` & `gammapy-1.1rc1/gammapy/catalog/hess.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/tests/data/2fhl_j0822.6-4250e.txt` & `gammapy-1.1rc1/gammapy/catalog/tests/data/2fhl_j0822.6-4250e.txt`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/tests/data/2fhl_j1445.1-0329.txt` & `gammapy-1.1rc1/gammapy/catalog/tests/data/2fhl_j1445.1-0329.txt`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/tests/data/3fgl_J0000.1+6545.txt` & `gammapy-1.1rc1/gammapy/catalog/tests/data/3fgl_J0000.1+6545.txt`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/tests/data/3fgl_J0001.4+2120.txt` & `gammapy-1.1rc1/gammapy/catalog/tests/data/3fgl_J0001.4+2120.txt`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/tests/data/3fgl_J0023.4+0923.txt` & `gammapy-1.1rc1/gammapy/catalog/tests/data/3fgl_J0023.4+0923.txt`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/tests/data/3fgl_J0835.3-4510.txt` & `gammapy-1.1rc1/gammapy/catalog/tests/data/3fgl_J0835.3-4510.txt`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/tests/data/3fhl_j2301.9+5855e.txt` & `gammapy-1.1rc1/gammapy/catalog/tests/data/3fhl_j2301.9+5855e.txt`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/tests/data/4fgl_J0000.3-7355.txt` & `gammapy-1.1rc1/gammapy/catalog/tests/data/4fgl_J0000.3-7355.txt`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/tests/data/4fgl_J0001.5+2113.txt` & `gammapy-1.1rc1/gammapy/catalog/tests/data/4fgl_J0001.5+2113.txt`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/tests/data/4fgl_J0002.8+6217.txt` & `gammapy-1.1rc1/gammapy/catalog/tests/data/4fgl_J0002.8+6217.txt`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/tests/data/4fgl_J1409.1-6121e.txt` & `gammapy-1.1rc1/gammapy/catalog/tests/data/4fgl_J1409.1-6121e.txt`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/tests/data/gammacat_hess_j1813-178.txt` & `gammapy-1.1rc1/gammapy/catalog/tests/data/gammacat_hess_j1813-178.txt`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/tests/data/gammacat_hess_j1848-018.txt` & `gammapy-1.1rc1/gammapy/catalog/tests/data/gammacat_hess_j1848-018.txt`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/tests/data/gammacat_vela_x.txt` & `gammapy-1.1rc1/gammapy/catalog/tests/data/gammacat_vela_x.txt`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/tests/data/hess_j1713-397.txt` & `gammapy-1.1rc1/gammapy/catalog/tests/data/hess_j1713-397.txt`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/tests/data/hess_j1825-137.txt` & `gammapy-1.1rc1/gammapy/catalog/tests/data/hess_j1825-137.txt`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/tests/data/hess_j1930+188.txt` & `gammapy-1.1rc1/gammapy/catalog/tests/data/hess_j1930+188.txt`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/tests/data/make.py` & `gammapy-1.1rc1/gammapy/catalog/tests/data/make.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/tests/test_core.py` & `gammapy-1.1rc1/gammapy/catalog/tests/test_core.py`

 * *Files 1% similar despite different names*

```diff
@@ -21,15 +21,15 @@
     table["Source_Name"] = ["a", "bb", "ccc"]
     table["RA"] = Column([42.2, 43.3, 44.4], unit="deg")
     table["DEC"] = Column([1, 2, 3], unit="deg")
     return SomeSourceCatalog(table)
 
 
 class TestSourceCatalog:
-    def setup(self):
+    def setup_method(self):
         self.cat = make_test_catalog()
 
     def test_str(self):
         assert "description" in str(self.cat)
         assert "name" in str(self.cat)
 
     def test_table(self):
@@ -77,15 +77,15 @@
 
     def test_selection(self):
         new = self.cat[self.cat.table["Source_Name"] != "a"]
         assert len(new.table) == 2
 
 
 class TestSourceCatalogObject:
-    def setup(self):
+    def setup_method(self):
         self.cat = make_test_catalog()
         self.source = self.cat["bb"]
 
     def test_name(self):
         assert self.source.name == "bb"
 
     def test_row_index(self):
```

### Comparing `gammapy-1.0rc2/gammapy/catalog/tests/test_fermi.py` & `gammapy-1.1rc1/gammapy/catalog/tests/test_fermi.py`

 * *Files 4% similar despite different names*

```diff
@@ -19,14 +19,15 @@
     SuperExpCutoffPowerLaw3FGLSpectralModel,
     SuperExpCutoffPowerLaw4FGLSpectralModel,
 )
 from gammapy.utils.gauss import Gauss2DPDF
 from gammapy.utils.testing import (
     assert_quantity_allclose,
     assert_time_allclose,
+    modify_unit_order_astropy_5_3,
     requires_data,
 )
 
 SOURCES_4FGL = [
     dict(
         idx=0,
         name="4FGL J0000.3-7355",
@@ -158,16 +159,19 @@
 
     def test_row_index(self):
         assert self.source.row_index == 995
 
     @pytest.mark.parametrize("ref", SOURCES_4FGL, ids=lambda _: _["name"])
     def test_str(self, ref):
         actual = str(self.cat[ref["idx"]])
-        expected = open(get_pkg_data_filename(ref["str_ref_file"])).read()
-        assert actual == expected
+
+        with open(get_pkg_data_filename(ref["str_ref_file"])) as fh:
+            expected = fh.read()
+
+        assert actual == modify_unit_order_astropy_5_3(expected)
 
     @pytest.mark.parametrize("ref", SOURCES_4FGL, ids=lambda _: _["name"])
     def test_spectral_model(self, ref):
         model = self.cat[ref["idx"]].spectral_model()
 
         e_ref = model.reference.quantity
         dnde, dnde_err = model.evaluate_error(e_ref)
@@ -345,16 +349,19 @@
         position = self.source.position
         assert_allclose(position.ra.deg, 83.637199, atol=1e-3)
         assert_allclose(position.dec.deg, 22.024099, atol=1e-3)
 
     @pytest.mark.parametrize("ref", SOURCES_3FGL, ids=lambda _: _["name"])
     def test_str(self, ref):
         actual = str(self.cat[ref["idx"]])
-        expected = open(get_pkg_data_filename(ref["str_ref_file"])).read()
-        assert actual == expected
+
+        with open(get_pkg_data_filename(ref["str_ref_file"])) as fh:
+            expected = fh.read()
+
+        assert actual == modify_unit_order_astropy_5_3(expected)
 
     @pytest.mark.parametrize("ref", SOURCES_3FGL, ids=lambda _: _["name"])
     def test_spectral_model(self, ref):
         model = self.cat[ref["idx"]].spectral_model()
 
         dnde, dnde_err = model.evaluate_error(1 * u.GeV)
 
@@ -479,16 +486,19 @@
         position = self.source.position
         assert_allclose(position.ra.deg, 83.634102, atol=1e-3)
         assert_allclose(position.dec.deg, 22.0215, atol=1e-3)
 
     @pytest.mark.parametrize("ref", SOURCES_2FHL, ids=lambda _: _["name"])
     def test_str(self, ref):
         actual = str(self.cat[ref["idx"]])
-        expected = open(get_pkg_data_filename(ref["str_ref_file"])).read()
-        assert actual == expected
+
+        with open(get_pkg_data_filename(ref["str_ref_file"])) as fh:
+            expected = fh.read()
+
+        assert actual == modify_unit_order_astropy_5_3(expected)
 
     def test_spectral_model(self):
         model = self.source.spectral_model()
         energy = u.Quantity(100, "GeV")
         desired = u.Quantity(6.8700477298e-12, "cm-2 GeV-1 s-1")
         assert_quantity_allclose(model(energy), desired)
 
@@ -563,16 +573,19 @@
         assert self.source.row_index == 352
 
     def test_data(self):
         assert_allclose(self.source.data["Signif_Avg"], 168.64082)
 
     def test_str(self):
         actual = str(self.cat["3FHL J2301.9+5855e"])  # an extended source
-        expected = open(get_pkg_data_filename("data/3fhl_j2301.9+5855e.txt")).read()
-        assert actual == expected
+
+        with open(get_pkg_data_filename("data/3fhl_j2301.9+5855e.txt")) as fh:
+            expected = fh.read()
+
+        assert actual == modify_unit_order_astropy_5_3(expected)
 
     def test_position(self):
         position = self.source.position
         assert_allclose(position.ra.deg, 83.634834, atol=1e-3)
         assert_allclose(position.dec.deg, 22.019203, atol=1e-3)
 
     @pytest.mark.parametrize("ref", SOURCES_3FHL, ids=lambda _: _["name"])
```

### Comparing `gammapy-1.0rc2/gammapy/catalog/tests/test_gammacat.py` & `gammapy-1.1rc1/gammapy/catalog/tests/test_gammacat.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,15 +1,19 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import pytest
 from numpy.testing import assert_allclose
 from astropy import units as u
 from astropy.utils.data import get_pkg_data_filename
 from gammapy.catalog import SourceCatalogGammaCat
 from gammapy.utils.gauss import Gauss2DPDF
-from gammapy.utils.testing import assert_quantity_allclose, requires_data
+from gammapy.utils.testing import (
+    assert_quantity_allclose,
+    modify_unit_order_astropy_5_3,
+    requires_data,
+)
 
 SOURCES = [
     {
         "name": "Vela X",
         "str_ref_file": "data/gammacat_vela_x.txt",
         "spec_type": "ecpl",
         "dnde_1TeV": 1.36e-11 * u.Unit("cm-2 s-1 TeV-1"),
@@ -85,16 +89,19 @@
         assert isinstance(source.data, dict)
         assert source.data["common_name"] == "CTA 1"
         assert_quantity_allclose(source.data["dec"], 72.782997 * u.deg)
 
     @pytest.mark.parametrize("ref", SOURCES, ids=lambda _: _["name"])
     def test_str(self, gammacat, ref):
         actual = str(gammacat[ref["name"]])
-        expected = open(get_pkg_data_filename(ref["str_ref_file"])).read()
-        assert actual == expected
+
+        with open(get_pkg_data_filename(ref["str_ref_file"])) as fh:
+            expected = fh.read()
+
+        assert actual == modify_unit_order_astropy_5_3(expected)
 
     @pytest.mark.parametrize("ref", SOURCES, ids=lambda _: _["name"])
     def test_spectral_model(self, gammacat, ref):
         source = gammacat[ref["name"]]
         spectral_model = source.spectral_model()
 
         assert source.data["spec_type"] == ref["spec_type"]
```

### Comparing `gammapy-1.0rc2/gammapy/catalog/tests/test_hawc.py` & `gammapy-1.1rc1/gammapy/catalog/tests/test_hawc.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/catalog/tests/test_hess.py` & `gammapy-1.1rc1/gammapy/catalog/tests/test_hess.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,15 +8,19 @@
 from astropy.utils.data import get_pkg_data_filename
 from gammapy.catalog import SourceCatalogHGPS, SourceCatalogLargeScaleHGPS
 from gammapy.modeling.models import (
     ExpCutoffPowerLawSpectralModel,
     PowerLawSpectralModel,
 )
 from gammapy.utils.gauss import Gauss2DPDF
-from gammapy.utils.testing import assert_quantity_allclose, requires_data
+from gammapy.utils.testing import (
+    assert_quantity_allclose,
+    modify_unit_order_astropy_5_3,
+    requires_data,
+)
 
 SOURCES = [
     {"idx": 33, "name": "HESS J1713-397", "str_ref_file": "data/hess_j1713-397.txt"},
     {"idx": 54, "name": "HESS J1825-137", "str_ref_file": "data/hess_j1825-137.txt"},
     {"idx": 76, "name": "HESS J1930+188", "str_ref_file": "data/hess_j1930+188.txt"},
 ]
 
@@ -95,16 +99,19 @@
         assert "Source name          : HESS J1843-033" in ss
         assert "Component HGPSC 083:" in ss
 
     @staticmethod
     @pytest.mark.parametrize("ref", SOURCES)
     def test_str(cat, ref):
         actual = str(cat[ref["idx"]])
-        expected = open(get_pkg_data_filename(ref["str_ref_file"])).read()
-        assert actual == expected
+
+        with open(get_pkg_data_filename(ref["str_ref_file"])) as fh:
+            expected = fh.read()
+
+        assert actual == modify_unit_order_astropy_5_3(expected)
 
     @staticmethod
     def test_position(source):
         position = source.position
         assert_allclose(position.ra.deg, 280.95162964)
         assert_allclose(position.dec.deg, -3.55410194)
 
@@ -300,32 +307,32 @@
         assert_allclose(p["lat_0"].value, -0.0727819949388504)
         assert_allclose(p["lat_0"].error, 0.06880396604537964)
         assert_allclose(p["sigma"].value, 0.2294706553220749)
         assert_allclose(p["sigma"].error, 0.04618723690509796)
 
 
 class TestSourceCatalogLargeScaleHGPS:
-    def setup(self):
+    @pytest.fixture(scope="class")
+    def model(self):
         table = Table()
         table["GLON"] = [-30, -10, 10, 20] * u.deg
         table["Surface_Brightness"] = [0, 1, 10, 0] * u.Unit("cm-2 s-1 sr-1")
         table["GLAT"] = [-1, 0, 1, 0] * u.deg
         table["Width"] = [0.4, 0.5, 0.3, 1.0] * u.deg
-        self.table = table
-        self.model = SourceCatalogLargeScaleHGPS(table)
+        return SourceCatalogLargeScaleHGPS(table)
 
-    def test_evaluate(self):
+    def test_evaluate(self, model):
         x = np.linspace(-100, 20, 5)
         y = np.linspace(-2, 2, 7)
         x, y = np.meshgrid(x, y)
         coords = SkyCoord(x, y, unit="deg", frame="galactic")
-        image = self.model.evaluate(coords)
+        image = model.evaluate(coords)
         desired = 1.223962643740966 * u.Unit("cm-2 s-1 sr-1")
         assert_quantity_allclose(image.sum(), desired)
 
-    def test_parvals(self):
+    def test_parvals(self, model):
         glon = Angle(10, unit="deg")
         assert_quantity_allclose(
-            self.model.peak_brightness(glon), 10 * u.Unit("cm-2 s-1 sr-1")
+            model.peak_brightness(glon), 10 * u.Unit("cm-2 s-1 sr-1")
         )
-        assert_quantity_allclose(self.model.peak_latitude(glon), 1 * u.deg)
-        assert_quantity_allclose(self.model.width(glon), 0.3 * u.deg)
+        assert_quantity_allclose(model.peak_latitude(glon), 1 * u.deg)
+        assert_quantity_allclose(model.width(glon), 0.3 * u.deg)
```

### Comparing `gammapy-1.0rc2/gammapy/conftest.py` & `gammapy-1.1rc1/gammapy/conftest.py`

 * *Files 2% similar despite different names*

```diff
@@ -36,14 +36,15 @@
     PYTEST_HEADER_MODULES["matplotlib"] = "matplotlib"
     PYTEST_HEADER_MODULES["astropy"] = "astropy"
     PYTEST_HEADER_MODULES["regions"] = "regions"
     PYTEST_HEADER_MODULES["healpy"] = "healpy"
     PYTEST_HEADER_MODULES["sherpa"] = "sherpa"
     PYTEST_HEADER_MODULES["gammapy"] = "gammapy"
     PYTEST_HEADER_MODULES["naima"] = "naima"
+    PYTEST_HEADER_MODULES["ray"] = "ray"
 
     print("")
     print("Gammapy test data availability:")
 
     has_it = "yes" if has_data("gammapy-data") else "no"
     print(f"gammapy-data ... {has_it}")
```

### Comparing `gammapy-1.0rc2/gammapy/data/__init__.py` & `gammapy-1.1rc1/gammapy/data/__init__.py`

 * *Files 17% similar despite different names*

```diff
@@ -4,22 +4,23 @@
 from .event_list import EventList
 from .filters import ObservationFilter
 from .gti import GTI
 from .hdu_index_table import HDUIndexTable
 from .obs_table import ObservationTable
 from .observations import Observation, Observations
 from .observers import observatory_locations
-from .pointing import FixedPointingInfo, PointingInfo
+from .pointing import FixedPointingInfo, PointingInfo, PointingMode
 
 __all__ = [
     "DataStore",
     "EventList",
     "FixedPointingInfo",
     "GTI",
     "HDUIndexTable",
     "Observation",
     "ObservationFilter",
     "Observations",
     "ObservationTable",
     "observatory_locations",
     "PointingInfo",
+    "PointingMode",
 ]
```

### Comparing `gammapy-1.0rc2/gammapy/data/data_store.py` & `gammapy-1.1rc1/gammapy/data/data_store.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,25 +1,27 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import logging
 import subprocess
+from copy import copy
 from pathlib import Path
 import numpy as np
 from astropy import units as u
 from astropy.coordinates import SkyCoord
 from astropy.io import fits
+import gammapy.utils.time as tu
 from gammapy.utils.scripts import make_path
 from gammapy.utils.testing import Checker
 from .hdu_index_table import HDUIndexTable
 from .obs_table import ObservationTable, ObservationTableChecker
 from .observations import Observation, ObservationChecker, Observations
 
 __all__ = ["DataStore"]
 
 ALL_IRFS = ["aeff", "edisp", "psf", "bkg", "rad_max"]
-ALL_HDUS = ["events", "gti"] + ALL_IRFS
+ALL_HDUS = ["events", "gti", "pointing"] + ALL_IRFS
 REQUIRED_IRFS = {
     "full-enclosure": {"aeff", "edisp", "psf", "bkg"},
     "point-like": {"aeff", "edisp"},
     "all-optional": {},
 }
 
 
@@ -254,15 +256,15 @@
             s += "No observation index table."
 
         if show:
             print(s)
         else:
             return s
 
-    def obs(self, obs_id, required_irf="full-enclosure"):
+    def obs(self, obs_id, required_irf="full-enclosure", require_events=True):
         """Access a given `~gammapy.data.Observation`.
 
         Parameters
         ----------
         obs_id : int
             Observation ID.
         required_irf : list of str or str
@@ -276,14 +278,16 @@
             * `"psf"` : Point Spread Function
             * `"rad_max"` : Maximal radius
 
             Alternatively single string can be used as shortcut:
 
             * `"full-enclosure"` : includes `["events", "gti", "aeff", "edisp", "psf", "bkg"]`
             * `"point-like"` : includes `["events", "gti", "aeff", "edisp"]`
+        require_events : bool
+            Require events and gti table or not.
 
         Returns
         -------
         observation : `~gammapy.data.Observation`
             Observation container
 
         """
@@ -298,15 +302,18 @@
 
         if not set(required_irf).issubset(ALL_IRFS):
             difference = set(required_irf).difference(ALL_IRFS)
             raise ValueError(
                 f"{difference} is not a valid hdu key. Choose from: {ALL_IRFS}"
             )
 
-        required_hdus = {"event", "gti"}.union(required_irf)
+        if require_events:
+            required_hdus = {"events", "gti"}.union(required_irf)
+        else:
+            required_hdus = required_irf
 
         missing_hdus = []
         for hdu in ALL_HDUS:
             hdu_location = self.hdu_table.hdu_location(
                 obs_id=obs_id,
                 hdu_type=hdu,
                 warn_missing=False,
@@ -317,18 +324,29 @@
                 missing_hdus.append(hdu)
 
         if len(missing_hdus) > 0:
             raise MissingRequiredHDU(
                 f"Required HDUs {missing_hdus} not found in observation {obs_id}"
             )
 
+        # TODO: right now, gammapy doesn't support using the pointing table of GADF
+        # so we always pass the events location here to be read into a FixedPointingInfo
+        if "events" in kwargs:
+            pointing_location = copy(kwargs["events"])
+            pointing_location.hdu_class = "pointing"
+            kwargs["pointing"] = pointing_location
+
         return Observation(**kwargs)
 
     def get_observations(
-        self, obs_id=None, skip_missing=False, required_irf="full-enclosure"
+        self,
+        obs_id=None,
+        skip_missing=False,
+        required_irf="full-enclosure",
+        require_events=True,
     ):
         """Generate a `~gammapy.data.Observations`.
 
         Parameters
         ----------
         obs_id : list
             Observation IDs (default of ``None`` means "all")
@@ -352,28 +370,31 @@
             Alternatively single string can be used as shortcut:
 
             * `"full-enclosure"` : includes `["events", "gti", "aeff", "edisp", "psf", "bkg"]`
             * `"point-like"` : includes `["events", "gti", "aeff", "edisp"]`
             * `"all-optional"` : no HDUs are required, only warnings will be emitted
               for missing HDUs among all possibilities.
 
+        require_events : bool
+            Require events and gti table or not.
+
         Returns
         -------
         observations : `~gammapy.data.Observations`
             Container holding a list of `~gammapy.data.Observation`
         """
 
         if obs_id is None:
             obs_id = self.obs_ids
 
         obs_list = []
 
         for _ in obs_id:
             try:
-                obs = self.obs(_, required_irf)
+                obs = self.obs(_, required_irf, require_events)
             except ValueError as err:
                 if skip_missing:
                     log.warning(f"Skipping missing obs_id: {_!r}")
                     continue
                 else:
                     raise err
             except MissingRequiredHDU as e:
@@ -604,35 +625,40 @@
         if irf_path is not None:
             info["IRF_FILENAME"] = str(irf_path)
         elif info["CALDB"] != na_str and info["IRF"] != na_str:
             caldb_irf = CalDBIRF.from_meta(info)
             info["IRF_FILENAME"] = str(caldb_irf.file_path)
         else:
             info["IRF_FILENAME"] = info["EVENTS_FILENAME"]
+
+        # Mandatory fields defining the time data
+        for name in tu.TIME_KEYWORDS:
+            info[name] = header.get(name, None)
+
         return info
 
     def make_obs_table(self):
         rows = []
+        time_rows = []
         for events_path, irf_path in zip(self.events_paths, self.irfs_paths):
             row = self.get_obs_info(events_path, irf_path)
             rows.append(row)
+            time_row = tu.extract_time_info(row)
+            time_rows.append(time_row)
 
         names = list(rows[0].keys())
         table = ObservationTable(rows=rows, names=names)
 
-        # TODO: Values copied from one of the EVENTS headers
-        # TODO: check consistency for all EVENTS files and handle inconsistent case
-        # Transform times to first ref time? Or raise error for now?
-        # Test by combining some HESS & CTA runs?
         m = table.meta
-        m["MJDREFI"] = 51544
-        m["MJDREFF"] = 5.0000000000e-01
-        m["TIMEUNIT"] = "s"
-        m["TIMESYS"] = "TT"
-        m["TIMEREF"] = "LOCAL"
+        if not tu.unique_time_info(time_rows):
+            raise RuntimeError(
+                "The time information in the EVENT header are not consistent between observations"
+            )
+        for name in tu.TIME_KEYWORDS:
+            m[name] = time_rows[0][name]
 
         m["HDUCLASS"] = "GADF"
         m["HDUDOC"] = "https://github.com/open-gamma-ray-astro/gamma-astro-data-formats"
         m["HDUVERS"] = "0.2"
         m["HDUCLAS1"] = "INDEX"
         m["HDUCLAS2"] = "OBS"
```

### Comparing `gammapy-1.0rc2/gammapy/data/event_list.py` & `gammapy-1.1rc1/gammapy/data/event_list.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,14 +8,15 @@
 from astropy.coordinates.angle_utilities import angular_separation
 from astropy.io import fits
 from astropy.table import Table
 from astropy.table import vstack as vstack_tables
 from astropy.visualization import quantity_support
 import matplotlib.pyplot as plt
 from gammapy.maps import MapAxis, MapCoord, RegionGeom, WcsNDMap
+from gammapy.maps.axes import UNIT_STRING_FORMAT
 from gammapy.utils.fits import earth_location_from_dict
 from gammapy.utils.scripts import make_path
 from gammapy.utils.testing import Checker
 from gammapy.utils.time import time_ref_from_dict
 from .gti import GTI
 
 __all__ = ["EventList"]
@@ -471,29 +472,31 @@
         """
         ax = plt.gca() if ax is None else ax
 
         # Note the events are not necessarily in time order
         time = self.table["TIME"]
         time = time - np.min(time)
 
-        ax.set_xlabel("Time (sec)")
+        ax.set_xlabel(f"Time [{u.s.to_string(UNIT_STRING_FORMAT)}]")
         ax.set_ylabel("Counts")
         y, x_edges = np.histogram(time, bins=20)
 
         xerr = np.diff(x_edges) / 2
         x = x_edges[:-1] + xerr
         yerr = np.sqrt(y)
 
         kwargs.setdefault("fmt", "none")
 
         ax.errorbar(x=x, y=y, xerr=xerr, yerr=yerr, **kwargs)
 
         return ax
 
-    def plot_offset2_distribution(self, ax=None, center=None, **kwargs):
+    def plot_offset2_distribution(
+        self, ax=None, center=None, max_percentile=98, **kwargs
+    ):
         """Plot offset^2 distribution of the events.
 
         The distribution shown in this plot is for this quantity::
 
             offset = center.separation(events.radec).deg
             offset2 = offset ** 2
 
@@ -509,14 +512,16 @@
         Parameters
         ----------
         ax : `~matplotlib.axes.Axes` (optional)
             Axes
         center : `astropy.coordinates.SkyCoord`
             Center position for the offset^2 distribution.
             Default is the observation pointing position.
+        max_percentile : float
+            Define the percentile of the offset^2 distribution used to define the maximum offset^2 value.
         **kwargs :
             Extra keyword arguments are passed to `~matplotlib.pyplot.hist`.
 
         Returns
         -------
         ax : `~matplotlib.axes.Axes`
             Axes
@@ -548,22 +553,24 @@
         """
         ax = plt.gca() if ax is None else ax
 
         if center is None:
             center = self._plot_center
 
         offset2 = center.separation(self.radec) ** 2
+        max2 = np.percentile(offset2, q=max_percentile)
 
         kwargs.setdefault("histtype", "step")
         kwargs.setdefault("bins", 30)
+        kwargs.setdefault("range", (0.0, max2.value))
 
         with quantity_support():
             ax.hist(offset2, **kwargs)
 
-        ax.set_xlabel(f"Offset^2 ({ax.xaxis.units})")
+        ax.set_xlabel(rf"Offset$^2$ [{ax.xaxis.units.to_string(UNIT_STRING_FORMAT)}]")
         ax.set_ylabel("Counts")
         return ax
 
     def plot_energy_offset(self, ax=None, center=None, **kwargs):
         """Plot counts histogram with energy and offset axes
 
         Parameters
```

### Comparing `gammapy-1.0rc2/gammapy/data/filters.py` & `gammapy-1.1rc1/gammapy/data/filters.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/data/gti.py` & `gammapy-1.1rc1/gammapy/data/gti.py`

 * *Files 10% similar despite different names*

```diff
@@ -3,19 +3,15 @@
 from operator import le, lt
 import numpy as np
 import astropy.units as u
 from astropy.io import fits
 from astropy.table import Table, vstack
 from astropy.time import Time
 from gammapy.utils.scripts import make_path
-from gammapy.utils.time import (
-    time_ref_from_dict,
-    time_ref_to_dict,
-    time_relative_to_ref,
-)
+from gammapy.utils.time import TIME_REF_DEFAULT, time_ref_from_dict, time_ref_to_dict
 
 __all__ = ["GTI"]
 
 
 class GTI:
     """Good time intervals (GTI) `~astropy.table.Table`.
 
@@ -25,14 +21,18 @@
     EVENTS header ... the GTI header just deals with
     observation times.
 
     Parameters
     ----------
     table : `~astropy.table.Table`
         GTI table
+    reference_time : `~astropy.time.Time`
+        the reference time
+        If None, use TIME_REF_DEFAULT.
+        Default is None
 
     Examples
     --------
     Load GTIs for a H.E.S.S. event list:
 
     >>> from gammapy.data import GTI
     >>> gti = GTI.read('$GAMMAPY_DATA/hess-dl3-dr1//data/hess_dl3_dr1_obs_id_023523.fits.gz')
@@ -54,61 +54,114 @@
     - Duration: 183139597.9032163 s
     - Start: 239557417.49417615 s MET
     - Start: 2008-08-04T15:44:41.678 (time standard: TT)
     - Stop: 460250000.0 s MET
     - Stop: 2015-08-02T23:14:24.184 (time standard: TT)
     """
 
-    def __init__(self, table):
-        self.table = table
+    def __init__(self, table, reference_time=None):
+        self.table = self._validate_table(table)
+
+        if reference_time is None:
+            reference_time = TIME_REF_DEFAULT
+        self._time_ref = Time(reference_time)
+
+    @staticmethod
+    def _validate_table(table):
+        """Checks that the input GTI fits the gammapy internal model."""
+        if not isinstance(table, Table):
+            raise TypeError("GTI table is not an astropy Table.")
+
+        colnames = ["START", "STOP"]
+
+        if not set(colnames).issubset(table.colnames):
+            raise ValueError("GTI table not correctly defined.")
+
+        if len(table) == 0:
+            return table
+
+        for name in colnames:
+            if not isinstance(table[name], Time):
+                raise TypeError(f"Column {name} is not a Time object.")
+
+        return table
 
     def copy(self):
         return copy.deepcopy(self)
 
     @classmethod
-    def create(cls, start, stop, reference_time="2000-01-01"):
+    def create(cls, start, stop, reference_time=None):
         """Creates a GTI table from start and stop times.
 
         Parameters
         ----------
         start : `~astropy.time.Time` or `~astropy.units.Quantity`
             Start times, if a quantity then w.r.t. reference time
         stop : `~astropy.time.Time` or `~astropy.units.Quantity`
             Stop times, if a quantity then w.r.t. reference time
         reference_time : `~astropy.time.Time`
-            the reference time to use in GTI definition
+            the reference time to use in GTI definition.
+            If None, use TIME_REF_DEFAULT.
+            Default is None
         """
+        if reference_time is None:
+            reference_time = TIME_REF_DEFAULT
         reference_time = Time(reference_time)
+        reference_time.format = "mjd"
 
-        if isinstance(start, Time):
-            start = (start - reference_time).to(u.s)
+        if not isinstance(start, Time):
+            start = reference_time + u.Quantity(start)
 
-        if isinstance(stop, Time):
-            stop = (stop - reference_time).to(u.s)
+        if not isinstance(stop, Time):
+            stop = reference_time + u.Quantity(stop)
 
-        start = u.Quantity(start, ndmin=1)
-        stop = u.Quantity(stop, ndmin=1)
-        meta = time_ref_to_dict(reference_time)
-        table = Table({"START": start.to("s"), "STOP": stop.to("s")}, meta=meta)
-        return cls(table)
+        table = Table({"START": np.atleast_1d(start), "STOP": np.atleast_1d(stop)})
+
+        return cls(table, reference_time=reference_time)
 
     @classmethod
-    def read(cls, filename, hdu="GTI"):
+    def read(cls, filename, hdu="GTI", format="gadf"):
         """Read from FITS file.
 
         Parameters
         ----------
         filename : `pathlib.Path`, str
             Filename
         hdu : str
             hdu name. Default GTI.
+        format: str
+            Input format, currently only "gadf" is supported
         """
         filename = make_path(filename)
-        table = Table.read(filename, hdu=hdu)
-        return cls(table)
+        with fits.open(str(make_path(filename)), memmap=False) as hdulist:
+            return cls.from_table_hdu(hdulist[hdu], format=format)
+
+    @classmethod
+    def from_table_hdu(cls, table_hdu, format="gadf"):
+        """Read from table HDU.
+
+        Parameters
+        ----------
+        table_hdu : `~astropy.io.fits.BinTableHDU`
+            table hdu
+        format: str
+            Input format, currently only "gadf" is supported
+        """
+        if format != "gadf":
+            raise ValueError(f'Only the "gadf" format supported, got {format}')
+
+        table = Table.read(table_hdu)
+        time_ref = time_ref_from_dict(table.meta, format="mjd", scale="tt")
+
+        # Check if TIMEUNIT keyword is present, otherwise assume seconds
+        unit = table.meta.pop("TIMEUNIT", "s")
+        start = u.Quantity(table["START"], unit)
+        stop = u.Quantity(table["STOP"], unit)
+
+        return cls.create(start, stop, time_ref)
 
     def to_table_hdu(self, format="gadf"):
         """
         Convert this GTI instance to a `astropy.io.fits.BinTableHDU`.
 
         Parameters
         ----------
@@ -119,31 +172,37 @@
         -------
         hdu: `astropy.io.fits.BinTableHDU`
             GTI table converted to FITS representation
         """
         if format != "gadf":
             raise ValueError(f'Only the "gadf" format supported, got {format}')
 
-        return fits.BinTableHDU(self.table, name="GTI")
+        # Don't impose the scale. GADF does not require it to be TT
+        meta = time_ref_to_dict(self.time_ref, scale=self.time_ref.scale)
+        start = self.time_start - self.time_ref
+        stop = self.time_stop - self.time_ref
+        table = Table({"START": start.to("s"), "STOP": stop.to("s")}, meta=meta)
+
+        return fits.BinTableHDU(table, name="GTI")
 
     def write(self, filename, **kwargs):
         """Write to file.
 
         Parameters
         ----------
         filename : str or `Path`
             File name to write to.
         """
         hdu = self.to_table_hdu()
         hdulist = fits.HDUList([fits.PrimaryHDU(), hdu])
         hdulist.writeto(make_path(filename), **kwargs)
 
     def __str__(self):
-        t_start_met = u.Quantity(self.table["START"][0].astype("float64"), "second")
-        t_stop_met = u.Quantity(self.table["STOP"][-1].astype("float64"), "second")
+        t_start_met = self.met_start[0]
+        t_stop_met = self.met_stop[-1]
         t_start = self.time_start[0].fits
         t_stop = self.time_stop[-1].fits
         return (
             "GTI info:\n"
             f"- Number of GTIs: {len(self.table)}\n"
             f"- Duration: {self.time_sum}\n"
             f"- Start: {t_start_met} MET\n"
@@ -151,124 +210,128 @@
             f"- Stop: {t_stop_met} MET\n"
             f"- Stop: {t_stop} (time standard: {self.time_stop[-1].scale.upper()})\n"
         )
 
     @property
     def time_delta(self):
         """GTI durations in seconds (`~astropy.units.Quantity`)."""
-        start = self.table["START"].astype("float64")
-        stop = self.table["STOP"].astype("float64")
-        return u.Quantity(stop - start, "second")
+        delta = self.time_stop - self.time_start
+        return delta.to("s")
 
     @property
     def time_ref(self):
         """Time reference (`~astropy.time.Time`)."""
-        return time_ref_from_dict(self.table.meta)
+        return self._time_ref
 
     @property
     def time_sum(self):
         """Sum of GTIs in seconds (`~astropy.units.Quantity`)."""
         return self.time_delta.sum()
 
     @property
     def time_start(self):
         """GTI start times (`~astropy.time.Time`)."""
-        met = u.Quantity(self.table["START"].astype("float64"), "second")
-        return self.time_ref + met
+        return self.table["START"]
 
     @property
     def time_stop(self):
         """GTI end times (`~astropy.time.Time`)."""
-        met = u.Quantity(self.table["STOP"].astype("float64"), "second")
-        return self.time_ref + met
+        return self.table["STOP"]
+
+    @property
+    def met_start(self):
+        """GTI start time difference with reference time in sec, MET (`~astropy.units.Quantity`)."""
+        return (self.time_start - self.time_ref).to("s")
+
+    @property
+    def met_stop(self):
+        """GTI start time difference with reference time in sec, MET (`~astropy.units.Quantity`)."""
+        return (self.time_stop - self.time_ref).to("s")
 
     @property
     def time_intervals(self):
         """List of time intervals"""
         return [
             (t_start, t_stop)
             for t_start, t_stop in zip(self.time_start, self.time_stop)
         ]
 
     @classmethod
-    def from_time_intervals(cls, time_intervals, reference_time="2000-01-01"):
+    def from_time_intervals(cls, time_intervals, reference_time=None):
         """From list of time intervals
 
         Parameters
         ----------
         time_intervals : list of `~astropy.time.Time` objects
             Time intervals
         reference_time : `~astropy.time.Time`
-            Reference time to use in GTI definition
+            Reference time to use in GTI definition. Default is None.
+            If None, use TIME_REF_DEFAULT.
 
         Returns
         -------
         gti : `GTI`
             GTI table.
         """
-        reference_time = Time(reference_time)
-        start = Time([_[0] for _ in time_intervals]) - reference_time
-        stop = Time([_[1] for _ in time_intervals]) - reference_time
-        meta = time_ref_to_dict(reference_time)
-        table = Table({"START": start.to("s"), "STOP": stop.to("s")}, meta=meta)
-        return cls(table=table)
+        start = Time([_[0] for _ in time_intervals])
+        stop = Time([_[1] for _ in time_intervals])
+
+        if reference_time is None:
+            reference_time = TIME_REF_DEFAULT
+
+        return cls.create(start, stop, reference_time)
 
     def select_time(self, time_interval):
         """Select and crop GTIs in time interval.
 
         Parameters
         ----------
         time_interval : `astropy.time.Time`
             Start and stop time for the selection.
 
         Returns
         -------
         gti : `GTI`
             Copy of the GTI table with selection applied.
         """
+        interval_start, interval_stop = time_interval
+        interval_start.format = self.time_start.format
+        interval_stop.format = self.time_stop.format
+
         # get GTIs that fall within the time_interval
-        mask = self.time_start < time_interval[1]
-        mask &= self.time_stop > time_interval[0]
+        mask = self.time_start < interval_stop
+        mask &= self.time_stop > interval_start
         gti_within = self.table[mask]
 
         # crop the GTIs
-        start_met = time_relative_to_ref(time_interval[0], self.table.meta)
-        stop_met = time_relative_to_ref(time_interval[1], self.table.meta)
-        np.clip(
-            gti_within["START"],
-            start_met.value,
-            stop_met.value,
-            out=gti_within["START"],
-        )
-        np.clip(
-            gti_within["STOP"], start_met.value, stop_met.value, out=gti_within["STOP"]
+        gti_within["START"] = np.clip(
+            gti_within["START"], interval_start, interval_stop
         )
 
+        gti_within["STOP"] = np.clip(gti_within["STOP"], interval_start, interval_stop)
+
         return self.__class__(gti_within)
 
     def stack(self, other):
         """Stack with another GTI in place.
 
         This simply changes the time reference of the second GTI table
         and stack the two tables. No logic is applied to the intervals.
 
         Parameters
         ----------
         other : `~gammapy.data.GTI`
             GTI to stack to self
 
         """
-        start = (other.time_start - self.time_ref).sec
-        end = (other.time_stop - self.time_ref).sec
-        table = Table({"START": start, "STOP": end}, names=["START", "STOP"])
-        self.table = vstack([self.table, table])
+        self.table = self._validate_table(vstack([self.table, other.table]))
 
     @classmethod
     def from_stack(cls, gtis, **kwargs):
-        """Stack (concatenate) list of event lists.
+        """Stack (concatenate) list of GTIs.
 
         Calls `~astropy.table.vstack`.
 
         Parameters
         ----------
         gtis : list of `GTI`
             List of good time intervals to stack
@@ -315,15 +378,15 @@
             else:
                 if not overlap_ok:
                     raise ValueError("Overlapping time bins")
 
                 merged[-1]["STOP"] = max(interval["STOP"], merged[-1]["STOP"])
 
         merged = Table(rows=merged, names=["START", "STOP"], meta=self.table.meta)
-        return self.__class__(merged)
+        return self.__class__(merged, reference_time=self.time_ref)
 
     def group_table(self, time_intervals, atol="1e-6 s"):
         """Compute the table with the info on the group to which belong each time interval.
 
         The t_start and t_stop are stored in MJD from a scale in "utc".
 
         Parameters
```

### Comparing `gammapy-1.0rc2/gammapy/data/hdu_index_table.py` & `gammapy-1.1rc1/gammapy/data/hdu_index_table.py`

 * *Files 8% similar despite different names*

```diff
@@ -13,28 +13,38 @@
 
 class HDUIndexTable(Table):
     """HDU index table.
 
     See :ref:`gadf:hdu-index`.
     """
 
-    VALID_HDU_TYPE = ["events", "gti", "aeff", "edisp", "psf", "bkg", "rad_max"]
+    VALID_HDU_TYPE = [
+        "events",
+        "gti",
+        "aeff",
+        "edisp",
+        "psf",
+        "bkg",
+        "rad_max",
+        "pointing",
+    ]
     """Valid values for `HDU_TYPE`."""
 
     VALID_HDU_CLASS = [
         "events",
         "gti",
         "aeff_2d",
         "edisp_2d",
         "psf_table",
         "psf_3gauss",
         "psf_king",
         "bkg_2d",
         "bkg_3d",
         "rad_max_2d",
+        "pointing",
     ]
     """Valid values for `HDU_CLASS`."""
 
     @classmethod
     def read(cls, filename, **kwargs):
         """Read :ref:`gadf:hdu-index`.
```

### Comparing `gammapy-1.0rc2/gammapy/data/obs_table.py` & `gammapy-1.1rc1/gammapy/data/obs_table.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/data/observations.py` & `gammapy-1.1rc1/gammapy/data/observations.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,22 +1,24 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import collections.abc
 import copy
 import inspect
 import logging
+import warnings
 from itertools import zip_longest
 import numpy as np
 import astropy.units as u
 from astropy.coordinates import SkyCoord
 from astropy.io import fits
 from astropy.time import Time
 from astropy.units import Quantity
 from astropy.utils import lazyproperty
 import matplotlib.pyplot as plt
 from gammapy import __version__
+from gammapy.utils.deprecation import GammapyDeprecationWarning, deprecated
 from gammapy.utils.fits import LazyFitsData, earth_location_to_dict
 from gammapy.utils.scripts import make_path
 from gammapy.utils.testing import Checker
 from gammapy.utils.time import time_ref_to_dict, time_relative_to_ref
 from .event_list import EventList, EventListChecker
 from .filters import ObservationFilter
 from .gti import GTI
@@ -58,37 +60,42 @@
     aeff = LazyFitsData(cache=False)
     edisp = LazyFitsData(cache=False)
     psf = LazyFitsData(cache=False)
     bkg = LazyFitsData(cache=False)
     _rad_max = LazyFitsData(cache=False)
     _events = LazyFitsData(cache=False)
     _gti = LazyFitsData(cache=False)
+    _pointing = LazyFitsData(cache=True)
 
     def __init__(
         self,
         obs_id=None,
         obs_info=None,
         gti=None,
         aeff=None,
         edisp=None,
         psf=None,
         bkg=None,
         rad_max=None,
         events=None,
         obs_filter=None,
+        pointing=None,
+        location=None,
     ):
         self.obs_id = obs_id
         self._obs_info = obs_info
         self.aeff = aeff
         self.edisp = edisp
         self.psf = psf
         self.bkg = bkg
         self._rad_max = rad_max
         self._gti = gti
         self._events = events
+        self._pointing = pointing
+        self._location = location
         self.obs_filter = obs_filter or ObservationFilter()
 
     @property
     def rad_max(self):
         # prevent circular import
         from gammapy.irf import RadMax2D
 
@@ -138,18 +145,20 @@
 
     @staticmethod
     def _get_obs_info(
         pointing, deadtime_fraction, time_start, time_stop, reference_time, location
     ):
         """Create obs info dict from in memory data"""
         obs_info = {
-            "RA_PNT": pointing.icrs.ra.deg,
-            "DEC_PNT": pointing.icrs.dec.deg,
             "DEADC": 1 - deadtime_fraction,
         }
+        if isinstance(pointing, SkyCoord):
+            obs_info["RA_PNT"] = pointing.icrs.ra.deg
+            obs_info["DEC_PNT"] = pointing.icrs.dec.deg
+
         obs_info.update(time_ref_to_dict(reference_time))
         obs_info["TSTART"] = time_relative_to_ref(time_start, obs_info).to_value(u.s)
         obs_info["TSTOP"] = time_relative_to_ref(time_stop, obs_info).to_value(u.s)
 
         if location is not None:
             obs_info.update(earth_location_to_dict(location))
 
@@ -170,16 +179,16 @@
     ):
         """Create an observation.
 
         User must either provide the livetime, or the start and stop times.
 
         Parameters
         ----------
-        pointing : `~astropy.coordinates.SkyCoord`
-            Pointing position
+        pointing : `~gammapy.data.FixedPointingInfo` or `~astropy.coordinates.SkyCoord`
+            Pointing information
         obs_id : int
             Observation ID as identifier
         livetime : ~astropy.units.Quantity`
             Livetime exposure of the simulated observation
         tstart: `~astropy.time.Time` or `~astropy.units.Quantity`
             Start time of observation as `~astropy.time.Time` or duration
             relative to `reference_time`
@@ -200,46 +209,59 @@
         if tstart is None:
             tstart = reference_time.copy()
 
         if tstop is None:
             tstop = tstart + Quantity(livetime)
 
         gti = GTI.create(tstart, tstop, reference_time=reference_time)
-
         obs_info = cls._get_obs_info(
             pointing=pointing,
             deadtime_fraction=deadtime_fraction,
             time_start=gti.time_start[0],
             time_stop=gti.time_stop[0],
             reference_time=reference_time,
             location=location,
         )
 
+        if not isinstance(pointing, FixedPointingInfo):
+            warnings.warn(
+                "Pointing will be required to be provided as FixedPointingInfo",
+                GammapyDeprecationWarning,
+            )
+            pointing = FixedPointingInfo.from_fits_header(obs_info)
+
         return cls(
             obs_id=obs_id,
             obs_info=obs_info,
             gti=gti,
             aeff=irfs.get("aeff"),
             bkg=irfs.get("bkg"),
             edisp=irfs.get("edisp"),
             psf=irfs.get("psf"),
             rad_max=irfs.get("rad_max"),
+            pointing=pointing,
+            location=location,
         )
 
     @property
     def tstart(self):
         """Observation start time (`~astropy.time.Time`)."""
         return self.gti.time_start[0]
 
     @property
     def tstop(self):
         """Observation stop time (`~astropy.time.Time`)."""
         return self.gti.time_stop[0]
 
     @property
+    def tmid(self):
+        """Midpoint between start and stop time"""
+        return self.tstart + 0.5 * (self.tstop - self.tstart)
+
+    @property
     def observation_time_duration(self):
         """Observation time duration in seconds (`~astropy.units.Quantity`).
 
         The wall time, including dead-time.
         """
         return self.gti.time_sum
 
@@ -282,37 +304,64 @@
                     k: v
                     for k, v in self.events.table.meta.items()
                     if not k.startswith("HDU")
                 }
             )
         return meta
 
+    @property
+    def pointing(self):
+        if self._pointing is None:
+            self._pointing = FixedPointingInfo.from_fits_header(self.obs_info)
+        return self._pointing
+
+    def get_pointing_altaz(self, time):
+        """Get the pointing in altaz for given time"""
+        return self.pointing.get_altaz(time, self.observatory_earth_location)
+
+    def get_pointing_icrs(self, time):
+        """Get the pointing in icrs for given time"""
+        return self.pointing.get_icrs(time, self.observatory_earth_location)
+
     @lazyproperty
+    @deprecated(
+        "v1.1",
+        message="Use observation.pointing or observation.get_pointing_{{altaz,icrs}} instead",
+    )
     def fixed_pointing_info(self):
         """Fixed pointing info for this observation (`FixedPointingInfo`)."""
-        return FixedPointingInfo(self.obs_info)
+        return self._pointing
 
     @property
+    @deprecated("v1.1", message="Use observation.get_pointing_icrs(time) instead")
     def pointing_radec(self):
         """Pointing RA / DEC sky coordinates (`~astropy.coordinates.SkyCoord`)."""
         return self.fixed_pointing_info.radec
 
     @property
+    @deprecated("v1.1", message="Use observation.get_pointing_altaz(time) instead")
     def pointing_altaz(self):
         return self.fixed_pointing_info.altaz
 
     @property
+    @deprecated("v1.1", message="Use observation.get_pointing_altaz(time).zen instead")
     def pointing_zen(self):
         """Pointing zenith angle sky (`~astropy.units.Quantity`)."""
-        return self.fixed_pointing_info.altaz.zen
+        return self.get_pointing_altaz(self.tmid).zen
 
     @property
     def observatory_earth_location(self):
         """Observatory location (`~astropy.coordinates.EarthLocation`)."""
-        return self.fixed_pointing_info.location
+        if self._location is not None:
+            return self._location
+
+        # for now we catch the deprecation warning until we store location on the observation properly
+        with warnings.catch_warnings():
+            warnings.simplefilter("ignore", category=GammapyDeprecationWarning)
+            return self.fixed_pointing_info.location
 
     @lazyproperty
     def target_radec(self):
         """Target RA / DEC sky coordinates (`~astropy.coordinates.SkyCoord`)."""
         lon, lat = (
             self.obs_info.get("RA_OBJ", np.nan),
             self.obs_info.get("DEC_OBJ", np.nan),
@@ -321,16 +370,17 @@
 
     @property
     def muoneff(self):
         """Observation muon efficiency."""
         return self.obs_info.get("MUONEFF", 1)
 
     def __str__(self):
-        ra = self.pointing_radec.ra.deg
-        dec = self.pointing_radec.dec.deg
+        pointing = self.get_pointing_icrs(self.tmid)
+        ra = pointing.ra.deg
+        dec = pointing.dec.deg
 
         pointing = f"{ra:.1f} deg, {dec:.1f} deg\n"
         # TODO: Which target was observed?
         # TODO: print info about available HDUs for this observation ...
         return (
             f"{self.__class__.__name__}\n\n"
             f"\tobs id            : {self.obs_id} \n "
@@ -456,14 +506,15 @@
 
         obs_info = events.table.meta
         return cls(
             events=events,
             gti=gti,
             obs_info=obs_info,
             obs_id=obs_info.get("OBS_ID"),
+            pointing=FixedPointingInfo.from_fits_header(obs_info),
             **irf_dict,
         )
 
     def write(self, path, overwrite=False, format="gadf", include_irfs=True):
         """
         Write this observation into `path` using the specified format
 
@@ -487,15 +538,17 @@
         primary.header["CREATOR"] = f"Gammapy {__version__}"
         primary.header["DATE"] = Time.now().iso
 
         hdul = fits.HDUList([primary])
 
         events = self.events
         if events is not None:
-            hdul.append(events.to_table_hdu(format=format))
+            events_hdu = events.to_table_hdu(format=format)
+            events_hdu.header.update(self.pointing.to_fits_header())
+            hdul.append(events_hdu)
 
         gti = self.gti
         if gti is not None:
             hdul.append(gti.to_table_hdu(format=format))
 
         if include_irfs:
             for irf_name in self.available_irfs:
@@ -538,15 +591,19 @@
             Copied observation
         """
         if in_memory:
             argnames = inspect.getfullargspec(self.__init__).args
             argnames.remove("self")
 
             for name in argnames:
-                value = getattr(self, name)
+                if name == "location":
+                    attr = "observatory_earth_location"
+                else:
+                    attr = name
+                value = getattr(self, attr)
                 kwargs.setdefault(name, copy.deepcopy(value))
             return self.__class__(**kwargs)
 
         if kwargs:
             raise ValueError("Overwriting arguments requires to set 'in_memory=True'")
 
         return copy.deepcopy(self)
@@ -631,14 +688,35 @@
                     new_obs_list.append(new_obs)
 
         return self.__class__(new_obs_list)
 
     def _ipython_key_completions_(self):
         return self.ids
 
+    def group_by_label(self, labels):
+        """Split obsevations in multiple groups of observations
+
+        Parameters
+        ----------
+        labels : array
+            Array of group labels
+
+        Returns
+        -------
+        obs_clusters : dict of `~gammapy.data.Observations`
+            dict of Observations instance, one instance for each group.
+        """
+        obs_groups = {}
+        for label in np.unique(labels):
+            observations = self.__class__(
+                [obs for k, obs in enumerate(self) if labels[k] == label]
+            )
+            obs_groups[f"group_{label}"] = observations
+        return obs_groups
+
 
 class ObservationChecker(Checker):
     """Check an observation.
 
     Checks data format and a bit about the content.
     """
```

### Comparing `gammapy-1.0rc2/gammapy/data/observers.py` & `gammapy-1.1rc1/gammapy/data/observers.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/data/pointing.py` & `gammapy-1.1rc1/gammapy/maps/geom.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,499 +1,642 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
+import abc
+import copy
+import inspect
 import logging
-from enum import Enum, auto
 import numpy as np
-import scipy.interpolate
-import astropy.units as u
-from astropy.coordinates import (
-    AltAz,
-    CartesianRepresentation,
-    SkyCoord,
-    UnitSphericalRepresentation,
-)
-from astropy.table import Table
-from astropy.units import Quantity
-from astropy.utils import lazyproperty
-from gammapy.utils.fits import earth_location_from_dict
-from gammapy.utils.scripts import make_path
-from gammapy.utils.time import time_ref_from_dict
+from astropy import units as u
+from astropy.io import fits
+from .io import find_bands_hdu, find_hdu
+from .utils import INVALID_INDEX
+
+__all__ = ["Geom"]
 
 log = logging.getLogger(__name__)
 
-__all__ = ["FixedPointingInfo", "PointingInfo", "PointingMode"]
 
+def get_shape(param):
+    if param is None:
+        return tuple()
 
-class PointingMode(Enum):
-    """
-    Describes the behavior of the pointing during the observation.
+    if not isinstance(param, tuple):
+        param = [param]
 
-    See :ref:`gadf:obs-mode`.
+    return max([np.array(p, ndmin=1).shape for p in param])
 
-    For ground-based instruments, the most common options will be:
-    * POINTING: The telescope observes a fixed position in the ICRS frame
-    * DRIFT: The telescope observes a fixed position in the AltAz frame
-
-    Gammapy only supports fixed pointing positions over the whole observation
-    (either in equatorial or horizontal coordinates).
-    OGIP also defines RASTER, SLEW and SCAN. These cannot be treated using
-    a fixed pointing position in either frame, so they would require the
-    pointing table, which is at the moment not supported by gammapy.
-
-    Data releases based on gadf v0.2 do not have consistent OBS_MODE keyword
-    e.g. the H.E.S.S. data releases uses the not-defined value "WOBBLE".
-    For all gadf data, we assume OBS_MODE to be the same as "POINTING",
-    unless it is set to "DRIFT", making the assumption that one observation
-    only contains a single fixed position.
-    """
 
-    POINTING = auto()
-    DRIFT = auto()
+def pix_tuple_to_idx(pix):
+    """Convert a tuple of pixel coordinate arrays to a tuple of pixel indices.
 
-    @staticmethod
-    def from_gadf_string(val):
-        # OBS_MODE is not well-defined and not mandatory in GADF 0.2
-        # We always assume that the observations are pointing observations
-        # unless the OBS_MODE is set to DRIFT
-        if val.upper() == "DRIFT":
-            return PointingMode.DRIFT
-        else:
-            return PointingMode.POINTING
+    Pixel coordinates are rounded to the closest integer value.
 
+    Parameters
+    ----------
+    pix : tuple
+        Tuple of pixel coordinates with one element for each dimension
 
-class FixedPointingInfo:
-    """IACT array pointing info.
+    Returns
+    -------
+    idx : `~numpy.ndarray`
+        Array of pixel indices
+    """
+    idx = []
+    for p in pix:
+        p = np.array(p, ndmin=1)
+        if np.issubdtype(p.dtype, np.integer):
+            idx += [p]
+        else:
+            with np.errstate(invalid="ignore"):
+                p_idx = np.rint(p).astype(int)
+            p_idx[~np.isfinite(p)] = INVALID_INDEX.int
+            idx += [p_idx]
 
-    Data format specification: :ref:`gadf:iact-pnt`
+    return tuple(idx)
 
-    Parameters
-    ----------
-    meta : `~astropy.table.Table.meta`
-        Meta header info from Table on pointing
 
-    Examples
-    --------
-    >>> from gammapy.data import PointingInfo
-    >>> path = '$GAMMAPY_DATA/tests/pointing_table.fits.gz'
-    >>> pointing_info = PointingInfo.read(path)
-    >>> print(pointing_info)
-    Pointing info:
-    <BLANKLINE>
-    Location:     GeodeticLocation(lon=<Longitude 16.50022222 deg>, lat=<Latitude -23.27177778 deg>, height=<Quantity 1835. m>)  # noqa: E501
-    MJDREFI, MJDREFF, TIMESYS = (51910, 0.000742870370370241, 'TT')
-    Time ref:     2001-01-01T00:01:04.184
-    Time ref:     51910.00074287037 MJD (TT)
-    Duration:     1586.0000000000018 sec = 0.44055555555555603 hours
-    Table length: 100
-    <BLANKLINE>
-    START:
-    Time:  2004-01-21T19:50:02.184
-    Time:  53025.826414166666 MJD (TT)
-    RADEC: 83.6333 24.5144 deg
-    ALTAZ: 11.4575 41.3409 deg
-    <BLANKLINE>
-    <BLANKLINE>
-    END:
-    Time:  2004-01-21T20:16:28.184
-    Time:  53025.844770648146 MJD (TT)
-    RADEC: 83.6333 24.5144 deg
-    ALTAZ: 3.44573 42.1319 deg
-    <BLANKLINE>
-    <BLANKLINE>
-
-    Note: In order to reproduce the example you need the tests datasets folder.
-    You may download it with the command
-    ``gammapy download datasets --tests --out $GAMMAPY_DATA``
+class Geom(abc.ABC):
+    """Map geometry base class.
+
+    See also: `~gammapy.maps.WcsGeom` and `~gammapy.maps.HpxGeom`
     """
 
-    def __init__(self, meta):
-        self.meta = meta
+    # workaround for the lru_cache pickle issue
+    # see e.g. https://github.com/cloudpipe/cloudpickle/issues/178
+    def __getstate__(self):
+        state = self.__dict__.copy()
+        for key, value in state.items():
+            func = getattr(value, "__wrapped__", None)
+            if func is not None:
+                state[key] = func
+        return state
+
+    @property
+    @abc.abstractmethod
+    def data_shape(self):
+        """Shape of the Numpy data array matching this geometry."""
+        pass
+
+    def data_nbytes(self, dtype="float32"):
+        """Estimate memory usage in megabytes of the Numpy data array
+        matching this geometry depending on the given type.
+
+        Parameters
+        ----------
+        dtype : data-type
+            The desired data-type for the array. Default is "float32"
+
+        Returns
+        -------
+        memory : `~astropy.units.Quantity`
+            Estimated memory usage in megabytes (MB)
+        """
+        return (np.empty(self.data_shape, dtype).nbytes * u.byte).to("MB")
+
+    @property
+    @abc.abstractmethod
+    def is_allsky(self):
+        pass
+
+    @property
+    @abc.abstractmethod
+    def center_coord(self):
+        pass
+
+    @property
+    @abc.abstractmethod
+    def center_pix(self):
+        pass
+
+    @property
+    @abc.abstractmethod
+    def center_skydir(self):
+        pass
 
     @classmethod
-    def read(cls, filename, hdu="EVENTS"):
-        """Read pointing information table from file to obtain the metadata.
+    def from_hdulist(cls, hdulist, hdu=None, hdu_bands=None):
+        """Load a geometry object from a FITS HDUList.
 
         Parameters
         ----------
-        filename : str
-            File name
-        hdu : int or str
-            HDU number or name
+        hdulist :  `~astropy.io.fits.HDUList`
+            HDU list containing HDUs for map data and bands.
+        hdu : str
+            Name or index of the HDU with the map data.
+        hdu_bands : str
+            Name or index of the HDU with the BANDS table.  If not
+            defined this will be inferred from the FITS header of the
+            map HDU.
 
         Returns
         -------
-        pointing_info : `PointingInfo`
-            Pointing info object
+        geom : `~Geom`
+            Geometry object.
         """
-        filename = make_path(filename)
-        table = Table.read(filename, hdu=hdu)
-        return cls(meta=table.meta)
+        if hdu is None:
+            hdu = find_hdu(hdulist)
+        else:
+            hdu = hdulist[hdu]
 
-    @lazyproperty
-    def mode(self):
-        """See `PointingMode`, if not present, assume POINTING"""
-        obs_mode = self.meta.get("OBS_MODE")
-        if obs_mode is None:
-            return PointingMode.POINTING
-        return PointingMode.from_gadf_string(obs_mode)
+        if hdu_bands is None:
+            hdu_bands = find_bands_hdu(hdulist, hdu)
 
-    @lazyproperty
-    def location(self):
-        """Observatory location (`~astropy.coordinates.EarthLocation`)."""
-        return earth_location_from_dict(self.meta)
+        if hdu_bands is not None:
+            hdu_bands = hdulist[hdu_bands]
 
-    @lazyproperty
-    def time_ref(self):
-        """Time reference (`~astropy.time.Time`)."""
-        return time_ref_from_dict(self.meta)
+        return cls.from_header(hdu.header, hdu_bands)
+
+    def to_bands_hdu(self, hdu_bands=None, format="gadf"):
+        table_hdu = self.axes.to_table_hdu(format=format, hdu_bands=hdu_bands)
+        cols = table_hdu.columns.columns
+        cols.extend(self._make_bands_cols())
+        return fits.BinTableHDU.from_columns(
+            cols, header=table_hdu.header, name=table_hdu.name
+        )
 
-    @lazyproperty
-    def time_start(self):
-        """Start time (`~astropy.time.Time`)."""
-        t_start = Quantity(self.meta["TSTART"], "second")
-        return self.time_ref + t_start
+    @abc.abstractmethod
+    def _make_bands_cols(self):
+        pass
+
+    @abc.abstractmethod
+    def get_idx(self, idx=None, local=False, flat=False):
+        """Get tuple of pixel indices for this geometry.
+
+        Returns all pixels in the geometry by default. Pixel indices
+        for a single image plane can be accessed by setting ``idx``
+        to the index tuple of a plane.
 
-    @lazyproperty
-    def time_stop(self):
-        """Stop time (`~astropy.time.Time`)."""
-        t_stop = Quantity(self.meta["TSTOP"], "second")
-        return self.time_ref + t_stop
+        Parameters
+        ----------
+        idx : tuple, optional
+            A tuple of indices with one index for each non-spatial
+            dimension.  If defined only pixels for the image plane with
+            this index will be returned.  If none then all pixels
+            will be returned.
+        local : bool
+            Flag to return local or global pixel indices.  Local
+            indices run from 0 to the number of pixels in a given
+            image plane.
+        flat : bool, optional
+            Return a flattened array containing only indices for
+            pixels contained in the geometry.
 
-    @lazyproperty
-    def obstime(self):
-        """Average observation time for the observation (`~astropy.time.Time`)."""
-        return self.time_start + self.duration / 2
+        Returns
+        -------
+        idx : tuple
+            Tuple of pixel index vectors with one vector for each
+            dimension.
+        """
+        pass
+
+    @abc.abstractmethod
+    def get_coord(self, idx=None, flat=False):
+        """Get the coordinate array for this geometry.
+
+        Returns a coordinate array with the same shape as the data
+        array.  Pixels outside the geometry are set to NaN.
+        Coordinates for a single image plane can be accessed by
+        setting ``idx`` to the index tuple of a plane.
 
-    @lazyproperty
-    def duration(self):
-        """Pointing duration (`~astropy.time.TimeDelta`).
+        Parameters
+        ----------
+        idx : tuple, optional
+            A tuple of indices with one index for each non-spatial
+            dimension.  If defined only coordinates for the image
+            plane with this index will be returned.  If none then
+            coordinates for all pixels will be returned.
+        flat : bool, optional
+            Return a flattened array containing only coordinates for
+            pixels contained in the geometry.
+
+        Returns
+        -------
+        coords : tuple
+            Tuple of coordinate vectors with one vector for each
+            dimension.
+        """
+        pass
+
+    @abc.abstractmethod
+    def coord_to_pix(self, coords):
+        """Convert map coordinates to pixel coordinates.
 
-        The time difference between the TSTART and TSTOP.
+        Parameters
+        ----------
+        coords : tuple
+            Coordinate values in each dimension of the map.  This can
+            either be a tuple of numpy arrays or a MapCoord object.
+            If passed as a tuple then the ordering should be
+            (longitude, latitude, c_0, ..., c_N) where c_i is the
+            coordinate vector for axis i.
+
+        Returns
+        -------
+        pix : tuple
+            Tuple of pixel coordinates in image and band dimensions.
         """
-        return self.time_stop - self.time_start
+        pass
+
+    def coord_to_idx(self, coords, clip=False):
+        """Convert map coordinates to pixel indices.
+
+        Parameters
+        ----------
+        coords : tuple or `~MapCoord`
+            Coordinate values in each dimension of the map.  This can
+            either be a tuple of numpy arrays or a MapCoord object.
+            If passed as a tuple then the ordering should be
+            (longitude, latitude, c_0, ..., c_N) where c_i is the
+            coordinate vector for axis i.
+        clip : bool
+            Choose whether to clip indices to the valid range of the
+            geometry.  If false then indices for coordinates outside
+            the geometry range will be set -1.
 
-    @lazyproperty
-    def radec(self):
+        Returns
+        -------
+        pix : tuple
+            Tuple of pixel indices in image and band dimensions.
+            Elements set to -1 correspond to coordinates outside the
+            map.
+        """
+        pix = self.coord_to_pix(coords)
+        return self.pix_to_idx(pix, clip=clip)
+
+    @abc.abstractmethod
+    def pix_to_coord(self, pix):
+        """Convert pixel coordinates to map coordinates.
+
+        Parameters
+        ----------
+        pix : tuple
+            Tuple of pixel coordinates.
+
+        Returns
+        -------
+        coords : tuple
+            Tuple of map coordinates.
         """
-        RA/DEC pointing position from table (`~astropy.coordinates.SkyCoord`).
+        pass
+
+    @abc.abstractmethod
+    def pix_to_idx(self, pix, clip=False):
+        """Convert pixel coordinates to pixel indices.
+
+        Returns -1 for pixel coordinates that lie outside of the map.
+
+        Parameters
+        ----------
+        pix : tuple
+            Tuple of pixel coordinates.
+        clip : bool
+            Choose whether to clip indices to the valid range of the
+            geometry.  If false then indices for coordinates outside
+            the geometry range will be set -1.
 
-        Use `get_icrs` to get the pointing at a specific time, correctly
-        handling different pointing modes.
+        Returns
+        -------
+        idx : tuple
+            Tuple of pixel indices.
         """
-        ra = self.meta["RA_PNT"]
-        dec = self.meta["DEC_PNT"]
-        return SkyCoord(ra, dec, unit="deg", frame="icrs")
+        pass
 
-    @lazyproperty
-    def altaz_frame(self):
-        """ALT / AZ frame (`~astropy.coordinates.AltAz`)."""
-        return AltAz(obstime=self.obstime, location=self.location)
+    @abc.abstractmethod
+    def contains(self, coords):
+        """Check if a given map coordinate is contained in the geometry.
 
-    @lazyproperty
-    def altaz(self):
+        Parameters
+        ----------
+        coords : tuple or `~gammapy.maps.MapCoord`
+            Tuple of map coordinates.
+
+        Returns
+        -------
+        containment : `~numpy.ndarray`
+            Bool array.
         """
-        ALT/AZ pointing position computed from RA/DEC (`~astropy.coordinates.SkyCoord`)
-        for the midpoint of the run.
+        pass
+
+    def contains_pix(self, pix):
+        """Check if a given pixel coordinate is contained in the geometry.
 
-        Use `get_altaz` to get the pointing at a specific time, correctly
-        handling different pointing modes.
+        Parameters
+        ----------
+        pix : tuple
+            Tuple of pixel coordinates.
+
+        Returns
+        -------
+        containment : `~numpy.ndarray`
+            Bool array.
         """
-        try:
-            frame = self.altaz_frame
-        except KeyError:
-            log.warn(
-                "Location or time information missing,"
-                " using ALT_PNT/AZ_PNT and incomplete frame"
-            )
-            return SkyCoord(
-                alt=self.meta.get("ALT_PNT", np.nan),
-                az=self.meta.get("AZ_PNT", np.nan),
-                unit=u.deg,
-                frame=AltAz(),
-            )
+        idx = self.pix_to_idx(pix)
+        return np.all(np.stack([t != INVALID_INDEX.int for t in idx]), axis=0)
 
-        return self.radec.transform_to(frame)
+    def slice_by_idx(self, slices):
+        """Create a new geometry by slicing the non-spatial axes.
 
-    @lazyproperty
-    def fixed_altaz(self):
-        """The fixed coordinates in AltAz of the observation.
+        Parameters
+        ----------
+        slices : dict
+            Dict of axes names and integers or `slice` object pairs. Contains one
+            element for each non-spatial dimension. For integer indexing the
+            corresponding axes is dropped from the map. Axes not specified in the
+            dict are kept unchanged.
 
-        None if not a DRIFT observation
+        Returns
+        -------
+        geom : `~Geom`
+            Sliced geometry.
         """
-        if self.mode != PointingMode.DRIFT:
-            return None
+        axes = self.axes.slice_by_idx(slices)
+        return self._init_copy(axes=axes)
 
-        alt = u.Quantity(self.meta["ALT_PNT"], u.deg)
-        az = u.Quantity(self.meta["AZ_PNT"], u.deg)
-        return SkyCoord(alt=alt, az=az, frame=self.altaz_frame)
+    def rename_axes(self, names, new_names):
+        """Rename axes contained in the geometry
 
-    @lazyproperty
-    def fixed_icrs(self):
+        Parameters
+        ----------
+        names : list or str
+            Names of the axes.
+        new_names : list or str
+            New names of the axes (list must be of same length than `names`).
+
+        Returns
+        -------
+        geom : `~Geom`
+            Renamed geometry.
         """
-        The fixed coordinates in ICRS of the observation.
+        axes = self.axes.rename_axes(names=names, new_names=new_names)
+        return self._init_copy(axes=axes)
+
+    @property
+    def as_energy_true(self):
+        """If the geom contains an energy axis rename it to energy true"""
+        return self.rename_axes(names="energy", new_names="energy_true")
+
+    @property
+    def has_energy_axis(self):
+        """Whether geom has an energy axis"""
+        return ("energy" in self.axes.names) ^ ("energy_true" in self.axes.names)
+
+    @abc.abstractmethod
+    def to_image(self):
+        """Create 2D image geometry (drop non-spatial dimensions).
 
-        None if not a POINTING observation
+        Returns
+        -------
+        geom : `~Geom`
+            Image geometry.
         """
-        if self.mode != PointingMode.POINTING:
-            return None
+        pass
 
-        return self.radec
+    @abc.abstractmethod
+    def to_cube(self, axes):
+        """Append non-spatial axes to create a higher-dimensional geometry.
+
+        This will result in a new geometry with
+        N+M dimensions where N is the number of current dimensions and
+        M is the number of axes in the list.
 
-    def get_icrs(self, obstime):
+        Parameters
+        ----------
+        axes : list
+            Axes that will be appended to this geometry.
+
+        Returns
+        -------
+        geom : `~Geom`
+            Map geometry.
         """
-        Get the pointing position in ICRS frame for a given time.
+        pass
+
+    def squash(self, axis_name):
+        """Squash geom axis.
 
-        If the observation was performed tracking a fixed position in ICRS,
-        the icrs pointing is returned with the given obstime attached.
+        Parameters
+        ----------
+        axis_name : str
+            Axis to squash.
 
-        If the observation was performed in drift mode, the fixed altaz coordinates
-        are transformed to ICRS using the observation location and the given time.
+        Returns
+        -------
+        geom : `Geom`
+            Geom with squashed axis.
+        """
+        axes = self.axes.squash(axis_name=axis_name)
+        return self.to_image().to_cube(axes=axes)
 
+    def drop(self, axis_name):
+        """Drop an axis from the geom.
 
         Parameters
         ----------
-        obstime: `astropy.time.Time`
-            Time for which to get the pointing position in ICRS frame
+        axis_name : str
+            Name of the axis to remove.
+
+        Returns
+            -------
+        geom : `Geom`
+            New geom with the axis removed.
         """
-        if self.mode == PointingMode.POINTING:
-            icrs = self.fixed_icrs
-            return SkyCoord(ra=icrs.ra, dec=icrs.dec, obstime=obstime, frame="icrs")
+        axes = self.axes.drop(axis_name=axis_name)
+        return self.to_image().to_cube(axes=axes)
 
-        if self.mode == PointingMode.DRIFT:
-            return self.get_altaz(obstime).icrs
+    def pad(self, pad_width, axis_name):
+        """
+        Pad the geometry at the edges.
 
-        raise ValueError(f"Unsupported pointing mode: {self.mode}.")
+        Parameters
+        ----------
+        pad_width : {sequence, array_like, int}
+            Number of values padded to the edges of each axis.
+        axis_name : str
+            Name of the axis to pad.
 
-    def get_altaz(self, obstime):
+        Returns
+        -------
+        geom : `~Geom`
+            Padded geometry.
         """
-        Get the pointing position in AltAz frame for a given time.
+        if axis_name is None:
+            return self._pad_spatial(pad_width)
+        else:
+            axes = self.axes.pad(axis_name=axis_name, pad_width=pad_width)
+            return self.to_image().to_cube(axes)
 
-        If the observation was performed tracking a fixed position in ICRS,
-        the icrs pointing is transformed at the given time using the location
-        of the observation.
+    @abc.abstractmethod
+    def _pad_spatial(self, pad_width):
+        pass
 
-        If the observation was performed in drift mode,
-        the fixed altaz coordinate is returned with `obstime` attached.
+    @abc.abstractmethod
+    def crop(self, crop_width):
+        """
+        Crop the geometry at the edges.
 
         Parameters
         ----------
-        obstime: `astropy.time.Time`
-            Time for which to get the pointing position in AltAz frame
+        crop_width : {sequence, array_like, int}
+            Number of values cropped from the edges of each axis.
+
+        Returns
+        -------
+        geom : `~Geom`
+            Cropped geometry.
         """
-        frame = AltAz(location=self.location, obstime=obstime)
+        pass
 
-        if self.mode == PointingMode.POINTING:
-            return self.fixed_icrs.transform_to(frame)
+    @abc.abstractmethod
+    def downsample(self, factor, axis_name):
+        """Downsample the spatial dimension of the geometry by a given factor.
 
-        if self.mode == PointingMode.DRIFT:
-            # see https://github.com/astropy/astropy/issues/12965
-            return SkyCoord(
-                alt=np.full(obstime.shape, self.fixed_altaz.alt.deg) * u.deg,
-                az=np.full(obstime.shape, self.fixed_altaz.az.deg) * u.deg,
-                frame=frame,
-            )
+        Parameters
+        ----------
+        factor : int
+            Downsampling factor.
+        axis_name : str
+            Axis to downsample.
 
-        raise ValueError(f"Unsupported pointing mode: {self.mode}.")
+        Returns
+        -------
+        geom : `~Geom`
+            Downsampled geometry.
 
+        """
+        pass
 
-class PointingInfo:
-    """IACT array pointing info.
+    @abc.abstractmethod
+    def upsample(self, factor, axis_name=None):
+        """Upsample the spatial dimension of the geometry by a given factor.
 
-    Data format specification: :ref:`gadf:iact-pnt`
+        Parameters
+        ----------
+        factor : int
+            Upsampling factor.
+        axis_name : str
+            Axis to upsample.
 
-    Parameters
-    ----------
-    table : `~astropy.table.Table`
-        Table (with meta header info) on pointing
+        Returns
+        -------
+        geom : `~Geom`
+            Upsampled geometry.
 
-    Examples
-    --------
-    >>> from gammapy.data import PointingInfo
-    >>> pointing_info = PointingInfo.read('$GAMMAPY_DATA/tests/pointing_table.fits.gz')
-    >>> print(pointing_info)
-    Pointing info:
-    <BLANKLINE>
-    Location:     GeodeticLocation(lon=<Longitude 16.50022222 deg>, lat=<Latitude -23.27177778 deg>, height=<Quantity 1835. m>) # noqa: E501
-    MJDREFI, MJDREFF, TIMESYS = (51910, 0.000742870370370241, 'TT')
-    Time ref:     2001-01-01T00:01:04.184
-    Time ref:     51910.00074287037 MJD (TT)
-    Duration:     1586.0000000000018 sec = 0.44055555555555603 hours
-    Table length: 100
-    <BLANKLINE>
-    START:
-    Time:  2004-01-21T19:50:02.184
-    Time:  53025.826414166666 MJD (TT)
-    RADEC: 83.6333 24.5144 deg
-    ALTAZ: 11.4575 41.3409 deg
-    <BLANKLINE>
-    <BLANKLINE>
-    END:
-    Time:  2004-01-21T20:16:28.184
-    Time:  53025.844770648146 MJD (TT)
-    RADEC: 83.6333 24.5144 deg
-    ALTAZ: 3.44573 42.1319 deg
-    <BLANKLINE>
-    <BLANKLINE>
-
-    Note: In order to reproduce the example you need the tests datasets folder.
-    You may download it with the command
-    ``gammapy download datasets --tests --out $GAMMAPY_DATA``
-    """
+        """
+        pass
 
-    def __init__(self, table):
-        self.table = table
+    def resample_axis(self, axis):
+        """Resample geom to a new axis binning.
 
-    @classmethod
-    def read(cls, filename, hdu="POINTING"):
-        """Read `PointingInfo` table from file.
+        This method groups the existing bins into a new binning.
 
         Parameters
         ----------
-        filename : str
-            File name
-        hdu : int or str
-            HDU number or name
+        axis : `MapAxis`
+            New map axis.
 
         Returns
         -------
-        pointing_info : `PointingInfo`
-            Pointing info object
+        map : `Geom`
+            Geom with resampled axis.
         """
-        filename = make_path(filename)
-        table = Table.read(filename, hdu=hdu)
-        return cls(table=table)
+        axes = self.axes.resample(axis=axis)
+        return self._init_copy(axes=axes)
 
-    def __str__(self):
-        ss = "Pointing info:\n\n"
-        ss += f"Location:     {self.location.geodetic}\n"
-        m = self.table.meta
-        ss += "MJDREFI, MJDREFF, TIMESYS = {}\n".format(
-            (m["MJDREFI"], m["MJDREFF"], m["TIMESYS"])
-        )
-        ss += f"Time ref:     {self.time_ref.fits}\n"
-        ss += f"Time ref:     {self.time_ref.mjd} MJD (TT)\n"
-        sec = self.duration.to("second").value
-        hour = self.duration.to("hour").value
-        ss += f"Duration:     {sec} sec = {hour} hours\n"
-        ss += "Table length: {}\n".format(len(self.table))
-
-        ss += "\nSTART:\n" + self._str_for_index(0) + "\n"
-        ss += "\nEND:\n" + self._str_for_index(-1) + "\n"
-
-        return ss
-
-    def _str_for_index(self, idx):
-        """Information for one point in the pointing table."""
-        ss = "Time:  {}\n".format(self.time[idx].fits)
-        ss += "Time:  {} MJD (TT)\n".format(self.time[idx].mjd)
-        ss += "RADEC: {} deg\n".format(self.radec[idx].to_string())
-        ss += "ALTAZ: {} deg\n".format(self.altaz[idx].to_string())
-        return ss
-
-    @lazyproperty
-    def location(self):
-        """Observatory location (`~astropy.coordinates.EarthLocation`)."""
-        return earth_location_from_dict(self.table.meta)
-
-    @lazyproperty
-    def time_ref(self):
-        """Time reference (`~astropy.time.Time`)."""
-        return time_ref_from_dict(self.table.meta)
-
-    @lazyproperty
-    def duration(self):
-        """Pointing table duration (`~astropy.time.TimeDelta`).
-
-        The time difference between the first and last entry.
-        """
-        return self.time[-1] - self.time[0]
-
-    @lazyproperty
-    def time(self):
-        """Time array (`~astropy.time.Time`)."""
-        met = Quantity(self.table["TIME"].astype("float64"), "second")
-        time = self.time_ref + met
-        return time.tt
-
-    @lazyproperty
-    def radec(self):
-        """RA / DEC position from table (`~astropy.coordinates.SkyCoord`)."""
-        lon = self.table["RA_PNT"]
-        lat = self.table["DEC_PNT"]
-        return SkyCoord(lon, lat, unit="deg", frame="icrs")
-
-    @lazyproperty
-    def altaz_frame(self):
-        """ALT / AZ frame (`~astropy.coordinates.AltAz`)."""
-        return AltAz(obstime=self.time, location=self.location)
-
-    @lazyproperty
-    def altaz(self):
-        """ALT / AZ position computed from RA / DEC (`~astropy.coordinates.SkyCoord`)."""
-        return self.radec.transform_to(self.altaz_frame)
-
-    @lazyproperty
-    def altaz_from_table(self):
-        """ALT / AZ position from table (`~astropy.coordinates.SkyCoord`)."""
-        lon = self.table["AZ_PNT"]
-        lat = self.table["ALT_PNT"]
-        return SkyCoord(lon, lat, unit="deg", frame=self.altaz_frame)
-
-    @staticmethod
-    def _interpolate_cartesian(mjd_support, coord_support, mjd):
-        xyz = coord_support.cartesian
-        x_new = scipy.interpolate.interp1d(mjd_support, xyz.x)(mjd)
-        y_new = scipy.interpolate.interp1d(mjd_support, xyz.y)(mjd)
-        z_new = scipy.interpolate.interp1d(mjd_support, xyz.z)(mjd)
-        return CartesianRepresentation(x_new, y_new, z_new).represent_as(
-            UnitSphericalRepresentation
-        )
+    def replace_axis(self, axis):
+        """Replace axis with a new one.
 
-    def altaz_interpolate(self, time):
-        """Interpolate pointing for a given time."""
-        altaz_frame = AltAz(obstime=time, location=self.location)
-        return SkyCoord(
-            self._interpolate_cartesian(self.time.mjd, self.altaz, time.mjd),
-            frame=altaz_frame,
-        )
+        Parameters
+        ----------
+        axis : `MapAxis`
+            New map axis.
 
-    def get_icrs(self, obstime):
+        Returns
+        -------
+        map : `Geom`
+            Geom with replaced axis.
         """
-        Get the pointing position in ICRS frame for a given time.
+        axes = self.axes.replace(axis=axis)
+        return self._init_copy(axes=axes)
+
+    @abc.abstractmethod
+    def solid_angle(self):
+        """Solid angle (`~astropy.units.Quantity` in ``sr``)."""
+        pass
+
+    @property
+    def is_image(self):
+        """Whether the geom is an image without extra dimensions."""
+        if self.axes is None:
+            return True
+        return len(self.axes) == 0
+
+    @property
+    def is_flat(self):
+        """Whether the geom non spatial axes have length 1, equivalent to an image."""
+        if self.is_image:
+            return True
+        else:
+            valid = True
+            for axis in self.axes:
+                valid = valid and (axis.nbin == 1)
+            return valid
+
+    def _init_copy(self, **kwargs):
+        """Init map geom instance by copying missing init arguments from self."""
+        argnames = inspect.getfullargspec(self.__init__).args
+        argnames.remove("self")
+
+        for arg in argnames:
+            value = getattr(self, "_" + arg)
+            if arg not in kwargs:
+                kwargs[arg] = copy.deepcopy(value)
+
+        return self.__class__(**kwargs)
+
+    def copy(self, **kwargs):
+        """Copy and overwrite given attributes.
 
         Parameters
         ----------
-        obstime: `astropy.time.Time`
-            Time for which to get the pointing position in ICRS frame
-        """
-        return SkyCoord(
-            self._interpolate_cartesian(self.time.mjd, self.radec, obstime.mjd),
-            obstime=obstime,
-            frame="icrs",
-        )
+        **kwargs : dict
+            Keyword arguments to overwrite in the map geometry constructor.
 
-    def get_altaz(self, obstime):
+        Returns
+        -------
+        copy : `Geom`
+            Copied map geometry.
         """
-        Get the pointing position in AltAz frame for a given time.
+        return self._init_copy(**kwargs)
 
-        If the observation was performed tracking a fixed position in ICRS,
-        the icrs pointing is transformed at the given time using the location
-        of the observation.
+    def energy_mask(self, energy_min=None, energy_max=None, round_to_edge=False):
+        """Create a mask for a given energy range.
 
-        If the observation was performed in drift mode,
-        the fixed altaz coordinate is returned with `obstime` attached.
+        The energy bin must be fully contained to be included in the mask.
 
         Parameters
         ----------
-        obstime: `astropy.time.Time`
-            Time for which to get the pointing position in AltAz frame
+        energy_min, energy_max : `~astropy.units.Quantity`
+            Energy range
+
+        Returns
+        -------
+        mask : `~numpy.ndarray`
+            Energy mask
         """
-        # give precedence to ALT_PNT / AZ_PNT if present
-        if "ALT_PNT" in self.table and "AZ_PNT" in self.table:
-            altaz = self.altaz_from_table
-            frame = AltAz(obstime=obstime, location=self.location)
-            return SkyCoord(
-                self._interpolate_cartesian(self.time.mjd, altaz, obstime.mjd),
-                frame=frame,
-            )
+        from . import Map
+
+        # get energy axes and values
+        energy_axis = self.axes["energy"]
+
+        if round_to_edge:
+            energy_min, energy_max = energy_axis.round([energy_min, energy_max])
+
+        # TODO: make this more general
+        shape = (-1, 1) if self.is_hpx else (-1, 1, 1)
+        energy_edges = energy_axis.edges.reshape(shape)
+
+        # set default values
+        energy_min = energy_min if energy_min is not None else energy_edges[0]
+        energy_max = energy_max if energy_max is not None else energy_edges[-1]
 
-        # fallback to transformation from required ICRS if not
-        return self.altaz_interpolate(time=obstime)
+        mask = (energy_edges[:-1] >= energy_min) & (energy_edges[1:] <= energy_max)
+        data = np.broadcast_to(mask, shape=self.data_shape)
+        return Map.from_geom(geom=self, data=data, dtype=data.dtype)
```

### Comparing `gammapy-1.0rc2/gammapy/data/tests/test_data_store.py` & `gammapy-1.1rc1/gammapy/data/tests/test_data_store.py`

 * *Files 8% similar despite different names*

```diff
@@ -131,15 +131,15 @@
 
     substore = DataStore.from_dir(tmp_path)
     assert len(substore.hdu_table) == 2
 
 
 @requires_data()
 class TestDataStoreChecker:
-    def setup(self):
+    def setup_method(self):
         self.data_store = DataStore.from_dir("$GAMMAPY_DATA/cta-1dc/index/gps")
 
     def test_check_all(self):
         records = list(self.data_store.check())
         assert len(records) == 32
 
 
@@ -159,22 +159,27 @@
     # data_store_dc1 fixture is needed to set CALDB
     # Test that `DataStore.from_events_files` works.
     # The real tests for `DataStoreMaker` are below.
     path = "$GAMMAPY_DATA/cta-1dc/data/baseline/gps/gps_baseline_110380.fits"
     data_store = DataStore.from_events_files([path])
     assert len(data_store.obs_table) == 1
     assert len(data_store.hdu_table) == 6
+    assert data_store.obs_table.meta["MJDREFI"] == 51544
+
+    path2 = "$GAMMAPY_DATA/hess-dl3-dr1/data/hess_dl3_dr1_obs_id_025511.fits.gz"
+    with pytest.raises(RuntimeError):
+        _ = DataStore.from_events_files([path, path2])
 
 
 @requires_data()
 def test_data_store_maker_obs_table(data_store_dc1):
     table = data_store_dc1.obs_table
     assert table.__class__.__name__ == "ObservationTable"
     assert len(table) == 4
-    assert len(table.colnames) == 22
+    assert len(table.colnames) == 27
     assert table["CALDB"][0] == "1dc"
     assert table["IRF"][0] == "South_z20_50h"
 
     path = Path(table["IRF_FILENAME"][0])
     # checking str(path) would convert to windows path conventions on windows
     assert "$CALDB/data/cta/1dc/bcf/South_z20_50h/irf_file.fits" in repr(path)
 
@@ -304,7 +309,27 @@
     )
     assert len(obs) == 2
     assert obs[0].rad_max is not None
 
     obs = store.get_observations([5029747, 5029748], required_irf="point-like")
     assert len(obs) == 2
     assert obs[0].rad_max.quantity is not None
+
+
+@requires_data()
+def test_data_store_no_events():
+    """Check behavior of the "point-like" option for data_store"""
+
+    data_path = "$GAMMAPY_DATA/hawc/crab_events_pass4/"
+    hdu_filename = "hdu-index-table-GP-no-events.fits.gz"
+    obs_filename = "obs-index-table-GP-no-events.fits.gz"
+    data_store = DataStore.from_dir(
+        data_path, hdu_table_filename=hdu_filename, obs_table_filename=obs_filename
+    )
+
+    observations = data_store.get_observations(
+        required_irf=["aeff", "psf", "edisp"], require_events=False
+    )
+    assert len(observations) == 3
+    for obs in observations:
+        assert not obs.events
+        assert not obs.gti
```

### Comparing `gammapy-1.0rc2/gammapy/data/tests/test_event_list.py` & `gammapy-1.1rc1/gammapy/data/tests/test_event_list.py`

 * *Files 2% similar despite different names*

```diff
@@ -50,15 +50,16 @@
         self.events.write("test.fits", overwrite=True, gti=gti)
         read_again_ev = EventList.read("test.fits")
         read_again_gti = GTI.read("test.fits")
 
         assert self.events.table.meta == read_again_ev.table.meta
         assert (self.events.table == read_again_ev.table).all()
         assert gti.table.meta == read_again_gti.table.meta
-        assert (gti.table == read_again_gti.table).all()
+        assert_allclose(gti.table["START"].mjd, read_again_gti.table["START"].mjd)
+        assert_allclose(gti.table["STOP"].mjd, read_again_gti.table["STOP"].mjd)
 
         # test that it won't work if gti is not a GTI
         with pytest.raises(TypeError):
             self.events.write("test.fits", overwrite=True, gti=gti.table)
         # test that it won't work if format is not "gadf"
         with pytest.raises(ValueError):
             self.events.write("test.fits", overwrite=True, format="something")
```

### Comparing `gammapy-1.0rc2/gammapy/data/tests/test_filters.py` & `gammapy-1.1rc1/gammapy/data/tests/test_filters.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/data/tests/test_gti.py` & `gammapy-1.1rc1/gammapy/data/tests/test_gti.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,16 +1,55 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import pytest
 from numpy.testing import assert_allclose
 import astropy.units as u
-from astropy.table import Table
+from astropy.table import QTable, Table
 from astropy.time import Time
 from gammapy.data import GTI
 from gammapy.utils.testing import assert_time_allclose, requires_data
-from gammapy.utils.time import time_ref_to_dict
+
+
+def make_gti(mets, time_ref="2010-01-01"):
+    """Create GTI from a dict of MET (assumed to be in seconds) and a reference time."""
+    time_ref = Time(time_ref)
+    times = {name: time_ref + met for name, met in mets.items()}
+    table = Table(times)
+    return GTI(table, reference_time=time_ref)
+
+
+def test_gti_table_validation():
+    start = Time([53090.123451203704], format="mjd", scale="tt")
+    stop = Time([53090.14291879629], format="mjd", scale="tt")
+
+    table = QTable([start, stop], names=["START", "STOP"])
+    validated = GTI._validate_table(table)
+    assert validated == table
+
+    bad_table = QTable([start, stop], names=["bad", "STOP"])
+    with pytest.raises(ValueError):
+        GTI._validate_table(bad_table)
+
+    with pytest.raises(TypeError):
+        GTI._validate_table([start, stop])
+
+    bad_table = QTable([[1], [2]], names=["START", "STOP"])
+    with pytest.raises(TypeError):
+        GTI._validate_table(bad_table)
+
+
+def test_simple_gti():
+    time_ref = Time("2010-01-01")
+    gti = make_gti({"START": [0, 2] * u.s, "STOP": [1, 3] * u.s}, time_ref=time_ref)
+
+    assert_allclose(gti.time_start.mjd - time_ref.mjd, [0, 2.3148146e-5])
+    assert_allclose(
+        (gti.time_stop - time_ref).to_value("d"), [1.15740741e-05, 3.4722222e-05]
+    )
+    assert_allclose(gti.time_delta.to_value("s"), [1, 1])
+    assert_allclose(gti.time_sum.to_value("s"), 2.0)
 
 
 @requires_data()
 def test_gti_hess():
     gti = GTI.read("$GAMMAPY_DATA/hess-dl3-dr1/data/hess_dl3_dr1_obs_id_020136.fits.gz")
 
     str_gti = str(gti)
@@ -87,68 +126,68 @@
 
     if expected_length != 0:
         expected_times.format = "mjd"
         assert_time_allclose(gti_selected.time_start[0], expected_times[0])
         assert_time_allclose(gti_selected.time_stop[-1], expected_times[1])
 
 
-def make_gti(times, time_ref="2010-01-01"):
-    meta = time_ref_to_dict(time_ref)
-    table = Table(times, meta=meta)
-    return GTI(table)
-
-
 def test_gti_stack():
     time_ref = Time("2010-01-01")
-    gti1 = make_gti({"START": [0, 2], "STOP": [1, 3]}, time_ref=time_ref)
+    gti1 = make_gti({"START": [0, 2] * u.s, "STOP": [1, 3] * u.s}, time_ref=time_ref)
     gt1_pre_stack = gti1.copy()
-    gti2 = make_gti({"START": [4], "STOP": [5]}, time_ref=time_ref + 10 * u.s)
+    gti2 = make_gti(
+        {"START": [4] * u.s, "STOP": [5] * u.s}, time_ref=time_ref + 10 * u.s
+    )
 
     gti1.stack(gti2)
 
     assert len(gti1.table) == 3
     assert_time_allclose(gt1_pre_stack.time_ref, gti1.time_ref)
-    assert_allclose(gti1.table["START"], [0, 2, 14])
-    assert_allclose(gti1.table["STOP"], [1, 3, 15])
+
+    assert_allclose(gti1.met_start.value, [0, 2, 14])
+    assert_allclose(gti1.met_stop.value, [1, 3, 15])
 
 
 def test_gti_union():
-    gti = make_gti({"START": [5, 6, 1, 2], "STOP": [8, 7, 3, 4]})
+    gti = make_gti({"START": [5, 6, 1, 2] * u.s, "STOP": [8, 7, 3, 4] * u.s})
 
     gti = gti.union()
 
-    assert_allclose(gti.table["START"], [1, 5])
-    assert_allclose(gti.table["STOP"], [4, 8])
+    assert_allclose(gti.met_start.value, [1, 5])
+    assert_allclose(gti.met_stop.value, [4, 8])
 
 
 def test_gti_create():
     start = u.Quantity([1, 2], "min")
     stop = u.Quantity([1.5, 2.5], "min")
     time_ref = Time("2010-01-01 00:00:00.0")
 
     gti = GTI.create(start, stop, time_ref)
 
     assert len(gti.table) == 2
     assert_allclose(gti.time_ref.mjd, time_ref.tt.mjd)
-    assert_allclose(gti.table["START"], start.to_value("s"))
+    start_met = (gti.time_start - gti.time_ref).to_value("s")
+    assert_allclose(start_met, start.to_value("s"))
 
 
 def test_gti_write(tmp_path):
-    gti = make_gti({"START": [5, 6, 1, 2], "STOP": [8, 7, 3, 4]})
+    time_ref = Time("2010-01-01", scale="tt")
+    time_ref.format = "mjd"
+    gti = make_gti({"START": [5, 6, 1, 2] * u.s, "STOP": [8, 7, 3, 4] * u.s}, time_ref)
 
     gti.write(tmp_path / "tmp.fits")
     new_gti = GTI.read(tmp_path / "tmp.fits")
 
     assert_time_allclose(new_gti.time_start, gti.time_start)
     assert_time_allclose(new_gti.time_stop, gti.time_stop)
-    assert new_gti.table.meta["MJDREFF"] == gti.table.meta["MJDREFF"]
+    assert_time_allclose(new_gti.time_ref, gti.time_ref)
 
 
 def test_gti_from_time():
     """Test astropy time is supported as input for GTI.create"""
     start = Time("2020-01-01T20:00:00")
     stop = Time("2020-01-01T20:15:00")
     ref = Time("2020-01-01T00:00:00")
     gti = GTI.create(start, stop, ref)
 
-    assert u.isclose(gti.table["START"], 20 * u.hour)
-    assert u.isclose(gti.table["STOP"], 20 * u.hour + 15 * u.min)
+    assert_time_allclose(gti.table["START"], start)
+    assert_time_allclose(gti.table["STOP"], stop)
```

### Comparing `gammapy-1.0rc2/gammapy/data/tests/test_hdu_index_table.py` & `gammapy-1.1rc1/gammapy/data/tests/test_hdu_index_table.py`

 * *Files 2% similar despite different names*

```diff
@@ -107,23 +107,23 @@
     msg = "You have to specify `hdu_type` or `hdu_class`."
     assert str(excinfo.value) == msg
 
     with pytest.raises(ValueError) as excinfo:
         hdu_index.hdu_location(obs_id=23523, hdu_type="invalid")
     msg = (
         "Invalid hdu_type: invalid. Valid values are: ['events', 'gti', 'aeff', "
-        "'edisp', 'psf', 'bkg', 'rad_max']"
+        "'edisp', 'psf', 'bkg', 'rad_max', 'pointing']"
     )
     assert str(excinfo.value) == msg
 
     with pytest.raises(ValueError) as excinfo:
         hdu_index.hdu_location(obs_id=23523, hdu_class="invalid")
     msg = (
         "Invalid hdu_class: invalid. Valid values are: ['events', 'gti', 'aeff_2d', 'edisp_2d', "
-        "'psf_table', 'psf_3gauss', 'psf_king', 'bkg_2d', 'bkg_3d', 'rad_max_2d']"
+        "'psf_table', 'psf_3gauss', 'psf_king', 'bkg_2d', 'bkg_3d', 'rad_max_2d', 'pointing']"
     )
     assert str(excinfo.value) == msg
 
     location = hdu_index.hdu_location(obs_id=23523, hdu_class="psf_king")
     assert location is None
 
     location = hdu_index.hdu_location(obs_id=23523, hdu_class="bkg_2d")
```

### Comparing `gammapy-1.0rc2/gammapy/data/tests/test_obs_table.py` & `gammapy-1.1rc1/gammapy/data/tests/test_obs_table.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/data/tests/test_observations.py` & `gammapy-1.1rc1/gammapy/data/tests/test_observations.py`

 * *Files 14% similar despite different names*

```diff
@@ -3,15 +3,19 @@
 import numpy as np
 from numpy.testing import assert_allclose
 import astropy.units as u
 from astropy.coordinates import EarthLocation, SkyCoord
 from astropy.time import Time
 from astropy.units import Quantity
 from gammapy.data import DataStore, Observation
-from gammapy.irf import PSF3D, load_cta_irfs
+from gammapy.data.pointing import FixedPointingInfo, PointingMode
+from gammapy.data.utils import get_irfs_features
+from gammapy.irf import PSF3D, load_irf_dict_from_file
+from gammapy.utils.cluster import hierarchical_clustering
+from gammapy.utils.deprecation import GammapyDeprecationWarning
 from gammapy.utils.fits import HDULocation
 from gammapy.utils.testing import (
     assert_skycoord_allclose,
     assert_time_allclose,
     mpl_plot_check,
     requires_data,
 )
@@ -27,18 +31,22 @@
     """Test Observation class"""
     obs = data_store.obs(23523)
 
     assert_time_allclose(obs.tstart, Time(53343.92234009259, scale="tt", format="mjd"))
     assert_time_allclose(obs.tstop, Time(53343.94186555556, scale="tt", format="mjd"))
 
     c = SkyCoord(83.63333129882812, 21.51444435119629, unit="deg")
-    assert_skycoord_allclose(obs.pointing_radec, c)
+    assert_skycoord_allclose(obs.get_pointing_icrs(obs.tmid), c)
+    with pytest.warns(GammapyDeprecationWarning):
+        assert_skycoord_allclose(obs.pointing_radec, c)
 
     c = SkyCoord(22.558341, 41.950807, unit="deg")
-    assert_skycoord_allclose(obs.pointing_altaz, c)
+    assert_skycoord_allclose(obs.get_pointing_altaz(obs.tmid), c)
+    with pytest.warns(GammapyDeprecationWarning):
+        assert_skycoord_allclose(obs.pointing_altaz, c)
 
     c = SkyCoord(83.63333129882812, 22.01444435119629, unit="deg")
     assert_skycoord_allclose(obs.target_radec, c)
 
 
 @requires_data()
 def test_observation_peek(data_store):
@@ -214,16 +222,19 @@
     assert_time_allclose(new_obss[1].gti.time_start[0], time_intervals[1][0])
     assert_time_allclose(new_obss[1].gti.time_stop[-1], time_intervals[1][1])
 
 
 @requires_data()
 def test_observation_cta_1dc():
     ontime = 5.0 * u.hr
-    pointing = SkyCoord(0, 0, unit="deg", frame="galactic")
-    irfs = load_cta_irfs(
+    pointing = FixedPointingInfo(
+        mode=PointingMode.POINTING,
+        fixed_icrs=SkyCoord(0, 0, unit="deg", frame="galactic").icrs,
+    )
+    irfs = load_irf_dict_from_file(
         "$GAMMAPY_DATA/cta-1dc/caldb/data/cta/1dc/bcf/South_z20_50h/irf_file.fits"
     )
 
     t_ref = Time("2020-01-01T00:00:00")
     tstart = 20 * u.hour
     location = EarthLocation(lon="-70d18m58.84s", lat="-24d41m0.34s", height="2000m")
 
@@ -233,24 +244,28 @@
         deadtime_fraction=0.1,
         tstart=tstart,
         tstop=tstart + ontime,
         reference_time=t_ref,
         location=location,
     )
 
-    assert_skycoord_allclose(obs.pointing_radec, pointing.icrs)
+    assert_skycoord_allclose(obs.get_pointing_icrs(obs.tmid), pointing.fixed_icrs)
     assert_allclose(obs.observation_live_time_duration, 0.9 * ontime)
     assert_allclose(obs.target_radec.ra, np.nan)
-    assert not np.isnan(obs.pointing_zen)
+    with pytest.warns(GammapyDeprecationWarning):
+        assert not np.isnan(obs.pointing_zen)
     assert_allclose(obs.muoneff, 1)
 
 
 @requires_data()
 def test_observation_create_radmax():
-    pointing = SkyCoord(0, 0, unit="deg", frame="galactic")
+    pointing = FixedPointingInfo(
+        mode=PointingMode.POINTING,
+        fixed_icrs=SkyCoord(0, 0, unit="deg", frame="galactic").icrs,
+    )
     obs = Observation.read("$GAMMAPY_DATA/joint-crab/dl3/magic/run_05029748_DL3.fits")
     livetime = 5.0 * u.hr
     deadtime = 0.5
 
     irfs = {}
     for _ in obs.available_irfs:
         irfs[_] = getattr(obs, _)
@@ -258,15 +273,15 @@
     obs1 = Observation.create(
         pointing,
         irfs=irfs,
         deadtime_fraction=deadtime,
         livetime=livetime,
     )
 
-    assert_skycoord_allclose(obs1.pointing_radec, pointing.icrs)
+    assert_skycoord_allclose(obs1.get_pointing_icrs(obs1.tmid), pointing.fixed_icrs)
     assert_allclose(obs1.observation_live_time_duration, 0.5 * livetime)
     assert obs1.rad_max is not None
     assert obs1.psf is None
 
 
 @requires_data()
 def test_observation_read():
@@ -314,15 +329,15 @@
     assert obs.rad_max is not None
     assert obs.rad_max.quantity.shape == (1, 1)
     assert u.allclose(obs.rad_max.quantity, 0.1414213 * u.deg)
 
 
 @requires_data()
 class TestObservationChecker:
-    def setup(self):
+    def setup_method(self):
         self.data_store = DataStore.from_dir("$GAMMAPY_DATA/cta-1dc/index/gps")
 
     def test_check_all(self):
         observation = self.data_store.obs(111140)
         records = list(observation.check())
         assert len(records) == 8
 
@@ -382,7 +397,93 @@
 
     with pytest.raises(ValueError):
         _ = obs.copy(obs_id=1234)
 
     obs_copy = obs.copy(obs_id=1234, in_memory=True)
     assert isinstance(obs_copy.__dict__["psf"], PSF3D)
     assert obs_copy.obs_id == 1234
+
+
+def test_observation_tmid():
+    from gammapy.data import GTI
+
+    start = Time("2020-01-01T20:00:00")
+    stop = Time("2020-01-01T20:10:00")
+    expected = Time("2020-01-01T20:05:00")
+    epoch = Time("2020-01-01T00:00:00")
+
+    gti = GTI.create([(start - epoch).to(u.s)], [(stop - epoch).to(u.s)], epoch)
+    obs = Observation(gti=gti)
+    assert abs(obs.tmid - expected).to(u.ns) < 1 * u.us
+
+
+@requires_data()
+def test_observations_clustering(data_store):
+
+    selection = dict(
+        type="sky_circle",
+        frame="icrs",
+        lon="83.633 deg",
+        lat="22.014 deg",
+        radius="2 deg",
+    )
+    obs_table = data_store.obs_table.select_observations(selection)
+    observations = data_store.get_observations(obs_table["OBS_ID"])
+
+    coord = SkyCoord(83.63308, 22.01450, unit="deg", frame="icrs")
+    names = ["edisp-bias", "edisp-res", "psf-radius"]
+    features = get_irfs_features(
+        observations, energy_true="1 TeV", position=coord, names=names
+    )
+
+    n_features = len(names)
+    features_array = np.array(
+        [
+            features[col].data
+            for col in features.columns
+            if col not in ["obs_id", "dataset_name"]
+        ]
+    ).T
+    assert features_array.shape == (len(observations), n_features)
+
+    features = hierarchical_clustering(
+        features, linkage_kwargs={"method": "complete"}, fcluster_kwargs={"t": 2}
+    )
+
+    assert np.all(
+        features["labels"].data
+        == np.array(
+            [
+                1,
+                1,
+                2,
+                2,
+            ]
+        )
+    )
+
+    features = get_irfs_features(
+        observations,
+        energy_true="1 TeV",
+        position=coord,
+        names=names,
+        apply_standard_scaler=True,
+    )
+    features = hierarchical_clustering(features)
+    features_array = np.array(
+        [
+            features[col].data
+            for col in features.columns
+            if col not in ["obs_id", "dataset_name"]
+        ]
+    ).T
+
+    obs_clusters = observations.group_by_label(features["labels"])
+    for k in range(n_features):
+        assert_allclose(features_array[:, k].mean(), 0, atol=1e-7)
+        assert_allclose(features_array[:, k].std(), 1, atol=1e-7)
+
+    assert np.all(features["labels"].data == np.array([2, 1, 1, 1]))
+
+    assert len(obs_clusters["group_1"]) == 3
+    assert len(obs_clusters["group_2"]) == 1
+    assert obs_clusters["group_2"][0].obs_id == 23523
```

### Comparing `gammapy-1.0rc2/gammapy/datasets/__init__.py` & `gammapy-1.1rc1/gammapy/datasets/__init__.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/datasets/core.py` & `gammapy-1.1rc1/gammapy/datasets/core.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,32 +5,32 @@
 import logging
 import numpy as np
 from astropy import units as u
 from astropy.table import Table, vstack
 from gammapy.data import GTI
 from gammapy.modeling.models import DatasetModels, Models
 from gammapy.utils.scripts import make_name, make_path, read_yaml, write_yaml
-from gammapy.utils.table import table_from_row_data
 
 log = logging.getLogger(__name__)
 
 
 __all__ = ["Dataset", "Datasets"]
 
 
 class Dataset(abc.ABC):
     """Dataset abstract base class.
-
-    TODO: add tutorial how to create your own dataset types.
-
-    For now, see existing examples in Gammapy how this works:
+    For now, see existing examples of type of datasets:
 
     - `gammapy.datasets.MapDataset`
     - `gammapy.datasets.SpectrumDataset`
     - `gammapy.datasets.FluxPointsDataset`
+
+    For more information see :ref:`datasets`.
+
+    TODO: add tutorial how to create your own dataset types.
     """
 
     _residuals_labels = {
         "diff": "data - model",
         "diff/model": "(data - model) / model",
         "diff/sqrt(model)": "(data - model) / sqrt(model)",
     }
@@ -48,15 +48,15 @@
         """Convert to dict for YAML serialization."""
         name = self.name.replace(" ", "_")
         filename = f"{name}.fits"
         return {"name": self.name, "type": self.tag, "filename": filename}
 
     @property
     def mask(self):
-        """Combined fit and safe mask"""
+        """Combined fit and safe mask."""
         if self.mask_safe is not None and self.mask_fit is not None:
             return self.mask_safe & self.mask_fit
         elif self.mask_fit is not None:
             return self.mask_fit
         elif self.mask_safe is not None:
             return self.mask_safe
 
@@ -106,15 +106,15 @@
                 raise AttributeError(
                     f"Invalid method: {method!r} for computing residuals"
                 )
         return residuals
 
 
 class Datasets(collections.abc.MutableSequence):
-    """Dataset collection.
+    """Container class that holds a list of datasets.
 
     Parameters
     ----------
     datasets : `Dataset` or list of `Dataset`
         Datasets
     """
 
@@ -174,36 +174,36 @@
 
     @property
     def names(self):
         return [d.name for d in self._datasets]
 
     @property
     def is_all_same_type(self):
-        """Whether all contained datasets are of the same type"""
+        """Whether all contained datasets are of the same type."""
         return len(set(_.__class__ for _ in self)) == 1
 
     @property
     def is_all_same_shape(self):
-        """Whether all contained datasets have the same data shape"""
+        """Whether all contained datasets have the same data shape."""
         return len(set(_.data_shape for _ in self)) == 1
 
     @property
     def is_all_same_energy_shape(self):
-        """Whether all contained datasets have the same data shape"""
+        """Whether all contained datasets have the same data shape."""
         return len(set(_.data_shape[0] for _ in self)) == 1
 
     @property
     def energy_axes_are_aligned(self):
-        """Whether all contained datasets have aligned energy axis"""
+        """Whether all contained datasets have aligned energy axis."""
         axes = [d.counts.geom.axes["energy"] for d in self]
         return np.all([axes[0].is_aligned(ax) for ax in axes])
 
     @property
     def contributes_to_stat(self):
-        """Stat contributions
+        """Stat contributions.
 
         Returns
         -------
         contributions : `~numpy.array`
             Array indicating which dataset contributes to the likelihood.
         """
         contributions = []
@@ -213,15 +213,15 @@
                 value = np.any(dataset.mask)
             else:
                 value = True
             contributions.append(value)
         return np.array(contributions)
 
     def stat_sum(self):
-        """Compute joint likelihood"""
+        """Compute joint statistic function value."""
         stat_sum = 0
         # TODO: add parallel evaluation of likelihoods
         for dataset in self:
             stat_sum += dataset.stat_sum()
         return stat_sum
 
     def select_time(self, time_min, time_max, atol="1e-6 s"):
@@ -250,23 +250,23 @@
 
             if t_start >= (time_min - atol) and t_stop <= (time_max + atol):
                 datasets.append(dataset)
 
         return self.__class__(datasets)
 
     def slice_by_energy(self, energy_min, energy_max):
-        """Select and slice datasets in energy range
+        """Select and slice datasets in energy range.
 
-        The method keeps the current dataset names. Datasets, that do not
+        The method keeps the current dataset names. Datasets that do not
         contribute to the selected energy range are dismissed.
 
         Parameters
         ----------
         energy_min, energy_max : `~astropy.units.Quantity`
-            Energy bounds to compute the flux point for.
+            Energy bounds to compute the flux point for
 
         Returns
         -------
         datasets : Datasets
             Datasets
 
         """
@@ -288,18 +288,21 @@
             datasets.append(dataset_sliced)
 
         return self.__class__(datasets=datasets)
 
     def to_spectrum_datasets(self, region):
         """Extract spectrum datasets for the given region.
 
+        To get more detailed information, see the corresponding function associated to each dataset type:
+        `~gammapy.datasets.MapDataset.to_spectrum_dataset` or `~gammapy.datasets.MapDatasetOnOff.to_spectrum_dataset`.
+
         Parameters
         ----------
         region : `~regions.SkyRegion`
-            Region definition.
+            Region definition
 
         Returns
         -------
         datasets : `Datasets`
             List of `~gammapy.datasets.SpectrumDataset`
         """
         datasets = Datasets()
@@ -319,15 +322,15 @@
 
         The energy range is derived as the minimum / maximum of the energy
         ranges of all datasets.
 
         Returns
         -------
         energy_min, energy_max : `~astropy.units.Quantity`
-            Energy range.
+            Energy range
         """
 
         energy_mins, energy_maxs = [], []
 
         for dataset in self:
             energy_axis = dataset.counts.geom.axes["energy"]
             energy_mins.append(energy_axis.edges[0])
@@ -365,19 +368,19 @@
         """De-serialize datasets from YAML and FITS files.
 
         Parameters
         ----------
         filename : str or `Path`
             File path or name of datasets yaml file
         filename_models : str or `Path`
-            File path or name of models fyaml ile
+            File path or name of models yaml file
         lazy : bool
             Whether to lazy load data into memory
         cache : bool
-            Whether to cache the data after loading.
+            Whether to cache the data after loading
 
         Returns
         -------
         dataset : `gammapy.datasets.Datasets`
             Datasets
         """
         from . import DATASET_REGISTRY
@@ -437,23 +440,23 @@
                 overwrite=overwrite,
                 write_covariance=write_covariance,
             )
 
     def stack_reduce(self, name=None, nan_to_num=True):
         """Reduce the Datasets to a unique Dataset by stacking them together.
 
-        This works only if all Dataset are of the same type and if a proper
+        This works only if all datasets are of the same type and with aligned geometries, and if a proper
         in-place stack method exists for the Dataset type.
 
         Parameters
         ----------
         name : str
-            Name of the stacked dataset.
+            Name of the stacked dataset
         nan_to_num: bool
-            Non-finite values are replaced by zero if True (default).
+            Non-finite values are replaced by zero if True (default)
 
         Returns
         -------
         dataset : `~gammapy.datasets.Dataset`
             the stacked dataset
         """
         if not self.is_all_same_type:
@@ -494,20 +497,20 @@
                 stacked.stack(dataset)
                 row = stacked.info_dict()
             else:
                 row = dataset.info_dict()
 
             rows.append(row)
 
-        return table_from_row_data(rows=rows)
+        return Table(rows)
 
     # TODO: merge with meta table?
     @property
     def gti(self):
-        """GTI table"""
+        """GTI table."""
         time_intervals = []
 
         for dataset in self:
             if dataset.gti is not None and len(dataset.gti.table) > 0:
                 interval = (dataset.gti.time_start[0], dataset.gti.time_stop[-1])
                 time_intervals.append(interval)
```

### Comparing `gammapy-1.0rc2/gammapy/datasets/evaluator.py` & `gammapy-1.1rc1/gammapy/datasets/evaluator.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,26 +4,29 @@
 import astropy.units as u
 from astropy.coordinates.angle_utilities import angular_separation
 from astropy.utils import lazyproperty
 from regions import CircleSkyRegion
 import matplotlib.pyplot as plt
 from gammapy.maps import HpxNDMap, Map, RegionNDMap, WcsNDMap
 from gammapy.modeling.models import PointSpatialModel, TemplateNPredModel
+from .utils import apply_edisp
 
+PSF_MAX_RADIUS = None
 PSF_CONTAINMENT = 0.999
 CUTOUT_MARGIN = 0.1 * u.deg
 
 log = logging.getLogger(__name__)
 
 
 class MapEvaluator:
     """Sky model evaluation on maps.
 
     Evaluates a sky model on a 3D map and returns a map of the predicted counts.
-    Convolution with IRFs will be performed as defined in the sky_model
+    The convolution with IRFs will be performed as defined in the sky_model. To do so, IRF kernels
+    are extracted at the position closest to the position of the model.
 
     Parameters
     ----------
     model : `~gammapy.modeling.models.SkyModel`
         Sky model
     exposure : `~gammapy.maps.Map`
         Exposure map
@@ -38,15 +41,15 @@
     evaluation_mode : {"local", "global"}
         Model evaluation mode.
         The "local" mode evaluates the model components on smaller grids to save computation time.
         This mode is recommended for local optimization algorithms.
         The "global" evaluation mode evaluates the model components on the full map.
         This mode is recommended for global optimization algorithms.
     use_cache : bool
-        Use npred caching.
+        Use npred caching
     """
 
     def __init__(
         self,
         model,
         exposure=None,
         psf=None,
@@ -83,32 +86,39 @@
 
         # define cached computations
         self._cached_parameter_values = None
         self._cached_parameter_values_previous = None
         self._cached_parameter_values_spatial = None
         self._cached_position = (0, 0)
         self._computation_cache = None
-        self._neval = 0  # for debugging
-        self._renorm = 1
         self._spatial_oversampling_factor = 1
         if self.exposure is not None:
             if not self.geom.is_region or self.geom.region is not None:
                 self.update_spatial_oversampling_factor(self.geom)
 
     def reset_cache_properties(self):
         """Reset cached properties."""
         del self._compute_npred
         del self._compute_flux_spatial
 
     @property
     def geom(self):
-        """True energy map geometry (`~gammapy.maps.Geom`)"""
+        """True energy map geometry (`~gammapy.maps.Geom`)."""
         return self.exposure.geom
 
     @property
+    def _geom_reco(self):
+        if self.edisp is not None:
+            energy_axis = self.edisp.axes["energy"].copy(name="energy")
+        else:
+            energy_axis = self.geom.axes["energy_true"].copy(name="energy")
+        geom = self.geom.to_image().to_cube(axes=[energy_axis])
+        return geom
+
+    @property
     def needs_update(self):
         """Check whether the model component has drifted away from its support."""
         # TODO: simplify and clean up
         if isinstance(self.model, TemplateNPredModel):
             return False
         elif not self.contributes:
             return False
@@ -121,50 +131,50 @@
         elif not self.parameters_spatial_changed(reset=False):
             return False
         else:
             return self.irf_position_changed
 
     @property
     def psf_width(self):
-        """Width of the PSF"""
+        """Width of the PSF."""
         if self.psf is not None:
             psf_width = np.max(self.psf.psf_kernel_map.geom.width)
         else:
             psf_width = 0 * u.deg
         return psf_width
 
     def use_psf_containment(self, geom):
-        """Use psf containment for point sources and circular regions"""
+        """Use psf containment for point sources and circular regions."""
         if not geom.is_region:
             return False
 
         is_point_model = isinstance(self.model.spatial_model, PointSpatialModel)
         is_circle_region = isinstance(geom.region, CircleSkyRegion)
         return is_point_model & is_circle_region
 
     @property
     def cutout_width(self):
-        """Cutout width for the model component"""
+        """Cutout width for the model component."""
         return self.psf_width + 2 * (self.model.evaluation_radius + CUTOUT_MARGIN)
 
     def update(self, exposure, psf, edisp, geom, mask):
         """Update MapEvaluator, based on the current position of the model component.
 
         Parameters
         ----------
         exposure : `~gammapy.maps.Map`
-            Exposure map.
+            Exposure map
         psf : `gammapy.irf.PSFMap`
-            PSF map.
+            PSF map
         edisp : `gammapy.irf.EDispMap`
-            Edisp map.
+            Edisp map
         geom : `WcsGeom`
             Counts geom
         mask : `~gammapy.maps.Map`
-            Mask to apply to the likelihood for fitting.
+            Mask to apply to the likelihood for fitting
         """
         # TODO: simplify and clean up
         log.debug("Updating model evaluator")
 
         # lookup edisp
         if edisp:
             energy_axis = geom.axes["energy"]
@@ -188,14 +198,15 @@
                 if geom_psf.is_region or geom_psf.is_hpx:
                     geom_psf = geom_psf.to_wcs_geom()
 
                 self.psf = psf.get_psf_kernel(
                     position=self.model.position,
                     geom=geom_psf,
                     containment=PSF_CONTAINMENT,
+                    max_radius=PSF_MAX_RADIUS,
                 )
 
         if self.evaluation_mode == "local":
             self.contributes = self.model.contributes(mask=mask, margin=self.psf_width)
 
             if self.contributes:
                 self.exposure = exposure.cutout(
@@ -209,15 +220,15 @@
                 self.update_spatial_oversampling_factor(self.geom)
 
         self.reset_cache_properties()
         self._computation_cache = None
         self._cached_parameter_previous = None
 
     def update_spatial_oversampling_factor(self, geom):
-        """Update spatial oversampling_factor for model evaluation"""
+        """Update spatial oversampling_factor for model evaluation."""
         res_scale = self.model.evaluation_bin_size_min
 
         res_scale = res_scale.to_value("deg") if res_scale is not None else 0
 
         if geom.is_region or geom.is_hpx:
             geom = geom.to_wcs_geom()
         if res_scale != 0:
@@ -226,21 +237,21 @@
 
     def compute_dnde(self):
         """Compute model differential flux at map pixel centers.
 
         Returns
         -------
         model_map : `~gammapy.maps.Map`
-            Sky cube with data filled with evaluated model values.
+            Sky cube with data filled with evaluated model values
             Units: ``cm-2 s-1 TeV-1 deg-2``
         """
         return self.model.evaluate_geom(self.geom, self.gti)
 
     def compute_flux(self, *arg):
-        """Compute flux"""
+        """Compute flux."""
         return self.model.integrate_geom(self.geom, self.gti)
 
     def compute_flux_psf_convolved(self, *arg):
         """Compute psf convolved and temporal model corrected flux."""
         value = self.compute_flux_spectral()
 
         if self.model.spatial_model:
@@ -251,27 +262,27 @@
 
         if self.model.temporal_model:
             value *= self.compute_temporal_norm()
 
         return Map.from_geom(geom=self.geom, data=value.value, unit=value.unit)
 
     def compute_flux_spatial(self):
-        """Compute spatial flux using caching"""
+        """Compute spatial flux using caching."""
         if self.parameters_spatial_changed() or not self.use_cache:
             del self._compute_flux_spatial
         return self._compute_flux_spatial
 
     @lazyproperty
     def _compute_flux_spatial(self):
-        """Compute spatial flux
+        """Compute spatial flux.
 
         Returns
         ----------
         value: `~astropy.units.Quantity`
-            Psf-corrected, integrated flux over a given region.
+            PSF-corrected, integrated flux over a given region
         """
         if self.geom.is_region:
             # We don't estimate spatial contributions if no psf are defined
             if self.geom.region is None or self.psf is None:
                 return 1
 
             wcs_geom = self.geom.to_wcs_geom(width_min=self.cutout_width).to_image()
@@ -289,53 +300,53 @@
             value = (values.quantity * weights).sum(axis=(1, 2), keepdims=True)
         else:
             value = self._compute_flux_spatial_geom(self.geom)
 
         return value
 
     def _compute_flux_spatial_geom(self, geom):
-        """Compute spatial flux oversampling geom if necessary"""
+        """Compute spatial flux oversampling geom if necessary."""
         if not self.model.spatial_model.is_energy_dependent:
             geom = geom.to_image()
         value = self.model.spatial_model.integrate_geom(geom)
 
         if self.psf and self.model.apply_irf["psf"]:
             value = self.apply_psf(value)
 
         return value
 
     def compute_flux_spectral(self):
-        """Compute spectral flux"""
+        """Compute spectral flux."""
         energy = self.geom.axes["energy_true"].edges
         value = self.model.spectral_model.integral(
             energy[:-1],
             energy[1:],
         )
         if self.geom.is_hpx:
             return value.reshape((-1, 1))
         else:
             return value.reshape((-1, 1, 1))
 
     def compute_temporal_norm(self):
-        """Compute temporal norm"""
+        """Compute temporal norm."""
         integral = self.model.temporal_model.integral(
             self.gti.time_start, self.gti.time_stop
         )
         return np.sum(integral)
 
     def apply_exposure(self, flux):
-        """Compute npred cube
+        """Compute npred cube.
 
-        For now just divide flux cube by exposure
+        For now just divide flux cube by exposure.
         """
         npred = (flux.quantity * self.exposure.quantity).to_value("")
         return Map.from_geom(self.geom, data=npred, unit="")
 
     def apply_psf(self, npred):
-        """Convolve npred cube with PSF"""
+        """Convolve npred cube with PSF."""
         tmp = npred.convolve(self.psf)
         return tmp
 
     def apply_edisp(self, npred):
         """Convolve map data with energy dispersion.
 
         Parameters
@@ -344,23 +355,28 @@
             Predicted counts in true energy bins
 
         Returns
         -------
         npred_reco : `~gammapy.maps.Map`
             Predicted counts in reco energy bins
         """
-        return npred.apply_edisp(self.edisp)
+        return apply_edisp(npred, self.edisp)
 
     @lazyproperty
     def _compute_npred(self):
-        """Compute npred"""
+        """Compute npred."""
         if isinstance(self.model, TemplateNPredModel):
             npred = self.model.evaluate()
         else:
-            if not self.parameter_norm_only_changed:
+            if (
+                self._norm_idx is not None
+                and self.model.parameters.value[self._norm_idx] == 0
+            ):
+                npred = Map.from_geom(self._geom_reco, data=0)
+            elif not self.parameter_norm_only_changed or not self.use_cache:
                 for method in self.methods_sequence:
                     values = method(self._computation_cache)
                     self._computation_cache = values
                 npred = self._computation_cache
             else:
                 npred = self._computation_cache * self.renorm()
         return npred
@@ -382,65 +398,65 @@
         if self.parameters_changed or not self.use_cache:
             del self._compute_npred
 
         return self._compute_npred
 
     @property
     def parameters_changed(self):
-        """Parameters changed"""
+        """Parameters changed."""
         values = self.model.parameters.value
 
         # TODO: possibly allow for a tolerance here?
         changed = ~np.all(self._cached_parameter_values == values)
 
         if changed:
             self._cached_parameter_values = values
 
         return changed
 
     @property
     def parameter_norm_only_changed(self):
-        """Only norm parameter changed"""
+        """Only norm parameter changed."""
         norm_only_changed = False
         idx = self._norm_idx
         values = self.model.parameters.value
-        if idx and self._computation_cache is not None:
-            changed = self._cached_parameter_values_previous == values
-            norm_only_changed = sum(changed) == 1 and changed[idx]
+        if idx is not None and self._computation_cache is not None:
+            changed = self._cached_parameter_values_previous != values
+            norm_only_changed = np.count_nonzero(changed) == 1 and changed[idx]
 
         if not norm_only_changed:
             self._cached_parameter_values_previous = values
         return norm_only_changed
 
     def parameters_spatial_changed(self, reset=True):
-        """Parameters changed
+        """Parameters changed.
 
         Parameters
         ----------
         reset : bool
             Reset cached values
 
         Returns
         -------
         changed : bool
-            Whether spatial parameters changed.
+            Whether spatial parameters changed
         """
         values = self.model.spatial_model.parameters.value
 
         # TODO: possibly allow for a tolerance here?
         changed = ~np.all(self._cached_parameter_values_spatial == values)
 
         if changed and reset:
             self._cached_parameter_values_spatial = values
 
         return changed
 
     @property
     def irf_position_changed(self):
-        """Position for IRF changed"""
+        """Position for IRF changed."""
 
         # Here we do not use SkyCoord.separation to improve performance
         # (it avoids equivalence comparisons for frame and units)
         lon_cached, lat_cached = self._cached_position
         lon, lat = self.model.position_lonlat
 
         separation = angular_separation(lon, lat, lon_cached, lat_cached)
@@ -451,30 +467,30 @@
         if changed:
             self._cached_position = lon, lat
 
         return changed
 
     @lazyproperty
     def _norm_idx(self):
-        """norm index"""
+        """Norm index."""
         names = self.model.parameters.names
         ind = [idx for idx, name in enumerate(names) if name in ["norm", "amplitude"]]
         if len(ind) == 1:
             return ind[0]
         else:
             return None
 
     def renorm(self):
         value = self.model.parameters.value[self._norm_idx]
         value_cached = self._cached_parameter_values_previous[self._norm_idx]
         return value / value_cached
 
     @lazyproperty
     def methods_sequence(self):
-        """order to apply irf"""
+        """Order to apply the IRFs."""
 
         if self.apply_psf_after_edisp:
             methods = [
                 self.compute_flux,
                 self.apply_exposure,
                 self.apply_edisp,
                 self.apply_psf,
@@ -494,15 +510,15 @@
         return methods
 
     def peek(self, figsize=(12, 15)):
         """Quick-look summary plots.
         Parameters
         ----------
         figsize : tuple
-            Size of the figure.
+            Size of the figure
         """
         if self.needs_update:
             raise AttributeError(
                 "The evaluator needs to be updated first. Execute "
                 "`MapDataset.npred_signal(model_name=...)` before calling this method."
             )
```

### Comparing `gammapy-1.0rc2/gammapy/datasets/flux_points.py` & `gammapy-1.1rc1/gammapy/datasets/flux_points.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,40 +2,43 @@
 import logging
 import numpy as np
 from astropy import units as u
 from astropy.table import Table
 from astropy.visualization import quantity_support
 import matplotlib.pyplot as plt
 from matplotlib.gridspec import GridSpec
+from gammapy.maps.axes import UNIT_STRING_FORMAT
 from gammapy.modeling.models import DatasetModels
 from gammapy.utils.scripts import make_name, make_path
 from .core import Dataset
 
 log = logging.getLogger(__name__)
 
 __all__ = ["FluxPointsDataset"]
 
 
 class FluxPointsDataset(Dataset):
     """Bundle a set of flux points with a parametric model,
     to compute fit statistic function using chi2 statistics.
 
+    For more information see :ref:`datasets`.
+
     Parameters
     ----------
     models : `~gammapy.modeling.models.Models`
         Models (only spectral part needs to be set)
     data : `~gammapy.estimators.FluxPoints`
         Flux points. Must be sorted along the energy axis
     mask_fit : `numpy.ndarray`
         Mask to apply for fitting
     mask_safe : `numpy.ndarray`
-        Mask defining the safe data range. By default upper limit values are excluded.
+        Mask defining the safe data range. By default, upper limit values are excluded.
     meta_table : `~astropy.table.Table`
         Table listing information on observations used to create the dataset.
-        One line per observation for stacked datasets.
+        One line per observation for stacked datasets
 
     Examples
     --------
     Load flux points from file and fit with a power-law model::
 
     >>> from gammapy.modeling import Fit
     >>> from gammapy.modeling.models import PowerLawSpectralModel, SkyModel
@@ -70,15 +73,15 @@
     >>> print(result.parameters.to_table())
       type      name     value         unit      ... max frozen is_norm link
     -------- --------- ---------- -------------- ... --- ------ ------- ----
     spectral     index 2.2159e+00                ... nan  False   False
     spectral amplitude 2.1619e-13 cm-2 s-1 TeV-1 ... nan  False    True
     spectral reference 1.0000e+00            TeV ... nan   True   False
 
-    Note: In order to reproduce the example you need the tests datasets folder.
+    Note: In order to reproduce the example, you need the tests datasets folder.
     You may download it with the command
     ``gammapy download datasets --tests --out $GAMMAPY_DATA``
     """
 
     stat_type = "chi2"
     tag = "FluxPointsDataset"
 
@@ -106,15 +109,15 @@
 
     @property
     def name(self):
         return self._name
 
     @property
     def gti(self):
-        """Good time interval info (`GTI`)"""
+        """Good time interval info (`GTI`)."""
         return self.data.gti
 
     @property
     def models(self):
         return self._models
 
     @models.setter
@@ -127,43 +130,43 @@
 
     def write(self, filename, overwrite=False, **kwargs):
         """Write flux point dataset to file.
 
         Parameters
         ----------
         filename : str
-            Filename to write to.
+            Filename to write to
         overwrite : bool
-            Overwrite existing file.
+            Overwrite existing file
         **kwargs : dict
-             Keyword arguments passed to `~astropy.table.Table.write`.
+             Keyword arguments passed to `~astropy.table.Table.write`
         """
         table = self.data.to_table()
 
         if self.mask_fit is None:
             mask_fit = self.mask_safe
         else:
             mask_fit = self.mask_fit
 
         table["mask_fit"] = mask_fit
         table["mask_safe"] = self.mask_safe
         table.write(make_path(filename), overwrite=overwrite, **kwargs)
 
     @classmethod
     def read(cls, filename, name=None, format="gadf-sed"):
-        """Read pre-computed flux points and create a dataset
+        """Read pre-computed flux points and create a dataset.
 
         Parameters
         ----------
         filename : str
-            Filename to read from.
+            Filename to read from
         name : str
-            Name of the new dataset.
+            Name of the new dataset
         format : {"gadf-sed"}
-            Format of the dataset file.
+            Format of the dataset file
 
         Returns
         -------
         dataset : `FluxPointsDataset`
             FluxPointsDataset
         """
         from gammapy.estimators import FluxPoints
@@ -189,15 +192,15 @@
     @classmethod
     def from_dict(cls, data, **kwargs):
         """Create flux point dataset from dict.
 
         Parameters
         ----------
         data : dict
-            Dict containing data to create dataset from.
+            Dict containing data to create dataset from
 
         Returns
         -------
         dataset : `FluxPointsDataset`
             Flux point datasets.
         """
         from gammapy.estimators import FluxPoints
@@ -284,27 +287,27 @@
         try:
             sigma = self.data.dnde_err
         except AttributeError:
             sigma = (self.data.dnde_errn + self.data.dnde_errp) / 2
         return ((data - model) / sigma.quantity[:, 0, 0]).to_value("") ** 2
 
     def residuals(self, method="diff"):
-        """Compute flux point residuals
+        """Compute flux point residuals.
 
         Parameters
         ----------
         method: {"diff", "diff/model"}
             Method used to compute the residuals. Available options are:
                 - `diff` (default): data - model
                 - `diff/model`: (data - model) / model
 
         Returns
         -------
         residuals : `~numpy.ndarray`
-            Residuals array.
+            Residuals array
         """
         fp = self.data
 
         model = self.flux_pred()
 
         residuals = self._compute_residuals(fp.dnde.quantity[:, 0, 0], model, method)
         # Remove residuals for upper_limits
@@ -321,26 +324,26 @@
         """Plot flux points, best fit model and residuals in two panels.
 
         Calls `~FluxPointsDataset.plot_spectrum` and `~FluxPointsDataset.plot_residuals`.
 
         Parameters
         ----------
         ax_spectrum : `~matplotlib.axes.Axes`
-            Axes to plot flux points and best fit model on.
+            Axes to plot flux points and best fit model on
         ax_residuals : `~matplotlib.axes.Axes`
-            Axes to plot residuals on.
+            Axes to plot residuals on
         kwargs_spectrum : dict
-            Keyword arguments passed to `~FluxPointsDataset.plot_spectrum`.
+            Keyword arguments passed to `~FluxPointsDataset.plot_spectrum`
         kwargs_residuals : dict
-            Keyword arguments passed to `~FluxPointsDataset.plot_residuals`.
+            Keyword arguments passed to `~FluxPointsDataset.plot_residuals`
 
         Returns
         -------
         ax_spectrum, ax_residuals : `~matplotlib.axes.Axes`
-            Flux points, best fit model and residuals plots.
+            Flux points, best fit model and residuals plots
 
         Examples
         --------
         >>> from gammapy.modeling.models import PowerLawSpectralModel, SkyModel
         >>> from gammapy.estimators import FluxPoints
         >>> from gammapy.datasets import FluxPointsDataset
 
@@ -384,24 +387,24 @@
 
     def plot_residuals(self, ax=None, method="diff", **kwargs):
         """Plot flux point residuals.
 
         Parameters
         ----------
         ax : `~matplotlib.axes.Axes`
-            Axes to plot on.
+            Axes to plot on
         method : {"diff", "diff/model"}
-            Normalization used to compute the residuals, see `FluxPointsDataset.residuals`.
+            Normalization used to compute the residuals, see `FluxPointsDataset.residuals`
         **kwargs : dict
-            Keyword arguments passed to `~matplotlib.axes.Axes.errorbar`.
+            Keyword arguments passed to `~matplotlib.axes.Axes.errorbar`
 
         Returns
         -------
         ax : `~matplotlib.axes.Axes`
-            Axes object.
+            Axes object
 
         """
         ax = ax or plt.gca()
 
         fp = self.data
         residuals = self.residuals(method)
 
@@ -425,15 +428,15 @@
 
         with quantity_support():
             ax.errorbar(fp.energy_ref, residuals, xerr=xerr, yerr=yerr, **kwargs)
 
         ax.axhline(0, color=kwargs["color"], lw=0.5)
 
         # format axes
-        ax.set_xlabel(f"Energy [{self._energy_unit}]")
+        ax.set_xlabel(f"Energy [{self._energy_unit.to_string(UNIT_STRING_FORMAT)}]")
         ax.set_xscale("log")
         label = self._residuals_labels[method]
         ax.set_ylabel(f"Residuals\n {label}")
         ymin = np.nanmin(residuals - yerr[0])
         ymax = np.nanmax(residuals + yerr[1])
         ymax = max(abs(ymin), ymax)
         ax.set_ylim(-1.05 * ymax, 1.05 * ymax)
@@ -441,25 +444,25 @@
 
     def plot_spectrum(self, ax=None, kwargs_fp=None, kwargs_model=None):
         """Plot spectrum including flux points and model.
 
         Parameters
         ----------
         ax : `~matplotlib.axes.Axes`
-            Axes to plot on.
+            Axes to plot on
         kwargs_fp : dict
-            Keyword arguments passed to `gammapy.estimators.FluxPoints.plot`.
+            Keyword arguments passed to `gammapy.estimators.FluxPoints.plot` to configure the plot style
         kwargs_model : dict
             Keyword arguments passed to `gammapy.modeling.models.SpectralModel.plot` and
-            `gammapy.modeling.models.SpectralModel.plot_error`.
+            `gammapy.modeling.models.SpectralModel.plot_error` to configure the plot style
 
         Returns
         -------
         ax : `~matplotlib.axes.Axes`
-            Axes object.
+            Axes object
 
         Examples
         --------
         >>> from gammapy.modeling.models import PowerLawSpectralModel, SkyModel
         >>> from gammapy.estimators import FluxPoints
         >>> from gammapy.datasets import FluxPointsDataset
```

### Comparing `gammapy-1.0rc2/gammapy/datasets/io.py` & `gammapy-1.1rc1/gammapy/datasets/io.py`

 * *Files 1% similar despite different names*

```diff
@@ -15,59 +15,59 @@
     "DatasetWriter",
     "OGIPDatasetReader",
     "OGIPDatasetWriter",
 ]
 
 
 class DatasetReader(abc.ABC):
-    """Dataset reader base class"""
+    """Dataset reader base class."""
 
     @property
     @abc.abstractmethod
     def tag(self):
         pass
 
     @abc.abstractmethod
     def read(self):
         pass
 
 
 class DatasetWriter(abc.ABC):
-    """Dataset writer base class"""
+    """Dataset writer base class."""
 
     @property
     @abc.abstractmethod
     def tag(self):
         pass
 
     @abc.abstractmethod
     def write(self, dataset):
         pass
 
 
 class OGIPDatasetWriter(DatasetWriter):
     """Write OGIP files.
 
-    If you want to use the written files with Sherpa you have to use the
+    If you want to use the written files with Sherpa, you have to use the
     ``ogip-sherpa`` format. Then all files will be written in units of 'keV' and
     'cm2'.
 
     The naming scheme is fixed as following:
 
     * PHA file is named filename.fits
     * BKG file is named filename_bkg.fits
     * ARF file is named filename_arf.fits
     * RMF file is named filename_rmf.fits
 
     Parameters
     ----------
     filename : `pathlib.Path` or str
-        Filename.
+        Filename
     format : {"ogip", "ogip-sherpa"}
-        Which format to use.
+        Which format to use
     overwrite : bool
         Overwrite existing files?
     """
 
     tag = ["ogip", "ogip-sherpa"]
 
     def __init__(self, filename, format="ogip", overwrite=False):
@@ -76,37 +76,37 @@
 
         self.filename = filename
         self.format = format
         self.overwrite = overwrite
 
     @staticmethod
     def get_filenames(filename):
-        """Get filenames
+        """Get filenames.
 
         Parameters
         ----------
         filename : `~pathlib.Path`
             Filename
 
         Returns
         -------
         filenames : dict
-            Dict of filenames.
+            Dict of filenames
         """
         suffix = "".join(filename.suffixes)
         name = filename.name.replace(suffix, "")
         name = f"{name}{{}}{suffix}"
         return {
             "respfile": name.format("_rmf"),
             "backfile": name.format("_bkg"),
             "ancrfile": name.format("_arf"),
         }
 
     def get_ogip_meta(self, dataset, is_bkg=False):
-        """Meta info for the OGIP data format"""
+        """Meta info for the OGIP data format."""
         try:
             livetime = dataset.exposure.meta["livetime"]
         except KeyError:
             raise ValueError(
                 "Storing in ogip format require the livetime "
                 "to be defined in the exposure meta data"
             )
@@ -129,15 +129,15 @@
 
         if dataset.counts_off:
             meta["RESPFILE"] = filenames["respfile"]
 
         return meta
 
     def write(self, dataset):
-        """Write dataset to files
+        """Write dataset to file.
 
         Parameters
         ----------
         dataset : `SpectrumDatasetOnOff`
             Dataset to write
         """
         filenames = self.get_filenames(self.filename)
@@ -157,46 +157,46 @@
         """Write energy dispersion.
 
         Parameters
         ----------
         dataset : `SpectrumDatasetOnOff`
             Dataset to write
         filename : str or `Path`
-            Filename to use.
+            Filename to use
         """
         kernel = dataset.edisp.get_edisp_kernel()
         kernel.write(filename=filename, overwrite=self.overwrite, format=self.format)
 
     def write_arf(self, dataset, filename):
-        """Write effective area
+        """Write effective area.
 
         Parameters
         ----------
         dataset : `SpectrumDatasetOnOff`
             Dataset to write
         filename : str or `Path`
-            Filename to use.
+            Filename to use
 
         """
         aeff = dataset.exposure / dataset.exposure.meta["livetime"]
         aeff.write(
             filename=filename,
             overwrite=self.overwrite,
             format=self.format.replace("ogip", "ogip-arf"),
         )
 
     def to_counts_hdulist(self, dataset, is_bkg=False):
-        """Convert counts region map to hdulist
+        """Convert counts region map to hdulist.
 
         Parameters
         ----------
         dataset : `SpectrumDatasetOnOff`
             Dataset to write
         is_bkg : bool
-            Whether to use counts off.
+            Whether to use counts off
         """
         counts = dataset.counts_off if is_bkg else dataset.counts
         acceptance = dataset.acceptance_off if is_bkg else dataset.acceptance
 
         hdulist = counts.to_hdulist(format=self.format)
 
         table = Table.read(hdulist["SPECTRUM"])
@@ -215,41 +215,41 @@
 
         # adapt meta data
         table.meta.update(meta)
         hdulist["SPECTRUM"] = fits.BinTableHDU(table)
         return hdulist
 
     def write_pha(self, dataset, filename):
-        """Write counts file
+        """Write counts file.
 
         Parameters
         ----------
         dataset : `SpectrumDatasetOnOff`
             Dataset to write
         filename : str or `Path`
-            Filename to use.
+            Filename to use
 
         """
         hdulist = self.to_counts_hdulist(dataset)
 
         if dataset.gti:
-            hdu = fits.BinTableHDU(dataset.gti.table, name="GTI")
+            hdu = dataset.gti.to_table_hdu()
             hdulist.append(hdu)
 
         hdulist.writeto(filename, overwrite=self.overwrite)
 
     def write_bkg(self, dataset, filename):
-        """Write off counts file
+        """Write off counts file.
 
         Parameters
         ----------
         dataset : `SpectrumDatasetOnOff`
             Dataset to write
         filename : str or `Path`
-            Filename to use.
+            Filename to use
         """
         hdulist = self.to_counts_hdulist(dataset, is_bkg=True)
         hdulist.writeto(filename, overwrite=self.overwrite)
 
 
 class OGIPDatasetReader(DatasetReader):
     """Read `~gammapy.datasets.SpectrumDatasetOnOff` from OGIP files.
@@ -273,15 +273,15 @@
 
     tag = "ogip"
 
     def __init__(self, filename):
         self.filename = make_path(filename)
 
     def get_valid_path(self, filename):
-        """Get absolute or relative path
+        """Get absolute or relative path.
 
         The relative path is with respect to the name of the reference file.
 
         Parameters
         ----------
         filename : str or `Path`
             Filename
@@ -295,15 +295,15 @@
 
         if not filename.exists():
             return self.filename.parent / filename
         else:
             return filename
 
     def get_filenames(self, pha_meta):
-        """Get filenames
+        """Get filenames.
 
         Parameters
         ----------
         pha_meta : dict
             Meta data from the PHA file
 
         Returns
@@ -320,15 +320,15 @@
         if "RESPFILE" in pha_meta:
             filenames["rmffile"] = self.get_valid_path(pha_meta["RESPFILE"])
 
         return filenames
 
     @staticmethod
     def read_pha(filename):
-        """Read PHA file
+        """Read PHA file.
 
         Parameters
         ----------
         filename : str or `Path`
             PHA file name
 
         Returns
@@ -341,25 +341,25 @@
         with fits.open(filename, memmap=False) as hdulist:
             data["counts"] = RegionNDMap.from_hdulist(hdulist, format="ogip")
             data["acceptance"] = RegionNDMap.from_hdulist(
                 hdulist, format="ogip", ogip_column="BACKSCAL"
             )
 
             if "GTI" in hdulist:
-                data["gti"] = GTI(Table.read(hdulist["GTI"]))
+                data["gti"] = GTI.from_table_hdu(hdulist["GTI"])
 
             data["mask_safe"] = RegionNDMap.from_hdulist(
                 hdulist, format="ogip", ogip_column="QUALITY"
             )
 
         return data
 
     @staticmethod
     def read_bkg(filename):
-        """Read PHA background file
+        """Read PHA background file.
 
         Parameters
         ----------
         filename : str or `Path`
             PHA file name
 
         Returns
@@ -372,15 +372,15 @@
             acceptance_off = RegionNDMap.from_hdulist(
                 hdulist, ogip_column="BACKSCAL", format="ogip"
             )
         return {"counts_off": counts_off, "acceptance_off": acceptance_off}
 
     @staticmethod
     def read_rmf(filename, exposure):
-        """Read RMF file
+        """Read RMF file.
 
         Parameters
         ----------
         filename : str or `Path`
             PHA file name
         exposure : `RegionNDMap`
             Exposure map
@@ -395,15 +395,15 @@
 
         # TODO: resolve this separate handling of exposure for edisp
         edisp.exposure_map.data = exposure.data[:, :, np.newaxis, :]
         return edisp
 
     @staticmethod
     def read_arf(filename, livetime):
-        """Read ARF file
+        """Read ARF file.
 
         Parameters
         ----------
         filename : str or `Path`
             PHA file name
         livetime : `Quantity`
             Livetime
@@ -415,15 +415,15 @@
         """
         aeff = RegionNDMap.read(filename, format="ogip-arf")
         exposure = aeff * livetime
         exposure.meta["livetime"] = livetime
         return exposure
 
     def read(self):
-        """Read dataset
+        """Read dataset.
 
         Returns
         -------
         dataset : SpectrumDatasetOnOff
             Spectrum dataset
         """
         kwargs = self.read_pha(self.filename)
```

### Comparing `gammapy-1.0rc2/gammapy/datasets/map.py` & `gammapy-1.1rc1/gammapy/datasets/map.py`

 * *Files 1% similar despite different names*

```diff
@@ -4,24 +4,25 @@
 import astropy.units as u
 from astropy.io import fits
 from astropy.table import Table
 from regions import CircleSkyRegion
 import matplotlib.pyplot as plt
 from gammapy.data import GTI
 from gammapy.irf import EDispKernelMap, EDispMap, PSFKernel, PSFMap, RecoPSFMap
-from gammapy.maps import Map, MapAxis
+from gammapy.maps import LabelMapAxis, Map, MapAxis
 from gammapy.modeling.models import DatasetModels, FoVBackgroundModel
 from gammapy.stats import (
     CashCountsStatistic,
     WStatCountsStatistic,
     cash,
     cash_sum_cython,
     get_wstat_mu_bkg,
     wstat,
 )
+from gammapy.utils.deprecation import deprecated_renamed_argument
 from gammapy.utils.fits import HDULocation, LazyFitsData
 from gammapy.utils.random import get_random_state
 from gammapy.utils.scripts import make_name, make_path
 from gammapy.utils.table import hstack_columns
 from .core import Dataset
 from .evaluator import MapEvaluator
 from .utils import get_axes
@@ -35,60 +36,66 @@
 RAD_AXIS_DEFAULT = MapAxis.from_bounds(
     0, RAD_MAX, nbin=66, node_type="edges", name="rad", unit="deg"
 )
 MIGRA_AXIS_DEFAULT = MapAxis.from_bounds(
     0.2, 5, nbin=48, node_type="edges", name="migra"
 )
 
-BINSZ_IRF_DEFAULT = 0.2
+BINSZ_IRF_DEFAULT = 0.2 * u.deg
 
 EVALUATION_MODE = "local"
 USE_NPRED_CACHE = True
 
 
 def create_map_dataset_geoms(
     geom,
     energy_axis_true=None,
     migra_axis=None,
     rad_axis=None,
-    binsz_irf=None,
+    binsz_irf=BINSZ_IRF_DEFAULT,
+    reco_psf=False,
 ):
-    """Create map geometries for a `MapDataset`
+    """Create map geometries for a `MapDataset`.
 
     Parameters
     ----------
     geom : `~gammapy.maps.WcsGeom`
         Reference target geometry in reco energy, used for counts and background maps
     energy_axis_true : `~gammapy.maps.MapAxis`
         True energy axis used for IRF maps
     migra_axis : `~gammapy.maps.MapAxis`
         If set, this provides the migration axis for the energy dispersion map.
         If not set, an EDispKernelMap is produced instead. Default is None
     rad_axis : `~gammapy.maps.MapAxis`
         Rad axis for the psf map
     binsz_irf : float
         IRF Map pixel size in degrees.
+    reco_psf : bool
+        Use reconstructed energy for the PSF geometry. Default is False
 
     Returns
     -------
     geoms : dict
-        Dict with map geometries.
+        Dict with map geometries
     """
     rad_axis = rad_axis or RAD_AXIS_DEFAULT
 
     if energy_axis_true is not None:
         energy_axis_true.assert_name("energy_true")
     else:
         energy_axis_true = geom.axes["energy"].copy(name="energy_true")
 
-    binsz_irf = binsz_irf or BINSZ_IRF_DEFAULT
     geom_image = geom.to_image()
     geom_exposure = geom_image.to_cube([energy_axis_true])
     geom_irf = geom_image.to_binsz(binsz=binsz_irf)
-    geom_psf = geom_irf.to_cube([rad_axis, energy_axis_true])
+
+    if reco_psf:
+        geom_psf = geom_irf.to_cube([rad_axis, geom.axes["energy"]])
+    else:
+        geom_psf = geom_irf.to_cube([rad_axis, energy_axis_true])
 
     if migra_axis:
         geom_edisp = geom_irf.to_cube([migra_axis, energy_axis_true])
     else:
         geom_edisp = geom_irf.to_cube([geom.axes["energy"], energy_axis_true])
 
     return {
@@ -96,17 +103,22 @@
         "geom_exposure": geom_exposure,
         "geom_psf": geom_psf,
         "geom_edisp": geom_edisp,
     }
 
 
 class MapDataset(Dataset):
-    """
-    Bundle together binned counts, background, IRFs, models and compute a likelihood.
-     Uses Cash statistics by default.
+    """Main map dataset for likelihood fitting.
+
+    It bundles together binned counts, background, IRFs in the form of `~gammapy.maps.Map`.
+    A safe mask and a fit mask can be added to exclude bins during the analysis.
+    If models are assigned to it, it can compute predicted counts in each bin of the  counts `Map` and compute
+    the associated statistic function, here the Cash statistic (see `~gammapy.stats.cash`).
+
+    For more information see :ref:`datasets`.
 
     Parameters
     ----------
     models : `~gammapy.modeling.models.Models`
         Source sky models.
     counts : `~gammapy.maps.WcsNDMap` or `~gammapy.utils.fits.HDULocation`
         Counts cube
@@ -124,14 +136,15 @@
         Mask defining the safe data range.
     gti : `~gammapy.data.GTI`
         GTI of the observation or union of GTI if it is a stacked observation
     meta_table : `~astropy.table.Table`
         Table listing information on observations used to create the dataset.
         One line per observation for stacked datasets.
 
+
     If an `HDULocation` is passed the map is loaded lazily. This means the
     map data is only loaded in memory as the corresponding data attribute
     on the MapDataset is accessed. If it was accessed once it is cached for
     the next time.
 
     Examples
     --------
@@ -287,15 +300,15 @@
         if self.models is not None:
             str_ += "\t" + "\n\t".join(str(self.models).split("\n")[2:])
 
         return str_.expandtabs(tabsize=2)
 
     @property
     def geoms(self):
-        """Map geometries
+        """Map geometries.
 
         Returns
         -------
         geoms : dict
             Dict of map geometries involved in the dataset.
         """
         geoms = {}
@@ -316,15 +329,15 @@
     @property
     def models(self):
         """Models set on the dataset (`~gammapy.modeling.models.Models`)."""
         return self._models
 
     @property
     def excess(self):
-        """Observed excess: counts-background"""
+        """Observed excess: counts-background."""
         return self.counts - self.background
 
     @models.setter
     def models(self, models):
         """Models setter"""
         self._evaluators = {}
 
@@ -342,20 +355,20 @@
                     )
                     self._evaluators[model.name] = evaluator
 
         self._models = models
 
     @property
     def evaluators(self):
-        """Model evaluators"""
+        """Model evaluators."""
         return self._evaluators
 
     @property
     def _geom(self):
-        """Main analysis geometry"""
+        """Main analysis geometry."""
         if self.counts is not None:
             return self.counts.geom
         elif self.background is not None:
             return self.background.geom
         elif self.mask_safe is not None:
             return self.mask_safe.geom
         elif self.mask_fit is not None:
@@ -364,15 +377,15 @@
             raise ValueError(
                 "Either 'counts', 'background', 'mask_fit'"
                 " or 'mask_safe' must be defined."
             )
 
     @property
     def data_shape(self):
-        """Shape of the counts or background data (tuple)"""
+        """Shape of the counts or background data (tuple)."""
         return self._geom.data_shape
 
     def _energy_range(self, mask_map=None):
         """Compute the energy range maps with or without the fit mask."""
         geom = self._geom
         energy = geom.axes["energy"].edges
         e_i = geom.axes.index_data("energy")
@@ -420,30 +433,30 @@
     @property
     def energy_range_total(self):
         """Largest energy range among all pixels, defined by mask_safe and mask_fit."""
         energy_min_map, energy_max_map = self.energy_range
         return np.nanmin(energy_min_map.quantity), np.nanmax(energy_max_map.quantity)
 
     def npred(self):
-        """Total predicted source and background counts
+        """Total predicted source and background counts.
 
         Returns
         -------
         npred : `Map`
             Total predicted counts
         """
         npred_total = self.npred_signal()
 
         if self.background:
             npred_total += self.npred_background()
         npred_total.data[npred_total.data < 0.0] = 0
         return npred_total
 
     def npred_background(self):
-        """Predicted background counts
+        """Predicted background counts.
 
         The predicted background counts depend on the parameters
         of the `FoVBackgroundModel` defined in the dataset.
 
         Returns
         -------
         npred_background : `Map`
@@ -469,51 +482,68 @@
         values = self.background_model.parameters.value
         # TODO: possibly allow for a tolerance here?
         changed = ~np.all(self._background_parameters_cached == values)
         if changed:
             self._background_parameters_cached = values
         return changed
 
-    def npred_signal(self, model_name=None):
+    @deprecated_renamed_argument("model_name", "model_names", "1.1")
+    def npred_signal(self, model_names=None, stack=True):
         """Model predicted signal counts.
 
-        If a model name is passed, predicted counts from that component are returned.
-        Else, the total signal counts are returned.
+        If a list of model name is passed, predicted counts from these components are returned.
+        If stack is set to True, a map of the sum of all the predicted counts is returned.
+        If stack is set to False, a map with an additional axis representing the models is returned.
 
         Parameters
         ----------
-        model_name: str
-            Name of  SkyModel for which to compute the npred for.
-            If none, the sum of all components (minus the background model)
-            is returned
+        model_names: list of str
+            List of name of  SkyModel for which to compute the npred.
+            If none, all the SkyModel predicted counts are computed
+        stack: bool
+            Whether to stack the npred maps upon each other.
 
         Returns
         -------
         npred_sig: `gammapy.maps.Map`
             Map of the predicted signal counts
         """
         npred_total = Map.from_geom(self._geom, dtype=float)
 
         evaluators = self.evaluators
-        if model_name is not None:
-            evaluators = {model_name: self.evaluators[model_name]}
-
-        for evaluator in evaluators.values():
+        if model_names is not None:
+            if isinstance(model_names, str):
+                model_names = [model_names]
+            evaluators = {name: self.evaluators[name] for name in model_names}
+
+        npred_list = []
+        labels = []
+        for evaluator_name, evaluator in evaluators.items():
             if evaluator.needs_update:
                 evaluator.update(
                     self.exposure,
                     self.psf,
                     self.edisp,
                     self._geom,
                     self.mask_image,
                 )
 
             if evaluator.contributes:
                 npred = evaluator.compute_npred()
-                npred_total.stack(npred)
+                if stack:
+                    npred_total.stack(npred)
+                else:
+                    npred_geom = Map.from_geom(self._geom, dtype=float)
+                    npred_geom.stack(npred)
+                    labels.append(evaluator_name)
+                    npred_list.append(npred_geom)
+
+        if npred_list != []:
+            label_axis = LabelMapAxis(labels=labels, name="models")
+            npred_total = Map.from_stack(npred_list, axis=label_axis)
 
         return npred_total
 
     @classmethod
     def from_geoms(
         cls,
         geom,
@@ -521,15 +551,15 @@
         geom_psf=None,
         geom_edisp=None,
         reference_time="2000-01-01",
         name=None,
         **kwargs,
     ):
         """
-        Create a MapDataset object with zero filled maps according to the specified geometries
+        Create a MapDataset object with zero filled maps according to the specified geometries.
 
         Parameters
         ----------
         geom : `Geom`
             geometry for the counts and background maps
         geom_exposure : `Geom`
             geometry for the exposure map
@@ -578,18 +608,19 @@
     @classmethod
     def create(
         cls,
         geom,
         energy_axis_true=None,
         migra_axis=None,
         rad_axis=None,
-        binsz_irf=None,
+        binsz_irf=BINSZ_IRF_DEFAULT,
         reference_time="2000-01-01",
         name=None,
         meta_table=None,
+        reco_psf=False,
         **kwargs,
     ):
         """Create a MapDataset object with zero filled maps.
 
         Parameters
         ----------
         geom : `~gammapy.maps.WcsGeom`
@@ -606,14 +637,16 @@
         reference_time : `~astropy.time.Time`
             the reference time to use in GTI definition
         name : str
             Name of the returned dataset.
         meta_table : `~astropy.table.Table`
             Table listing information on observations used to create the dataset.
             One line per observation for stacked datasets.
+        reco_psf : bool
+            Use reconstructed energy for the PSF geometry. Default is False
 
         Returns
         -------
         empty_maps : `MapDataset`
             A MapDataset containing zero filled maps
 
         Examples
@@ -637,58 +670,59 @@
 
         geoms = create_map_dataset_geoms(
             geom=geom,
             energy_axis_true=energy_axis_true,
             rad_axis=rad_axis,
             migra_axis=migra_axis,
             binsz_irf=binsz_irf,
+            reco_psf=reco_psf,
         )
 
         kwargs.update(geoms)
         return cls.from_geoms(
             reference_time=reference_time, name=name, meta_table=meta_table, **kwargs
         )
 
     @property
     def mask_safe_image(self):
-        """Reduced mask safe"""
+        """Reduced safe mask."""
         if self.mask_safe is None:
             return None
         return self.mask_safe.reduce_over_axes(func=np.logical_or)
 
     @property
     def mask_fit_image(self):
-        """Reduced mask fit"""
+        """Reduced fit mask."""
         if self.mask_fit is None:
             return None
         return self.mask_fit.reduce_over_axes(func=np.logical_or)
 
     @property
     def mask_image(self):
-        """Reduced mask"""
+        """Reduced mask."""
         if self.mask is None:
             mask = Map.from_geom(self._geom.to_image(), dtype=bool)
             mask.data |= True
             return mask
 
         return self.mask.reduce_over_axes(func=np.logical_or)
 
     @property
     def mask_safe_psf(self):
-        """Mask safe for psf maps"""
+        """Safe mask for psf maps."""
         if self.mask_safe is None or self.psf is None:
             return None
 
         geom = self.psf.psf_map.geom.squash("energy_true").squash("rad")
         mask_safe_psf = self.mask_safe_image.interp_to_geom(geom.to_image())
         return mask_safe_psf.to_cube(geom.axes)
 
     @property
     def mask_safe_edisp(self):
-        """Mask safe for edisp maps"""
+        """Safe mask for edisp maps."""
         if self.mask_safe is None or self.edisp is None:
             return None
 
         if self.mask_safe.geom.is_region:
             return self.mask_safe
 
         geom = self.edisp.edisp_map.geom.squash("energy_true")
@@ -697,15 +731,15 @@
             geom = geom.squash("migra")
             mask_safe_edisp = self.mask_safe_image.interp_to_geom(geom.to_image())
             return mask_safe_edisp.to_cube(geom.axes)
 
         return self.mask_safe.interp_to_geom(geom)
 
     def to_masked(self, name=None, nan_to_num=True):
-        """Return masked dataset
+        """Return masked dataset.
 
         Parameters
         ----------
         name : str
             Name of the masked dataset.
         nan_to_num: bool
             Non-finite values are replaced by zero if True (default).
@@ -779,15 +813,15 @@
                 else:
                     self.exposure.meta["livetime"] = other.exposure.meta[
                         "livetime"
                     ].copy()
 
         if self.stat_type == "cash":
             if self.background and other.background:
-                background = self.npred_background() * self.mask_safe
+                background = self.npred_background()
                 background.stack(
                     other.npred_background(),
                     weights=other.mask_safe,
                     nan_to_num=nan_to_num,
                 )
                 self.background = background
 
@@ -811,15 +845,15 @@
 
         if self.meta_table and other.meta_table:
             self.meta_table = hstack_columns(self.meta_table, other.meta_table)
         elif other.meta_table:
             self.meta_table = other.meta_table.copy()
 
     def stat_array(self):
-        """Likelihood per bin given the current model parameters"""
+        """Statistic function value per bin given the current model parameters."""
         return cash(n_on=self.counts.data, mu_on=self.npred().data)
 
     def residuals(self, method="diff", **kwargs):
         """Compute residuals map.
 
         Parameters
         ----------
@@ -1076,15 +1110,15 @@
         if region is not None:
             pix_region = region.to_pixel(self._geom.to_image().wcs)
             pix_region.plot(ax=ax_spatial)
 
         return ax_spatial, ax_spectral
 
     def stat_sum(self):
-        """Total likelihood given the current model parameters."""
+        """Total statistic function value given the current model parameters."""
         counts, npred = self.counts.data.astype(float), self.npred().data
 
         if self.mask is not None:
             return cash_sum_cython(counts[self.mask.data], npred[self.mask.data])
         else:
             return cash_sum_cython(counts.ravel(), npred.ravel())
 
@@ -1140,15 +1174,15 @@
         if self.mask_safe is not None:
             hdulist += self.mask_safe.to_hdulist(hdu="mask_safe")[exclude_primary]
 
         if self.mask_fit is not None:
             hdulist += self.mask_fit.to_hdulist(hdu="mask_fit")[exclude_primary]
 
         if self.gti is not None:
-            hdulist.append(fits.BinTableHDU(self.gti.table, name="GTI"))
+            hdulist.append(self.gti.to_table_hdu())
 
         if self.meta_table is not None:
             hdulist.append(fits.BinTableHDU(self.meta_table, name="META_TABLE"))
 
         return hdulist
 
     @classmethod
@@ -1183,50 +1217,35 @@
 
         if "BACKGROUND" in hdulist:
             kwargs["background"] = Map.from_hdulist(
                 hdulist, hdu="background", format=format
             )
 
         if "EDISP" in hdulist:
-            edisp_map = Map.from_hdulist(hdulist, hdu="edisp", format=format)
-
-            try:
-                exposure_map = Map.from_hdulist(
-                    hdulist, hdu="edisp_exposure", format=format
-                )
-            except KeyError:
-                exposure_map = None
-
-            if edisp_map.geom.axes[0].name == "energy":
-                kwargs["edisp"] = EDispKernelMap(edisp_map, exposure_map)
-            else:
-                kwargs["edisp"] = EDispMap(edisp_map, exposure_map)
+            kwargs["edisp"] = EDispMap.from_hdulist(
+                hdulist, hdu="edisp", exposure_hdu="edisp_exposure", format=format
+            )
 
         if "PSF" in hdulist:
-            psf_map = Map.from_hdulist(hdulist, hdu="psf", format=format)
-            try:
-                exposure_map = Map.from_hdulist(
-                    hdulist, hdu="psf_exposure", format=format
-                )
-            except KeyError:
-                exposure_map = None
-            kwargs["psf"] = PSFMap(psf_map, exposure_map)
+            kwargs["psf"] = PSFMap.from_hdulist(
+                hdulist, hdu="psf", exposure_hdu="psf_exposure", format=format
+            )
 
         if "MASK_SAFE" in hdulist:
             mask_safe = Map.from_hdulist(hdulist, hdu="mask_safe", format=format)
             mask_safe.data = mask_safe.data.astype(bool)
             kwargs["mask_safe"] = mask_safe
 
         if "MASK_FIT" in hdulist:
             mask_fit = Map.from_hdulist(hdulist, hdu="mask_fit", format=format)
             mask_fit.data = mask_fit.data.astype(bool)
             kwargs["mask_fit"] = mask_fit
 
         if "GTI" in hdulist:
-            gti = GTI(Table.read(hdulist, hdu="GTI"))
+            gti = GTI.from_table_hdu(hdulist["GTI"])
             kwargs["gti"] = gti
 
         if "META_TABLE" in hdulist:
             meta_table = Table.read(hdulist, hdu="META_TABLE")
             kwargs["meta_table"] = meta_table
 
         return cls(**kwargs)
@@ -1263,15 +1282,15 @@
                 file_name=path.name,
                 hdu_name=hdu_name.upper(),
                 cache=cache,
                 format=format,
             )
 
         kwargs["edisp"] = HDULocation(
-            hdu_class="edisp_kernel_map",
+            hdu_class="edisp_map",
             file_dir=path.parent,
             file_name=path.name,
             hdu_name="EDISP",
             cache=cache,
             format=format,
         )
 
@@ -1331,15 +1350,15 @@
 
     @property
     def _counts_statistic(self):
         """Counts statistics of the dataset."""
         return CashCountsStatistic(self.counts, self.background)
 
     def info_dict(self, in_safe_data_range=True):
-        """Info dict with summary statistics, summed over energy
+        """Info dict with summary statistics, summed over energy.
 
         Parameters
         ----------
         in_safe_data_range : bool
             Whether to sum only in the safe energy range
 
         Returns
@@ -1508,15 +1527,15 @@
 
         return SpectrumDataset(**kwargs)
 
     def to_region_map_dataset(self, region, name=None):
         """Integrate the map dataset in a given region.
 
         Counts and background of the dataset are integrated in the given region,
-        taking the safe mask into accounts. The exposure is averaged in the
+        taking the safe mask into account. The exposure is averaged in the
         region again taking the safe mask into account. The PSF and energy
         dispersion kernel are taken at the center of the region.
 
         Parameters
         ----------
         region : `~regions.SkyRegion`
             Region from which to extract the spectrum
@@ -1950,15 +1969,23 @@
         axes[3].set_title("Background")
         self.background.sum_over_axes().plot(ax=axes[3], add_cbar=True)
         plot_mask(ax=axes[3], mask=self.mask_fit_image, alpha=0.2)
         plot_mask(ax=axes[3], mask=self.mask_safe_image, hatches=["///"], colors="w")
 
 
 class MapDatasetOnOff(MapDataset):
-    """Map dataset for on-off likelihood fitting. Uses wstat statistics.
+    """Map dataset for on-off likelihood fitting.
+
+    It bundles together the binned on and off counts, the binned IRFs as well as the on and off acceptances.
+
+    A safe mask and a fit mask can be added to exclude bins during the analysis.
+
+    It uses the Wstat statistic (see `~gammapy.stats.wstat`), therefore no background model is needed.
+
+    For more information see :ref:`datasets`.
 
     Parameters
     ----------
     models : `~gammapy.modeling.models.Models`
         Source sky models.
     counts : `~gammapy.maps.WcsNDMap`
         Counts cube
@@ -2072,18 +2099,18 @@
 
         Returns
         -------
         alpha : `Map`
             Alpha map
         """
         with np.errstate(invalid="ignore", divide="ignore"):
-            alpha = self.acceptance / self.acceptance_off
+            data = self.acceptance.quantity / self.acceptance_off.quantity
+        data = np.nan_to_num(data)
 
-        alpha.data = np.nan_to_num(alpha.data)
-        return alpha
+        return Map.from_geom(self._geom, data=data.to_value(""), unit="")
 
     def npred_background(self):
         """Predicted background counts estimated from the marginalized likelihood estimate.
 
         See :ref:`wstat`
 
         Returns
@@ -2124,15 +2151,15 @@
             Background map
         """
         if self.counts_off is None:
             return None
         return self.alpha * self.counts_off
 
     def stat_array(self):
-        """Likelihood per bin given the current model parameters"""
+        """Statistic function value per bin given the current model parameters"""
         mu_sig = self.npred_signal().data
         on_stat_ = wstat(
             n_on=self.counts.data,
             n_off=self.counts_off.data,
             alpha=list(self.alpha.data),
             mu_sig=mu_sig,
         )
@@ -2150,15 +2177,15 @@
         geom_exposure,
         geom_psf=None,
         geom_edisp=None,
         reference_time="2000-01-01",
         name=None,
         **kwargs,
     ):
-        """Create an empty `MapDatasetOnOff` object according to the specified geometries
+        """Create an empty `MapDatasetOnOff` object according to the specified geometries.
 
         Parameters
         ----------
         geom : `gammapy.maps.WcsGeom`
             geometry for the counts, counts_off, acceptance and acceptance_off maps
         geom_exposure : `gammapy.maps.WcsGeom`
             geometry for the exposure map
@@ -2245,17 +2272,17 @@
             acceptance_off=acceptance_off,
             gti=dataset.gti,
             name=name,
             meta_table=dataset.meta_table,
         )
 
     def to_map_dataset(self, name=None):
-        """Convert a MapDatasetOnOff to  MapDataset
+        """Convert a MapDatasetOnOff to a MapDataset.
 
-        The background model template is taken as alpha * counts_off
+        The background model template is taken as alpha * counts_off.
 
         Parameters
         ----------
         name: str
             Name of the new dataset
 
         Returns
@@ -2310,15 +2337,15 @@
         nan_to_num: bool
             Non-finite values are replaced by zero if True (default).
         """
         if not isinstance(other, MapDatasetOnOff):
             raise TypeError("Incompatible types for MapDatasetOnOff stacking")
 
         if not self._is_stackable or not other._is_stackable:
-            raise ValueError("Cannot stack incomplete MapDatsetOnOff.")
+            raise ValueError("Cannot stack incomplete MapDatasetOnOff.")
 
         geom = self.counts.geom
         total_off = Map.from_geom(geom)
         total_alpha = Map.from_geom(geom)
 
         if self.counts_off:
             total_off.stack(
@@ -2352,16 +2379,23 @@
         self.acceptance_off = acceptance_off
 
         self.counts_off = total_off
 
         super().stack(other, nan_to_num=nan_to_num)
 
     def stat_sum(self):
-        """Total likelihood given the current model parameters."""
-        return Dataset.stat_sum(self)
+        """Total statistic function value given the current model parameters.
+
+        If the off counts are passed as None and the elements of the safe mask are False, zero will be returned.
+        Otherwise, the stat sum will be calculated and returned.
+        """
+        if self.counts_off is None and not np.any(self.mask_safe.data):
+            return 0
+        else:
+            return Dataset.stat_sum(self)
 
     def fake(self, npred_background, random_state="random-seed"):
         """Simulate fake counts (on and off) for the current model and reduced IRFs.
 
         This method overwrites the counts defined on the dataset object.
 
         Parameters
@@ -2495,24 +2529,24 @@
             kwargs["mask_safe"] = mask_safe
 
         if "MASK_FIT" in hdulist:
             mask_fit = Map.from_hdulist(hdulist, hdu="mask_fit", format=format)
             kwargs["mask_fit"] = mask_fit
 
         if "GTI" in hdulist:
-            gti = GTI(Table.read(hdulist, hdu="GTI"))
+            gti = GTI.from_table_hdu(hdulist["GTI"])
             kwargs["gti"] = gti
 
         if "META_TABLE" in hdulist:
             meta_table = Table.read(hdulist, hdu="META_TABLE")
             kwargs["meta_table"] = meta_table
         return cls(**kwargs)
 
     def info_dict(self, in_safe_data_range=True):
-        """Basic info dict with summary statistics
+        """Basic info dict with summary statistics.
 
         If a region is passed, then a spectrum dataset is
         extracted, and the corresponding info returned.
 
         Parameters
         ----------
         in_safe_data_range : bool
@@ -2665,15 +2699,15 @@
         a corresponding axis is given.
 
         Parameters
         ----------
         factor : int
             Downsampling factor.
         axis_name : str
-            Which non-spatial axis to downsample. By default only spatial axes are downsampled.
+            Which non-spatial axis to downsample. By default, only spatial axes are downsampled.
         name : str
             Name of the downsampled dataset.
 
         Returns
         -------
         dataset : `MapDatasetOnOff`
             Downsampled map dataset.
```

### Comparing `gammapy-1.0rc2/gammapy/datasets/simulate.py` & `gammapy-1.1rc1/gammapy/datasets/simulate.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,68 +1,230 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
-"""Simulate observations"""
+"""Simulate observations."""
 import numpy as np
 import astropy.units as u
-from astropy.coordinates import AltAz, SkyCoord, SkyOffsetFrame
+from astropy.coordinates import SkyCoord, SkyOffsetFrame
 from astropy.table import Table
+from astropy.time import Time
 import gammapy
 from gammapy.data import EventList, observatory_locations
-from gammapy.maps import MapCoord
-from gammapy.modeling.models import ConstantTemporalModel
+from gammapy.maps import MapAxis, MapCoord, RegionNDMap, TimeMapAxis
+from gammapy.modeling.models import (
+    ConstantSpectralModel,
+    ConstantTemporalModel,
+    PointSpatialModel,
+)
 from gammapy.utils.random import get_random_state
 
 __all__ = ["MapDatasetEventSampler"]
 
 
 class MapDatasetEventSampler:
-    """Sample events from a map dataset
+    """Sample events from a map dataset.
 
     Parameters
     ----------
     random_state : {int, 'random-seed', 'global-rng', `~numpy.random.RandomState`}
-        Defines random number generator initialisation.
-        Passed to `~gammapy.utils.random.get_random_state`.
+        Defines random number generator initialisation via the `~gammapy.utils.random.get_random_state` function
+    oversample_energy_factor: {int}
+        Defines an oversampling factor for the energies; it is used only when sampling
+        an energy-dependent time-varying source
+    t_delta : `~astropy.units.Quantity`
+        Time interval used to sample the time-dependent source
     """
 
-    def __init__(self, random_state="random-seed"):
+    def __init__(
+        self, random_state="random-seed", oversample_energy_factor=10, t_delta=0.5 * u.s
+    ):
         self.random_state = get_random_state(random_state)
+        self.oversample_energy_factor = oversample_energy_factor
+        self.t_delta = t_delta
 
-    def _sample_coord_time(self, npred, temporal_model, gti):
-        data = npred.data[np.isfinite(npred.data)]
-        n_events = self.random_state.poisson(np.sum(data))
+    def _make_table(self, coords, time_ref):
+        """Create a table for sampled events.
 
-        coords = npred.sample_coord(n_events=n_events, random_state=self.random_state)
+        Parameters
+        ----------
+        coords : `~gammapy.maps.MapCoord`
+            Coordinates of the sampled events
+        time_ref : `~astropy.time.Time`
+            Reference time of the event list
 
+        Returns
+        -------
+        table : `~astropy.table.Table`
+            Table of the sampled events
+        """
         table = Table()
         try:
             energy = coords["energy_true"]
         except KeyError:
             energy = coords["energy"]
 
+        table["TIME"] = (coords["time"] - time_ref).to("s")
         table["ENERGY_TRUE"] = energy
+
         table["RA_TRUE"] = coords.skycoord.icrs.ra.to("deg")
         table["DEC_TRUE"] = coords.skycoord.icrs.dec.to("deg")
 
+        return table
+
+    def _evaluate_timevar_source(
+        self,
+        dataset,
+        model,
+    ):
+        """Calculate Npred for a given `dataset.model` by evaluating
+        it on a region geometry.
+
+        Parameters
+        ----------
+        dataset : `~gammapy.datasets.MapDataset`
+            Map dataset
+        model : `~gammapy.modeling.models.SkyModel`
+            Sky model instance
+
+        Returns
+        -------
+        npred : `~gammapy.maps.RegionNDMap`
+            Npred map
+        """
+        energy_true = dataset.edisp.edisp_map.geom.axes["energy_true"]
+        energy_new = energy_true.upsample(self.oversample_energy_factor)
+
+        position = model.spatial_model.position
+        region_exposure = dataset.exposure.to_region_nd_map(position)
+
+        time_axis_eval = TimeMapAxis.from_gti_bounds(
+            gti=dataset.gti, t_delta=self.t_delta
+        )
+
+        time_min, time_max = time_axis_eval.time_bounds
+        time_axis = MapAxis.from_bounds(
+            time_min.mjd * u.d,
+            time_max.mjd * u.d,
+            nbin=time_axis_eval.nbin,
+            name="time",
+        )
+
+        temp_eval = model.temporal_model.evaluate(
+            time_axis_eval.time_mid, energy=energy_new.center
+        )
+
+        norm_parameters = model.spectral_model.parameters.norm_parameters
+        norm = norm_parameters[0].quantity
+
+        if temp_eval.unit.is_equivalent(norm.unit):
+            flux_diff = temp_eval.to(norm.unit)
+        else:
+            flux_diff = temp_eval * norm
+
+        flux_inte = flux_diff * energy_new.bin_width[:, None]
+
+        flux_pred = RegionNDMap.create(
+            region=position,
+            axes=[time_axis, energy_new],
+            data=np.array(flux_inte),
+            unit=flux_inte.unit,
+        )
+
+        mapcoord = flux_pred.geom.get_coord()
+        mapcoord["energy_true"] = energy_true.center[:, None, None, None]
+
+        flux_values = flux_pred.interp_by_coord(mapcoord) * flux_pred.unit
+        data = flux_values * region_exposure.quantity[:, None, :, :]
+        data /= time_axis.nbin / self.oversample_energy_factor
+
+        npred = RegionNDMap.create(
+            region=position,
+            axes=[time_axis, energy_true],
+            data=data.to_value(""),
+        )
+
+        return npred
+
+    def _sample_coord_time_energy(self, dataset, model):
+        """Sample model components of a source with time-dependent spectrum.
+
+        Parameters
+        ----------
+        dataset : `~gammapy.datasets.MapDataset`
+            Map dataset
+        model : `~gammapy.modeling.models.SkyModel`
+            Sky model instance
+
+        Returns
+        -------
+        table : `~astropy.table.Table`
+            Table of sampled events
+        """
+        if not isinstance(model.spatial_model, PointSpatialModel):
+            raise TypeError(
+                f"Event sampler expects PointSpatialModel for a time varying source. Got {model.spatial_model} instead."
+            )
+
+        if not isinstance(model.spectral_model, ConstantSpectralModel):
+            raise TypeError(
+                f"Event sampler expects ConstantSpectralModel for a time varying source. Got {model.spectral_model} instead."
+            )
+
+        npred = self._evaluate_timevar_source(dataset, model=model)
+        data = npred.data[np.isfinite(npred.data)]
+        n_events = self.random_state.poisson(np.sum(data))
+
+        coords = npred.sample_coord(n_events=n_events, random_state=self.random_state)
+
+        coords["time"] = Time(coords["time"], format="mjd", scale="tt")
+
+        table = self._make_table(coords, dataset.gti.time_ref)
+
+        return table
+
+    def _sample_coord_time(self, npred, temporal_model, gti):
+        """Sample model components of a time-varying source.
+
+        Parameters
+        ----------
+        npred : `~gammapy.dataset.MapDataset`
+            Npred map
+        temporal_model : `~gammapy.modeling.models\
+            Temporal model of the source
+        gti : `~gammapy.data.GTI`
+             GTI of the dataset
+
+        Returns
+        -------
+        table : `~astropy.table.Table`
+            Table of sampled events
+        """
+        data = npred.data[np.isfinite(npred.data)]
+        n_events = self.random_state.poisson(np.sum(data))
+
+        coords = npred.sample_coord(n_events=n_events, random_state=self.random_state)
+
         time_start, time_stop, time_ref = (gti.time_start, gti.time_stop, gti.time_ref)
-        time = temporal_model.sample_time(
+        coords["time"] = temporal_model.sample_time(
             n_events=n_events,
             t_min=time_start,
             t_max=time_stop,
             random_state=self.random_state,
+            t_delta=self.t_delta,
         )
-        table["TIME"] = u.Quantity(((time.mjd - time_ref.mjd) * u.day).to(u.s)).to("s")
+
+        table = self._make_table(coords, time_ref)
+
         return table
 
     def sample_sources(self, dataset):
         """Sample source model components.
 
         Parameters
         ----------
         dataset : `~gammapy.datasets.MapDataset`
-            Map dataset.
+            Map dataset
 
         Returns
         -------
         events : `~gammapy.data.EventList`
             Event list
         """
 
@@ -73,38 +235,40 @@
                     dataset.exposure,
                     dataset.psf,
                     dataset.edisp,
                     dataset._geom,
                     dataset.mask,
                 )
 
-            flux = evaluator.compute_flux()
-            npred = evaluator.apply_exposure(flux)
-
             if evaluator.model.temporal_model is None:
                 temporal_model = ConstantTemporalModel()
             else:
                 temporal_model = evaluator.model.temporal_model
 
-            table = self._sample_coord_time(npred, temporal_model, dataset.gti)
+            if temporal_model.is_energy_dependent:
+                table = self._sample_coord_time_energy(dataset, evaluator.model)
+            else:
+                flux = evaluator.compute_flux()
+                npred = evaluator.apply_exposure(flux)
+                table = self._sample_coord_time(npred, temporal_model, dataset.gti)
 
             if len(table) == 0:
                 mcid = table.Column(name="MC_ID", length=0, dtype=int)
                 table.add_column(mcid)
 
             table["MC_ID"] = idx + 1
             table.meta["MID{:05d}".format(idx + 1)] = idx + 1
             table.meta["MMN{:05d}".format(idx + 1)] = evaluator.model.name
 
             events_all.append(EventList(table))
 
         return EventList.from_stack(events_all)
 
     def sample_background(self, dataset):
-        """Sample background
+        """Sample background.
 
         Parameters
         ----------
         dataset : `~gammapy.datasets.MapDataset`
             Map dataset
 
         Returns
@@ -137,15 +301,15 @@
             Energy dispersion map
         events : `~gammapy.data.EventList`
             Event list with the true energies
 
         Returns
         -------
         events : `~gammapy.data.EventList`
-            Event list with reconstructed energy column.
+            Event list with reconstructed energy column
         """
         coord = MapCoord(
             {
                 "lon": events.table["RA_TRUE"].quantity,
                 "lat": events.table["DEC_TRUE"].quantity,
                 "energy_true": events.table["ENERGY_TRUE"].quantity,
             },
@@ -158,22 +322,22 @@
 
     def sample_psf(self, psf_map, events):
         """Sample psf map.
 
         Parameters
         ----------
         psf_map : `~gammapy.irf.PSFMap`
-            PSF map.
+            PSF map
         events : `~gammapy.data.EventList`
-            Event list.
+            Event list
 
         Returns
         -------
         events : `~gammapy.data.EventList`
-            Event list with reconstructed position columns.
+            Event list with reconstructed position columns
         """
         coord = MapCoord(
             {
                 "lon": events.table["RA_TRUE"].quantity,
                 "lat": events.table["DEC_TRUE"].quantity,
                 "energy_true": events.table["ENERGY_TRUE"].quantity,
             },
@@ -188,72 +352,70 @@
     @staticmethod
     def event_det_coords(observation, events):
         """Add columns of detector coordinates (DETX-DETY) to the event list.
 
         Parameters
         ----------
         observation : `~gammapy.data.Observation`
-            In memory observation.
+            In memory observation
         events : `~gammapy.data.EventList`
-            Event list.
+            Event list
 
         Returns
         -------
         events : `~gammapy.data.EventList`
-            Event list with columns of event detector coordinates.
+            Event list with columns of event detector coordinates
         """
         sky_coord = SkyCoord(events.table["RA"], events.table["DEC"], frame="icrs")
-        frame = SkyOffsetFrame(origin=observation.pointing_radec.icrs)
+        frame = SkyOffsetFrame(origin=observation.get_pointing_icrs(observation.tmid))
         pseudo_fov_coord = sky_coord.transform_to(frame)
 
         events.table["DETX"] = pseudo_fov_coord.lon
         events.table["DETY"] = pseudo_fov_coord.lat
         return events
 
     @staticmethod
     def event_list_meta(dataset, observation):
         """Event list meta info.
 
         Parameters
         ----------
         dataset : `~gammapy.datasets.MapDataset`
-            Map dataset.
+            Map dataset
         observation : `~gammapy.data.Observation`
-            In memory observation.
+            In memory observation
 
         Returns
         -------
         meta : dict
-            Meta dictionary.
+            Meta dictionary
         """
         # See: https://gamma-astro-data-formats.readthedocs.io/en/latest/events/events.html#mandatory-header-keywords  # noqa: E501
         meta = {}
 
         meta["HDUCLAS1"] = "EVENTS"
         meta["EXTNAME"] = "EVENTS"
         meta[
             "HDUDOC"
         ] = "https://github.com/open-gamma-ray-astro/gamma-astro-data-formats"
         meta["HDUVERS"] = "0.2"
         meta["HDUCLASS"] = "GADF"
 
         meta["OBS_ID"] = observation.obs_id
 
-        meta["TSTART"] = (
-            ((observation.tstart.mjd - dataset.gti.time_ref.mjd) * u.day).to(u.s).value
-        )
-        meta["TSTOP"] = (
-            ((observation.tstop.mjd - dataset.gti.time_ref.mjd) * u.day).to(u.s).value
-        )
+        meta["TSTART"] = (observation.tstart - dataset.gti.time_ref).to_value("s")
+        meta["TSTOP"] = (observation.tstop - dataset.gti.time_ref).to_value("s")
+
         meta["ONTIME"] = observation.observation_time_duration.to("s").value
         meta["LIVETIME"] = observation.observation_live_time_duration.to("s").value
         meta["DEADC"] = 1 - observation.observation_dead_time_fraction
 
-        meta["RA_PNT"] = observation.pointing_radec.icrs.ra.deg
-        meta["DEC_PNT"] = observation.pointing_radec.icrs.dec.deg
+        fixed_icrs = observation.pointing.fixed_icrs
+        meta["RA_PNT"] = fixed_icrs.ra.deg
+        meta["DEC_PNT"] = fixed_icrs.dec.deg
 
         meta["EQUINOX"] = "J2000"
         meta["RADECSYS"] = "icrs"
 
         meta["CREATOR"] = "Gammapy {}".format(gammapy.__version__)
         meta["EUNIT"] = "TeV"
         meta["EVTVER"] = ""
@@ -269,15 +431,15 @@
             "DSVAL2"
         ] = f'{dataset._geom.axes["energy"].edges.min().value}:{dataset._geom.axes["energy"].edges.max().value}'  # noqa: E501
         meta["DSTYP3"] = "POS(RA,DEC)     "
 
         offset_max = np.max(dataset._geom.width).to_value("deg")
         meta[
             "DSVAL3"
-        ] = f"CIRCLE({observation.pointing_radec.ra.deg},{observation.pointing_radec.dec.deg},{offset_max})"  # noqa: E501
+        ] = f"CIRCLE({fixed_icrs.ra.deg},{fixed_icrs.dec.deg},{offset_max})"  # noqa: E501
         meta["DSUNI3"] = "deg             "
         meta["NDSKEYS"] = " 3 "
 
         # get first non background model component
         for model in dataset.models:
             if model is not dataset.background_model:
                 break
@@ -314,16 +476,15 @@
             else:
                 loc = observatory_locations["cta_south"]
 
         else:
             loc = observatory_locations[telescope.lower()]
 
         # this is not really correct but maybe OK for now
-        altaz_frame = AltAz(obstime=dataset.gti.time_start, location=loc)
-        coord_altaz = observation.pointing_radec.transform_to(altaz_frame)
+        coord_altaz = observation.pointing.get_altaz(dataset.gti.time_start, loc)
 
         meta["ALT_PNT"] = str(coord_altaz.alt.deg[0])
         meta["AZ_PNT"] = str(coord_altaz.az.deg[0])
 
         # TO DO: these keywords should be taken from the IRF of the dataset
         meta["ORIGIN"] = "Gammapy"
         meta["TELESCOP"] = observation.aeff.meta["TELESCOP"]
@@ -341,22 +502,22 @@
         """Run the event sampler, applying IRF corrections.
 
         Parameters
         ----------
         dataset : `~gammapy.datasets.MapDataset`
             Map dataset
         observation : `~gammapy.data.Observation`
-            In memory observation.
+            In memory observation
         edisp : Bool
-            It allows to include or exclude the Edisp in the simulation.
+            Whether to include or exclude the Edisp in the simulation
 
         Returns
         -------
         events : `~gammapy.data.EventList`
-            Event list.
+            Event list
         """
         if len(dataset.models) > 1:
             events_src = self.sample_sources(dataset)
 
             if len(events_src.table) > 0:
                 if dataset.psf:
                     events_src = self.sample_psf(dataset.psf, events_src)
```

### Comparing `gammapy-1.0rc2/gammapy/datasets/spectrum.py` & `gammapy-1.1rc1/gammapy/datasets/spectrum.py`

 * *Files 6% similar despite different names*

```diff
@@ -8,15 +8,15 @@
 
 __all__ = ["SpectrumDatasetOnOff", "SpectrumDataset"]
 
 log = logging.getLogger(__name__)
 
 
 class PlotMixin:
-    """Plot mixin for the spectral datasets"""
+    """Plot mixin for the spectral datasets."""
 
     def plot_fit(
         self,
         ax_spectrum=None,
         ax_residuals=None,
         kwargs_spectrum=None,
         kwargs_residuals=None,
@@ -24,26 +24,26 @@
         """Plot spectrum and residuals in two panels.
 
         Calls `~SpectrumDataset.plot_excess` and `~SpectrumDataset.plot_residuals_spectral`.
 
         Parameters
         ----------
         ax_spectrum : `~matplotlib.axes.Axes`
-            Axes to plot spectrum on.
+            Axes to plot spectrum on
         ax_residuals : `~matplotlib.axes.Axes`
-            Axes to plot residuals on.
+            Axes to plot residuals on
         kwargs_spectrum : dict
-            Keyword arguments passed to `~SpectrumDataset.plot_excess`.
+            Keyword arguments passed to `~SpectrumDataset.plot_excess`
         kwargs_residuals : dict
-            Keyword arguments passed to `~SpectrumDataset.plot_residuals_spectral`.
+            Keyword arguments passed to `~SpectrumDataset.plot_residuals_spectral`
 
         Returns
         -------
         ax_spectrum, ax_residuals : `~matplotlib.axes.Axes`
-            Spectrum and residuals plots.
+            Spectrum and residuals plots
 
         Examples
         --------
         >>> #Creating a spectral dataset
         >>> from gammapy.datasets import SpectrumDatasetOnOff
         >>> from gammapy.modeling.models import PowerLawSpectralModel, SkyModel
         >>> filename = "$GAMMAPY_DATA/joint-crab/spectra/hess/pha_obs23523.fits"
@@ -84,26 +84,26 @@
         self, ax=None, kwargs_counts=None, kwargs_background=None, **kwargs
     ):
         """Plot counts and background.
 
         Parameters
         ----------
         ax : `~matplotlib.axes.Axes`
-            Axes to plot on.
+            Axes to plot on
         kwargs_counts: dict
-            Keyword arguments passed to `~matplotlib.axes.Axes.hist` for the counts.
+            Keyword arguments passed to `~matplotlib.axes.Axes.hist` for the counts
         kwargs_background: dict
-            Keyword arguments passed to `~matplotlib.axes.Axes.hist` for the background.
+            Keyword arguments passed to `~matplotlib.axes.Axes.hist` for the background
         **kwargs: dict
-            Keyword arguments passed to both `~matplotlib.axes.Axes.hist`.
+            Keyword arguments passed to both `~matplotlib.axes.Axes.hist`
 
         Returns
         -------
         ax : `~matplotlib.axes.Axes`
-            Axes object.
+            Axes object
         """
         kwargs_counts = kwargs_counts or {}
         kwargs_background = kwargs_background or {}
 
         plot_kwargs = kwargs.copy()
         plot_kwargs.update(kwargs_counts)
         plot_kwargs.setdefault("label", "Counts")
@@ -115,24 +115,24 @@
         plot_kwargs.setdefault("label", "Background")
         self.background.plot_hist(ax=ax, **plot_kwargs)
 
         ax.legend(numpoints=1)
         return ax
 
     def plot_masks(self, ax=None, kwargs_fit=None, kwargs_safe=None):
-        """Plot mask safe and mask fit
+        """Plot safe mask and fit mask.
 
         Parameters
         ----------
         ax : `~matplotlib.axes.Axes`
-            Axes to plot on.
+            Axes to plot on
         kwargs_fit: dict
-            Keyword arguments passed to `~RegionNDMap.plot_mask()` for mask fit.
+            Keyword arguments passed to `~RegionNDMap.plot_mask()` for mask fit
         kwargs_safe: dict
-            Keyword arguments passed to `~RegionNDMap.plot_mask()` for mask safe.
+            Keyword arguments passed to `~RegionNDMap.plot_mask()` for mask safe
 
         Returns
         -------
         ax : `~matplotlib.axes.Axes`
             Axes object.
 
         Examples
@@ -248,47 +248,64 @@
 
         if self.edisp is not None:
             kernel = self.edisp.get_edisp_kernel()
             kernel.plot_matrix(ax=ax3, add_cbar=True)
 
 
 class SpectrumDataset(PlotMixin, MapDataset):
+    """Main dataset for spectrum fitting (1D analysis).
+    It bundles together binned counts, background, IRFs into `~gammapy.maps.RegionNDMap` (a Map with only one spatial bin).
+    A safe mask and a fit mask can be added to exclude bins during the analysis.
+    If models are assigned to it, it can compute the predicted number of counts and the statistic function,
+    here the Cash statistic (see `~gammapy.stats.cash`).
+
+    For more information see :ref:`datasets`.
+    """
+
     stat_type = "cash"
     tag = "SpectrumDataset"
 
     def cutout(self, *args, **kwargs):
         raise NotImplementedError("Method not supported on a spectrum dataset")
 
     def plot_residuals_spatial(self, *args, **kwargs):
         raise NotImplementedError("Method not supported on a spectrum dataset")
 
     def to_spectrum_dataset(self, *args, **kwargs):
         raise NotImplementedError("Already a Spectrum Dataset. Method not supported")
 
 
 class SpectrumDatasetOnOff(PlotMixin, MapDatasetOnOff):
+    """Spectrum dataset for 1D on-off likelihood fitting.
+    It bundles together the binned on and off counts, the binned IRFs as well as the on and off acceptances.
+
+    A fit mask can be added to exclude bins during the analysis.
+
+    It uses the Wstat statistic (see `~gammapy.stats.wstat`).
+
+    For more information see :ref:`datasets`.
+    """
+
     stat_type = "wstat"
     tag = "SpectrumDatasetOnOff"
 
     def cutout(self, *args, **kwargs):
         raise NotImplementedError("Method not supported on a spectrum dataset")
 
     def plot_residuals_spatial(self, *args, **kwargs):
         raise NotImplementedError("Method not supported on a spectrum dataset")
 
     @classmethod
     def read(cls, filename, format="ogip", **kwargs):
-        """Read from file
+        """Read from file.
 
-        For OGIP formats, filename is assumed to the name of a PHA file where
-        BKG file, ARF, and RMF names
-        must be set in the PHA header and be present in the same folder.
-        For details, see `OGIPDatasetReader.read`
+        For OGIP formats, filename is the name of a PHA file. The BKG, ARF, and RMF file names must be
+        set in the PHA header and the files must be present in the same folder. For details, see `OGIPDatasetReader.read`.
 
-        For the GADF format, a MapDataset serialisation is used
+        For the GADF format, a MapDataset serialisation is used.
 
         Parameters
         ----------
         filename : `~pathlib.Path` or str
             OGIP PHA file to read
         format : {"ogip", "ogip-sherpa", "gadf"}
             Format to use.
@@ -303,15 +320,15 @@
         return reader.read()
 
     def write(self, filename, overwrite=False, format="ogip"):
         """Write spectrum dataset on off to file.
 
         Can be serialised either as a `MapDataset` with a `RegionGeom`
         following the GADF specifications, or as per the OGIP format.
-        For OGIP formats specs see `OGIPDatasetWriter`
+        For OGIP formats specs, see `OGIPDatasetWriter`.
 
         Parameters
         ----------
         filename : `~pathlib.Path` or str
             Filename to write to.
         overwrite : bool
             Overwrite existing file.
@@ -329,15 +346,15 @@
             writer.write(self)
         else:
             raise ValueError(f"{format} is not a valid serialisation format")
 
     @classmethod
     def from_dict(cls, data, **kwargs):
         """Create spectrum dataset from dict.
-        Reads file from the disk as specified in the dict
+        Reads file from the disk as specified in the dict.
 
         Parameters
         ----------
         data : dict
             Dict containing data to create dataset from.
 
         Returns
@@ -354,44 +371,44 @@
     def to_dict(self):
         """Convert to dict for YAML serialization."""
         filename = f"pha_obs{self.name}.fits"
         return {"name": self.name, "type": self.tag, "filename": filename}
 
     @classmethod
     def from_spectrum_dataset(cls, **kwargs):
-        """Create spectrum dataseton off from another dataset.
+        """Create a SpectrumDatasetOnOff from a `SpectrumDataset` dataset.
 
         Parameters
         ----------
         dataset : `SpectrumDataset`
             Spectrum dataset defining counts, edisp, exposure etc.
         acceptance : `~numpy.array` or float
             Relative background efficiency in the on region.
         acceptance_off : `~numpy.array` or float
             Relative background efficiency in the off region.
         counts_off : `~gammapy.maps.RegionNDMap`
-            Off counts spectrum . If the dataset provides a background model,
+            Off counts spectrum. If the dataset provides a background model,
             and no off counts are defined. The off counts are deferred from
             counts_off / alpha.
 
         Returns
         -------
         dataset : `SpectrumDatasetOnOff`
             Spectrum dataset on off.
         """
         return cls.from_map_dataset(**kwargs)
 
     def to_spectrum_dataset(self, name=None):
-        """Convert a SpectrumDatasetOnOff to a SpectrumDataset
-        The background model template is taken as alpha*counts_off
+        """Convert a SpectrumDatasetOnOff to a SpectrumDataset.
+        The background model template is taken as alpha*counts_off.
 
         Parameters
         ----------
         name: str
             Name of the new dataset
 
         Returns
         -------
         dataset: `SpectrumDataset`
-            SpectrumDatset with cash statistics
+            SpectrumDataset with Cash statistic
         """
         return self.to_map_dataset(name=name).to_spectrum_dataset(on_region=None)
```

### Comparing `gammapy-1.0rc2/gammapy/datasets/tests/test_datasets.py` & `gammapy-1.1rc1/gammapy/datasets/tests/test_datasets.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/datasets/tests/test_evaluator.py` & `gammapy-1.1rc1/gammapy/datasets/tests/test_evaluator.py`

 * *Files 4% similar despite different names*

```diff
@@ -210,7 +210,47 @@
     exposure = Map.from_geom(geom, unit="m2 s")
     exposure.data += 1.0
 
     evaluator = MapEvaluator(model=model, exposure=exposure)
 
     with mpl_plot_check():
         evaluator.peek()
+
+
+def test_norm_only_changed():
+    center = SkyCoord("0 deg", "0 deg", frame="galactic")
+    energy_axis_true = MapAxis.from_energy_bounds(
+        ".1 TeV", "10 TeV", nbin=2, name="energy_true"
+    )
+    geom = WcsGeom.create(
+        skydir=center,
+        width=1 * u.deg,
+        axes=[energy_axis_true],
+        frame="galactic",
+        binsz=0.2 * u.deg,
+    )
+
+    spectral_model = PowerLawSpectralModel(index=2, amplitude="1e-11 TeV-1 s-1 m-2")
+
+    spatial_model = PointSpatialModel(
+        lon_0=0 * u.deg, lat_0=0 * u.deg, frame="galactic"
+    )
+    model = SkyModel(spectral_model=spectral_model, spatial_model=spatial_model)
+
+    exposure = Map.from_geom(geom, unit="m2 s")
+    exposure.data += 1.0
+
+    psf = PSFKernel.from_gauss(geom, sigma="0.1 deg")
+
+    evaluator = MapEvaluator(model=model, exposure=exposure, psf=psf)
+
+    _ = evaluator.compute_npred()
+
+    spectral_model.amplitude.value *= 2
+    assert evaluator.parameter_norm_only_changed
+
+    spectral_model.index.value *= 2
+    assert not evaluator.parameter_norm_only_changed
+
+    spectral_model.amplitude.value *= 2
+    spectral_model.index.value *= 2
+    assert not evaluator.parameter_norm_only_changed
```

### Comparing `gammapy-1.0rc2/gammapy/datasets/tests/test_flux_points.py` & `gammapy-1.1rc1/gammapy/datasets/tests/test_flux_points.py`

 * *Files 2% similar despite different names*

```diff
@@ -27,15 +27,17 @@
 
 
 @pytest.fixture()
 def dataset():
     path = "$GAMMAPY_DATA/tests/spectrum/flux_points/diff_flux_points.fits"
     table = Table.read(make_path(path))
     table["e_ref"] = table["e_ref"].quantity.to("TeV")
-    gti = GTI.create(start=0 * u.s, stop=30 * u.min)
+    gti = GTI.create(
+        start=0 * u.s, stop=30 * u.min, reference_time=Time("2000-01-01", scale="utc")
+    )
     data = FluxPoints.from_table(table, format="gadf-sed")
     data.gti = gti
     model = SkyModel(
         spectral_model=PowerLawSpectralModel(
             index=2.3, amplitude="2e-13 cm-2 s-1 TeV-1", reference="1 TeV"
         )
     )
```

### Comparing `gammapy-1.0rc2/gammapy/datasets/tests/test_io.py` & `gammapy-1.1rc1/gammapy/datasets/tests/test_io.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/datasets/tests/test_map.py` & `gammapy-1.1rc1/gammapy/datasets/tests/test_map.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import json
 import pytest
 import numpy as np
-from numpy.testing import assert_allclose
+from numpy.testing import assert_allclose, assert_equal
 import astropy.units as u
 from astropy.coordinates import SkyCoord
 from astropy.table import Table
 from regions import CircleSkyRegion
 from gammapy.catalog import SourceCatalog3FHL
 from gammapy.data import GTI
 from gammapy.datasets import Datasets, MapDataset, MapDatasetOnOff
@@ -14,17 +14,26 @@
 from gammapy.irf import (
     EDispKernelMap,
     EDispMap,
     EffectiveAreaTable2D,
     EnergyDependentMultiGaussPSF,
     EnergyDispersion2D,
     PSFMap,
+    RecoPSFMap,
 )
 from gammapy.makers.utils import make_map_exposure_true_energy, make_psf_map
-from gammapy.maps import HpxGeom, Map, MapAxis, RegionGeom, WcsGeom, WcsNDMap
+from gammapy.maps import (
+    HpxGeom,
+    LabelMapAxis,
+    Map,
+    MapAxis,
+    RegionGeom,
+    WcsGeom,
+    WcsNDMap,
+)
 from gammapy.maps.io import JsonQuantityEncoder
 from gammapy.modeling import Fit
 from gammapy.modeling.models import (
     DiskSpatialModel,
     FoVBackgroundModel,
     GaussianSpatialModel,
     Models,
@@ -921,21 +930,30 @@
     stacked.stack(dataset2)
 
     stacked.models = [sky_model]
     npred_b = stacked.npred()
 
     assert_allclose(npred_b.data.sum(), 1459.985035, 1e-5)
     assert_allclose(stacked.npred_background().data.sum(), 1360.00, 1e-5)
+    assert_allclose(stacked.background.data.sum(), 1360, 1e-5)
     assert_allclose(stacked.counts.data.sum(), 9000, 1e-5)
     assert_allclose(stacked.mask_safe.data.sum(), 4600)
     assert_allclose(stacked.mask_fit.data.sum(), 4600)
     assert_allclose(stacked.exposure.data.sum(), 1.6e11)
 
     assert_allclose(stacked.meta_table["OBS_ID"][0], [0, 1])
 
+    # stacking when no safe masks are defined
+    dataset1 = MapDataset(counts=cnt1, background=bkg1)
+    stacked = MapDataset.from_geoms(**dataset1.geoms)
+    for i in range(3):
+        stacked.stack(dataset1)
+    assert_allclose(stacked.background.data.sum(), 2880.0, 1e-5)
+    assert_allclose(stacked.counts.data.sum(), 14400.0, 1e-5)
+
 
 @requires_data()
 def test_npred(sky_model, geom, geom_etrue):
     dataset = get_map_dataset(geom, geom_etrue)
 
     pwl = PowerLawSpectralModel()
     gauss = GaussianSpatialModel(
@@ -943,32 +961,54 @@
     )
     model1 = SkyModel(pwl, gauss, name="m1")
 
     bkg = FoVBackgroundModel(dataset_name=dataset.name)
     dataset.models = [bkg, sky_model, model1]
 
     assert_allclose(
-        dataset.npred_signal(model_name=model1.name).data.sum(), 150.7487, rtol=1e-3
+        dataset.npred_signal(model_names=[model1.name]).data.sum(), 150.7487, rtol=1e-3
+    )
+    npred_model1_not_stack = dataset.npred_signal(
+        model_names=[model1.name], stack=False
     )
+    assert isinstance(npred_model1_not_stack.geom.axes[-1], LabelMapAxis)
+    assert npred_model1_not_stack.geom.axes[-1].name == "models"
+    assert_equal(npred_model1_not_stack.geom.axes[-1].center, [model1.name])
+
     assert dataset._background_cached is None
     assert_allclose(dataset.npred_background().data.sum(), 4000.0, rtol=1e-3)
     assert_allclose(dataset._background_cached.data.sum(), 4000.0, rtol=1e-3)
 
     assert_allclose(dataset.npred().data.sum(), 9676.047906, rtol=1e-3)
     assert_allclose(dataset.npred_signal().data.sum(), 5676.04790, rtol=1e-3)
+    assert_allclose(
+        dataset.npred_signal(model_names=[model1.name, sky_model.name]).data.sum(),
+        5676.04790,
+        rtol=1e-3,
+    )
+
+    npred_all_models_not_stack = dataset.npred_signal(
+        model_names=[model1.name, sky_model.name], stack=False
+    )
+    assert_allclose(npred_all_models_not_stack.geom.data_shape, (2, 2, 100, 100))
+    assert_allclose(
+        npred_all_models_not_stack.sum_over_axes(["models"]).data.sum(),
+        5676.04790,
+        rtol=1e-3,
+    )
 
     bkg.spectral_model.norm.value = 1.1
     assert_allclose(dataset.npred_background().data.sum(), 4400.0, rtol=1e-3)
     assert_allclose(dataset._background_cached.data.sum(), 4400.0, rtol=1e-3)
 
     with pytest.raises(
         KeyError,
         match="m2",
     ):
-        dataset.npred_signal(model_name="m2")
+        dataset.npred_signal(model_names=["m2"])
 
 
 def test_stack_npred():
     pwl = PowerLawSpectralModel()
     gauss = GaussianSpatialModel(sigma="0.2 deg")
     model = SkyModel(pwl, gauss)
 
@@ -1860,7 +1900,12 @@
 
 @requires_data()
 def test_peek(images):
     dataset = get_map_dataset_onoff(images)
 
     with mpl_plot_check():
         dataset.peek()
+
+
+def test_create_psf_reco(geom):
+    dat = MapDataset.create(geom, reco_psf=True)
+    assert isinstance(dat.psf, RecoPSFMap)
```

### Comparing `gammapy-1.0rc2/gammapy/datasets/tests/test_spectrum.py` & `gammapy-1.1rc1/gammapy/datasets/tests/test_spectrum.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,31 +1,30 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import pytest
 import numpy as np
-from numpy.testing import assert_allclose
+from numpy.testing import assert_allclose, assert_equal
 import astropy.units as u
 from astropy.table import Table
 from astropy.time import Time
 from gammapy.data import GTI
 from gammapy.datasets import Datasets, SpectrumDataset, SpectrumDatasetOnOff
 from gammapy.irf import EDispKernelMap, EffectiveAreaTable2D
 from gammapy.makers.utils import make_map_exposure_true_energy
-from gammapy.maps import MapAxis, RegionGeom, RegionNDMap, WcsGeom
+from gammapy.maps import LabelMapAxis, MapAxis, RegionGeom, RegionNDMap, WcsGeom
 from gammapy.modeling import Fit
 from gammapy.modeling.models import (
     ConstantSpectralModel,
     ExpCutoffPowerLawSpectralModel,
     Models,
     PowerLawSpectralModel,
     SkyModel,
 )
 from gammapy.utils.random import get_random_state
 from gammapy.utils.regions import compound_region_to_regions
 from gammapy.utils.testing import assert_time_allclose, mpl_plot_check, requires_data
-from gammapy.utils.time import time_ref_to_dict
 
 
 def test_data_shape(spectrum_dataset):
     assert spectrum_dataset.data_shape[0] == 30
 
 
 def test_str(spectrum_dataset):
@@ -122,17 +121,41 @@
     npred = spectrum_dataset.npred()
 
     assert_allclose(npred.data.sum(), 64.8)
 
     npred_sig = spectrum_dataset.npred_signal()
     assert_allclose(npred_sig.data.sum(), 64.8)
 
-    npred_sig_model1 = spectrum_dataset.npred_signal(model_name=model_1.name)
+    npred_sig_model1 = spectrum_dataset.npred_signal(model_names=[model_1.name])
     assert_allclose(npred_sig_model1.data.sum(), 32.4)
 
+    assert_allclose(
+        spectrum_dataset.npred_signal(
+            model_names=[model_1.name, model_2.name]
+        ).data.sum(),
+        64.8,
+    )
+
+    npred_model1_not_stack = spectrum_dataset.npred_signal(
+        model_names=[model_1.name], stack=False
+    )
+    assert_allclose(npred_model1_not_stack.geom.data_shape, (1, 3, 1, 1))
+    assert_allclose(npred_model1_not_stack.data.sum(), 32.4)
+    assert isinstance(npred_model1_not_stack.geom.axes[-1], LabelMapAxis)
+    assert npred_model1_not_stack.geom.axes[-1].name == "models"
+    assert_equal(npred_model1_not_stack.geom.axes[-1].center, [model_1.name])
+
+    npred_all_models_not_stack = spectrum_dataset.npred_signal(
+        model_names=[model_1.name, model_2.name], stack=False
+    )
+    assert_allclose(npred_all_models_not_stack.geom.data_shape, (2, 3, 1, 1))
+    assert_allclose(
+        npred_all_models_not_stack.sum_over_axes(["models"]).data.sum(), 64.8
+    )
+
 
 def test_npred_spatial_model(spectrum_dataset):
     model = SkyModel.create("pl", "gauss", name="test")
 
     spectrum_dataset.models = [model]
 
     npred = spectrum_dataset.npred()
@@ -345,15 +368,15 @@
     with mpl_plot_check():
         spectrum_dataset.peek()
 
 
 class TestSpectrumOnOff:
     """Test ON OFF SpectrumDataset"""
 
-    def setup(self):
+    def setup_method(self):
         etrue = np.logspace(-1, 1, 10) * u.TeV
         self.e_true = MapAxis.from_energy_edges(etrue, name="energy_true")
         ereco = np.logspace(-1, 1, 5) * u.TeV
         elo = ereco[:-1]
         self.e_reco = MapAxis.from_energy_edges(ereco, name="energy")
 
         start = u.Quantity([0], "s")
@@ -666,15 +689,15 @@
         assert_allclose(np.squeeze(grouped.acceptance_off), 40)
 
 
 @requires_data()
 class TestSpectralFit:
     """Test fit in astrophysical scenario"""
 
-    def setup(self):
+    def setup_method(self):
         path = "$GAMMAPY_DATA/joint-crab/spectra/hess/"
         self.datasets = Datasets(
             [
                 SpectrumDatasetOnOff.read(path + "pha_obs23523.fits"),
                 SpectrumDatasetOnOff.read(path + "pha_obs23592.fits"),
             ]
         )
@@ -792,17 +815,15 @@
     path = "$GAMMAPY_DATA/joint-crab/spectra/hess/"
     obs1 = SpectrumDatasetOnOff.read(path + "pha_obs23523.fits")
     obs2 = SpectrumDatasetOnOff.read(path + "pha_obs23592.fits")
     return [obs1, obs2]
 
 
 def make_gti(times, time_ref="2010-01-01"):
-    meta = time_ref_to_dict(time_ref)
-    table = Table(times, meta=meta)
-    return GTI(table)
+    return GTI.create(times["START"], times["STOP"], time_ref)
 
 
 @requires_data("gammapy-data")
 def make_observation_list():
     """obs with dummy IRF"""
     nbin = 3
     energy = np.logspace(-1, 1, nbin + 1) * u.TeV
@@ -831,16 +852,18 @@
 
     aeff = RegionNDMap.from_geom(geom_true, data=1, unit="m2")
     edisp = EDispKernelMap.from_gauss(
         energy_axis=axis, energy_axis_true=axis_true, sigma=0.2, bias=0, geom=geom
     )
 
     time_ref = Time("2010-01-01")
-    gti1 = make_gti({"START": [5, 6, 1, 2], "STOP": [8, 7, 3, 4]}, time_ref=time_ref)
-    gti2 = make_gti({"START": [14], "STOP": [15]}, time_ref=time_ref)
+    gti1 = make_gti(
+        {"START": [5, 6, 1, 2] * u.s, "STOP": [8, 7, 3, 4] * u.s}, time_ref=time_ref
+    )
+    gti2 = make_gti({"START": [14] * u.s, "STOP": [15] * u.s}, time_ref=time_ref)
 
     exposure = aeff * livetime
     exposure.meta["livetime"] = livetime
 
     obs1 = SpectrumDatasetOnOff(
         counts=on_vector,
         counts_off=off_vector1,
@@ -866,15 +889,15 @@
 
     obs_list = [obs1, obs2]
     return obs_list
 
 
 @requires_data("gammapy-data")
 class TestSpectrumDatasetOnOffStack:
-    def setup(self):
+    def setup_method(self):
         self.datasets = _read_hess_obs()
         # Change threshold to make stuff more interesting
 
         geom = self.datasets[0]._geom
         self.datasets[0].mask_safe = geom.energy_mask(
             energy_min=1.2 * u.TeV, energy_max=50 * u.TeV
         )
@@ -941,18 +964,17 @@
         # When the OFF stack observation counts=0, the alpha is averaged on the
         # total OFF counts for each run.
         assert_allclose(obs1.alpha.data[1], 2.5 / 8.0)
 
     def test_stack_gti(self):
         obs1, obs2 = make_observation_list()
         obs1.stack(obs2)
-        table_gti = Table({"START": [1.0, 5.0, 14.0], "STOP": [4.0, 8.0, 15.0]})
-        table_gti_stacked_obs = obs1.gti.table
-        assert_allclose(table_gti_stacked_obs["START"], table_gti["START"])
-        assert_allclose(table_gti_stacked_obs["STOP"], table_gti["STOP"])
+
+        assert_allclose(obs1.gti.met_start.value, [1.0, 5.0, 14.0])
+        assert_allclose(obs1.gti.met_stop.value, [4.0, 8.0, 15.0])
 
 
 @requires_data("gammapy-data")
 def test_datasets_stack_reduce():
     datasets = Datasets()
     obs_ids = [23523, 23526, 23559, 23592]
 
@@ -1036,15 +1058,15 @@
     assert datasets_read[1].name == datasets[1].name
     assert datasets_read[1].counts.data.sum() == datasets[1].counts.data.sum()
 
 
 class TestFit:
     """Test fit on counts spectra without any IRFs"""
 
-    def setup(self):
+    def setup_method(self):
         self.nbins = 30
         energy = np.logspace(-1, 1, self.nbins + 1) * u.TeV
         self.source_model = SkyModel(
             spectral_model=PowerLawSpectralModel(
                 index=2, amplitude=1e5 * u.Unit("cm-2 s-1 TeV-1"), reference=0.1 * u.TeV
             )
         )
@@ -1151,7 +1173,21 @@
 
         values = np.linspace(0.95 * true_idx, 1.05 * true_idx, 100)
         self.source_model.spectral_model.index.scan_values = values
 
         profile = fit.stat_profile(datasets=[dataset], parameter="index")
         actual = values[np.argmin(profile["stat_scan"])]
         assert_allclose(actual, true_idx, rtol=0.01)
+
+
+def test_stat_sum():
+    axis = MapAxis.from_energy_bounds(0.1, 10, 5, unit="TeV")
+    geom = RegionGeom.create(None, axes=[axis])
+    dataset = SpectrumDatasetOnOff.create(geom)
+    dataset.counts_off = None
+
+    stat = dataset.stat_sum()
+    assert stat == 0
+
+    dataset.mask_safe.data[0] = True
+    with pytest.raises(AttributeError):
+        dataset.stat_sum()
```

### Comparing `gammapy-1.0rc2/gammapy/estimators/__init__.py` & `gammapy-1.1rc1/gammapy/estimators/__init__.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/estimators/core.py` & `gammapy-1.1rc1/gammapy/estimators/core.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/estimators/flux.py` & `gammapy-1.1rc1/gammapy/estimators/flux.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import logging
 import numpy as np
 from gammapy.datasets import Datasets
 from gammapy.estimators.parameter import ParameterEstimator
 from gammapy.maps import Map, MapAxis
-from gammapy.modeling import Parameter, Parameters
+from gammapy.modeling import Parameter
 from gammapy.modeling.models import ScaleSpectralModel
 
 log = logging.getLogger(__name__)
 
 
 class FluxEstimator(ParameterEstimator):
     """Flux estimator.
@@ -117,15 +117,16 @@
         if ref_model.is_norm_spectral_model:
             raise ValueError(
                 "Instances of `NormSpectralModel` are not supported for flux point estimation."
             )
 
         scale_model = ScaleSpectralModel(ref_model)
 
-        norms = Parameters([p for p in ref_model.parameters if p.is_norm])
+        norms = ref_model.parameters.norm_parameters
+
         if len(norms) == 0 or len(norms.free_parameters) > 1:
             raise ValueError(
                 f"{self.tag} requires one and only one free 'norm' or 'amplitude' parameter"
                 " in the model to run"
             )
         elif len(norms.free_parameters) == 1:
             norms = norms.free_parameters
@@ -147,15 +148,15 @@
             Dict with an array with one entry per dataset with the sum of the
             masked npred excess.
         """
         npred_excess = []
 
         for dataset in datasets:
             name = datasets.models[self.source].name
-            npred_signal = dataset.npred_signal(model_name=name)
+            npred_signal = dataset.npred_signal(model_names=[name])
             npred = Map.from_geom(dataset.counts.geom)
             npred.stack(npred_signal)
             npred_excess.append(npred.data[dataset.mask].sum())
 
         return {"npred_excess": np.array(npred_excess), "datasets": datasets.names}
 
     def run(self, datasets):
```

### Comparing `gammapy-1.0rc2/gammapy/estimators/map/asmooth.py` & `gammapy-1.1rc1/gammapy/estimators/map/asmooth.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/estimators/map/core.py` & `gammapy-1.1rc1/gammapy/estimators/map/core.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,12 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import logging
 import numpy as np
 from astropy import units as u
 from astropy.io import fits
-from astropy.table import Table
 from astropy.utils import classproperty
 from gammapy.data import GTI
 from gammapy.maps import Map, Maps, TimeMapAxis
 from gammapy.modeling.models import (
     Models,
     PowerLawSpectralModel,
     SkyModel,
@@ -427,15 +426,15 @@
         """Predicted background counts from best fit hypothesis"""
         self._check_quantity("npred")
         self._check_quantity("npred_excess")
         return self.npred - self.npred_excess
 
     @property
     def npred_excess(self):
-        """Predicted excess count  rom best fit hypothesis"""
+        """Predicted excess count from best fit hypothesis"""
         self._check_quantity("npred_excess")
         return self._data["npred_excess"]
 
     def _expand_dims(self, data):
         # TODO: instead make map support broadcasting
         axes = self.npred.geom.axes
         # here we need to rely on broadcasting
@@ -955,15 +954,15 @@
         hdu_primary.header["SED_TYPE"] = sed_type
         hdulist = fits.HDUList([hdu_primary])
 
         maps = self.to_maps(sed_type=sed_type)
         hdulist.extend(maps.to_hdulist(hdu_bands=hdu_bands)[exclude_primary])
 
         if self.gti:
-            hdu = fits.BinTableHDU(self.gti.table, name="GTI")
+            hdu = self.gti.to_table_hdu(format="gadf")
             hdulist.append(hdu)
 
         return hdulist
 
     @classmethod
     def from_hdulist(cls, hdulist, hdu_bands=None, sed_type=None):
         """Create flux map dataset from list of HDUs.
@@ -992,15 +991,15 @@
 
         if filename:
             reference_model = Models.read(filename)[0]
         else:
             reference_model = None
 
         if "GTI" in hdulist:
-            gti = GTI(Table.read(hdulist["GTI"]))
+            gti = GTI.from_table_hdu(hdulist["GTI"])
         else:
             gti = None
 
         return cls.from_maps(
             maps=maps, sed_type=sed_type, reference_model=reference_model, gti=gti
         )
```

### Comparing `gammapy-1.0rc2/gammapy/estimators/map/excess.py` & `gammapy-1.1rc1/gammapy/estimators/map/excess.py`

 * *Files 12% similar despite different names*

```diff
@@ -19,60 +19,60 @@
 log = logging.getLogger(__name__)
 
 
 def convolved_map_dataset_counts_statistics(dataset, kernel, mask, correlate_off):
     """Return CountsDataset objects containing smoothed maps from the MapDataset"""
     # Kernel is modified later make a copy here
     kernel = copy.deepcopy(kernel)
-    kernel.normalize("peak")
+    kernel_data = kernel.data / kernel.data.max()
 
     # fft convolution adds numerical noise, to ensure integer results we call
     # np.rint
     n_on = dataset.counts * mask
-    n_on_conv = np.rint(n_on.convolve(kernel.array).data)
+    n_on_conv = np.rint(n_on.convolve(kernel_data).data)
 
     if isinstance(dataset, MapDatasetOnOff):
         n_off = dataset.counts_off * mask
         npred_sig = dataset.npred_signal() * mask
         acceptance_on = dataset.acceptance * mask
         acceptance_off = dataset.acceptance_off * mask
 
-        npred_sig_convolve = npred_sig.convolve(kernel.array)
+        npred_sig_convolve = npred_sig.convolve(kernel_data)
         if correlate_off:
             background = dataset.background * mask
             background.data[dataset.acceptance_off == 0] = 0.0
-            background_conv = background.convolve(kernel.array)
+            background_conv = background.convolve(kernel_data)
 
-            n_off = n_off.convolve(kernel.array)
+            n_off = n_off.convolve(kernel_data)
             with np.errstate(invalid="ignore", divide="ignore"):
                 alpha = background_conv / n_off
 
         else:
-            acceptance_on_convolve = acceptance_on.convolve(kernel.array)
+            acceptance_on_convolve = acceptance_on.convolve(kernel_data)
 
             with np.errstate(invalid="ignore", divide="ignore"):
                 alpha = acceptance_on_convolve / acceptance_off
 
         return WStatCountsStatistic(
             n_on_conv.data, n_off.data, alpha.data, npred_sig_convolve.data
         )
     else:
 
         npred = dataset.npred() * mask
-        background_conv = npred.convolve(kernel.array)
+        background_conv = npred.convolve(kernel_data)
         return CashCountsStatistic(n_on_conv.data, background_conv.data)
 
 
 class ExcessMapEstimator(Estimator):
     """Computes correlated excess, significance and error maps from a map dataset.
 
     If a model is set on the dataset the excess map estimator will compute the
     excess taking into account the predicted counts of the model.
 
-    ..note::
+    .. note::
 
         By default the excess estimator correlates the off counts as well to avoid
         artifacts at the edges of the :term:`FoV` for stacked on-off datasets.
         However when the on-off dataset has been derived from a ring background
         estimate, this leads to the off counts being correlated twice. To avoid
         artifacts and the double correlation, the `ExcessMapEstimator` has to
         be applied per dataset and the resulting maps need to be stacked, taking
@@ -191,60 +191,118 @@
         else:
             resampled_dataset.background = dataset.npred().resample_axis(axis=axis)
             resampled_dataset.models = None
 
         result = self.estimate_excess_map(resampled_dataset)
         return result
 
-    def estimate_excess_map(self, dataset):
-        """Estimate excess and ts maps for single dataset.
-
-        If exposure is defined, a flux map is also computed.
+    def estimate_kernel(self, dataset):
+        """Get the convolution kernel for the input dataset.
 
         Parameters
         ----------
-        dataset : `MapDataset`
-            Map dataset
+        dataset : `~gammapy.datasets.MapDataset`
+            Input dataset.
+
+        Returns
+        -------
+        kernel : `~astropy.convolution.Tophat2DKernel`
+            Kernel
         """
 
         pixel_size = np.mean(np.abs(dataset.counts.geom.wcs.wcs.cdelt))
         size = self.correlation_radius.deg / pixel_size
         kernel = Tophat2DKernel(size)
 
-        geom = dataset.counts.geom
+        geom = dataset.counts.geom.to_image()
+        geom = geom.to_odd_npix(max_radius=self.correlation_radius)
+        return Map.from_geom(geom, data=kernel.array)
+
+    @staticmethod
+    def estimate_mask_default(dataset):
+        """Get mask used by the estimator.
 
+        Parameters
+        ----------
+        dataset : `~gammapy.datasets.MapDataset`
+            Input dataset.
+
+        Returns
+        -------
+        mask : `Map`
+            Mask map
+        """
         if dataset.mask_fit:
             mask = dataset.mask
         elif dataset.mask_safe:
             mask = dataset.mask_safe
         else:
-            mask = Map.from_geom(geom, data=True, dtype=bool)
+            mask = Map.from_geom(dataset.counts.geom, data=True, dtype=bool)
+        return mask
+
+    def estimate_exposure_reco_energy(self, dataset, kernel, mask):
+        """Estimate exposure map in reconstructed energy for a single dataset
+           assuming the given spectral_model shape.
+
+        Parameters
+        ----------
+        dataset : `MapDataset`
+            Map dataset
+        kernel : `~astropy.convolution.Tophat2DKernel`
+            Kernel
+        mask : `Map`
+            Mask map
+
+        Returns
+        -------
+        reco_exposure : `Map`
+            Reconstructed exposure map
+        """
+        if dataset.exposure:
+            reco_exposure = estimate_exposure_reco_energy(
+                dataset, self.spectral_model, normalize=False
+            )
+            with np.errstate(invalid="ignore", divide="ignore"):
+                reco_exposure = reco_exposure.convolve(kernel.data) / mask.convolve(
+                    kernel.data
+                )
+        else:
+            reco_exposure = 1
+        return reco_exposure
+
+    def estimate_excess_map(self, dataset):
+        """Estimate excess and ts maps for a single dataset.
+
+        If exposure is defined, a flux map is also computed.
+
+        Parameters
+        ----------
+        dataset : `MapDataset`
+            Map dataset
+        """
+
+        kernel = self.estimate_kernel(dataset)
+
+        geom = dataset.counts.geom
+
+        mask = self.estimate_mask_default(dataset)
 
         counts_stat = convolved_map_dataset_counts_statistics(
             dataset, kernel, mask, self.correlate_off
         )
 
         maps = {}
         maps["npred"] = Map.from_geom(geom, data=counts_stat.n_on)
         maps["npred_excess"] = Map.from_geom(geom, data=counts_stat.n_sig)
         maps["counts"] = maps["npred"]
 
         maps["ts"] = Map.from_geom(geom, data=counts_stat.ts)
         maps["sqrt_ts"] = Map.from_geom(geom, data=counts_stat.sqrt_ts)
 
-        if dataset.exposure:
-            reco_exposure = estimate_exposure_reco_energy(
-                dataset, self.spectral_model, normalize=False
-            )
-            with np.errstate(invalid="ignore", divide="ignore"):
-                reco_exposure = reco_exposure.convolve(kernel.array) / mask.convolve(
-                    kernel.array
-                )
-        else:
-            reco_exposure = 1
+        reco_exposure = self.estimate_exposure_reco_energy(dataset, kernel, mask)
 
         with np.errstate(invalid="ignore", divide="ignore"):
             maps["norm"] = maps["npred_excess"] / reco_exposure
             maps["norm_err"] = (
                 Map.from_geom(geom, data=counts_stat.error * self.n_sigma)
                 / reco_exposure
             )
```

### Comparing `gammapy-1.0rc2/gammapy/estimators/map/tests/test_asmooth.py` & `gammapy-1.1rc1/gammapy/estimators/map/tests/test_asmooth.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/estimators/map/tests/test_core.py` & `gammapy-1.1rc1/gammapy/estimators/map/tests/test_core.py`

 * *Files 0% similar despite different names*

```diff
@@ -329,15 +329,15 @@
 
     fluxmap = FluxMaps(partial_wcs_flux_map, reference_model, gti=gti)
 
     fluxmap.write(tmp_path / "tmp.fits", sed_type="dnde")
     new_fluxmap = FluxMaps.read(tmp_path / "tmp.fits")
 
     assert len(new_fluxmap.gti.table) == 2
-    assert_allclose(gti.table["START"], start.to_value("s"))
+    assert_allclose(gti.met_start.to_value("s"), start.to_value("s"))
 
 
 @pytest.mark.xfail
 def test_flux_map_read_write_no_reference_model(tmp_path, wcs_flux_map, caplog):
     fluxmap = FluxMaps(wcs_flux_map)
 
     fluxmap.write(tmp_path / "tmp.fits")
@@ -350,16 +350,16 @@
 
 def test_flux_map_read_write_missing_reference_model(
     tmp_path, wcs_flux_map, reference_model
 ):
     fluxmap = FluxMaps(wcs_flux_map, reference_model)
     fluxmap.write(tmp_path / "tmp.fits")
 
-    hdulist = fits.open(tmp_path / "tmp.fits")
-    hdulist[0].header["MODEL"] = "non_existent"
+    with fits.open(tmp_path / "tmp.fits") as hdulist:
+        hdulist[0].header["MODEL"] = "non_existent"
 
     with pytest.raises(FileNotFoundError):
         _ = FluxMaps.from_hdulist(hdulist)
 
 
 @pytest.mark.xfail
 def test_flux_map_init_no_reference_model(wcs_flux_map, caplog):
@@ -404,15 +404,15 @@
     coord = SkyCoord(0.0, 0.0, unit="deg", frame="galactic")
     table = fluxmap.get_flux_points(coord).to_table()
     assert_allclose(table["e_min"], [0.1, 1.0])
     assert_allclose(table["norm"], [1, 1])
     assert_allclose(table["norm_err"], [0.1, 0.1])
     assert_allclose(table["norm_ul"], [2, 2])
     assert "norm_errn" not in table.columns
-    assert table["success"].data.dtype == np.dtype(np.bool)
+    assert table["success"].data.dtype == np.dtype(bool)
 
 
 def test_flux_map_from_dict_inconsistent_units(wcs_flux_map, reference_model):
     ref_map = FluxMaps(wcs_flux_map, reference_model)
     map_dict = dict()
     map_dict["eflux"] = ref_map.eflux
     map_dict["eflux"].quantity = map_dict["eflux"].quantity.to("keV/m2/s")
```

### Comparing `gammapy-1.0rc2/gammapy/estimators/map/tests/test_excess.py` & `gammapy-1.1rc1/gammapy/estimators/map/tests/test_excess.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/estimators/map/tests/test_ts.py` & `gammapy-1.1rc1/gammapy/estimators/map/tests/test_ts.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import pytest
 import numpy as np
 from numpy.testing import assert_allclose
 import astropy.units as u
 from astropy.coordinates import Angle
-from gammapy.datasets import MapDataset
+from gammapy.datasets import MapDataset, MapDatasetOnOff
 from gammapy.estimators import TSMapEstimator
 from gammapy.irf import EDispKernelMap, PSFMap
 from gammapy.maps import Map, MapAxis, WcsGeom
 from gammapy.modeling.models import (
     GaussianSpatialModel,
     PointSpatialModel,
     PowerLawSpectralModel,
     SkyModel,
 )
-from gammapy.utils.testing import requires_data
+from gammapy.utils.testing import requires_data, requires_dependency
 
 
 @pytest.fixture(scope="session")
 def fake_dataset():
     axis = MapAxis.from_energy_bounds(0.1, 10, 5, unit="TeV", name="energy")
     axis_true = MapAxis.from_energy_bounds(0.05, 20, 10, unit="TeV", name="energy_true")
 
@@ -132,14 +132,69 @@
     assert np.isnan(result["ts"].data[0, 30, 40])
 
     energy_axis = result["ts"].geom.axes["energy"]
     assert_allclose(energy_axis.edges.value, [0.1, 1])
 
 
 @requires_data()
+@requires_dependency("ray")
+def test_compute_ts_map_parallel_ray(input_dataset):
+    """Minimal test of compute_ts_image"""
+    spatial_model = GaussianSpatialModel(sigma="0.1 deg")
+    spectral_model = PowerLawSpectralModel(index=2)
+    model = SkyModel(spatial_model=spatial_model, spectral_model=spectral_model)
+
+    ts_estimator = TSMapEstimator(
+        model=model,
+        threshold=1,
+        selection_optional=[],
+        parallel_backend="ray",
+        n_jobs=2,
+    )
+    assert ts_estimator.parallel_backend == "ray"
+    assert ts_estimator.n_jobs == 2
+
+    result = ts_estimator.run(input_dataset)
+    assert_allclose(result["ts"].data[0, 99, 99], 1704.23, rtol=1e-2)
+    assert_allclose(result["niter"].data[0, 99, 99], 7)
+    assert_allclose(result["flux"].data[0, 99, 99], 1.02e-09, rtol=1e-2)
+    assert_allclose(result["flux_err"].data[0, 99, 99], 3.84e-11, rtol=1e-2)
+    assert_allclose(result["npred"].data[0, 99, 99], 4744.020361, rtol=1e-2)
+    assert_allclose(result["npred_excess"].data[0, 99, 99], 1026.874063, rtol=1e-2)
+    assert_allclose(result["npred_excess_err"].data[0, 99, 99], 38.470995, rtol=1e-2)
+
+
+@requires_data()
+def test_compute_ts_map_parallel_multiprocessing(input_dataset):
+    """Minimal test of compute_ts_image"""
+    spatial_model = GaussianSpatialModel(sigma="0.1 deg")
+    spectral_model = PowerLawSpectralModel(index=2)
+    model = SkyModel(spatial_model=spatial_model, spectral_model=spectral_model)
+
+    ts_estimator = TSMapEstimator(
+        model=model,
+        threshold=1,
+        selection_optional=[],
+        n_jobs=3,
+        parallel_backend="multiprocessing",
+    )
+
+    result = ts_estimator.run(input_dataset)
+
+    assert ts_estimator.n_jobs == 3
+    assert_allclose(result["ts"].data[0, 99, 99], 1704.23, rtol=1e-2)
+    assert_allclose(result["niter"].data[0, 99, 99], 7)
+    assert_allclose(result["flux"].data[0, 99, 99], 1.02e-09, rtol=1e-2)
+    assert_allclose(result["flux_err"].data[0, 99, 99], 3.84e-11, rtol=1e-2)
+    assert_allclose(result["npred"].data[0, 99, 99], 4744.020361, rtol=1e-2)
+    assert_allclose(result["npred_excess"].data[0, 99, 99], 1026.874063, rtol=1e-2)
+    assert_allclose(result["npred_excess_err"].data[0, 99, 99], 38.470995, rtol=1e-2)
+
+
+@requires_data()
 def test_compute_ts_map_psf(fermi_dataset):
     spatial_model = PointSpatialModel()
     spectral_model = PowerLawSpectralModel(amplitude="1e-22 cm-2 s-1 keV-1")
     model = SkyModel(spatial_model=spatial_model, spectral_model=spectral_model)
 
     estimator = TSMapEstimator(
         model=model, kernel_width="1 deg", selection_optional="all"
@@ -271,7 +326,18 @@
     kernel = ts_estimator.estimate_kernel(dataset=holes_dataset)
     assert_allclose(kernel.geom.width, 1.0 * u.deg)
     assert_allclose(kernel.data.sum(), 1.0)
 
     holes_dataset.exposure.data[...] = 0.0
     with pytest.raises(ValueError):
         kernel = ts_estimator.estimate_kernel(dataset=holes_dataset)
+
+
+def test_MapDatasetOnOff_error():
+    """Test raise error when applying TSMapEStimator to MapDatasetOnOff"""
+    axis = MapAxis.from_edges([1, 10] * u.TeV, name="energy")
+    geom = WcsGeom.create(width=1, axes=[axis])
+    dataset_on_off = MapDatasetOnOff.create(geom)
+
+    ts_estimator = TSMapEstimator()
+    with pytest.raises(TypeError):
+        ts_estimator.run(dataset=dataset_on_off)
```

### Comparing `gammapy-1.0rc2/gammapy/estimators/map/ts.py` & `gammapy-1.1rc1/gammapy/estimators/map/ts.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,33 +1,30 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 """Functions to compute TS images."""
-import functools
-import logging
 import warnings
-from multiprocessing import Pool
+from itertools import repeat
 import numpy as np
 import scipy.optimize
 from astropy.coordinates import Angle
 from astropy.utils import lazyproperty
+import gammapy.utils.parallel as parallel
 from gammapy.datasets.map import MapEvaluator
 from gammapy.datasets.utils import get_nearest_valid_exposure_position
 from gammapy.maps import Map, Maps
 from gammapy.modeling.models import PointSpatialModel, PowerLawSpectralModel, SkyModel
 from gammapy.stats import cash_sum_cython, f_cash_root_cython, norm_bounds_cython
 from gammapy.utils.array import shape_2N, symmetric_crop_pad_width
 from gammapy.utils.pbar import progress_bar
 from gammapy.utils.roots import find_roots
 from ..core import Estimator
 from ..utils import estimate_exposure_reco_energy
 from .core import FluxMaps
 
 __all__ = ["TSMapEstimator"]
 
-log = logging.getLogger(__name__)
-
 
 def _extract_array(array, shape, position):
     """Helper function to extract parts of a larger array.
 
     Simple implementation of an array extract function , because
     `~astropy.ndata.utils.extract_array` introduces too much overhead.`
 
@@ -46,15 +43,15 @@
     y_lo = position[0] - y_width
     y_hi = position[0] + y_width + 1
     x_lo = position[1] - x_width
     x_hi = position[1] + x_width + 1
     return array[:, y_lo:y_hi, x_lo:x_hi]
 
 
-class TSMapEstimator(Estimator):
+class TSMapEstimator(Estimator, parallel.ParallelMixin):
     r"""Compute TS map from a MapDataset using different optimization methods.
 
     The map is computed fitting by a single parameter norm fit. The fit is
     simplified by finding roots of the derivative of the fit statistics using
     various root finding algorithms. The approach is described in Appendix A
     in Stewart (2009).
 
@@ -91,15 +88,19 @@
         Default is None so the optional steps are not executed.
     energy_edges : `~astropy.units.Quantity`
         Energy edges of the maps bins.
     sum_over_energy_groups : bool
         Whether to sum over the energy groups or fit the norm on the full energy
         cube.
     n_jobs : int
-        Number of processes used in parallel for the computation.
+        Number of processes used in parallel for the computation. Default is one,
+        unless `~gammapy.utils.parallel.N_JOBS_DEFAULT` was modified. The number
+        of jobs limited to the number of physical CPUs.
+    parallel_backend : {"multiprocessing", "ray"}
+        Which backend to use for multiprocessing. Defaults to `~gammapy.utils.parallel.BACKEND_DEFAULT`.
 
     Notes
     -----
     Negative :math:`TS` values are defined as following:
 
     .. math::
         TS = \left \{
@@ -156,14 +157,15 @@
         n_sigma_ul=2,
         threshold=None,
         rtol=0.01,
         selection_optional=None,
         energy_edges=None,
         sum_over_energy_groups=True,
         n_jobs=None,
+        parallel_backend=None,
     ):
         if kernel_width is not None:
             kernel_width = Angle(kernel_width)
 
         self.kernel_width = kernel_width
 
         if model is None:
@@ -176,14 +178,15 @@
         self.model = model
         self.downsampling_factor = downsampling_factor
         self.n_sigma = n_sigma
         self.n_sigma_ul = n_sigma_ul
         self.threshold = threshold
         self.rtol = rtol
         self.n_jobs = n_jobs
+        self.parallel_backend = parallel_backend
         self.sum_over_energy_groups = sum_over_energy_groups
 
         self.selection_optional = selection_optional
         self.energy_edges = energy_edges
         self._flux_estimator = BrentqFluxEstimator(
             rtol=self.rtol,
             n_sigma=self.n_sigma,
@@ -407,33 +410,33 @@
         Parameters
         ----------
         dataset : `MapDataset`
             Map dataset
         """
         maps = self.estimate_fit_input_maps(dataset=dataset)
 
-        wrap = functools.partial(
-            _ts_value,
-            counts=maps["counts"].data.astype(float),
-            exposure=maps["exposure"].data.astype(float),
-            background=maps["background"].data.astype(float),
-            kernel=maps["kernel"].data,
-            norm=maps["norm"].data,
-            flux_estimator=self._flux_estimator,
-        )
-
         x, y = np.where(np.squeeze(maps["mask"].data))
         positions = list(zip(x, y))
 
-        if self.n_jobs is None:
-            results = list(map(wrap, positions))
-        else:
-            with Pool(processes=self.n_jobs) as pool:
-                log.info("Using {} jobs to compute TS map.".format(self.n_jobs))
-                results = pool.map(wrap, positions)
+        inputs = zip(
+            positions,
+            repeat(maps["counts"].data.astype(float)),
+            repeat(maps["exposure"].data.astype(float)),
+            repeat(maps["background"].data.astype(float)),
+            repeat(maps["kernel"].data),
+            repeat(maps["norm"].data),
+            repeat(self._flux_estimator),
+        )
+
+        results = parallel.run_multiprocessing(
+            _ts_value,
+            inputs,
+            pool_kwargs=dict(processes=self.n_jobs),
+            task_name="TS map",
+        )
 
         result = {}
 
         j, i = zip(*positions)
 
         geom = maps["counts"].geom.squash(axis_name="energy")
 
@@ -464,14 +467,16 @@
                 * ts : delta TS map
                 * sqrt_ts : sqrt(delta TS), or significance map
                 * flux : flux map
                 * flux_err : symmetric error map
                 * flux_ul : upper limit map
 
         """
+        if dataset.stat_type != "cash":
+            raise TypeError(f"{type(dataset)} is not a valid type for {self.__class__}")
         dataset_models = dataset.models
 
         pad_width = self.estimate_pad_width(dataset=dataset)
         dataset = dataset.pad(pad_width, name=dataset.name)
         dataset = dataset.downsample(self.downsampling_factor, name=dataset.name)
 
         energy_axis = self._get_energy_axis(dataset=dataset)
```

### Comparing `gammapy-1.0rc2/gammapy/estimators/parameter.py` & `gammapy-1.1rc1/gammapy/estimators/parameter.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/estimators/points/core.py` & `gammapy-1.1rc1/gammapy/estimators/points/core.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,23 +1,25 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import logging
 from copy import deepcopy
 import numpy as np
 from scipy import stats
 from astropy.io.registry import IORegistryError
 from astropy.table import Table, vstack
+from astropy.time import Time
 from astropy.visualization import quantity_support
 import matplotlib.pyplot as plt
 from gammapy.maps import MapAxis, Maps, RegionNDMap, TimeMapAxis
-from gammapy.maps.axes import flat_if_equal
+from gammapy.maps.axes import flat_if_equal, UNIT_STRING_FORMAT
 from gammapy.modeling.models import TemplateSpectralModel
 from gammapy.modeling.models.spectral import scale_plot_flux
 from gammapy.modeling.scipy import stat_profile_ul_scipy
 from gammapy.utils.scripts import make_path
 from gammapy.utils.table import table_standardise_units_copy
+from gammapy.utils.time import time_ref_to_dict
 from ..map.core import DEFAULT_UNIT, FluxMaps
 
 __all__ = ["FluxPoints"]
 
 log = logging.getLogger(__name__)
 
 
@@ -383,14 +385,20 @@
 
                 for column in table.columns:
                     table_flat[column] = table[column][np.newaxis]
 
                 tables.append(table_flat)
 
             table = vstack(tables)
+
+            # serialize with reference time set to mjd=0.0
+            ref_time = Time(0.0, format="mjd", scale=time_axis.reference_time.scale)
+            table.meta.update(time_ref_to_dict(ref_time, scale=ref_time.scale))
+            table.meta["TIMEUNIT"] = "d"
+
         elif format == "binned-time-series":
             message = (
                 "Format 'binned-time-series' support a single time axis "
                 f"only. Got {self.geom.axes.names}"
             )
 
             if not self.geom.axes.is_unidimensional:
@@ -459,25 +467,27 @@
 
         if "norm_errp" in self.available_quantities:
             y_errn = getattr(self, sed_type + "_errn")
             y_errp = getattr(self, sed_type + "_errp")
 
         return y_errn, y_errp
 
-    def plot(self, ax=None, sed_type=None, energy_power=0, **kwargs):
+    def plot(self, ax=None, sed_type=None, energy_power=0, time_format="iso", **kwargs):
         """Plot flux points.
 
         Parameters
         ----------
         ax : `~matplotlib.axes.Axes`
             Axis object to plot on.
         sed_type : {"dnde", "flux", "eflux", "e2dnde"}
             Sed type
         energy_power : float
             Power of energy to multiply flux axis with
+        time_format : {"iso", "mjd"}
+            Used time format is a time axis is present. Default: "iso"
         **kwargs : dict
             Keyword arguments passed to `~RegionNDMap.plot`
 
         Returns
         -------
         ax : `~matplotlib.axes.Axes`
             Axis object
@@ -517,16 +527,18 @@
                 scale_plot_flux(y_errn, energy_power=energy_power).quantity, 0, np.inf
             )
             kwargs.setdefault("yerr", (y_errn, y_errp))
         else:
             kwargs.setdefault("yerr", None)
 
         flux = scale_plot_flux(flux=flux.to_unit(flux_unit), energy_power=energy_power)
+        if "time" in flux.geom.axes_names:
+            flux.geom.axes["time"].time_format = time_format
         ax = flux.plot(ax=ax, **kwargs)
-        ax.set_ylabel(f"{sed_type} [{ax.yaxis.units}]")
+        ax.set_ylabel(f"{sed_type} [{ax.yaxis.units.to_string(UNIT_STRING_FORMAT)}]")
         ax.set_yscale("log")
         return ax
 
     def plot_ts_profiles(
         self,
         ax=None,
         sed_type=None,
@@ -610,15 +622,15 @@
         z[-z < kwargs["vmin"]] = np.nan
 
         with quantity_support():
             caxes = ax.pcolormesh(axis.as_plot_edges, flux.edges, -z.T, **kwargs)
 
         axis.format_plot_xaxis(ax=ax)
 
-        ax.set_ylabel(f"{sed_type} ({ax.yaxis.units})")
+        ax.set_ylabel(f"{sed_type} [{ax.yaxis.units.to_string(UNIT_STRING_FORMAT)}]")
         ax.set_yscale("log")
 
         if add_cbar:
             label = "Fit statistic difference"
             ax.figure.colorbar(caxes, ax=ax, label=label)
 
         return ax
```

### Comparing `gammapy-1.0rc2/gammapy/estimators/points/lightcurve.py` & `gammapy-1.1rc1/gammapy/estimators/points/lightcurve.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,11 +1,13 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import logging
+from itertools import repeat
 import numpy as np
 import astropy.units as u
+import gammapy.utils.parallel as parallel
 from gammapy.data import GTI
 from gammapy.datasets import Datasets
 from gammapy.maps import LabelMapAxis, Map, TimeMapAxis
 from gammapy.utils.pbar import progress_bar
 from .core import FluxPoints
 from .sed import FluxPointsEstimator
 
@@ -61,27 +63,34 @@
             * "ul": estimate upper limits.
             * "scan": estimate fit statistic profiles.
 
         Default is None so the optional steps are not executed.
     fit : `Fit`
         Fit instance specifying the backend and fit options.
     reoptimize : bool
-        Re-optimize other free model parameters. Default is True.
+        Re-optimize other free model parameters. Default is False.
+    n_jobs : int
+        Number of processes used in parallel for the computation. Default is one,
+        unless `~gammapy.utils.parallel.N_JOBS_DEFAULT` was modified. The number
+        of jobs is limited to the number of physical CPUs.
+    parallel_backend : {"multiprocessing", "ray"}
+        Which backend to use for multiprocessing. Defaults to `~gammapy.utils.parallel.BACKEND_DEFAULT`.
 
     Examples
     --------
     For a usage example see :doc:`/tutorials/analysis-time/light_curve` tutorial.
 
     """
 
     tag = "LightCurveEstimator"
 
     def __init__(self, time_intervals=None, atol="1e-6 s", **kwargs):
         self.time_intervals = time_intervals
         self.atol = u.Quantity(atol)
+
         super().__init__(**kwargs)
 
     def run(self, datasets):
         """Run light curve extraction.
 
         Normalize integral and energy flux between emin and emax.
 
@@ -102,33 +111,48 @@
         else:
             gti = GTI.from_time_intervals(self.time_intervals)
 
         gti = gti.union(overlap_ok=False, merge_equal=False)
 
         rows = []
         valid_intervals = []
-        for t_min, t_max in progress_bar(gti.time_intervals, desc="Time intervals"):
+        parallel_datasets = []
+        dataset_names = datasets.names
+        for t_min, t_max in progress_bar(
+            gti.time_intervals, desc="Time intervals selection"
+        ):
             datasets_to_fit = datasets.select_time(
                 time_min=t_min, time_max=t_max, atol=self.atol
             )
 
             if len(datasets_to_fit) == 0:
                 log.info(
                     f"No Dataset for the time interval {t_min} to {t_max}. Skipping interval."
                 )
                 continue
 
             valid_intervals.append([t_min, t_max])
-            fp = self.estimate_time_bin_flux(datasets=datasets_to_fit)
 
-            for name in ["counts", "npred", "npred_excess"]:
-                fp._data[name] = self.expand_map(
-                    fp._data[name], dataset_names=datasets.names
-                )
-            rows.append(fp)
+            if self.n_jobs == 1:
+                fp = self.estimate_time_bin_flux(datasets_to_fit, dataset_names)
+                rows.append(fp)
+            else:
+                parallel_datasets.append(datasets_to_fit)
+
+        if self.n_jobs > 1:
+            rows = parallel.run_multiprocessing(
+                self.estimate_time_bin_flux,
+                zip(
+                    parallel_datasets,
+                    repeat(dataset_names),
+                ),
+                backend=self.parallel_backend,
+                pool_kwargs=dict(processes=self.n_jobs),
+                task_name="Time intervals",
+            )
 
         if len(rows) == 0:
             raise ValueError("LightCurveEstimator: No datasets in time intervals")
 
         gti = GTI.from_time_intervals(valid_intervals)
         axis = TimeMapAxis.from_gti(gti=gti)
         return FluxPoints.from_stack(
@@ -156,21 +180,29 @@
         geom = m.geom.replace_axis(axis=label_axis)
         result = Map.from_geom(geom, data=np.nan)
 
         coords = m.geom.get_coord(sparse=True)
         result.set_by_coord(coords, vals=m.data)
         return result
 
-    def estimate_time_bin_flux(self, datasets):
+    def estimate_time_bin_flux(self, datasets, dataset_names=None):
         """Estimate flux point for a single energy group.
 
         Parameters
         ----------
         datasets : `~gammapy.modeling.Datasets`
             List of dataset objects
 
         Returns
         -------
         result : `FluxPoints`
             Resulting flux points.
         """
-        return super().run(datasets)
+
+        fp = super().run(datasets)
+
+        if dataset_names:
+            for name in ["counts", "npred", "npred_excess"]:
+                fp._data[name] = self.expand_map(
+                    fp._data[name], dataset_names=dataset_names
+                )
+        return fp
```

### Comparing `gammapy-1.0rc2/gammapy/estimators/points/profile.py` & `gammapy-1.1rc1/gammapy/estimators/points/profile.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/estimators/points/sed.py` & `gammapy-1.1rc1/gammapy/estimators/points/sed.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,25 +1,26 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import logging
+from itertools import repeat
 import numpy as np
 from astropy import units as u
+from astropy.table import Table
+import gammapy.utils.parallel as parallel
 from gammapy.datasets import Datasets
 from gammapy.maps import MapAxis
 from gammapy.modeling import Fit
-from gammapy.utils.pbar import progress_bar
-from gammapy.utils.table import table_from_row_data
 from ..flux import FluxEstimator
 from .core import FluxPoints
 
 log = logging.getLogger(__name__)
 
 __all__ = ["FluxPointsEstimator"]
 
 
-class FluxPointsEstimator(FluxEstimator):
+class FluxPointsEstimator(FluxEstimator, parallel.ParallelMixin):
     """Flux points estimator.
 
     Estimates flux points for a given list of datasets, energies and spectral model.
 
     To estimate the flux point the amplitude of the reference spectral model is
     fitted within the energy range defined by the energy group. This is done for
     each group independently. The amplitude is re-normalized using the "norm" parameter,
@@ -58,27 +59,40 @@
             * "ul": estimate upper limits.
             * "scan": estimate fit statistic profiles.
 
         Default is None so the optional steps are not executed.
     fit : `Fit`
         Fit instance specifying the backend and fit options.
     reoptimize : bool
-        Re-optimize other free model parameters. Default is True.
+        Re-optimize other free model parameters. Default is False.
     sum_over_energy_groups : bool
         Whether to sum over the energy groups or fit the norm on the full energy
         grid.
+    n_jobs : int
+        Number of processes used in parallel for the computation. Default is one, unless
+        `~gammapy.utils.parallel.N_JOBS_DEFAULT` was modified. The number of jobs is
+        limited to the number of physical CPUs.
+    parallel_backend : {"multiprocessing", "ray"}
+        Which backend to use for multiprocessing.
     """
 
     tag = "FluxPointsEstimator"
 
     def __init__(
-        self, energy_edges=[1, 10] * u.TeV, sum_over_energy_groups=False, **kwargs
+        self,
+        energy_edges=[1, 10] * u.TeV,
+        sum_over_energy_groups=False,
+        n_jobs=None,
+        parallel_backend=None,
+        **kwargs,
     ):
         self.energy_edges = energy_edges
         self.sum_over_energy_groups = sum_over_energy_groups
+        self.n_jobs = n_jobs
+        self.parallel_backend = parallel_backend
 
         fit = Fit(confidence_opts={"backend": "scipy"})
         kwargs.setdefault("fit", fit)
         super().__init__(**kwargs)
 
     def run(self, datasets):
         """Run the flux point estimator for all energy groups.
@@ -103,31 +117,34 @@
             if not len(np.unique(telescopes)) == 1:
                 raise ValueError(
                     "All datasets must use the same value of the"
                     " 'TELESCOP' meta keyword."
                 )
 
         rows = []
-        for energy_min, energy_max in progress_bar(
-            zip(self.energy_edges[:-1], self.energy_edges[1:]), desc="Energy bins"
-        ):
-            row = self.estimate_flux_point(
-                datasets,
-                energy_min=energy_min,
-                energy_max=energy_max,
-            )
-            rows.append(row)
 
         meta = {
             "n_sigma": self.n_sigma,
             "n_sigma_ul": self.n_sigma_ul,
             "sed_type_init": "likelihood",
         }
 
-        table = table_from_row_data(rows=rows, meta=meta)
+        rows = parallel.run_multiprocessing(
+            self.estimate_flux_point,
+            zip(
+                repeat(datasets),
+                self.energy_edges[:-1],
+                self.energy_edges[1:],
+            ),
+            backend=self.parallel_backend,
+            pool_kwargs=dict(processes=self.n_jobs),
+            task_name="Energy bins",
+        )
+
+        table = Table(rows, meta=meta)
         model = datasets.models[self.source]
         return FluxPoints.from_table(
             table=table,
             reference_model=model.copy(),
             gti=datasets.gti,
             format="gadf-sed",
         )
```

### Comparing `gammapy-1.0rc2/gammapy/estimators/points/sensitivity.py` & `gammapy-1.1rc1/gammapy/estimators/points/sensitivity.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,20 +1,21 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
+import logging
 import numpy as np
 from astropy.table import Column, Table
 from gammapy.maps import Map
 from gammapy.modeling.models import PowerLawSpectralModel, SkyModel
 from gammapy.stats import WStatCountsStatistic
 from ..core import Estimator
 
 __all__ = ["SensitivityEstimator"]
 
 
 class SensitivityEstimator(Estimator):
-    """Estimate differential sensitivity.
+    """Estimate sensitivity.
 
     This class allows to determine for each reconstructed energy bin the flux
     associated to the number of gamma-ray events for which the significance is
     ``n_sigma``, and being larger than ``gamma_min`` and ``bkg_sys`` percent
     larger than the number of background events in the ON region.
 
 
@@ -34,15 +35,19 @@
     For a usage example see :doc:`/tutorials/analysis-1d/cta_sensitivity` tutorial.
 
     """
 
     tag = "SensitivityEstimator"
 
     def __init__(
-        self, spectrum=None, n_sigma=5.0, gamma_min=10, bkg_syst_fraction=0.05
+        self,
+        spectrum=None,
+        n_sigma=5.0,
+        gamma_min=10,
+        bkg_syst_fraction=0.05,
     ):
 
         if spectrum is None:
             spectrum = PowerLawSpectralModel(index=2, amplitude="1 cm-2 s-1 TeV-1")
 
         self.spectrum = spectrum
         self.n_sigma = n_sigma
@@ -131,41 +136,62 @@
         """
         energy = dataset._geom.axes["energy"].center
         excess = self.estimate_min_excess(dataset)
         e2dnde = self.estimate_min_e2dnde(excess, dataset)
         criterion = self._get_criterion(
             excess.data.squeeze(), dataset.background.data.squeeze()
         )
+        logging.warning(
+            "Table column name energy will be deprecated by e_ref since v1.2"
+        )
 
         return Table(
             [
                 Column(
                     data=energy,
                     name="energy",
                     format="5g",
                     description="Reconstructed Energy",
                 ),
                 Column(
+                    data=energy,
+                    name="e_ref",
+                    format="5g",
+                    description="Energy center",
+                ),
+                Column(
+                    data=dataset._geom.axes["energy"].edges_min,
+                    name="e_min",
+                    format="5g",
+                    description="Energy edge low",
+                ),
+                Column(
+                    data=dataset._geom.axes["energy"].edges_max,
+                    name="e_max",
+                    format="5g",
+                    description="Energy edge high",
+                ),
+                Column(
                     data=e2dnde,
                     name="e2dnde",
                     format="5g",
                     description="Energy squared times differential flux",
                 ),
                 Column(
-                    data=excess.data.squeeze(),
+                    data=np.atleast_1d(excess.data.squeeze()),
                     name="excess",
                     format="5g",
                     description="Number of excess counts in the bin",
                 ),
                 Column(
-                    data=dataset.background.data.squeeze(),
+                    data=np.atleast_1d(dataset.background.data.squeeze()),
                     name="background",
                     format="5g",
                     description="Number of background counts in the bin",
                 ),
                 Column(
-                    data=criterion,
+                    data=np.atleast_1d(criterion),
                     name="criterion",
                     description="Sensitivity-limiting criterion",
                 ),
             ]
         )
```

### Comparing `gammapy-1.0rc2/gammapy/estimators/points/tests/test_core.py` & `gammapy-1.1rc1/gammapy/estimators/points/tests/test_core.py`

 * *Files 1% similar despite different names*

```diff
@@ -226,22 +226,24 @@
         yunit = DEFAULT_UNIT[flux_points.sed_type_init]
         ax.yaxis.set_units(yunit)
 
         with mpl_plot_check():
             flux_points.plot(ax=ax)
 
     def test_plot_likelihood(self, flux_points_likelihood):
+        plt.figure()
         with mpl_plot_check():
             flux_points_likelihood.plot_ts_profiles()
 
     def test_plot_likelihood_error(self, flux_points_likelihood):
         del flux_points_likelihood._data["stat_scan"]
 
         with pytest.raises(AttributeError):
-            ax = plt.subplot()
+            fig = plt.figure()
+            ax = fig.add_subplot()
             flux_points_likelihood.plot_ts_profiles(ax=ax)
 
 
 @requires_data()
 def test_flux_points_single_bin_dnde():
     path = make_path("$GAMMAPY_DATA/tests/spectrum/flux_points/diff_flux_points.fits")
     table = Table.read(path)
```

### Comparing `gammapy-1.0rc2/gammapy/estimators/points/tests/test_lightcurve.py` & `gammapy-1.1rc1/gammapy/estimators/points/tests/test_lightcurve.py`

 * *Files 3% similar despite different names*

```diff
@@ -10,15 +10,20 @@
 from gammapy.estimators import FluxPoints, LightCurveEstimator
 from gammapy.estimators.points.tests.test_sed import (
     simulate_map_dataset,
     simulate_spectrum_dataset,
 )
 from gammapy.modeling import Fit
 from gammapy.modeling.models import FoVBackgroundModel, PowerLawSpectralModel, SkyModel
-from gammapy.utils.testing import mpl_plot_check, requires_data
+from gammapy.utils.testing import (
+    assert_time_allclose,
+    mpl_plot_check,
+    requires_data,
+    requires_dependency,
+)
 
 
 @pytest.fixture(scope="session")
 def lc():
     meta = dict(TIMESYS="utc", SED_TYPE="flux")
 
     table = Table(
@@ -113,14 +118,17 @@
 
 
 def test_lightcurve_plot(lc, lc_2d):
     with mpl_plot_check():
         lc.plot()
 
     with mpl_plot_check():
+        lc.plot(marker="o", time_format="mjd")
+
+    with mpl_plot_check():
         lc_2d.plot(axis_name="time")
 
 
 @requires_data()
 def test_lightcurve_to_time_series():
     from gammapy.catalog import SourceCatalog4FGL
 
@@ -147,20 +155,20 @@
     assert_allclose(result.duration, 182.625 * u.d)
 
 
 def get_spectrum_datasets():
     model = SkyModel(spectral_model=PowerLawSpectralModel())
     dataset_1 = simulate_spectrum_dataset(model=model, random_state=0)
     dataset_1._name = "dataset_1"
-    gti1 = GTI.create("0h", "1h", "2010-01-01T00:00:00")
+    gti1 = GTI.create("0h", "1h", Time("2010-01-01T00:00:00").tt)
     dataset_1.gti = gti1
 
     dataset_2 = simulate_spectrum_dataset(model=model, random_state=1)
     dataset_2._name = "dataset_2"
-    gti2 = GTI.create("1h", "2h", "2010-01-01T00:00:00")
+    gti2 = GTI.create("1h", "2h", Time("2010-01-01T00:00:00").tt)
     dataset_2.gti = gti2
 
     return [dataset_1, dataset_2]
 
 
 @requires_data()
 def test_group_datasets_in_time_interval():
@@ -216,25 +224,25 @@
         time_intervals=time_intervals,
         selection_optional="all",
         fit=Fit(backend="minuit", optimize_opts=dict(tol=0.2, strategy=1)),
     )
 
     assert_allclose(estimator.fit.optimize_opts["tol"], 0.2)
 
-    estimator.fit.run(datasets=datasets)
-    assert_allclose(estimator.fit.minuit.tol, 0.2)
+    result = estimator.fit.run(datasets=datasets)
+    assert_allclose(result.minuit.tol, 0.2)
 
 
 @requires_data()
 def test_lightcurve_estimator_spectrum_datasets():
     # Doing a LC on one hour bin
     datasets = get_spectrum_datasets()
     time_intervals = [
-        Time(["2010-01-01T00:00:00", "2010-01-01T01:00:00"]),
-        Time(["2010-01-01T01:00:00", "2010-01-01T02:00:00"]),
+        Time(["2010-01-01T00:00:00", "2010-01-01T01:00:00"]).tt,
+        Time(["2010-01-01T01:00:00", "2010-01-01T02:00:00"]).tt,
     ]
 
     estimator = LightCurveEstimator(
         energy_edges=[1, 30] * u.TeV,
         norm_n_values=3,
         time_intervals=time_intervals,
         selection_optional="all",
@@ -261,22 +269,32 @@
     assert_allclose(table["ts"], [[375.769735], [367.173374]], rtol=1e-2)
     assert_allclose(table[0]["norm_scan"], [[0.2, 1.0, 5.0]])
     assert_allclose(
         table[0]["stat_scan"],
         [[224.058304, 19.074405, 2063.75636]],
         rtol=1e-5,
     )
+    assert table.meta["TIMESYS"] == "tt"
+    assert table.meta["TIMEUNIT"] == "d"
+    assert table.meta["MJDREFF"] == 0
+    assert table.meta["MJDREFI"] == 0
 
     # TODO: fix reference model I/O
     fp = FluxPoints.from_table(
         table=table, format="lightcurve", reference_model=PowerLawSpectralModel()
     )
     assert fp.norm.geom.axes.names == ["energy", "time"]
     assert fp.counts.geom.axes.names == ["dataset", "energy", "time"]
     assert fp.stat_scan.geom.axes.names == ["norm", "energy", "time"]
+    assert_time_allclose(
+        fp.geom.axes["time"].time_min, lightcurve.geom.axes["time"].time_min
+    )
+    assert_time_allclose(
+        fp.geom.axes["time"].time_max, lightcurve.geom.axes["time"].time_max
+    )
 
 
 @requires_data()
 def test_lightcurve_estimator_spectrum_datasets_2_energy_bins():
     # Doing a LC on one hour bin
     datasets = get_spectrum_datasets()
     time_intervals = [
@@ -645,7 +663,44 @@
     selection = []
     estimator = LightCurveEstimator(
         energy_edges=[1, 30] * u.TeV, selection_optional=selection
     )
     lightcurve = estimator.run(datasets)
     with pytest.raises(ValueError):
         lightcurve.recompute_ul(n_sigma_ul=4)
+
+
+@requires_data()
+def test_lightcurve_parallel_multiprocessing():
+    datasets = get_spectrum_datasets()
+    selection = ["all"]
+    estimator = LightCurveEstimator(
+        energy_edges=[1, 3, 30] * u.TeV,
+        selection_optional=selection,
+        n_sigma_ul=2,
+        n_jobs=2,
+    )
+    assert estimator.n_jobs == 2
+    lightcurve = estimator.run(datasets)
+    assert_allclose(
+        lightcurve.dnde_ul.data[0], [[[3.260703e-13]], [[1.159354e-14]]], rtol=1e-3
+    )
+
+
+@requires_data()
+@requires_dependency("ray")
+def test_lightcurve_parallel_ray():
+    datasets = get_spectrum_datasets()
+    selection = ["all"]
+
+    estimator = LightCurveEstimator(
+        energy_edges=[1, 3, 30] * u.TeV,
+        selection_optional=selection,
+        n_sigma_ul=2,
+        n_jobs=2,
+        parallel_backend="ray",
+    )
+
+    lightcurve = estimator.run(datasets)
+    assert_allclose(
+        lightcurve.dnde_ul.data[0], [[[3.260703e-13]], [[1.159354e-14]]], rtol=1e-3
+    )
```

### Comparing `gammapy-1.0rc2/gammapy/estimators/points/tests/test_profile.py` & `gammapy-1.1rc1/gammapy/estimators/points/tests/test_profile.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/estimators/points/tests/test_sed.py` & `gammapy-1.1rc1/gammapy/estimators/points/tests/test_sed.py`

 * *Files 4% similar despite different names*

```diff
@@ -2,30 +2,32 @@
 import pytest
 import numpy as np
 from numpy.testing import assert_allclose
 from astropy import units as u
 from astropy.coordinates import EarthLocation, SkyCoord
 from astropy.table import Table
 from gammapy.data import Observation
+from gammapy.data.pointing import FixedPointingInfo, PointingMode
 from gammapy.datasets import MapDataset, SpectrumDatasetOnOff
 from gammapy.datasets.spectrum import SpectrumDataset
 from gammapy.estimators import FluxPoints, FluxPointsEstimator
-from gammapy.irf import EDispKernelMap, EffectiveAreaTable2D, load_cta_irfs
+from gammapy.irf import EDispKernelMap, EffectiveAreaTable2D, load_irf_dict_from_file
 from gammapy.makers import MapDatasetMaker
 from gammapy.makers.utils import make_map_exposure_true_energy
 from gammapy.maps import MapAxis, RegionGeom, RegionNDMap, WcsGeom
 from gammapy.modeling import Fit
 from gammapy.modeling.models import (
     ExpCutoffPowerLawSpectralModel,
     FoVBackgroundModel,
     GaussianSpatialModel,
     PowerLawSpectralModel,
     SkyModel,
 )
-from gammapy.utils.testing import requires_data
+from gammapy.utils import parallel
+from gammapy.utils.testing import requires_data, requires_dependency
 
 
 # TODO: use pre-generated data instead
 def simulate_spectrum_dataset(model, random_state=0):
     energy_edges = np.logspace(-0.5, 1.5, 21) * u.TeV
     energy_axis = MapAxis.from_edges(energy_edges, interp="log", name="energy")
     energy_axis_true = energy_axis.copy(name="energy_true")
@@ -92,34 +94,35 @@
         fit=Fit(backend="minuit", optimize_opts=dict(tol=0.2, strategy=1)),
     )
     datasets = [dataset]
     return datasets, fpe
 
 
 def simulate_map_dataset(random_state=0, name=None):
-    irfs = load_cta_irfs(
+    irfs = load_irf_dict_from_file(
         "$GAMMAPY_DATA/cta-1dc/caldb/data/cta/1dc/bcf/South_z20_50h/irf_file.fits"
     )
 
     skydir = SkyCoord("0 deg", "0 deg", frame="galactic")
+    pointing = FixedPointingInfo(mode=PointingMode.POINTING, fixed_icrs=skydir.icrs)
     energy_edges = np.logspace(-1, 2, 15) * u.TeV
     energy_axis = MapAxis.from_edges(edges=energy_edges, name="energy", interp="log")
 
     geom = WcsGeom.create(
         skydir=skydir, width=(4, 4), binsz=0.1, axes=[energy_axis], frame="galactic"
     )
 
     gauss = GaussianSpatialModel(
         lon_0="0 deg", lat_0="0 deg", sigma="0.4 deg", frame="galactic"
     )
     pwl = PowerLawSpectralModel(amplitude="1e-11 cm-2 s-1 TeV-1")
     skymodel = SkyModel(spatial_model=gauss, spectral_model=pwl, name="source")
 
     obs = Observation.create(
-        pointing=skydir,
+        pointing=pointing,
         livetime=1 * u.h,
         irfs=irfs,
         location=EarthLocation(lon="-70d18m58.84s", lat="-24d41m0.34s", height="2000m"),
     )
     empty = MapDataset.create(geom, name=name)
     maker = MapDatasetMaker(selection=["exposure", "background", "psf", "edisp"])
     dataset = maker.run(empty, obs)
@@ -387,15 +390,14 @@
 def test_flux_points_estimator_no_norm_scan(fpe_pwl, tmpdir):
     datasets, fpe = fpe_pwl
     fpe.selection_optional = None
 
     fp = fpe.run(datasets)
 
     assert_allclose(fpe.fit.optimize_opts["tol"], 0.2)
-    assert_allclose(fpe.fit.minuit.tol, 0.2)
 
     assert fp.sed_type_init == "likelihood"
     assert "stat_scan" not in fp._data
 
     # test GADF I/O
     fp.write(tmpdir / "test.fits", format="gadf-sed")
     fp_new = FluxPoints.read(tmpdir / "test.fits")
@@ -524,14 +526,61 @@
     assert fp1.meta["n_sigma_ul"] == 4
 
     # check that it returns a sensible value
     fp2 = fp.recompute_ul(n_sigma_ul=2)
     assert_allclose(fp2.flux_ul.data, fp.flux_ul.data, rtol=1e-2)
 
 
+def test_flux_points_parallel_multiprocessing(fpe_pwl):
+    datasets, fpe = fpe_pwl
+    fpe.selection_optional = ["all"]
+    fpe.n_jobs = 2
+    assert fpe.n_jobs == 2
+
+    fp = fpe.run(datasets)
+    assert_allclose(
+        fp.flux_ul.data,
+        [[[2.629819e-12]], [[9.319243e-13]], [[9.004449e-14]]],
+        rtol=1e-3,
+    )
+
+
+def test_global_n_jobs_default_handling():
+    fpe = FluxPointsEstimator(energy_edges=[1, 3, 10] * u.TeV)
+
+    assert fpe.n_jobs == 1
+
+    parallel.N_JOBS_DEFAULT = 2
+    assert fpe.n_jobs == 2
+
+    fpe.n_jobs = 5
+    assert fpe.n_jobs == 5
+
+    fpe.n_jobs = None
+    assert fpe.n_jobs == 2
+    assert fpe._n_jobs is None
+
+    parallel.N_JOBS_DEFAULT = 1
+    assert fpe.n_jobs == 1
+
+
+@requires_dependency("ray")
+def test_flux_points_parallel_ray(fpe_pwl):
+    datasets, fpe = fpe_pwl
+    fpe.selection_optional = ["all"]
+    fpe.parallel_backend = "ray"
+    fpe.n_jobs = 2
+    fp = fpe.run(datasets)
+    assert_allclose(
+        fp.flux_ul.data,
+        [[[2.629819e-12]], [[9.319243e-13]], [[9.004449e-14]]],
+        rtol=1e-3,
+    )
+
+
 def test_fpe_non_aligned_energy_axes():
     energy_axis = MapAxis.from_energy_bounds("1 TeV", "10 TeV", nbin=10)
     geom_1 = RegionGeom.create("icrs;circle(0, 0, 0.1)", axes=[energy_axis])
     dataset_1 = SpectrumDataset.create(geom=geom_1)
 
     energy_axis = MapAxis.from_energy_bounds("1 TeV", "10 TeV", nbin=7)
     geom_2 = RegionGeom.create("icrs;circle(0, 0, 0.1)", axes=[energy_axis])
```

### Comparing `gammapy-1.0rc2/gammapy/estimators/profile.py` & `gammapy-1.1rc1/gammapy/estimators/profile.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,14 +3,15 @@
 import numpy as np
 import scipy.ndimage
 from astropy import units as u
 from astropy.convolution import Box1DKernel, Gaussian1DKernel
 from astropy.coordinates import Angle
 from astropy.table import Table
 import matplotlib.pyplot as plt
+from gammapy.maps.axes import UNIT_STRING_FORMAT
 from .core import Estimator
 
 __all__ = ["ImageProfile", "ImageProfileEstimator"]
 
 
 # TODO: implement measuring profile along arbitrary directions
 # TODO: think better about error handling. e.g. MC based methods
@@ -321,15 +322,15 @@
         ymax = y + self.table["profile_err"].data
         x = self.x_ref.value
 
         # plotting defaults
         kwargs.setdefault("alpha", 0.5)
 
         ax.fill_between(x, ymin, ymax, **kwargs)
-        ax.set_xlabel("x (deg)")
+        ax.set_xlabel(f"x [{u.deg.to_string(UNIT_STRING_FORMAT)}]")
         ax.set_ylabel("profile")
         return ax
 
     @property
     def x_ref(self):
         """Reference x coordinates."""
         return self.table["x_ref"].quantity
```

### Comparing `gammapy-1.0rc2/gammapy/estimators/tests/test_flux.py` & `gammapy-1.1rc1/gammapy/estimators/tests/test_flux.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/estimators/tests/test_parameter_estimator.py` & `gammapy-1.1rc1/gammapy/estimators/tests/test_parameter_estimator.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/estimators/tests/test_profile.py` & `gammapy-1.1rc1/gammapy/estimators/tests/test_profile.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/estimators/tests/test_utils.py` & `gammapy-1.1rc1/gammapy/estimators/tests/test_utils.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/estimators/utils.py` & `gammapy-1.1rc1/gammapy/estimators/utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -9,15 +9,19 @@
 from gammapy.maps import WcsNDMap
 from gammapy.modeling.models import (
     ConstantFluxSpatialModel,
     PowerLawSpectralModel,
     SkyModel,
 )
 
-__all__ = ["estimate_exposure_reco_energy", "find_peaks", "resample_energy_edges"]
+__all__ = [
+    "estimate_exposure_reco_energy",
+    "find_peaks",
+    "resample_energy_edges",
+]
 
 
 def find_peaks(image, threshold, min_distance=1):
     """Find local peaks in an image.
 
     This is a very simple peak finder, that finds local peaks
     (i.e. maxima) in images above a given ``threshold`` within
```

### Comparing `gammapy-1.0rc2/gammapy/extern/xmltodict.py` & `gammapy-1.1rc1/gammapy/extern/xmltodict.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/irf/__init__.py` & `gammapy-1.1rc1/gammapy/irf/__init__.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/irf/background.py` & `gammapy-1.1rc1/gammapy/irf/background.py`

 * *Files 4% similar despite different names*

```diff
@@ -2,14 +2,15 @@
 import logging
 import numpy as np
 import astropy.units as u
 from astropy.visualization import quantity_support
 import matplotlib.pyplot as plt
 from matplotlib.colors import LogNorm
 from gammapy.maps import MapAxes, MapAxis
+from gammapy.maps.axes import UNIT_STRING_FORMAT
 from .core import IRF
 from .io import gadf_is_pointlike
 
 __all__ = ["Background3D", "Background2D"]
 
 log = logging.getLogger(__name__)
 
@@ -93,14 +94,16 @@
     ----------
     axes : list of `MapAxis` or `MapAxes` object
         Required data axes: ["energy", "fov_lon", "fov_lat"] in the given order.
     data : `~np.ndarray`
         Data array.
     unit : str or `~astropy.units.Unit`
         Data unit usually ``s^-1 MeV^-1 sr^-1``
+    fov_alignment: `~gammapy.irf.FoVAlignment`
+        The orientation of the field of view coordinate system.
     meta : dict
         Meta data
 
     Examples
     --------
     Here's an example you can use to learn about this class:
 
@@ -200,15 +203,15 @@
             with quantity_support():
                 caxes = ax.pcolormesh(X, Y, bkg.squeeze(), **kwargs)
 
             self.axes["fov_lat"].format_plot_xaxis(ax)
             self.axes["fov_lon"].format_plot_yaxis(ax)
             ax.set_title(str(ee))
             if add_cbar:
-                label = f"Background [{bkg.unit}]"
+                label = f"Background [{bkg.unit.to_string(UNIT_STRING_FORMAT)}]"
                 cbar = ax.figure.colorbar(caxes, ax=ax, label=label, fraction=cfraction)
                 cbar.formatter.set_powerlimits((0, 0))
 
             row, col = np.unravel_index(i, shape=(rows, cols))
             if col > 0:
                 ax.set_ylabel("")
             if row < rows - 1:
@@ -298,15 +301,17 @@
                 energy_axis.edges, offset_axis.edges, data.T, **kwargs
             )
 
         energy_axis.format_plot_xaxis(ax=ax)
         offset_axis.format_plot_yaxis(ax=ax)
 
         if add_cbar:
-            label = f"Background rate [{self.unit}]"
+            label = (
+                f"Background rate [{self.quantity.unit.to_string(UNIT_STRING_FORMAT)}]"
+            )
             ax.figure.colorbar(caxes, ax=ax, label=label)
 
     def plot_offset_dependence(self, ax=None, energy=None, **kwargs):
         """Plot background rate versus offset for a given energy.
 
         Parameters
         ----------
@@ -334,15 +339,17 @@
             if np.isnan(bkg).all():
                 continue
             label = f"energy = {ee:.1f}"
             with quantity_support():
                 ax.plot(offset_axis.center, bkg, label=label, **kwargs)
 
         offset_axis.format_plot_xaxis(ax=ax)
-        ax.set_ylabel(f"Background rate ({ax.yaxis.units})")
+        ax.set_ylabel(
+            f"Background rate [{ax.yaxis.units.to_string(UNIT_STRING_FORMAT)}]"
+        )
         ax.set_yscale("log")
         ax.legend(loc="upper right")
         return ax
 
     def plot_energy_dependence(self, ax=None, offset=None, **kwargs):
         """Plot background rate versus energy for a given offset.
 
@@ -373,15 +380,17 @@
             bkg = self.evaluate(offset=off, energy=energy_axis.center)
             label = f"offset = {off:.2f}"
             with quantity_support():
                 ax.plot(energy_axis.center, bkg, label=label, **kwargs)
 
         energy_axis.format_plot_xaxis(ax=ax)
         ax.set_yscale("log")
-        ax.set_ylabel(f"Background rate ({ax.yaxis.units})")
+        ax.set_ylabel(
+            f"Background rate [{ax.yaxis.units.to_string(UNIT_STRING_FORMAT)}]"
+        )
         ax.legend(loc="best")
         return ax
 
     def plot_spectrum(self, ax=None, **kwargs):
         """Plot angle integrated background rate versus energy.
 
         Parameters
@@ -404,15 +413,17 @@
         bkg = self.integral(offset=offset_axis.bounds[1], axis_name="offset")
 
         with quantity_support():
             ax.plot(energy_axis.center, bkg, label="integrated spectrum", **kwargs)
 
         energy_axis.format_plot_xaxis(ax=ax)
         ax.set_yscale("log")
-        ax.set_ylabel(f"Background rate ({ax.yaxis.units})")
+        ax.set_ylabel(
+            f"Background rate [{ax.yaxis.units.to_string(UNIT_STRING_FORMAT)}]"
+        )
         ax.legend(loc="best")
         return ax
 
     def peek(self, figsize=(10, 8)):
         """Quick-look summary plots."""
         fig, axes = plt.subplots(nrows=2, ncols=2, figsize=figsize)
         self.plot(ax=axes[1][1])
```

### Comparing `gammapy-1.0rc2/gammapy/irf/core.py` & `gammapy-1.1rc1/gammapy/irf/core.py`

 * *Files 1% similar despite different names*

```diff
@@ -480,14 +480,17 @@
 
         if format == "gadf-dl3":
             table.meta = self.meta.copy()
             spec = IRF_DL3_HDU_SPECIFICATION[self.tag]
 
             table.meta.update(spec["mandatory_keywords"])
 
+            if "FOVALIGN" in table.meta:
+                table.meta["FOVALIGN"] = self.fov_alignment.value
+
             if self.is_pointlike:
                 table.meta["HDUCLAS3"] = "POINT-LIKE"
             else:
                 table.meta["HDUCLAS3"] = "FULL-ENCLOSURE"
 
             table[spec["column_name"]] = self.quantity.T[np.newaxis]
         else:
@@ -719,14 +722,16 @@
             File format
 
         Returns
         -------
         irf_map : `IRFMap`
             IRF map.
         """
+
+        output_class = cls
         if format == "gadf":
             if hdu is None:
                 hdu = IRF_MAP_HDU_SPECIFICATION[cls.tag]
 
             irf_map = Map.from_hdulist(
                 hdulist, hdu=hdu, hdu_bands=hdu_bands, format=format
             )
@@ -739,14 +744,24 @@
                     hdulist,
                     hdu=exposure_hdu,
                     hdu_bands=exposure_hdu_bands,
                     format=format,
                 )
             else:
                 exposure_map = None
+
+            if cls.tag == "psf_map" and "energy" in irf_map.geom.axes.names:
+                from .psf import RecoPSFMap
+
+                output_class = RecoPSFMap
+            if cls.tag == "edisp_map" and irf_map.geom.axes[0].name == "energy":
+                from .edisp import EDispKernelMap
+
+                output_class = EDispKernelMap
+
         elif format == "gtpsf":
             rad_axis = MapAxis.from_table_hdu(hdulist["THETA"], format=format)
 
             table = Table.read(hdulist["PSF"])
             energy_axis_true = MapAxis.from_table(table, format=format)
 
             geom_psf = RegionGeom.create(region=None, axes=[rad_axis, energy_axis_true])
@@ -757,15 +772,15 @@
             exposure_map = Map.from_geom(
                 geom=geom_exposure, data=table["Exposure"].data, unit="cm2 s"
             )
             return cls(psf_map=psf_map, exposure_map=exposure_map)
         else:
             raise ValueError(f"Format {format} not supported")
 
-        return cls(irf_map, exposure_map)
+        return output_class(irf_map, exposure_map)
 
     @classmethod
     def read(cls, filename, format="gadf", hdu=None):
         """Read an IRF_map from file and create corresponding object"
 
         Parameters
         ----------
```

### Comparing `gammapy-1.0rc2/gammapy/irf/edisp/core.py` & `gammapy-1.1rc1/gammapy/irf/edisp/core.py`

 * *Files 3% similar despite different names*

```diff
@@ -48,14 +48,22 @@
     EnergyDispersion
     """
 
     tag = "edisp_2d"
     required_axes = ["energy_true", "migra", "offset"]
     default_unit = u.one
 
+    @property
+    def _default_offset(self):
+        if self.axes["offset"].nbin == 1:
+            default_offset = self.axes["offset"].center
+        else:
+            default_offset = [1.0] * u.deg
+        return default_offset
+
     def _mask_out_bounds(self, invalid):
         return (
             invalid[self.axes.index("energy_true")] & invalid[self.axes.index("migra")]
         ) | invalid[self.axes.index("offset")]
 
     @classmethod
     def from_gauss(
@@ -178,15 +186,15 @@
         -------
         ax : `~matplotlib.axes.Axes`
             Axis
         """
         ax = plt.gca() if ax is None else ax
 
         if offset is None:
-            offset = Angle([1], "deg")
+            offset = self._default_offset
         else:
             offset = np.atleast_1d(Angle(offset))
 
         if energy_true is None:
             energy_true = u.Quantity([0.1, 1, 10], "TeV")
         else:
             energy_true = np.atleast_1d(u.Quantity(energy_true))
@@ -228,15 +236,15 @@
         """
         kwargs.setdefault("cmap", "GnBu")
         kwargs.setdefault("norm", PowerNorm(gamma=0.5))
 
         ax = plt.gca() if ax is None else ax
 
         if offset is None:
-            offset = Angle(1, "deg")
+            offset = self._default_offset
 
         energy_true = self.axes["energy_true"]
         migra = self.axes["migra"]
 
         z = self.evaluate(
             offset=offset,
             energy_true=energy_true.center.reshape(1, -1, 1),
@@ -262,11 +270,11 @@
         ----------
         figsize : (float, float)
             Size of the resulting plot
         """
         fig, axes = plt.subplots(nrows=1, ncols=3, figsize=figsize)
         self.plot_bias(ax=axes[0])
         self.plot_migration(ax=axes[1])
-        edisp = self.to_edisp_kernel(offset="1 deg")
+        edisp = self.to_edisp_kernel(offset=self._default_offset[0])
         edisp.plot_matrix(ax=axes[2])
 
         plt.tight_layout()
```

### Comparing `gammapy-1.0rc2/gammapy/irf/edisp/kernel.py` & `gammapy-1.1rc1/gammapy/irf/edisp/kernel.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,14 +3,15 @@
 from astropy.io import fits
 from astropy.table import Table
 from astropy.units import Quantity
 from astropy.visualization import quantity_support
 import matplotlib.pyplot as plt
 from matplotlib.colors import PowerNorm
 from gammapy.maps import MapAxis
+from gammapy.maps.axes import UNIT_STRING_FORMAT
 from gammapy.utils.scripts import make_path
 from ..core import IRF
 
 __all__ = ["EDispKernel"]
 
 
 class EDispKernel(IRF):
@@ -324,17 +325,17 @@
             Matrix table
 
         """
         table = self.axes["energy_true"].to_table(format=format)
 
         rows = self.pdf_matrix.shape[0]
         n_grp = []
-        f_chan = np.ndarray(dtype=np.object, shape=rows)
-        n_chan = np.ndarray(dtype=np.object, shape=rows)
-        matrix = np.ndarray(dtype=np.object, shape=rows)
+        f_chan = np.ndarray(dtype=object, shape=rows)
+        n_chan = np.ndarray(dtype=object, shape=rows)
+        matrix = np.ndarray(dtype=object, shape=rows)
 
         # Make RMF type matrix
         for idx, row in enumerate(self.data):
             pos = np.nonzero(row)[0]
             borders = np.where(np.diff(pos) != 1)[0]
             # add 1 to borders for correct behaviour of np.split
             groups = np.split(pos, borders + 1)
@@ -570,15 +571,17 @@
 
         energy = self.axes["energy_true"].center
         bias = self.get_bias(energy)
 
         with quantity_support():
             ax.plot(energy, bias, **kwargs)
 
-        ax.set_xlabel(f"$E_\\mathrm{{True}}$ [{ax.yaxis.units}]")
+        ax.set_xlabel(
+            f"$E_\\mathrm{{True}}$ [{ax.yaxis.units.to_string(UNIT_STRING_FORMAT)}]"
+        )
         ax.set_ylabel(
             "($E_\\mathrm{{Reco}} - E_\\mathrm{{True}}) / E_\\mathrm{{True}}$"
         )
         ax.set_xscale("log")
         return ax
 
     def peek(self, figsize=(15, 5)):
```

### Comparing `gammapy-1.0rc2/gammapy/irf/edisp/map.py` & `gammapy-1.1rc1/gammapy/irf/edisp/map.py`

 * *Files 4% similar despite different names*

```diff
@@ -29,54 +29,54 @@
         the input Energy Dispersion Map. Should be a Map with 2 non spatial axes.
         migra and true energy axes should be given in this specific order.
     exposure_map : `~gammapy.maps.Map`, optional
         Associated exposure map. Needs to have a consistent map geometry.
 
     Examples
     --------
-    ::
+    .. doctest::
 
         import numpy as np
         from astropy import units as u
         from astropy.coordinates import SkyCoord
         from gammapy.maps import WcsGeom, MapAxis
         from gammapy.irf import EnergyDispersion2D, EffectiveAreaTable2D
         from gammapy.makers.utils import make_edisp_map, make_map_exposure_true_energy
 
         # Define energy dispersion map geometry
-        energy_axis = MapAxis.from_edges(np.logspace(-1, 1, 4), unit="TeV", name="energy")
+        energy_axis_true = MapAxis.from_edges(np.logspace(-1, 1, 10), unit="TeV", name="energy_true")
         migra_axis = MapAxis.from_edges(np.linspace(0, 3, 100), name="migra")
         pointing = SkyCoord(0, 0, unit="deg")
-        max_offset = 4 * u.deg
         geom = WcsGeom.create(
-            binsz=0.25 * u.deg,
-            width=10 * u.deg,
-            skydir=pointing,
-            axes=[migra_axis, energy_axis],
+                binsz=0.25 * u.deg,
+                width=10 * u.deg,
+                skydir=pointing,
+                axes=[migra_axis, energy_axis_true],
         )
 
         # Extract EnergyDispersion2D from CTA 1DC IRF
         filename = "$GAMMAPY_DATA/cta-1dc/caldb/data/cta/1dc/bcf/South_z20_50h/irf_file.fits"
         edisp2D = EnergyDispersion2D.read(filename, hdu="ENERGY DISPERSION")
         aeff2d = EffectiveAreaTable2D.read(filename, hdu="EFFECTIVE AREA")
 
         # Create the exposure map
-        exposure_geom = geom.to_image().to_cube([energy_axis])
+        exposure_geom = geom.squash(axis_name="migra")
         exposure_map = make_map_exposure_true_energy(pointing, "1 h", aeff2d, exposure_geom)
 
         # create the EDispMap for the specified pointing
-        edisp_map = make_edisp_map(edisp2D, pointing, geom, max_offset, exposure_map)
+        edisp_map = make_edisp_map(edisp2D, pointing, geom, exposure_map)
 
         # Get an Energy Dispersion (1D) at any position in the image
         pos = SkyCoord(2.0, 2.5, unit="deg")
-        energy = np.logspace(-1.0, 1.0, 10) * u.TeV
-        edisp = edisp_map.get_edisp_kernel(pos=pos, energy=energy)
+        energy_axis = MapAxis.from_energy_bounds(0.1, 10, 5, unit="TeV", name="energy")
+        edisp = edisp_map.get_edisp_kernel(energy_axis, position=pos)
 
         # Write map to disk
         edisp_map.write("edisp_map.fits")
+
     """
 
     tag = "edisp_map"
     required_axes = ["migra", "energy_true"]
 
     def __init__(self, edisp_map, exposure_map=None):
         super().__init__(irf_map=edisp_map, exposure_map=exposure_map)
```

### Comparing `gammapy-1.0rc2/gammapy/irf/edisp/tests/test_core.py` & `gammapy-1.1rc1/gammapy/irf/edisp/tests/test_core.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/irf/edisp/tests/test_kernel.py` & `gammapy-1.1rc1/gammapy/irf/edisp/tests/test_kernel.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 import astropy.units as u
 from gammapy.irf import EDispKernel
 from gammapy.maps import MapAxis
 from gammapy.utils.testing import mpl_plot_check, requires_data
 
 
 class TestEDispKernel:
-    def setup(self):
+    def setup_method(self):
         energy_axis = MapAxis.from_energy_bounds("1 TeV", "10 TeV", nbin=100)
         energy_axis_true = energy_axis.copy(name="energy_true")
 
         self.resolution = 0.1
         self.bias = 0
         self.edisp = EDispKernel.from_gauss(
             energy_axis_true=energy_axis_true,
```

### Comparing `gammapy-1.0rc2/gammapy/irf/edisp/tests/test_map.py` & `gammapy-1.1rc1/gammapy/irf/edisp/tests/test_map.py`

 * *Files 0% similar despite different names*

```diff
@@ -318,12 +318,15 @@
 
 def test_peek():
     e_reco = MapAxis.from_energy_bounds("0.1 TeV", "10 TeV", nbin=3)
     e_true = MapAxis.from_energy_bounds(
         "0.08 TeV", "20 TeV", nbin=5, name="energy_true"
     )
     edisp = EDispKernelMap.from_diagonal_response(e_reco, e_true)
+
     with mpl_plot_check():
         edisp.peek()
+
     edisp = EDispMap.from_diagonal_response(e_true)
+
     with mpl_plot_check():
         edisp.peek()
```

### Comparing `gammapy-1.0rc2/gammapy/irf/effective_area.py` & `gammapy-1.1rc1/gammapy/irf/effective_area.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import numpy as np
 import astropy.units as u
 from astropy.visualization import quantity_support
 import matplotlib.pyplot as plt
 from gammapy.maps import MapAxes, MapAxis
+from gammapy.maps.axes import UNIT_STRING_FORMAT
 from .core import IRF
 
 __all__ = ["EffectiveAreaTable2D"]
 
 
 class EffectiveAreaTable2D(IRF):
     """2D effective area table.
@@ -97,15 +98,17 @@
         for off in offset:
             area = self.evaluate(offset=off, energy_true=energy_axis.center)
             label = kwargs.pop("label", f"offset = {off:.1f}")
             with quantity_support():
                 ax.plot(energy_axis.center, area, label=label, **kwargs)
 
         energy_axis.format_plot_xaxis(ax=ax)
-        ax.set_ylabel(f"Effective Area [{ax.yaxis.units}]")
+        ax.set_ylabel(
+            f"Effective Area [{ax.yaxis.units.to_string(UNIT_STRING_FORMAT)}]"
+        )
         ax.legend()
         return ax
 
     def plot_offset_dependence(self, ax=None, energy=None, **kwargs):
         """Plot effective area versus offset for a given energy.
 
         Parameters
@@ -166,44 +169,46 @@
         with quantity_support():
             caxes = ax.pcolormesh(energy.edges, offset.edges, aeff.value.T, **kwargs)
 
         energy.format_plot_xaxis(ax=ax)
         offset.format_plot_yaxis(ax=ax)
 
         if add_cbar:
-            label = f"Effective Area [{aeff.unit}]"
+            label = f"Effective Area [{aeff.unit.to_string(UNIT_STRING_FORMAT)}]"
             ax.figure.colorbar(caxes, ax=ax, label=label)
 
         return ax
 
     def peek(self, figsize=(15, 5)):
         """Quick-look summary plots.
 
         Parameters
         ----------
         figsize : tuple
             Size of the figure.
 
         """
-        fig, axes = plt.subplots(nrows=1, ncols=3, figsize=figsize)
-        self.plot(ax=axes[2])
+        ncols = 2 if self.is_pointlike else 3
+        fig, axes = plt.subplots(nrows=1, ncols=ncols, figsize=figsize)
+        self.plot(ax=axes[ncols - 1])
         self.plot_energy_dependence(ax=axes[0])
-        self.plot_offset_dependence(ax=axes[1])
+        if self.is_pointlike is False:
+            self.plot_offset_dependence(ax=axes[1])
         plt.tight_layout()
 
     @classmethod
     def from_parametrization(cls, energy_axis_true=None, instrument="HESS"):
         r"""Create parametrized effective area.
 
         Parametrizations of the effective areas of different Cherenkov
         telescopes taken from Appendix B of Abramowski et al. (2010), see
         https://ui.adsabs.harvard.edu/abs/2010MNRAS.402.1342A .
 
         .. math::
-            A_{eff}(E) = g_1 \left(\frac{E}{\mathrm{MeV}}\right)^{-g_2}\exp{\left(-\frac{g_3}{E}\right)}  # noqa: E501
+            A_{eff}(E) = g_1 \left(\frac{E}{\mathrm{MeV}}\right)^{-g_2}\exp{\left(-\frac{g_3}{E}\right)}
 
         This method does not model the offset dependence of the effective area,
         but just assumes that it is constant.
 
         Parameters
         ----------
         energy_axis_true : `MapAxis`
@@ -211,15 +216,15 @@
         instrument : {'HESS', 'HESS2', 'CTA'}
             Instrument name
 
         Returns
         -------
         aeff : `EffectiveAreaTable2D`
             Effective area table
-        """
+        """  # noqa: E501
         # Put the parameters g in a dictionary.
         # Units: g1 (cm^2), g2 (), g3 (MeV)
         pars = {
             "HESS": [6.85e9, 0.0891, 5e5],
             "HESS2": [2.05e9, 0.0891, 1e5],
             "CTA": [1.71e11, 0.0891, 1e5],
         }
```

### Comparing `gammapy-1.0rc2/gammapy/irf/io.py` & `gammapy-1.1rc1/gammapy/irf/io.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,11 +1,12 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import logging
 from astropy.io import fits
 from gammapy.data.hdu_index_table import HDUIndexTable
+from gammapy.utils.deprecation import deprecated
 from gammapy.utils.fits import HDULocation
 from gammapy.utils.scripts import make_path
 
 __all__ = ["load_cta_irfs", "load_irf_dict_from_file"]
 
 log = logging.getLogger(__name__)
 
@@ -39,14 +40,15 @@
         "extname": "BACKGROUND",
         "column_name": "BKG",
         "mandatory_keywords": {
             **COMMON_IRF_HEADERS,
             "HDUCLAS2": "BKG",
             "HDUCLAS3": "FULL-ENCLOSURE",  # added here to have HDUCLASN in order
             "HDUCLAS4": "BKG_3D",
+            "FOVALIGN": "RADEC",
         },
     },
     "bkg_2d": {
         "extname": "BACKGROUND",
         "column_name": "BKG",
         "mandatory_keywords": {
             **COMMON_IRF_HEADERS,
@@ -137,16 +139,22 @@
 
 
 def gadf_is_pointlike(header):
     """Check if a GADF IRF is pointlike based on the header"""
     return header.get("HDUCLAS3") == "POINT-LIKE"
 
 
+@deprecated("v1.1", alternative="load_irf_dict_from_file")
 def load_cta_irfs(filename):
-    """load CTA instrument response function and return a dictionary container.
+    """Load IRFs from file as written by the CTA DC1 into a dict
+
+    This function has a hardcoded list of IRF types and HDU names
+    and does not check what types of IRFs are actually present in the file.
+
+    Please use `load_irf_dict_from_file` instead..
 
     The IRF format should be compliant with the one discussed
     at http://gamma-astro-data-formats.readthedocs.io/en/latest/irfs/.
 
     The various IRFs are accessible with the following keys:
 
     - 'aeff' is a `~gammapy.irf.EffectiveAreaTable2D`
@@ -191,17 +199,47 @@
     bkg = Background3D.read(filename, hdu="BACKGROUND")
     edisp = EnergyDispersion2D.read(filename, hdu="ENERGY DISPERSION")
     psf = EnergyDependentMultiGaussPSF.read(filename, hdu="POINT SPREAD FUNCTION")
 
     return dict(aeff=aeff, bkg=bkg, edisp=edisp, psf=psf)
 
 
+class UnknownHDUClass(IOError):
+    """Raised when a file contains an unknown HDUCLASS"""
+
+
+def _get_hdu_type_and_class(header):
+    """Get gammapy hdu_type and class from FITS header
+
+    Contains a workaround to support CTA 1DC irf file.
+    """
+    hdu_clas2 = header.get("HDUCLAS2", "")
+    hdu_clas4 = header.get("HDUCLAS4", "")
+
+    clas2_to_type = {"rpsf": "psf", "eff_area": "aeff"}
+    hdu_type = clas2_to_type.get(hdu_clas2.lower(), hdu_clas2.lower())
+    hdu_class = hdu_clas4.lower()
+
+    if hdu_type not in HDUIndexTable.VALID_HDU_TYPE:
+        raise UnknownHDUClass(f"HDUCLAS2={hdu_clas2}, HDUCLAS4={hdu_clas4}")
+
+    # workaround for CTA 1DC files with non-compliant HDUCLAS4 names
+    if hdu_class not in HDUIndexTable.VALID_HDU_CLASS:
+        hdu_class = f"{hdu_type}_{hdu_class}"
+
+    if hdu_class not in HDUIndexTable.VALID_HDU_CLASS:
+        raise UnknownHDUClass(f"HDUCLAS2={hdu_clas2}, HDUCLAS4={hdu_clas4}")
+
+    return hdu_type, hdu_class
+
+
 def load_irf_dict_from_file(filename):
-    """Open a fits file and generate a dictionary containing the Gammapy objects
-    corresponding to the IRF components stored
+    """Load all available IRF components from given file into a dict.
+
+    If multiple IRFs of the same type are present, the first encountered is returned.
 
     Parameters
     ----------
     filename : str, Path
         path to the file containing the IRF components, if EVENTS and GTI HDUs
         are included in the file, they are ignored
 
@@ -210,47 +248,47 @@
     irf_dict : dict of `~gammapy.irf.IRF`
         dictionary with instances of the Gammapy objects corresponding
         to the IRF components
     """
     from .rad_max import RadMax2D
 
     filename = make_path(filename)
-
-    hdulist = fits.open(make_path(filename))
-
     irf_dict = {}
-
     is_pointlike = False
 
-    for hdu in hdulist:
-        hdu_class = hdu.header.get("HDUCLAS1", "").lower()
-
-        if hdu_class == "response":
-            hdu_class = hdu.header.get("HDUCLAS4", "").lower()
-
-            is_pointlike |= hdu.header["HDUCLAS3"] == "POINT-LIKE"
+    with fits.open(filename) as hdulist:
+        for hdu in hdulist:
+            hdu_clas1 = hdu.header.get("HDUCLAS1", "").lower()
+
+            # not an IRF component
+            if hdu_clas1 != "response":
+                continue
+
+            is_pointlike |= hdu.header.get("HDUCLAS3") == "POINT-LIKE"
+
+            try:
+                hdu_type, hdu_class = _get_hdu_type_and_class(hdu.header)
+            except UnknownHDUClass as e:
+                log.warning("File has unknown class %s", e)
+                continue
 
             loc = HDULocation(
                 hdu_class=hdu_class,
                 hdu_name=hdu.name,
                 file_dir=filename.parent,
                 file_name=filename.name,
             )
 
-            for name in HDUIndexTable.VALID_HDU_TYPE:
-                if name in hdu_class:
-                    if name in irf_dict.keys():
-                        log.warning(f"more than one HDU of {name} type found")
-                        log.warning(
-                            f"loaded the {irf_dict[name].meta['EXTNAME']} HDU in the dictionary"
-                        )
-                        continue
-                    data = loc.load()
-                    # TODO: maybe introduce IRF.type attribute...
-                    irf_dict[name] = data
-        else:  # not an IRF component
-            continue
+            if hdu_type in irf_dict.keys():
+                log.warning(f"more than one HDU of {hdu_type} type found")
+                log.warning(
+                    f"loaded the {irf_dict[hdu_type].meta['EXTNAME']} HDU in the dictionary"
+                )
+                continue
+
+            data = loc.load()
+            irf_dict[hdu_type] = data
 
     if is_pointlike and "rad_max" not in irf_dict:
         irf_dict["rad_max"] = RadMax2D.from_irf(irf_dict["aeff"])
 
     return irf_dict
```

### Comparing `gammapy-1.0rc2/gammapy/irf/psf/core.py` & `gammapy-1.1rc1/gammapy/irf/psf/core.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import numpy as np
 from astropy import units as u
 from astropy.visualization import quantity_support
 import matplotlib.pyplot as plt
 import matplotlib.ticker as mtick
+from gammapy.maps.axes import UNIT_STRING_FORMAT
 from gammapy.utils.array import array_stats_str
 from ..core import IRF
 
 
 class PSF(IRF):
     """PSF base class"""
 
@@ -153,15 +154,17 @@
                 )
                 plot_kwargs.setdefault("label", f"{theta}, {100 * frac:.1f}%")
                 with quantity_support():
                     ax.plot(energy_true.center, radius, **plot_kwargs)
 
         energy_true.format_plot_xaxis(ax=ax)
         ax.legend(loc="best")
-        ax.set_ylabel(f"Containment radius [{ax.yaxis.units}]")
+        ax.set_ylabel(
+            f"Containment radius [{ax.yaxis.units.to_string(UNIT_STRING_FORMAT)}]"
+        )
         ax.yaxis.set_major_formatter(mtick.FormatStrFormatter("%.1e"))
         return ax
 
     def plot_containment_radius(self, ax=None, fraction=0.68, add_cbar=True, **kwargs):
         """Plot containment image with energy and theta axes.
 
         Parameters
@@ -244,15 +247,15 @@
                 label = f"Offset: {theta:.1f}, Energy: {energy:.1f}"
                 with quantity_support():
                     ax.plot(rad.center, psf_value, label=label, **kwargs)
 
         rad.format_plot_xaxis(ax=ax)
 
         ax.set_yscale("log")
-        ax.set_ylabel(f"PSF ({ax.yaxis.units})")
+        ax.set_ylabel(f"PSF [{ax.yaxis.units.to_string(UNIT_STRING_FORMAT)}]")
         plt.legend()
         return ax
 
     def peek(self, figsize=(15, 5)):
         """Quick-look summary plots.
 
         Parameters
```

### Comparing `gammapy-1.0rc2/gammapy/irf/psf/kernel.py` & `gammapy-1.1rc1/gammapy/irf/psf/kernel.py`

 * *Files 1% similar despite different names*

```diff
@@ -225,15 +225,15 @@
         Returns
         -------
         ax : `~matplotlib.axes.Axes`
             Axis
         """
         ax = plt.gca() if ax is None else ax
 
-        if energy:
+        if energy is not None:
             kernel_map = self.psf_kernel_map
             energy_center = kernel_map.geom.axes["energy_true"].center.to(energy.unit)
             idx = np.argmin(np.abs(energy_center.value - energy.value))
             kernel_map.get_image_by_idx([idx]).plot(ax=ax, add_cbar=add_cbar, **kwargs)
         else:
             self.to_image().psf_kernel_map.plot(ax=ax, add_cbar=add_cbar, **kwargs)
```

### Comparing `gammapy-1.0rc2/gammapy/irf/psf/map.py` & `gammapy-1.1rc1/gammapy/irf/psf/map.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import numpy as np
 import astropy.units as u
 from astropy.visualization import quantity_support
 import matplotlib.pyplot as plt
 from matplotlib.ticker import FormatStrFormatter
 from gammapy.maps import Map, MapAxes, MapAxis, MapCoord, WcsGeom
+from gammapy.maps.axes import UNIT_STRING_FORMAT
 from gammapy.modeling.models import PowerLawSpectralModel
 from gammapy.utils.gauss import Gauss2DPDF
 from gammapy.utils.random import InverseCDFSampler, get_random_state
 from ..core import IRFMap
 from .core import PSF
 from .kernel import PSFKernel
 
@@ -34,21 +35,21 @@
     Examples
     --------
     ::
 
         from astropy.coordinates import SkyCoord
         from gammapy.maps import WcsGeom, MapAxis
         from gammapy.data import Observation
-        from gammapy.irf import load_cta_irfs
+        from gammapy.irf import load_irf_dict_from_file
         from gammapy.makers import MapDatasetMaker
 
         # Define observation
         pointing = SkyCoord("0d", "0d")
         filename = "$GAMMAPY_DATA/cta-1dc/caldb/data/cta/1dc/bcf/South_z20_50h/irf_file.fits"
-        irfs = load_cta_irfs(filename)
+        irfs = load_irf_dict_from_file(filename)
         obs = Observation.create(pointing=pointing, irfs=irfs, livetime="1h")
 
         # Create WcsGeom
         # Define energy axis. Note that the name is fixed.
         energy_axis = MapAxis.from_energy_bounds("0.1 TeV", "10 TeV", nbin=3, name="energy_true")
 
         # Define rad axis. Again note the axis name
@@ -450,15 +451,17 @@
             with quantity_support():
                 ax.plot(energy_true, radius, label=label, **kwargs)
 
         ax.semilogx()
         ax.legend(loc="best")
         ax.yaxis.set_major_formatter(FormatStrFormatter("%.2f"))
         energy_axis.format_plot_xaxis(ax=ax)
-        ax.set_ylabel(f"Containment radius ({ax.yaxis.units})")
+        ax.set_ylabel(
+            f"Containment radius [{ax.yaxis.units.to_string(UNIT_STRING_FORMAT)}]"
+        )
         return ax
 
     def plot_psf_vs_rad(self, ax=None, energy_true=[0.1, 1, 10] * u.TeV, **kwargs):
         """Plot PSF vs radius.
 
         The method plots the profile at the center of the map.
 
@@ -486,20 +489,21 @@
                 {
                     "skycoord": self.psf_map.geom.center_skydir,
                     self.energy_name: value,
                     "rad": rad,
                 }
             )
             label = f"{value:.0f}"
+            psf_value *= self.psf_map.unit
             with quantity_support():
                 ax.plot(rad, psf_value, label=label, **kwargs)
 
         ax.set_yscale("log")
-        ax.set_xlabel(f"Rad ({ax.xaxis.units})")
-        ax.set_ylabel(f"PSF ({ax.yaxis.units})")
+        ax.set_xlabel(f"Rad [{ax.xaxis.units.to_string(UNIT_STRING_FORMAT)}]")
+        ax.set_ylabel(f"PSF [{ax.yaxis.units.to_string(UNIT_STRING_FORMAT)}]")
         ax.xaxis.set_major_formatter(FormatStrFormatter("%.2f"))
         plt.legend()
         return ax
 
     def __str__(self):
         return str(self.psf_map)
 
@@ -528,15 +532,16 @@
         axes[1].remove()
         ax1 = fig.add_subplot(2, 2, 2)
         ax1.set_ylim(1e-4, 1e4)
         ax1.set_title("PSF at center of map")
         self.plot_psf_vs_rad(ax=ax1)
 
         axes[2].set_title("Exposure")
-        self.exposure_map.reduce_over_axes().plot(ax=axes[2], add_cbar=True)
+        if self.exposure_map is not None:
+            self.exposure_map.reduce_over_axes().plot(ax=axes[2], add_cbar=True)
 
         axes[3].set_title("Containment radius at 1 TeV")
         kwargs = {self.energy_name: 1 * u.TeV}
         self.containment_radius_map(**kwargs).plot(ax=axes[3], add_cbar=True)
 
 
 class RecoPSFMap(PSFMap):
```

### Comparing `gammapy-1.0rc2/gammapy/irf/psf/parametric.py` & `gammapy-1.1rc1/gammapy/irf/psf/parametric.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/irf/psf/table.py` & `gammapy-1.1rc1/gammapy/irf/psf/table.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/irf/psf/tests/data/psf_info.txt` & `gammapy-1.1rc1/gammapy/irf/psf/tests/data/psf_info.txt`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/irf/psf/tests/test_kernel.py` & `gammapy-1.1rc1/gammapy/irf/psf/tests/test_kernel.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/irf/psf/tests/test_map.py` & `gammapy-1.1rc1/gammapy/irf/psf/tests/test_map.py`

 * *Files 3% similar despite different names*

```diff
@@ -240,21 +240,24 @@
     assert_allclose(np.mean(coords.skycoord.data.lon.wrap_at("180d").deg), 0, atol=2e-3)
     assert_allclose(np.mean(coords.lat), 0, atol=2e-3)
 
 
 def make_psf_map_obs(geom, obs):
     exposure_map = make_map_exposure_true_energy(
         geom=geom.squash(axis_name="rad"),
-        pointing=obs.pointing_radec,
+        pointing=obs.get_pointing_icrs(obs.tmid),
         aeff=obs.aeff,
         livetime=obs.observation_live_time_duration,
     )
 
     psf_map = make_psf_map(
-        geom=geom, psf=obs.psf, pointing=obs.pointing_radec, exposure_map=exposure_map
+        geom=geom,
+        psf=obs.psf,
+        pointing=obs.get_pointing_icrs(obs.tmid),
+        exposure_map=exposure_map,
     )
     return psf_map
 
 
 @requires_data()
 @pytest.mark.parametrize(
     "pars",
@@ -560,14 +563,33 @@
         "$GAMMAPY_DATA/hawc/crab_events_pass4/irfs/PSFMap_Crab_fHitbin5NN.fits.gz"
     )
     reco_psf_map = RecoPSFMap.read(filename, format="gadf")
 
     assert "energy" in reco_psf_map.psf_map.geom.axes.names
     assert reco_psf_map.energy_name == "energy"
     assert reco_psf_map.required_axes == ["rad", "energy"]
+    assert reco_psf_map.exposure_map is None
+
+    with mpl_plot_check():
+        reco_psf_map.plot_containment_radius_vs_energy()
+
+    with mpl_plot_check():
+        reco_psf_map.plot_psf_vs_rad()
+
+    assert_allclose(
+        reco_psf_map.containment_radius(0.68, [1, 2] * u.TeV),
+        [0.001, 0.43733357] * u.deg,
+    )
+
+    reco_psf_map = PSFMap.read(filename, format="gadf")
+    assert isinstance(reco_psf_map, RecoPSFMap)
+    assert "energy" in reco_psf_map.psf_map.geom.axes.names
+    assert reco_psf_map.energy_name == "energy"
+    assert reco_psf_map.required_axes == ["rad", "energy"]
+    assert reco_psf_map.exposure_map is None
 
     with mpl_plot_check():
         reco_psf_map.plot_containment_radius_vs_energy()
 
     with mpl_plot_check():
         reco_psf_map.plot_psf_vs_rad()
```

### Comparing `gammapy-1.0rc2/gammapy/irf/psf/tests/test_parametric.py` & `gammapy-1.1rc1/gammapy/irf/psf/tests/test_parametric.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/irf/psf/tests/test_table.py` & `gammapy-1.1rc1/gammapy/irf/psf/tests/test_table.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/irf/rad_max.py` & `gammapy-1.1rc1/gammapy/irf/rad_max.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,11 +1,12 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import astropy.units as u
 from astropy.visualization import quantity_support
 import matplotlib.pyplot as plt
+from gammapy.maps.axes import UNIT_STRING_FORMAT
 from .core import IRF
 
 __all__ = [
     "RadMax2D",
 ]
 
 
@@ -107,15 +108,14 @@
                 label = f"Offset {value:.2f}"
                 kwargs.setdefault("label", label)
                 ax.plot(energy_axis.center, rad_max, **kwargs)
 
         energy_axis.format_plot_xaxis(ax=ax)
         ax.set_ylim(0 * u.deg, None)
         ax.legend(loc="best")
-        ax.set_ylabel(f"Rad max. [{ax.yaxis.units}]")
-        ax.yaxis.set_major_formatter("{x:.1f}")
+        ax.set_ylabel(f"Rad max. [{ax.yaxis.units.to_string(UNIT_STRING_FORMAT)}]")
         return ax
 
     @property
     def is_fixed_rad_max(self):
         """Returns True if rad_max axes are flat."""
         return self.axes.is_flat
```

### Comparing `gammapy-1.0rc2/gammapy/irf/tests/test_background.py` & `gammapy-1.1rc1/gammapy/irf/tests/test_background.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 from copy import deepcopy
 import pytest
 import numpy as np
 from numpy.testing import assert_allclose
 import astropy.units as u
-from gammapy.irf import Background2D, Background3D
+from gammapy.irf import Background2D, Background3D, FoVAlignment
 from gammapy.maps import MapAxis
 from gammapy.utils.testing import mpl_plot_check, requires_data
 
 
 @pytest.fixture(scope="session")
 def bkg_3d():
     """Example with simple values to test evaluate"""
@@ -398,7 +398,28 @@
 
 def test_eq(bkg_2d):
     bkg1 = deepcopy(bkg_2d)
     assert bkg1 == bkg_2d
 
     bkg1.data[0][0] = 10
     assert not bkg1 == bkg_2d
+
+
+def test_write_bkg_3d():
+    e_reco = MapAxis.from_energy_bounds(0.1, 10, 6, unit="TeV", name="energy")
+    lon_axis = MapAxis.from_bounds(
+        -2.3, 2.3, 10, interp="lin", unit="deg", name="fov_lon"
+    )
+    lat_axis = MapAxis.from_bounds(
+        -2.3, 2.3, 10, interp="lin", unit="deg", name="fov_lat"
+    )
+    bg_3d = Background3D(
+        axes=[e_reco, lon_axis, lat_axis],
+        data=np.ones((6, 10, 10)),
+        unit=u.Unit("s-1 MeV-1 sr-1"),
+        fov_alignment=FoVAlignment.ALTAZ,
+    )
+    hduBackground = bg_3d.to_table_hdu()
+    hduBackground.writeto("background.fits", overwrite=True)
+    bg = Background3D.read("background.fits", hdu="BACKGROUND")
+
+    assert bg.fov_alignment.value == "ALTAZ"
```

### Comparing `gammapy-1.0rc2/gammapy/irf/tests/test_core.py` & `gammapy-1.1rc1/gammapy/irf/tests/test_core.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/irf/tests/test_effective_area.py` & `gammapy-1.1rc1/gammapy/irf/tests/test_effective_area.py`

 * *Files 2% similar despite different names*

```diff
@@ -76,14 +76,15 @@
 
     aeff = EffectiveAreaTable2D(
         axes=[energy_axis_true, offset_axis], data=1, unit="cm2"
     )
     hdu = aeff.to_table_hdu()
     assert_equal(hdu.data["ENERG_LO"][0], aeff.axes["energy_true"].edges[:-1].value)
     assert hdu.header["TUNIT1"] == aeff.axes["energy_true"].unit
+    assert "FOVALIGN" not in hdu.header
 
 
 def test_to_table_is_pointlike():
     energy_axis = MapAxis.from_energy_bounds(
         "1 TeV", "10 TeV", nbin=3, name="energy_true"
     )
     offset_axis = MapAxis.from_bounds(0 * u.deg, 2 * u.deg, nbin=2, name="offset")
```

### Comparing `gammapy-1.0rc2/gammapy/irf/tests/test_gadf.py` & `gammapy-1.1rc1/gammapy/irf/tests/test_gadf.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/irf/tests/test_io.py` & `gammapy-1.1rc1/gammapy/irf/tests/test_io.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,32 +1,36 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
+import pytest
 import numpy as np
 from numpy.testing import assert_allclose
 import astropy.units as u
 from astropy.io import fits
 from astropy.units import Quantity
 from gammapy.irf import (
     Background3D,
     EffectiveAreaTable2D,
     EnergyDispersion2D,
+    EnergyDependentMultiGaussPSF,
     RadMax2D,
     load_cta_irfs,
     load_irf_dict_from_file,
 )
 from gammapy.maps import MapAxis
 from gammapy.utils.scripts import make_path
 from gammapy.utils.testing import requires_data
+from gammapy.utils.deprecation import GammapyDeprecationWarning
 
 
 @requires_data()
 def test_cta_irf():
     """Test that CTA IRFs can be loaded and evaluated."""
-    irf = load_cta_irfs(
-        "$GAMMAPY_DATA/cta-1dc/caldb/data/cta/1dc/bcf/South_z20_50h/irf_file.fits"
-    )
+    with pytest.warns(GammapyDeprecationWarning):
+        irf = load_cta_irfs(
+            "$GAMMAPY_DATA/cta-1dc/caldb/data/cta/1dc/bcf/South_z20_50h/irf_file.fits"
+        )
 
     energy = Quantity(1, "TeV")
     offset = Quantity(3, "deg")
 
     val = irf["aeff"].evaluate(energy_true=energy, offset=offset)
     assert_allclose(val.value, 545269.4675, rtol=1e-5)
     assert val.unit == "m2"
@@ -44,17 +48,18 @@
     assert_allclose(val.value, 9.400071e-05, rtol=1e-5)
     assert val.unit == "1 / (MeV s sr)"
 
 
 @requires_data()
 def test_cta_irf_alpha_config_south():
     """Test that CTA IRFs can be loaded and evaluated."""
-    irf = load_cta_irfs(
-        "$GAMMAPY_DATA/cta-caldb/Prod5-South-20deg-AverageAz-14MSTs37SSTs.180000s-v0.1.fits.gz"
-    )
+    with pytest.warns(GammapyDeprecationWarning):
+        irf = load_cta_irfs(
+            "$GAMMAPY_DATA/cta-caldb/Prod5-South-20deg-AverageAz-14MSTs37SSTs.180000s-v0.1.fits.gz"
+        )
 
     energy = Quantity(1, "TeV")
     offset = Quantity(3, "deg")
 
     val = irf["aeff"].evaluate(energy_true=energy, offset=offset)
     assert_allclose(val.value, 493538.4460737773, rtol=1e-5)
     assert val.unit == "m2"
@@ -72,17 +77,18 @@
     assert_allclose(val.value, 8.98793486e-05, rtol=1e-5)
     assert val.unit == "1 / (MeV s sr)"
 
 
 @requires_data()
 def test_cta_irf_alpha_config_north():
     """Test that CTA IRFs can be loaded and evaluated."""
-    irf = load_cta_irfs(
-        "$GAMMAPY_DATA/cta-caldb/Prod5-North-20deg-AverageAz-4LSTs09MSTs.180000s-v0.1.fits.gz"
-    )
+    with pytest.warns(GammapyDeprecationWarning):
+        irf = load_cta_irfs(
+            "$GAMMAPY_DATA/cta-caldb/Prod5-North-20deg-AverageAz-4LSTs09MSTs.180000s-v0.1.fits.gz"
+        )
 
     energy = Quantity(1, "TeV")
     offset = Quantity(3, "deg")
 
     val = irf["aeff"].evaluate(energy_true=energy, offset=offset)
     assert_allclose(val.value, 277301.26585409, rtol=1e-5)
     assert val.unit == "m2"
@@ -166,15 +172,15 @@
     # check that has a single-bin in energy and offset
     assert irf["rad_max"].axes["energy"].nbin == 1
     assert irf["rad_max"].axes["offset"].nbin == 1
     assert irf["rad_max"].quantity.to_value("deg") == irf["aeff"].meta["RAD_MAX"]
 
 
 class TestIRFWrite:
-    def setup(self):
+    def setup_method(self):
         self.energy_lo = np.logspace(0, 1, 10)[:-1] * u.TeV
         self.energy_hi = np.logspace(0, 1, 10)[1:] * u.TeV
         self.energy_axis_true = MapAxis.from_energy_bounds(
             "1 TeV", "10 TeV", nbin=9, name="energy_true"
         )
 
         self.offset_lo = np.linspace(0, 1, 4)[:-1] * u.deg
@@ -282,7 +288,20 @@
         assert_allclose(read_aeff.quantity, self.aeff_data)
 
         read_edisp = EnergyDispersion2D.read(path, hdu="ENERGY DISPERSION")
         assert_allclose(read_edisp.quantity, self.edisp_data)
 
         read_bkg = Background3D.read(path, hdu="BACKGROUND")
         assert_allclose(read_bkg.quantity, self.bkg_data)
+
+
+@requires_data()
+def test_load_irf_dict_from_file_cta():
+    """Test that CTA IRFs can be loaded and evaluated."""
+    irf = load_irf_dict_from_file(
+        "$GAMMAPY_DATA/cta-1dc/caldb/data/cta/1dc/bcf/South_z20_50h/irf_file.fits"
+    )
+    assert set(irf.keys()) == {"aeff", "edisp", "psf", "bkg"}
+    assert isinstance(irf["aeff"], EffectiveAreaTable2D)
+    assert isinstance(irf["edisp"], EnergyDispersion2D)
+    assert isinstance(irf["psf"], EnergyDependentMultiGaussPSF)
+    assert isinstance(irf["bkg"], Background3D)
```

### Comparing `gammapy-1.0rc2/gammapy/irf/tests/test_rad_max.py` & `gammapy-1.1rc1/gammapy/irf/tests/test_rad_max.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/makers/__init__.py` & `gammapy-1.1rc1/gammapy/makers/__init__.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/makers/background/__init__.py` & `gammapy-1.1rc1/gammapy/makers/background/__init__.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/makers/background/fov.py` & `gammapy-1.1rc1/gammapy/makers/background/fov.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/makers/background/phase.py` & `gammapy-1.1rc1/gammapy/makers/background/phase.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,58 +1,65 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import numpy as np
 from gammapy.data import EventList
-from gammapy.datasets import SpectrumDatasetOnOff
-from gammapy.maps import RegionNDMap
+from gammapy.datasets import MapDatasetOnOff, SpectrumDataset
+from gammapy.maps import Map
+from gammapy.makers.utils import make_counts_rad_max
+from regions import PointSkyRegion
 from ..core import Maker
 
 __all__ = ["PhaseBackgroundMaker"]
 
 
 class PhaseBackgroundMaker(Maker):
     """Background estimation with on and off phases.
 
     TODO: For a usage example see future notebook.
 
-    TODO: The phase interval has to be between 0 and 1.
-    Cases like [-0.1, 0.1], for example, are still not supported.
-
     Parameters
     ----------
     on_phase : `tuple` or list of tuples
-        on-phase defined by the two edges of each interval (edges are excluded)
+        on-phase defined by the two edges of each interval (edges are excluded).
     off_phase : `tuple` or list of tuples
-        off-phase defined by the two edges of each interval (edges are excluded)
+        off-phase defined by the two edges of each interval (edges are excluded).
+    phase_column_name : `str`
+        The name of the column in the event file from which the phase informations are extracted. Default is 'PHASE'.
     """
 
     tag = "PhaseBackgroundMaker"
 
-    def __init__(self, on_phase, off_phase):
+    def __init__(self, on_phase, off_phase, phase_column_name="PHASE"):
         self.on_phase = self._check_intervals(on_phase)
         self.off_phase = self._check_intervals(off_phase)
+        self.phase_column_name = phase_column_name
 
     def __str__(self):
         s = self.__class__.__name__
-        s += f"\n{self.on_phase}"
-        s += f"\n{self.off_phase}"
+        s += f"\nOn phase interval : {self.on_phase}"
+        s += f"\nOff phase interval : {self.off_phase}"
+        s += f"\nPhase column name : {self.phase_column_name}"
         return s
 
     @staticmethod
-    def _make_counts(dataset, observation, phases):
+    def _make_counts(dataset, observation, phases, phase_column_name):
 
         event_lists = []
         for interval in phases:
             events = observation.events.select_parameter(
-                parameter="PHASE", band=interval
+                parameter=phase_column_name, band=interval
             )
             event_lists.append(events)
 
         events = EventList.from_stack(event_lists)
-        counts = RegionNDMap.from_geom(dataset.counts.geom)
-        counts.fill_events(events)
+        geom = dataset.counts.geom
+        if geom.is_region and isinstance(geom.region, PointSkyRegion):
+            counts = make_counts_rad_max(geom, observation.rad_max, events)
+        else:
+            counts = Map.from_geom(geom)
+            counts.fill_events(events)
         return counts
 
     def make_counts_off(self, dataset, observation):
         """Make off counts.
 
         Parameters
         ----------
@@ -62,32 +69,36 @@
             Data store observation.
 
         Returns
         -------
         counts_off : `RegionNDMap`
             Off counts.
         """
-        return self._make_counts(dataset, observation, self.off_phase)
+        return self._make_counts(
+            dataset, observation, self.off_phase, self.phase_column_name
+        )
 
     def make_counts(self, dataset, observation):
-        """Make off counts.
+        """Make on counts.
 
         Parameters
         ----------
         dataset : `SpectrumDataset`
             Input dataset.
         observation : `DatastoreObservation`
             Data store observation.
 
         Returns
         -------
-        counts_off : `RegionNDMap`
-            Off counts.
+        counts : `RegionNDMap`
+            On counts.
         """
-        return self._make_counts(dataset, observation, self.on_phase)
+        return self._make_counts(
+            dataset, observation, self.on_phase, self.phase_column_name
+        )
 
     def run(self, dataset, observation):
         """Run all steps.
 
         Parameters
         ----------
         dataset : `SpectrumDataset`
@@ -99,34 +110,38 @@
         -------
         dataset_on_off : `SpectrumDatasetOnOff`
             On off dataset.
         """
         counts_off = self.make_counts_off(dataset, observation)
         counts = self.make_counts(dataset, observation)
 
-        acceptance = RegionNDMap.from_geom(geom=dataset.counts.geom)
+        acceptance = Map.from_geom(geom=dataset.counts.geom)
         acceptance.data = np.sum([_[1] - _[0] for _ in self.on_phase])
 
-        acceptance_off = RegionNDMap.from_geom(geom=dataset.counts.geom)
+        acceptance_off = Map.from_geom(geom=dataset.counts.geom)
         acceptance_off.data = np.sum([_[1] - _[0] for _ in self.off_phase])
 
-        dataset_on_off = SpectrumDatasetOnOff.from_spectrum_dataset(
+        dataset_on_off = MapDatasetOnOff.from_map_dataset(
             dataset=dataset,
             counts_off=counts_off,
             acceptance=acceptance,
             acceptance_off=acceptance_off,
         )
         dataset_on_off.counts = counts
+
+        if isinstance(dataset, SpectrumDataset):
+            dataset_on_off = dataset_on_off.to_spectrum_dataset(dataset._geom.region)
+
         return dataset_on_off
 
     @staticmethod
     def _check_intervals(intervals):
-        """Split phase intervals that go beyond phase 1"""
+        """Split phase intervals that go below phase 0 and above phase 1"""
         if isinstance(intervals, tuple):
             intervals = [intervals]
 
         for phase_interval in intervals:
-            if phase_interval[0] > phase_interval[1]:
+            if phase_interval[0] % 1 > phase_interval[1] % 1:
                 intervals.remove(phase_interval)
-                intervals.append([phase_interval[0], 1])
-                intervals.append([0, phase_interval[1]])
+                intervals.append([phase_interval[0] % 1, 1])
+                intervals.append([0, phase_interval[1] % 1])
         return intervals
```

### Comparing `gammapy-1.0rc2/gammapy/makers/background/reflected.py` & `gammapy-1.1rc1/gammapy/makers/background/reflected.py`

 * *Files 1% similar despite different names*

```diff
@@ -276,17 +276,17 @@
     method, see also `~gammapy.makers.ReflectedRegionsBackgroundMaker`
 
     Parameters
     ----------
     angle_increment : `~astropy.coordinates.Angle`, optional
         Rotation angle applied when a region falls in an excluded region.
     min_distance : `~astropy.coordinates.Angle`, optional
-        Minimal distance between two consecutive reflected regions
+        Minimum rotation angle between two consecutive reflected regions
     min_distance_input : `~astropy.coordinates.Angle`, optional
-        Minimal distance from input region
+        Minimum rotation angle between the input region and the first reflected region
     max_region_number : int, optional
         Maximum number of regions to use
     binsz : `~astropy.coordinates.Angle`
         Bin size of the reference map used for region finding.
 
     Examples
     --------
@@ -508,15 +508,15 @@
             raise ValueError(
                 "Must use `PointSkyRegion` or `CircleSkyRegion` with rad max "
                 "equivalent radius in point-like analysis,"
                 f" got {type(geom.region)} instead"
             )
 
         regions_off, wcs = self.region_finder.run(
-            center=observation.pointing_radec,
+            center=observation.get_pointing_icrs(observation.tmid),
             region=geom.region,
             exclusion_mask=self.exclusion_mask,
         )
 
         if geom.is_all_point_sky_regions and len(regions_off) > 0:
             regions_off = self._filter_regions_off_rad_max(
                 regions_off, energy_axis, geom, events, observation.rad_max
```

### Comparing `gammapy-1.0rc2/gammapy/makers/background/ring.py` & `gammapy-1.1rc1/gammapy/makers/background/ring.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/makers/background/tests/test_fov.py` & `gammapy-1.1rc1/gammapy/makers/background/tests/test_fov.py`

 * *Files 0% similar despite different names*

```diff
@@ -56,15 +56,15 @@
 @pytest.fixture(scope="session")
 def obs_dataset(geom, observation):
     safe_mask_maker = SafeMaskMaker(methods=["offset-max"], offset_max="2 deg")
     map_dataset_maker = MapDatasetMaker(selection=["counts", "background", "exposure"])
 
     reference = MapDataset.create(geom)
     cutout = reference.cutout(
-        observation.pointing_radec, width="4 deg", name="test-fov"
+        observation.get_pointing_icrs(observation.tmid), width="4 deg", name="test-fov"
     )
 
     dataset = map_dataset_maker.run(cutout, observation)
     dataset = safe_mask_maker.run(dataset, observation)
     return dataset
```

### Comparing `gammapy-1.0rc2/gammapy/makers/background/tests/test_phase.py` & `gammapy-1.1rc1/gammapy/visualization/tests/test_datasets.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,67 +1,82 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import pytest
-import numpy as np
 from numpy.testing import assert_allclose
-from astropy import units as u
-from astropy.coordinates import Angle, SkyCoord
-from gammapy.data import DataStore
-from gammapy.datasets import SpectrumDataset
-from gammapy.makers import PhaseBackgroundMaker, SpectrumDatasetMaker
-from gammapy.maps import MapAxis, RegionGeom
-from gammapy.utils.regions import SphericalCircleSkyRegion
-from gammapy.utils.testing import requires_data
-
-
-@pytest.fixture(scope="session")
-def observations():
-    """Example observation list for testing."""
-    datastore = DataStore.from_dir("$GAMMAPY_DATA/cta-1dc/index/gps")
-    return datastore.get_observations([111630])
-
-
-@pytest.fixture(scope="session")
-def phase_bkg_maker():
-    """Example background estimator for testing."""
-    return PhaseBackgroundMaker(on_phase=(0.5, 0.6), off_phase=(0.7, 1))
+import matplotlib
+from packaging import version
+from gammapy.datasets.tests.test_map import MapDataset
+from gammapy.modeling.models import (
+    FoVBackgroundModel,
+    GaussianSpatialModel,
+    PowerLawSpectralModel,
+    SkyModel,
+)
+from gammapy.utils.testing import mpl_plot_check, requires_data
+from gammapy.visualization import plot_npred_signal, plot_spectrum_datasets_off_regions
 
 
-@requires_data()
-def test_basic(phase_bkg_maker):
-    assert "PhaseBackgroundMaker" in str(phase_bkg_maker)
+@pytest.fixture
+def sky_model():
+    spatial_model = GaussianSpatialModel(
+        lon_0="0.2 deg", lat_0="0.1 deg", sigma="0.2 deg", frame="galactic"
+    )
+    spectral_model = PowerLawSpectralModel(
+        index=3, amplitude="1e-11 cm-2 s-1 TeV-1", reference="1 TeV"
+    )
+    return SkyModel(
+        spatial_model=spatial_model, spectral_model=spectral_model, name="test-model"
+    )
+
+
+@pytest.mark.skipif(
+    version.parse(matplotlib.__version__) < version.parse("3.5"),
+    reason="Requires matplotlib 3.5 or higher",
+)
+def test_plot_spectrum_datasets_off_regions():
+    from gammapy.datasets import SpectrumDatasetOnOff
+    from gammapy.maps import Map, RegionNDMap
 
+    counts_off_1 = RegionNDMap.create("icrs;circle(0, 0.5, 0.2);circle(0.5, 0, 0.2)")
 
-@requires_data()
-def test_run(observations, phase_bkg_maker):
+    counts_off_2 = RegionNDMap.create("icrs;circle(0.5, 0.5, 0.2);circle(0, 0, 0.2)")
 
-    maker = SpectrumDatasetMaker()
+    counts_off_3 = RegionNDMap.create("icrs;point(0.5, 0.5);point(0, 0)")
 
-    e_reco = MapAxis.from_edges(np.logspace(0, 2, 5) * u.TeV, name="energy")
-    e_true = MapAxis.from_edges(np.logspace(-0.5, 2, 11) * u.TeV, name="energy_true")
+    m = Map.from_geom(geom=counts_off_1.geom.to_wcs_geom())
+    ax = m.plot()
 
-    pos = SkyCoord("08h35m20.65525s", "-45d10m35.1545s", frame="icrs")
-    radius = Angle(0.2, "deg")
-    region = SphericalCircleSkyRegion(pos, radius)
+    dataset_1 = SpectrumDatasetOnOff(counts_off=counts_off_1)
 
-    geom = RegionGeom.create(region=region, axes=[e_reco])
-    dataset_empty = SpectrumDataset.create(geom=geom, energy_axis_true=e_true)
+    dataset_2 = SpectrumDatasetOnOff(counts_off=counts_off_2)
 
-    obs = observations["111630"]
-    dataset = maker.run(dataset_empty, obs)
-    dataset_on_off = phase_bkg_maker.run(dataset, obs)
+    dataset_3 = SpectrumDatasetOnOff(counts_off=counts_off_3)
 
-    assert_allclose(dataset_on_off.acceptance, 0.1)
-    assert_allclose(dataset_on_off.acceptance_off, 0.3)
+    plot_spectrum_datasets_off_regions(
+        ax=ax, datasets=[dataset_1, dataset_2, dataset_3]
+    )
 
-    assert_allclose(dataset_on_off.counts.data.sum(), 28)
-    assert_allclose(dataset_on_off.counts_off.data.sum(), 57)
+    actual = ax.patches[0].get_edgecolor()
+    assert_allclose(actual, (0.121569, 0.466667, 0.705882, 1.0), rtol=1e-2)
 
+    actual = ax.patches[2].get_edgecolor()
+    assert_allclose(actual, (1.0, 0.498039, 0.054902, 1.0), rtol=1e-2)
+    assert ax.lines[0].get_color() in ["green", "C0"]
 
-@pytest.mark.parametrize(
-    "pars",
-    [
-        {"p_in": [[0.2, 0.3]], "p_out": [[0.2, 0.3]]},
-        {"p_in": [[0.9, 0.1]], "p_out": [[0.9, 1], [0, 0.1]]},
-    ],
-)
-def test_check_phase_intervals(pars):
-    assert PhaseBackgroundMaker._check_intervals(pars["p_in"]) == pars["p_out"]
+
+@requires_data()
+def test_plot_npred_signal(sky_model):
+    dataset = MapDataset.read("$GAMMAPY_DATA/cta-1dc-gc/cta-1dc-gc.fits.gz")
+
+    pwl = PowerLawSpectralModel()
+    gauss = GaussianSpatialModel(
+        lon_0="0.0 deg", lat_0="0.0 deg", sigma="0.5 deg", frame="galactic"
+    )
+    model1 = SkyModel(pwl, gauss, name="m1")
+
+    bkg = FoVBackgroundModel(dataset_name=dataset.name)
+    dataset.models = [bkg, sky_model, model1]
+
+    with mpl_plot_check():
+        plot_npred_signal(dataset)
+
+    with mpl_plot_check():
+        plot_npred_signal(dataset, model_names=[sky_model.name, model1.name])
```

### Comparing `gammapy-1.0rc2/gammapy/makers/background/tests/test_reflected.py` & `gammapy-1.1rc1/gammapy/makers/background/tests/test_reflected.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/makers/background/tests/test_ring.py` & `gammapy-1.1rc1/gammapy/makers/background/tests/test_ring.py`

 * *Files 8% similar despite different names*

```diff
@@ -52,15 +52,15 @@
     safe_mask_maker = SafeMaskMaker(methods=["offset-max"], offset_max="2 deg")
     map_dataset_maker = MapDatasetMaker(selection=["counts", "background", "exposure"])
 
     reference = MapDataset.create(geom)
     datasets = []
 
     for obs in observations:
-        cutout = reference.cutout(obs.pointing_radec, width="4 deg")
+        cutout = reference.cutout(obs.get_pointing_icrs(obs.tmid), width="4 deg")
         dataset = map_dataset_maker.run(cutout, obs)
         dataset = safe_mask_maker.run(dataset, obs)
         dataset = dataset.to_image()
 
         dataset_on_off = ring_bkg_maker.run(dataset)
         datasets.append(dataset_on_off)
 
@@ -123,15 +123,17 @@
         method=pars["method"],
     )
     safe_mask_maker = SafeMaskMaker(methods=["offset-max"], offset_max="2 deg")
     map_dataset_maker = MapDatasetMaker(selection=["counts", "background", "exposure"])
 
     obs = observations[pars["obs_idx"]]
 
-    dataset = MapDataset.create(geom).cutout(obs.pointing_radec, width="4 deg")
+    dataset = MapDataset.create(geom).cutout(
+        obs.get_pointing_icrs(obs.tmid), width="4 deg"
+    )
     dataset = map_dataset_maker.run(dataset, obs)
     dataset = safe_mask_maker.run(dataset, obs)
 
     dataset = dataset.to_image()
     dataset_on_off = adaptive_ring_bkg_maker.run(dataset)
 
     mask = dataset.mask_safe
```

### Comparing `gammapy-1.0rc2/gammapy/makers/core.py` & `gammapy-1.1rc1/gammapy/makers/core.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/makers/map.py` & `gammapy-1.1rc1/gammapy/makers/map.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,13 +1,12 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import logging
 import astropy.units as u
 from astropy.table import Table
 from regions import PointSkyRegion
-from gammapy.data.pointing import PointingMode
 from gammapy.irf import EDispKernelMap, PSFMap, RecoPSFMap
 from gammapy.maps import Map
 from .core import Maker
 from .utils import (
     make_counts_rad_max,
     make_edisp_kernel_map,
     make_edisp_map,
@@ -168,15 +167,15 @@
             Exposure map.
         """
         if isinstance(observation.aeff, Map):
             return observation.aeff.interp_to_geom(
                 geom=geom,
             )
         return make_map_exposure_true_energy(
-            pointing=observation.pointing_radec,
+            pointing=observation.get_pointing_icrs(observation.tmid),
             livetime=observation.observation_live_time_duration,
             aeff=observation.aeff,
             geom=geom,
             use_region_center=use_region_center,
         )
 
     @staticmethod
@@ -192,15 +191,15 @@
 
         Returns
         -------
         exposure : `~gammapy.maps.Map`
             Exposure map.
         """
         return make_map_exposure_true_energy(
-            pointing=observation.pointing_radec,
+            pointing=observation.get_pointing_icrs(observation.tmid),
             livetime=observation.observation_live_time_duration,
             aeff=observation.aeff,
             geom=geom,
             use_region_center=use_region_center,
         )
 
     def make_background(self, geom, observation):
@@ -229,20 +228,21 @@
         if self.background_interp_missing_data:
             bkg.interp_missing_data(axis_name="energy")
 
         if self.background_pad_offset and bkg.has_offset_axis:
             bkg = bkg.pad(1, mode="edge", axis_name="offset")
 
         return make_map_background_irf(
-            pointing=observation.fixed_pointing_info,
+            pointing=observation.pointing,
             ontime=observation.observation_time_duration,
             bkg=bkg,
             geom=geom,
             oversampling=self.background_oversampling,
             use_region_center=use_region_center,
+            obstime=observation.tmid,
         )
 
     def make_edisp(self, geom, observation):
         """Make energy dispersion map.
 
         Parameters
         ----------
@@ -258,15 +258,15 @@
         """
         exposure = self.make_exposure_irf(geom.squash(axis_name="migra"), observation)
 
         use_region_center = getattr(self, "use_region_center", True)
 
         return make_edisp_map(
             edisp=observation.edisp,
-            pointing=observation.pointing_radec,
+            pointing=observation.get_pointing_icrs(observation.tmid),
             geom=geom,
             exposure_map=exposure,
             use_region_center=use_region_center,
         )
 
     def make_edisp_kernel(self, geom, observation):
         """Make energy dispersion kernel map.
@@ -290,15 +290,15 @@
 
         exposure = self.make_exposure_irf(geom.squash(axis_name="energy"), observation)
 
         use_region_center = getattr(self, "use_region_center", True)
 
         return make_edisp_kernel_map(
             edisp=observation.edisp,
-            pointing=observation.pointing_radec,
+            pointing=observation.get_pointing_icrs(observation.tmid),
             geom=geom,
             exposure_map=exposure,
             use_region_center=use_region_center,
         )
 
     def make_psf(self, geom, observation):
         """Make psf map.
@@ -321,15 +321,15 @@
             return RecoPSFMap(psf.psf_map.interp_to_geom(geom))
         elif isinstance(psf, PSFMap):
             return PSFMap(psf.psf_map.interp_to_geom(geom))
         exposure = self.make_exposure_irf(geom.squash(axis_name="rad"), observation)
 
         return make_psf_map(
             psf=psf,
-            pointing=observation.pointing_radec,
+            pointing=observation.get_pointing_icrs(observation.tmid),
             geom=geom,
             exposure_map=exposure,
         )
 
     @staticmethod
     def make_meta_table(observation):
         """Make info meta table.
@@ -339,30 +339,28 @@
         observation : `~gammapy.data.Observation`
             Observation
 
         Returns
         -------
         meta_table: `~astropy.table.Table`
         """
-        meta_table = Table()
-        meta_table["TELESCOP"] = [observation.aeff.meta.get("TELESCOP", "Unknown")]
-        meta_table["OBS_ID"] = [observation.obs_id]
-
-        if observation.fixed_pointing_info.mode == PointingMode.POINTING:
-            meta_table["OBS_MODE"] = "POINTING"
-            meta_table["RA_PNT"] = [observation.pointing_radec.icrs.ra.deg] * u.deg
-            meta_table["DEC_PNT"] = [observation.pointing_radec.icrs.dec.deg] * u.deg
-        elif observation.fixed_pointing_info.mode == PointingMode.DRIFT:
-            meta_table["OBS_MODE"] = "DRIFT"
-            meta_table["ALT_PNT"] = [
-                observation.fixed_pointing_info.fixed_altaz.alt.deg
-            ] * u.deg
-            meta_table["AZ_PNT"] = [
-                observation.fixed_pointing_info.fixed_altaz.az.deg
-            ] * u.deg
+
+        row = {}
+        row["TELESCOP"] = observation.aeff.meta.get("TELESCOP", "Unknown")
+        row["OBS_ID"] = observation.obs_id
+
+        row.update(observation.pointing.to_fits_header())
+
+        meta_table = Table([row])
+        if "ALT_PNT" in meta_table.colnames:
+            meta_table["ALT_PNT"].unit = u.deg
+            meta_table["AZ_PNT"].unit = u.deg
+        if "RA_PNT" in meta_table.colnames:
+            meta_table["RA_PNT"].unit = u.deg
+            meta_table["DEC_PNT"].unit = u.deg
 
         return meta_table
 
     def run(self, dataset, observation):
         """Make map dataset.
 
         Parameters
```

### Comparing `gammapy-1.0rc2/gammapy/makers/reduce.py` & `gammapy-1.1rc1/gammapy/makers/reduce.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,68 +1,76 @@
 import logging
-from multiprocessing import Pool
-import numpy as np
 from astropy.coordinates import Angle
+import gammapy.utils.parallel as parallel
 from gammapy.datasets import Datasets, MapDataset, MapDatasetOnOff, SpectrumDataset
 from .core import Maker
 from .safe import SafeMaskMaker
 
 log = logging.getLogger(__name__)
 
 
 __all__ = [
     "DatasetsMaker",
 ]
 
 
-class DatasetsMaker(Maker):
+class DatasetsMaker(Maker, parallel.ParallelMixin):
     """Run makers in a chain
 
     Parameters
     ----------
     makers : list of `Maker` objects
         Makers
     stack_datasets : bool
         If True stack into the reference dataset (see `run` method arguments).
     n_jobs : int
-        Number of processes to run in parallel
+        Number of processes to run in parallel.
+        Default is one, unless `~gammapy.utils.parallel.N_JOBS_DEFAULT` was modified.
     cutout_mode : {'trim', 'partial', 'strict'}
         Used only to cutout the reference `MapDataset` around each processed observation.
         Mode is an option for Cutout2D, for details see `~astropy.nddata.utils.Cutout2D`.
         Default is "trim".
     cutout_width : tuple of `~astropy.coordinates.Angle`
         Angular sizes of the region in (lon, lat) in that specific order.
         If only one value is passed, a square region is extracted.
         If None it returns an error, except if the list of makers includes a `SafeMaskMaker`
         with the offset-max method defined. In that case it is set to two times `offset_max`.
+    parallel_backend : {'multiprocessing', 'ray'}
+        Which backend to use for multiprocessing.
     """
 
     tag = "DatasetsMaker"
 
     def __init__(
         self,
         makers,
         stack_datasets=True,
         n_jobs=None,
         cutout_mode="trim",
         cutout_width=None,
+        parallel_backend=None,
     ):
         self.log = logging.getLogger(__name__)
         self.makers = makers
         self.cutout_mode = cutout_mode
+
         if cutout_width is not None:
             cutout_width = Angle(cutout_width)
+
         self.cutout_width = cutout_width
         self._apply_cutout = True
+
         if self.cutout_width is None:
             if self.offset_max is None:
                 self._apply_cutout = False
             else:
                 self.cutout_width = 2 * self.offset_max
+
         self.n_jobs = n_jobs
+        self.parallel_backend = parallel_backend
         self.stack_datasets = stack_datasets
 
         self._datasets = []
         self._error = False
 
     @property
     def offset_max(self):
@@ -85,32 +93,35 @@
             Reference dataset
         observation : `Observation`
             Observation
         """
 
         if self._apply_cutout:
             cutouts_kwargs = {
-                "position": observation.pointing_radec.galactic,
+                "position": observation.get_pointing_icrs(observation.tmid).galactic,
                 "width": self.cutout_width,
                 "mode": self.cutout_mode,
             }
             dataset_obs = dataset.cutout(
                 **cutouts_kwargs,
             )
         else:
             dataset_obs = dataset.copy()
+
         if dataset.models is not None:
             models = dataset.models.copy()
             models.reassign(dataset.name, dataset_obs.name)
             dataset_obs.models = models
 
         log.info(f"Computing dataset for observation {observation.obs_id}")
+
         for maker in self.makers:
             log.info(f"Running {maker.tag}")
             dataset_obs = maker.run(dataset=dataset_obs, observation=observation)
+
         return dataset_obs
 
     def callback(self, dataset):
         if self.stack_datasets:
             if isinstance(self._dataset, MapDataset) and isinstance(
                 dataset, MapDatasetOnOff
             ):
@@ -152,43 +163,32 @@
             self._apply_cutout = False
 
         if datasets is not None:
             self._apply_cutout = False
         else:
             datasets = len(observations) * [dataset]
 
-        if self.n_jobs is not None and self.n_jobs > 1:
-            n_jobs = min(self.n_jobs, len(observations))
-            with Pool(processes=n_jobs) as pool:
-                log.info("Using {} jobs.".format(n_jobs))
-                results = []
-                for base, obs in zip(datasets, observations):
-                    result = pool.apply_async(
-                        self.make_dataset,
-                        (
-                            base,
-                            obs,
-                        ),
-                        callback=self.callback,
-                        error_callback=self.error_callback,
-                    )
-                    results.append(result)
-                # wait async run is done
-                [result.wait() for result in results]
-            if self._error:
-                raise RuntimeError("Execution of a sub-process failed")
-        else:
-            for base, obs in zip(datasets, observations):
-                dataset = self.make_dataset(base, obs)
-                self.callback(dataset)
+        n_jobs = min(self.n_jobs, len(observations))
+
+        parallel.run_multiprocessing(
+            self.make_dataset,
+            zip(datasets, observations),
+            backend=self.parallel_backend,
+            pool_kwargs=dict(processes=n_jobs),
+            method="apply_async",
+            method_kwargs=dict(
+                callback=self.callback,
+                error_callback=self.error_callback,
+            ),
+            task_name="Data reduction",
+        )
+
+        if self._error:
+            raise RuntimeError("Execution of a sub-process failed")
 
         if self.stack_datasets:
             return Datasets([self._dataset])
-        else:
-            # have to sort datasets because of async
-            obs_ids = [d.meta_table["OBS_ID"][0] for d in self._datasets]
-            ordered = []
-            for obs in observations:
-                ind = np.where(np.array(obs_ids) == obs.obs_id)[0][0]
-                ordered.append(self._datasets[ind])
-            self._datasets = ordered
-            return Datasets(self._datasets)
+
+        lookup = {
+            d.meta_table["OBS_ID"][0]: idx for idx, d in enumerate(self._datasets)
+        }
+        return Datasets([self._datasets[lookup[obs.obs_id]] for obs in observations])
```

### Comparing `gammapy-1.0rc2/gammapy/makers/safe.py` & `gammapy-1.1rc1/gammapy/makers/safe.py`

 * *Files 2% similar despite different names*

```diff
@@ -98,15 +98,17 @@
         -------
         mask_safe : `~numpy.ndarray`
             Maximum offset mask.
         """
         if observation is None:
             raise ValueError("Method 'offset-max' requires an observation object.")
 
-        separation = dataset._geom.separation(observation.pointing_radec)
+        separation = dataset._geom.separation(
+            observation.get_pointing_icrs(observation.tmid)
+        )
         return separation < self.offset_max
 
     @staticmethod
     def make_mask_energy_aeff_default(dataset, observation):
         """Make safe energy mask from aeff default.
 
         Parameters
@@ -157,17 +159,19 @@
         Returns
         -------
         mask_safe : `~numpy.ndarray`
             Safe data range mask.
         """
         geom, exposure = dataset._geom, dataset.exposure
 
-        if self.fixed_offset:
+        if self.fixed_offset is not None:
             if observation:
-                position = observation.pointing_radec.directional_offset_by(
+                position = observation.get_pointing_icrs(
+                    observation.tmid
+                ).directional_offset_by(
                     position_angle=0.0 * u.deg, separation=self.fixed_offset
                 )
             else:
                 raise ValueError(
                     f"observation argument is mandatory with {self.fixed_offset}"
                 )
 
@@ -215,35 +219,35 @@
         -------
         mask_safe : `~numpy.ndarray`
             Safe data range mask.
         """
         edisp, geom = dataset.edisp, dataset._geom
         position = None
 
-        if self.fixed_offset:
+        if self.fixed_offset is not None:
             if observation:
-                position = observation.pointing_radec.directional_offset_by(
+                pointing = observation.get_pointing_icrs(observation.tmid)
+                position = pointing.directional_offset_by(
                     position_angle=0 * u.deg, separation=self.fixed_offset
                 )
             else:
                 raise ValueError(
                     f"{observation} argument is mandatory with {self.fixed_offset}"
                 )
 
         if isinstance(edisp, EDispKernelMap):
             if position:
                 edisp = edisp.get_edisp_kernel(position=position)
             else:
                 edisp = edisp.get_edisp_kernel(position=self.position)
         else:
+            e_reco = dataset._geom.axes["energy"]
             if position:
-                e_reco = dataset._geom.axes["energy"].edges
                 edisp = edisp.get_edisp_kernel(position=position, energy_axis=e_reco)
             else:
-                e_reco = dataset._geom.axes["energy"].edges
                 edisp = edisp.get_edisp_kernel(
                     position=self.position, energy_axis=e_reco
                 )
 
         energy_min = edisp.get_bias_energy(self.bias_percent / 100)
         return geom.energy_mask(energy_min=energy_min[0])
```

### Comparing `gammapy-1.0rc2/gammapy/makers/spectrum.py` & `gammapy-1.1rc1/gammapy/makers/spectrum.py`

 * *Files 1% similar despite different names*

```diff
@@ -78,15 +78,15 @@
                     "Cannot apply containment correction for point-like IRF."
                 )
 
             if not isinstance(geom.region, CircleSkyRegion):
                 raise TypeError(
                     "Containment correction only supported for circular regions."
                 )
-            offset = geom.separation(observation.pointing_radec)
+            offset = geom.separation(observation.get_pointing_icrs(observation.tmid))
             containment = observation.psf.containment(
                 rad=geom.region.radius,
                 offset=offset,
                 energy_true=geom.axes["energy_true"].center,
             )
             exposure.quantity *= containment.reshape(geom.data_shape)
```

### Comparing `gammapy-1.0rc2/gammapy/makers/tests/test_map.py` & `gammapy-1.1rc1/gammapy/makers/tests/test_map.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,21 +7,23 @@
 from astropy.table import Table
 from astropy.time import Time
 from regions import CircleSkyRegion
 from gammapy.data import (
     GTI,
     DataStore,
     EventList,
+    FixedPointingInfo,
     HDUIndexTable,
     Observation,
     ObservationTable,
+    PointingMode,
 )
 from gammapy.datasets import MapDataset
 from gammapy.datasets.map import RAD_AXIS_DEFAULT
-from gammapy.irf import EDispKernelMap, EDispMap, PSFMap, Background2D
+from gammapy.irf import Background2D, EDispKernelMap, EDispMap, PSFMap
 from gammapy.makers import FoVBackgroundMaker, MapDatasetMaker, SafeMaskMaker
 from gammapy.maps import HpxGeom, Map, MapAxis, WcsGeom
 from gammapy.utils.testing import requires_data, requires_dependency
 
 
 @pytest.fixture(scope="session")
 def observations():
@@ -144,15 +146,15 @@
         migra_axis=pars["migra"],
     )
 
     maker = MapDatasetMaker(background_oversampling=pars.get("background_oversampling"))
     safe_mask_maker = SafeMaskMaker(methods=["offset-max"], offset_max="2 deg")
 
     for obs in observations:
-        cutout = stacked.cutout(position=obs.pointing_radec, width="4 deg")
+        cutout = stacked.cutout(position=obs.get_pointing_icrs(obs.tmid), width="4 deg")
         dataset = maker.run(cutout, obs)
         dataset = safe_mask_maker.run(dataset, obs)
         stacked.stack(dataset)
 
     counts = stacked.counts
     assert counts.unit == ""
     assert_allclose(counts.data.sum(), pars["counts"], rtol=1e-5)
@@ -334,22 +336,24 @@
 
     events = EventList(ev_t)
     gti = GTI(gti_t)
 
     # define observation
     obs = Observation(
         obs_id=0,
-        obs_info={"RA_PNT": 0.0, "DEC_PNT": 0.0},
         gti=gti,
         aeff=aeff_map,
         edisp=edispmap,
         psf=psfMap,
         bkg=bkg_map,
         events=events,
         obs_filter=None,
+        pointing=FixedPointingInfo(
+            mode=PointingMode.POINTING, fixed_icrs=SkyCoord(0 * u.deg, 0 * u.deg)
+        ),
     )
 
     # define analysis geometry
     geom_target = WcsGeom.create(
         skydir=(0, 0), width=(5, 5), binsz=0.1 * u.deg, axes=[energy]
     )
```

### Comparing `gammapy-1.0rc2/gammapy/makers/tests/test_reduce.py` & `gammapy-1.1rc1/gammapy/makers/tests/test_reduce.py`

 * *Files 6% similar despite different names*

```diff
@@ -13,15 +13,15 @@
     MapDatasetMaker,
     ReflectedRegionsBackgroundMaker,
     SafeMaskMaker,
     SpectrumDatasetMaker,
     WobbleRegionsFinder,
 )
 from gammapy.maps import MapAxis, RegionGeom, WcsGeom
-from gammapy.utils.testing import requires_data
+from gammapy.utils.testing import requires_data, requires_dependency
 
 
 @pytest.fixture(scope="session")
 def observations_cta():
     data_store = DataStore.from_dir("$GAMMAPY_DATA/cta-1dc/index/gps/")
     return data_store.get_observations()[:3]
 
@@ -42,40 +42,43 @@
         Observation.read(
             "$GAMMAPY_DATA/magic/rad_max/data/20131004_05029748_DL3_CrabNebula-W0.40+215.fits"
         ),
     ]
     return observations
 
 
-def get_mapdataset(name):
+@pytest.fixture()
+def map_dataset():
     skydir = SkyCoord(0, -1, unit="deg", frame="galactic")
     energy_axis = MapAxis.from_edges(
         [0.1, 1, 10], name="energy", unit="TeV", interp="log"
     )
     geom = WcsGeom.create(
         skydir=skydir, binsz=0.5, width=(10, 5), frame="galactic", axes=[energy_axis]
     )
-    return MapDataset.create(geom, name=name)
+    return MapDataset.create(geom=geom)
 
 
-def get_spectrumdataset(name):
+@pytest.fixture()
+def spectrum_dataset():
     target_position = SkyCoord(ra=83.63, dec=22.01, unit="deg", frame="icrs")
     on_region_radius = Angle("0.11 deg")
     on_region = CircleSkyRegion(center=target_position, radius=on_region_radius)
 
     energy_axis = MapAxis.from_energy_bounds(
         0.1, 40, nbin=15, per_decade=True, unit="TeV", name="energy"
     )
     energy_axis_true = MapAxis.from_energy_bounds(
         0.05, 100, nbin=20, per_decade=True, unit="TeV", name="energy_true"
     )
 
     geom = RegionGeom.create(region=on_region, axes=[energy_axis])
     return SpectrumDataset.create(
-        geom=geom, energy_axis_true=energy_axis_true, name=name
+        geom=geom,
+        energy_axis_true=energy_axis_true,
     )
 
 
 def get_spectrum_dataset_rad_max(name, e_min=0.005 * u.TeV):
     """get the spectrum dataset maker for the energy-dependent spectrum extraction"""
     target_position = SkyCoord(ra=83.63, dec=22.01, unit="deg", frame="icrs")
     on_center = PointSkyRegion(target_position)
@@ -130,44 +133,44 @@
 
 
 @requires_data()
 @pytest.mark.parametrize(
     "pars",
     [
         {
-            "dataset": get_mapdataset(name="linear_staking"),
             "stack_datasets": True,
             "cutout_width": None,
             "n_jobs": 1,
+            "backend": None,
         },
         {
-            "dataset": get_mapdataset(name="parallel"),
             "stack_datasets": False,
             "cutout_width": None,
             "n_jobs": 2,
+            "backend": "multiprocessing",
         },
         {
-            "dataset": get_mapdataset(name="parallel_staking"),
             "stack_datasets": True,
             "cutout_width": None,
             "n_jobs": 2,
+            "backend": "multiprocessing",
         },
     ],
 )
-@requires_data()
-def test_datasets_maker_map(pars, observations_cta, makers_map):
+def test_datasets_maker_map(pars, observations_cta, makers_map, map_dataset):
     makers = DatasetsMaker(
         makers_map,
         stack_datasets=pars["stack_datasets"],
         cutout_mode="partial",
         cutout_width=pars["cutout_width"],
         n_jobs=pars["n_jobs"],
+        parallel_backend=pars["backend"],
     )
 
-    datasets = makers.run(pars["dataset"], observations_cta)
+    datasets = makers.run(map_dataset, observations_cta)
     if len(datasets) == 1:
         counts = datasets[0].counts
         assert counts.unit == ""
         assert_allclose(counts.data.sum(), 46716, rtol=1e-5)
 
         exposure = datasets[0].exposure
         assert exposure.unit == "m2 s"
@@ -181,75 +184,94 @@
 
         exposure = datasets[0].exposure
         assert exposure.unit == "m2 s"
         assert_allclose(exposure.data.mean(), 2.436063e09, rtol=3e-3)
 
 
 @requires_data()
-def test_datasets_maker_map_cutout_width(observations_cta, makers_map, tmp_path):
+@requires_dependency("ray")
+def test_datasets_maker_map_ray(observations_cta, makers_map, map_dataset):
+    makers = DatasetsMaker(
+        makers_map,
+        stack_datasets=True,
+        cutout_mode="partial",
+        cutout_width=None,
+        n_jobs=2,
+        parallel_backend="ray",
+    )
+
+    datasets = makers.run(dataset=map_dataset, observations=observations_cta)
+    counts = datasets[0].counts
+    assert counts.unit == ""
+    assert_allclose(counts.data.sum(), 46716, rtol=1e-5)
+
+    exposure = datasets[0].exposure
+    assert exposure.unit == "m2 s"
+    assert_allclose(exposure.data.mean(), 1.350841e09, rtol=3e-3)
+
+
+@requires_data()
+def test_datasets_maker_map_cutout_width(observations_cta, makers_map, map_dataset):
     makers = DatasetsMaker(
         makers_map,
         stack_datasets=True,
         cutout_mode="partial",
         cutout_width="5 deg",
         n_jobs=1,
     )
-    datasets = makers.run(get_mapdataset(name="linear_staking_1deg"), observations_cta)
+    datasets = makers.run(map_dataset, observations_cta)
 
     counts = datasets[0].counts
 
     assert counts.unit == ""
     assert_allclose(counts.data.sum(), 46716, rtol=1e-5)
 
     exposure = datasets[0].exposure
     assert exposure.unit == "m2 s"
     assert_allclose(exposure.data.mean(), 1.350841e09, rtol=3e-3)
 
 
 @requires_data()
-def test_datasets_maker_map_2steps(observations_cta, makers_map, tmp_path):
-
+def test_datasets_maker_map_2_steps(observations_cta, map_dataset):
     makers = DatasetsMaker(
         [MapDatasetMaker()],
         stack_datasets=False,
         cutout_mode="partial",
         cutout_width="5 deg",
         n_jobs=1,
     )
 
-    dataset = get_mapdataset(name="2steps")
-    datasets = makers.run(dataset, observations_cta)
+    datasets = makers.run(map_dataset, observations_cta)
 
     makers_list = [
         SafeMaskMaker(methods=["offset-max"], offset_max="2 deg"),
         FoVBackgroundMaker(method="scale"),
     ]
     makers = DatasetsMaker(
         makers_list,
         stack_datasets=True,
         cutout_mode="partial",
         cutout_width="5 deg",
         n_jobs=1,
     )
-    datasets = makers.run(dataset, observations_cta, datasets)
+    datasets = makers.run(map_dataset, observations_cta, datasets)
 
     counts = datasets[0].counts
     assert counts.unit == ""
     assert_allclose(counts.data.sum(), 46716, rtol=1e-5)
 
     exposure = datasets[0].exposure
     assert exposure.unit == "m2 s"
     assert_allclose(exposure.data.mean(), 1.350841e09, rtol=3e-3)
 
 
 @requires_data()
-def test_datasetsmaker_spectrum(observations_hess, makers_spectrum):
-
+def test_datasets_maker_spectrum(observations_hess, makers_spectrum, spectrum_dataset):
     makers = DatasetsMaker(makers_spectrum, stack_datasets=False, n_jobs=2)
-    datasets = makers.run(get_spectrumdataset(name="spec"), observations_hess)
+    datasets = makers.run(spectrum_dataset, observations_hess)
 
     counts = datasets[0].counts
     assert counts.unit == ""
     assert_allclose(counts.data.sum(), 192, rtol=1e-5)
     assert_allclose(datasets[0].background.data.sum(), 18.66666664, rtol=1e-5)
 
     exposure = datasets[0].exposure
@@ -362,21 +384,21 @@
     maker = SpectrumDatasetMaker(
         containment_correction=False, selection=["counts", "exposure", "edisp"]
     )
     dataset = maker.run(get_spectrum_dataset_rad_max("spec"), observation)
 
     # excludes all possible off regions
     exclusion_region = CircleSkyRegion(
-        center=observation.pointing_radec,
+        center=observation.get_pointing_icrs(observation.tmid),
         radius=1 * u.deg,
     )
     geom = WcsGeom.create(
         npix=(150, 150),
         binsz=0.05,
-        skydir=observation.pointing_radec,
+        skydir=observation.get_pointing_icrs(observation.tmid),
         proj="TAN",
         frame="icrs",
     )
 
     exclusion_mask = ~geom.region_mask([exclusion_region])
 
     finder = WobbleRegionsFinder(n_off_regions=1)
```

### Comparing `gammapy-1.0rc2/gammapy/makers/tests/test_safe.py` & `gammapy-1.1rc1/gammapy/makers/tests/test_safe.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,17 +1,18 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import logging
 import pytest
 import numpy as np
 from numpy.testing import assert_allclose
 from astropy import units as u
+from regions import CircleSkyRegion
 from gammapy.data import DataStore
-from gammapy.datasets import MapDataset
+from gammapy.datasets import MapDataset, SpectrumDatasetOnOff
 from gammapy.makers import MapDatasetMaker, SafeMaskMaker
-from gammapy.maps import MapAxis, WcsGeom
+from gammapy.maps import MapAxis, RegionGeom, WcsGeom
 from gammapy.utils.testing import requires_data
 
 
 @pytest.fixture(scope="session")
 def observations():
     data_store = DataStore.from_dir("$GAMMAPY_DATA/cta-1dc/index/gps/")
     obs_id = [110380, 111140]
@@ -36,56 +37,78 @@
 def dataset(observation_cta_1dc):
     axis = MapAxis.from_bounds(
         0.1, 10, nbin=16, unit="TeV", name="energy", interp="log"
     )
     axis_true = MapAxis.from_bounds(
         0.1, 50, nbin=30, unit="TeV", name="energy_true", interp="log"
     )
-    geom = WcsGeom.create(
-        npix=(11, 11), axes=[axis], skydir=observation_cta_1dc.pointing_radec
-    )
+    pointing = observation_cta_1dc.get_pointing_icrs(observation_cta_1dc.tmid)
+    geom = WcsGeom.create(npix=(11, 11), axes=[axis], skydir=pointing)
 
     empty_dataset = MapDataset.create(geom=geom, energy_axis_true=axis_true)
     dataset_maker = MapDatasetMaker()
     return dataset_maker.run(dataset=empty_dataset, observation=observation_cta_1dc)
 
 
 @pytest.fixture(scope="session")
 def shifted_dataset(observation_cta_1dc):
     axis = MapAxis.from_bounds(0.1, 1, nbin=5, unit="TeV", name="energy", interp="log")
     axis_true = MapAxis.from_bounds(
         0.1, 2, nbin=10, unit="TeV", name="energy_true", interp="log"
     )
-    skydir = observation_cta_1dc.pointing_radec.directional_offset_by(
+    pointing = observation_cta_1dc.get_pointing_icrs(observation_cta_1dc.tmid)
+    skydir = pointing.directional_offset_by(
         position_angle=0.0 * u.deg, separation=10 * u.deg
     )
     geom = WcsGeom.create(npix=(11, 11), axes=[axis], skydir=skydir)
 
     empty_dataset = MapDataset.create(
         geom=geom, energy_axis_true=axis_true, name="shifted"
     )
     dataset_maker = MapDatasetMaker()
     return dataset_maker.run(dataset=empty_dataset, observation=observation_cta_1dc)
 
 
+@pytest.fixture(scope="session")
+def spectrum_dataset_on_off(observation_cta_1dc):
+    axis = MapAxis.from_bounds(
+        0.1, 10, nbin=16, unit="TeV", name="energy", interp="log"
+    )
+    axis_true = MapAxis.from_bounds(
+        0.1, 50, nbin=30, unit="TeV", name="energy_true", interp="log"
+    )
+    axis_migra = MapAxis.from_bounds(0.2, 5.0, nbin=48, name="migra")
+
+    pointing = observation_cta_1dc.get_pointing_icrs(observation_cta_1dc.tmid)
+    region = CircleSkyRegion(pointing, radius=0.3 * u.deg)
+    geom = RegionGeom.create(region, axes=[axis])
+
+    return SpectrumDatasetOnOff.create(
+        geom, energy_axis_true=axis_true, migra_axis=axis_migra
+    )
+
+
 @requires_data()
 def test_safe_mask_maker_offset_max(dataset, observation_cta_1dc):
+    pointing = observation_cta_1dc.get_pointing_icrs(observation_cta_1dc.tmid)
     safe_mask_maker = SafeMaskMaker(
-        offset_max="3 deg", position=observation_cta_1dc.pointing_radec
+        offset_max="3 deg",
+        position=pointing,
     )
 
     mask_offset = safe_mask_maker.make_mask_offset_max(
         dataset=dataset, observation=observation_cta_1dc
     )
     assert_allclose(mask_offset.sum(), 109)
 
 
 @requires_data()
 def test_safe_mask_maker_aeff_default(dataset, observation_cta_1dc, caplog):
-    safe_mask_maker = SafeMaskMaker(position=observation_cta_1dc.pointing_radec)
+    pointing = observation_cta_1dc.get_pointing_icrs(observation_cta_1dc.tmid)
+    safe_mask_maker = SafeMaskMaker(position=pointing)
 
     mask_energy_aeff_default = safe_mask_maker.make_mask_energy_aeff_default(
         dataset=dataset, observation=observation_cta_1dc
     )
     assert_allclose(mask_energy_aeff_default.data.sum(), 1936)
 
     assert "WARNING" in [_.levelname for _ in caplog.records]
@@ -96,15 +119,16 @@
 
     message = "No default lower safe energy threshold defined for obs 110380"
     assert message == messages[1]
 
 
 @requires_data()
 def test_safe_mask_maker_aeff_max(dataset, observation_cta_1dc):
-    safe_mask_maker = SafeMaskMaker(position=observation_cta_1dc.pointing_radec)
+    pointing = observation_cta_1dc.get_pointing_icrs(observation_cta_1dc.tmid)
+    safe_mask_maker = SafeMaskMaker(position=pointing)
 
     mask_aeff_max = safe_mask_maker.make_mask_energy_aeff_max(dataset)
 
     assert_allclose(mask_aeff_max.data.sum(), 1210)
 
 
 @requires_data()
@@ -157,81 +181,93 @@
         dataset=dataset, observation=observation_cta_1dc
     )
     assert_allclose(mask_aeff_max_offset.data.sum(), 1210)
 
 
 @requires_data()
 def test_safe_mask_maker_edisp_bias(dataset, observation_cta_1dc):
-    safe_mask_maker = SafeMaskMaker(
-        bias_percent=0.02, position=observation_cta_1dc.pointing_radec
-    )
+    pointing = observation_cta_1dc.get_pointing_icrs(observation_cta_1dc.tmid)
+    safe_mask_maker = SafeMaskMaker(bias_percent=0.02, position=pointing)
 
     mask_edisp_bias = safe_mask_maker.make_mask_energy_edisp_bias(dataset=dataset)
     assert_allclose(mask_edisp_bias.data.sum(), 1815)
 
 
 @requires_data()
+def test_safe_mask_maker_spectrum_dataset_edisp_bias_no_position(
+    spectrum_dataset_on_off,
+):
+    safe_mask_maker = SafeMaskMaker(methods=["edisp-bias"], bias_percent=0.02)
+    safe_mask_maker.run(spectrum_dataset_on_off)
+    mask_edisp_bias = safe_mask_maker.make_mask_energy_edisp_bias(
+        dataset=spectrum_dataset_on_off
+    )
+    assert_allclose(mask_edisp_bias.data.sum(), 14)
+
+
+@requires_data()
 def test_safe_mask_maker_edisp_bias_fixed_offset(dataset, observation_cta_1dc):
     safe_mask_maker_offset = SafeMaskMaker(
         offset_max="3 deg", bias_percent=0.02, fixed_offset=1.5 * u.deg
     )
 
     mask_edisp_bias_offset = safe_mask_maker_offset.make_mask_energy_edisp_bias(
         dataset=dataset, observation=observation_cta_1dc
     )
     assert_allclose(mask_edisp_bias_offset.data.sum(), 1694)
 
 
 @requires_data()
 def test_safe_mask_maker_bkg_peak(dataset, observation_cta_1dc):
-    safe_mask_maker = SafeMaskMaker(position=observation_cta_1dc.pointing_radec)
+    pointing = observation_cta_1dc.get_pointing_icrs(observation_cta_1dc.tmid)
+    safe_mask_maker = SafeMaskMaker(position=pointing)
 
     mask_bkg_peak = safe_mask_maker.make_mask_energy_bkg_peak(dataset)
     assert_allclose(mask_bkg_peak.data.sum(), 1936)
 
 
 @requires_data()
 def test_safe_mask_maker_bkg_peak_first_bin(dataset, observation_cta_1dc):
-    safe_mask_maker = SafeMaskMaker(position=observation_cta_1dc.pointing_radec)
+    pointing = observation_cta_1dc.get_pointing_icrs(observation_cta_1dc.tmid)
+    safe_mask_maker = SafeMaskMaker(position=pointing)
 
     dataset_maker = MapDatasetMaker()
 
     axis = MapAxis.from_bounds(1.0, 10, nbin=6, unit="TeV", name="energy", interp="log")
 
-    geom = WcsGeom.create(
-        npix=(5, 5), axes=[axis], skydir=observation_cta_1dc.pointing_radec
-    )
+    geom = WcsGeom.create(npix=(5, 5), axes=[axis], skydir=pointing)
     empty_dataset = MapDataset.create(geom=geom)
     dataset = dataset_maker.run(empty_dataset, observation_cta_1dc)
     mask_bkg_peak = safe_mask_maker.make_mask_energy_bkg_peak(dataset)
     assert np.all(mask_bkg_peak)
 
 
 @requires_data()
-def test_safe_mask_maker_no_root(dataset, observation_cta_1dc):
+def test_safe_mask_maker_no_root(dataset):
     safe_mask_maker_noroot = SafeMaskMaker(
         offset_max="3 deg", aeff_percent=-10, bias_percent=-10
     )
     mask_aeff_max_noroot = safe_mask_maker_noroot.make_mask_energy_aeff_max(dataset)
     mask_edisp_bias_noroot = safe_mask_maker_noroot.make_mask_energy_edisp_bias(dataset)
     assert_allclose(mask_aeff_max_noroot.data.sum(), 1815)
     assert_allclose(mask_edisp_bias_noroot.data.sum(), 1936)
 
 
 @requires_data()
 def test_safe_mask_maker_bkg_invalid(observations_hess_dl3):
     obs = observations_hess_dl3[0]
+    pointing = obs.get_pointing_icrs(obs.tmid)
 
     axis = MapAxis.from_bounds(
         0.1, 10, nbin=16, unit="TeV", name="energy", interp="log"
     )
     axis_true = MapAxis.from_bounds(
         0.1, 50, nbin=30, unit="TeV", name="energy_true", interp="log"
     )
-    geom = WcsGeom.create(npix=(9, 9), axes=[axis], skydir=obs.pointing_radec)
+    geom = WcsGeom.create(npix=(9, 9), axes=[axis], skydir=pointing)
 
     empty_dataset = MapDataset.create(geom=geom, energy_axis_true=axis_true)
     dataset_maker = MapDatasetMaker()
 
     safe_mask_maker_nonan = SafeMaskMaker([])
 
     dataset = dataset_maker.run(empty_dataset, obs)
```

### Comparing `gammapy-1.0rc2/gammapy/makers/tests/test_spectrum.py` & `gammapy-1.1rc1/gammapy/makers/tests/test_spectrum.py`

 * *Files 4% similar despite different names*

```diff
@@ -213,21 +213,21 @@
 
     mask_safe = safe_mask_maker.make_mask_energy_bkg_peak(dataset)
     assert mask_safe.data.sum() == 4
 
 
 @requires_data()
 def test_safe_mask_maker_dc1(spectrum_dataset_gc, observations_cta_dc1):
-    safe_mask_maker = SafeMaskMaker(methods=["edisp-bias", "aeff-max"])
-
-    obs = observations_cta_dc1[0]
+    safe_mask_maker = SafeMaskMaker(methods=["aeff-max"])
+    empty = SpectrumDataset.from_geoms(**spectrum_dataset_gc.geoms)
+    obs = observations_cta_dc1[1]
     maker = SpectrumDatasetMaker()
-    dataset = maker.run(spectrum_dataset_gc, obs)
+    dataset = maker.run(empty, obs)
     dataset = safe_mask_maker.run(dataset, obs)
-    assert_allclose(dataset.energy_range[0], 1, rtol=1e-3)
+    assert_allclose(dataset.energy_range[0].data, 1.0, rtol=1e-3)
     assert dataset.energy_range[0].unit == "TeV"
 
 
 @requires_data()
 def test_make_meta_table(observations_hess_dl3):
     maker_obs = SpectrumDatasetMaker()
     map_spectrumdataset_meta_table = maker_obs.make_meta_table(
@@ -337,18 +337,16 @@
 
         # TODO: Introduce assert_stats_allclose
         info = dataset.info_dict()
 
         assert info["counts"] == results["n_on"]
         assert_allclose(info["sqrt_ts"], results["sigma"], rtol=1e-2)
 
-        gti_obs = obs.gti.table
-        gti_dataset = dataset.gti.table
-        assert_allclose(gti_dataset["START"], gti_obs["START"])
-        assert_allclose(gti_dataset["STOP"], gti_obs["STOP"])
+        assert_allclose(dataset.gti.met_start, obs.gti.met_start)
+        assert_allclose(dataset.gti.met_stop, obs.gti.met_stop)
 
     def test_compute_energy_threshold(
         self, spectrum_dataset_crab_fine, observations_hess_dl3
     ):
 
         maker = SpectrumDatasetMaker(containment_correction=True)
         safe_mask_maker = SafeMaskMaker(methods=["aeff-max"], aeff_percent=10)
```

### Comparing `gammapy-1.0rc2/gammapy/makers/tests/test_utils.py` & `gammapy-1.1rc1/gammapy/makers/tests/test_utils.py`

 * *Files 9% similar despite different names*

```diff
@@ -2,35 +2,53 @@
 import pytest
 import numpy as np
 from numpy.testing import assert_allclose
 from astropy import units as u
 from astropy.coordinates import EarthLocation, SkyCoord
 from astropy.table import Table
 from astropy.time import Time
-from gammapy.data import GTI, EventList, FixedPointingInfo, Observation
+from regions import PointSkyRegion
+from gammapy.data import (
+    GTI,
+    DataStore,
+    EventList,
+    FixedPointingInfo,
+    Observation,
+    PointingMode,
+)
 from gammapy.irf import (
     Background2D,
     Background3D,
     EffectiveAreaTable2D,
     EnergyDispersion2D,
 )
+from gammapy.makers import WobbleRegionsFinder
 from gammapy.makers.utils import (
     _map_spectrum_weight,
+    make_counts_off_rad_max,
+    make_counts_rad_max,
     make_edisp_kernel_map,
     make_map_background_irf,
     make_map_exposure_true_energy,
     make_theta_squared_table,
 )
-from gammapy.maps import HpxGeom, MapAxis, WcsGeom, WcsNDMap
+from gammapy.maps import HpxGeom, MapAxis, RegionGeom, WcsGeom, WcsNDMap
 from gammapy.modeling.models import ConstantSpectralModel
 from gammapy.utils.testing import requires_data
 from gammapy.utils.time import time_ref_to_dict
 
 
 @pytest.fixture(scope="session")
+def observations():
+    """Example observation list for testing."""
+    datastore = DataStore.from_dir("$GAMMAPY_DATA/magic/rad_max/data")
+    return datastore.get_observations(required_irf="point-like")[0]
+
+
+@pytest.fixture(scope="session")
 def aeff():
     filename = (
         "$GAMMAPY_DATA/cta-1dc/caldb/data/cta/1dc/bcf/South_z20_50h/irf_file.fits"
     )
     return EffectiveAreaTable2D.read(filename, hdu="EFFECTIVE AREA")
 
 
@@ -96,36 +114,29 @@
 @pytest.fixture(scope="session")
 def fixed_pointing_info():
     filename = "$GAMMAPY_DATA/cta-1dc/data/baseline/gps/gps_baseline_110380.fits"
     return FixedPointingInfo.read(filename)
 
 
 @pytest.fixture(scope="session")
-def fixed_pointing_info_aligned(fixed_pointing_info):
+def fixed_pointing_info_aligned():
     # Create Fixed Pointing Info aligned between sky and horizon coordinates
     # (removes rotation in FoV and results in predictable solid angles)
-    origin = SkyCoord(
-        0,
-        0,
-        unit="deg",
-        frame="icrs",
-        location=EarthLocation(lat=90 * u.deg, lon=0 * u.deg),
-        obstime=Time("2000-9-21 12:00:00"),
-    )
-    fpi = fixed_pointing_info
-    meta = fpi.meta.copy()
-    meta["RA_PNT"] = origin.icrs.ra
-    meta["DEC_PNT"] = origin.icrs.dec
-    meta["GEOLON"] = origin.location.lon
-    meta["GEOLAT"] = origin.location.lat
-    meta["ALTITUDE"] = origin.location.height
-    time_start = origin.obstime.datetime - fpi.time_ref.datetime
-    meta["TSTART"] = time_start.total_seconds()
-    meta["TSTOP"] = meta["TSTART"] + 60
-    return FixedPointingInfo(meta)
+    time_start = Time("2000-09-21 11:55:00")
+    time_stop = Time("2000-09-12 12:05:00")
+    location = EarthLocation(lat=90 * u.deg, lon=0 * u.deg)
+    fixed_icrs = SkyCoord(0 * u.deg, 0 * u.deg, frame="icrs")
+
+    return FixedPointingInfo(
+        mode=PointingMode.POINTING,
+        fixed_icrs=fixed_icrs,
+        location=location,
+        time_start=time_start,
+        time_stop=time_stop,
+    )
 
 
 @pytest.fixture(scope="session")
 def bkg_3d():
     filename = (
         "$GAMMAPY_DATA/cta-1dc/caldb/data/cta/1dc/bcf/South_z20_50h/irf_file.fits"
     )
@@ -168,15 +179,17 @@
         # allow extrapolation for symmetry tests
     )
 
 
 @requires_data()
 def test_map_background_2d(bkg_2d, fixed_pointing_info):
     axis = MapAxis.from_edges([0.1, 1, 10], name="energy", unit="TeV", interp="log")
-    skydir = fixed_pointing_info.radec.galactic
+
+    obstime = Time("2020-01-01T20:00:00")
+    skydir = fixed_pointing_info.get_icrs(obstime).galactic
     geom = WcsGeom.create(
         npix=(3, 3), binsz=4, axes=[axis], skydir=skydir, frame="galactic"
     )
 
     bkg = make_map_background_irf(
         pointing=skydir,
         ontime="42 s",
@@ -188,25 +201,28 @@
 
     # Check that function works also passing the FixedPointingInfo
     bkg_fpi = make_map_background_irf(
         pointing=fixed_pointing_info,
         ontime="42 s",
         bkg=bkg_2d,
         geom=geom,
+        obstime=obstime,
     )
     assert_allclose(bkg.data, bkg_fpi.data, rtol=1e-5)
 
 
 def make_map_background_irf_with_symmetry(fpi, symmetry="constant"):
     axis = MapAxis.from_edges([0.1, 1, 10], name="energy", unit="TeV", interp="log")
+    obstime = Time("2020-01-01T20:00:00")
     return make_map_background_irf(
         pointing=fpi,
         ontime="42 s",
         bkg=bkg_3d_custom(symmetry),
-        geom=WcsGeom.create(npix=(3, 3), binsz=4, axes=[axis], skydir=fpi.radec),
+        geom=WcsGeom.create(npix=(3, 3), binsz=4, axes=[axis], skydir=fpi.fixed_icrs),
+        obstime=obstime,
     )
 
 
 def geom(map_type, ebounds, skydir):
     axis = MapAxis.from_edges(ebounds, name="energy", unit="TeV", interp="log")
     if map_type == "wcs":
         return WcsGeom.create(npix=(4, 3), binsz=2, axes=[axis], skydir=skydir)
@@ -245,17 +261,18 @@
     m = make_map_background_irf(
         pointing=fixed_pointing_info,
         ontime="42 s",
         bkg=bkg_3d,
         geom=geom(
             map_type=pars["map_type"],
             ebounds=pars["ebounds"],
-            skydir=fixed_pointing_info.radec,
+            skydir=fixed_pointing_info.fixed_icrs,
         ),
         oversampling=10,
+        obstime=Time("2020-01-01T20:00"),
     )
 
     assert m.data.shape == pars["shape"]
     assert m.unit == ""
     assert_allclose(m.data.sum(), pars["sum"], rtol=1e-5)
 
 
@@ -299,15 +316,15 @@
             assert_allclose(d[0, 1], d[2, 1], rtol=1e-4)  # Symmetric along lat
         assert_allclose(d[0, 1] * 9, d[2, 1], rtol=1e-4)  # Asymmetric along lat
 
 
 @requires_data()
 def test_make_map_background_irf_skycoord(fixed_pointing_info_aligned):
     axis = MapAxis.from_edges([0.1, 1, 10], name="energy", unit="TeV", interp="log")
-    position = fixed_pointing_info_aligned.radec
+    position = fixed_pointing_info_aligned.fixed_icrs
     with pytest.raises(TypeError):
         make_map_background_irf(
             pointing=position,
             ontime="42 s",
             bkg=bkg_3d_custom("asymmetric", "ALTAZ"),
             geom=WcsGeom.create(npix=(3, 3), binsz=4, axes=[axis], skydir=position),
         )
@@ -329,36 +346,82 @@
 
     kernel = edispmap.get_edisp_kernel(position=pointing)
     assert_allclose(kernel.pdf_matrix[:, 0], (1.0, 1.0, 0.0, 0.0, 0.0, 0.0), atol=1e-14)
     assert_allclose(kernel.pdf_matrix[:, 1], (0.0, 0.0, 1.0, 1.0, 0.0, 0.0), atol=1e-14)
     assert_allclose(kernel.pdf_matrix[:, 2], (0.0, 0.0, 0.0, 0.0, 1.0, 1.0), atol=1e-14)
 
 
+@requires_data()
+def test_make_counts_rad_max(observations):
+
+    pos = SkyCoord(083.6331144560900, +22.0144871383400, unit="deg", frame="icrs")
+    on_region = PointSkyRegion(pos)
+    energy_axis = MapAxis.from_energy_bounds(
+        0.05, 100, nbin=6, unit="TeV", name="energy"
+    )
+    geome = RegionGeom.create(region=on_region, axes=[energy_axis])
+    counts = make_counts_rad_max(geome, observations.rad_max, observations.events)
+
+    assert_allclose(np.squeeze(counts.data), np.array([547, 188, 52, 8, 0, 0]))
+
+
+@requires_data()
+def test_make_counts_off_rad_max(observations):
+
+    pos = SkyCoord(83.6331, +22.0145, unit="deg", frame="icrs")
+    on_region = PointSkyRegion(pos)
+    energy_axis = MapAxis.from_energy_bounds(
+        0.05, 100, nbin=6, unit="TeV", name="energy"
+    )
+
+    region_finder = WobbleRegionsFinder(n_off_regions=3)
+    region_off, wcs = region_finder.run(on_region, pos)
+    geom_off = RegionGeom.from_regions(regions=region_off, axes=[energy_axis], wcs=wcs)
+
+    counts_off = make_counts_off_rad_max(
+        geom_off=geom_off, rad_max=observations.rad_max, events=observations.events
+    )
+
+    assert_allclose(np.squeeze(counts_off.data), np.array([1641, 564, 156, 24, 0, 0]))
+
+
 class TestTheta2Table:
     def setup_class(self):
         self.observations = []
         for sign in [-1, 1]:
             events = Table()
             events["RA"] = [0.0, 0.0, 0.0, 0.0, 10.0] * u.deg
             events["DEC"] = sign * ([0.0, 0.05, 0.9, 10.0, 10.0] * u.deg)
             events["ENERGY"] = [1.0, 1.0, 1.5, 1.5, 10.0] * u.TeV
             events["OFFSET"] = [0.1, 0.1, 0.5, 1.0, 1.5] * u.deg
+            events["TIME"] = [0.1, 0.2, 0.3, 0.4, 0.5] * u.s
 
             obs_info = dict(
-                RA_PNT=0 * u.deg,
-                DEC_PNT=sign * 0.5 * u.deg,
                 DEADC=1,
             )
-            events.meta.update(obs_info)
             meta = time_ref_to_dict("2010-01-01")
-            gti_table = Table({"START": [1], "STOP": [3]}, meta=meta)
-            gti = GTI(gti_table)
+            obs_info.update(meta)
+            events.meta.update(obs_info)
+            gti = GTI.create(
+                start=[1] * u.s,
+                stop=[3] * u.s,
+                reference_time=Time("2010-01-01", scale="tt"),
+            )
+            pointing = FixedPointingInfo(
+                mode=PointingMode.POINTING,
+                fixed_icrs=SkyCoord(0 * u.deg, sign * 0.5 * u.deg),
+            )
 
             self.observations.append(
-                Observation(events=EventList(events), obs_info=obs_info, gti=gti)
+                Observation(
+                    events=EventList(events),
+                    obs_info=obs_info,
+                    gti=gti,
+                    pointing=pointing,
+                )
             )
 
     def test_make_theta_squared_table(self):
         # pointing position: (0,0.5) degree in ra/dec
         # On theta2 distribution compute from (0,0) in ra/dec.
         # OFF theta2 distribution from the mirror position at (0,1) in ra/dec.
         position = SkyCoord(ra=0, dec=0, unit="deg", frame="icrs")
```

### Comparing `gammapy-1.0rc2/gammapy/makers/utils.py` & `gammapy-1.1rc1/gammapy/makers/utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,10 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import logging
+import warnings
 import numpy as np
 from astropy.coordinates import Angle, SkyOffsetFrame
 from astropy.table import Table
 from gammapy.data import FixedPointingInfo
 from gammapy.irf import EDispMap, FoVAlignment, PSFMap
 from gammapy.maps import Map, RegionNDMap
 from gammapy.modeling.models import PowerLawSpectralModel
@@ -105,15 +106,21 @@
     weights /= weights.sum()
     shape = np.ones(len(map.geom.data_shape))
     shape[0] = -1
     return map * weights.reshape(shape.astype(int))
 
 
 def make_map_background_irf(
-    pointing, ontime, bkg, geom, oversampling=None, use_region_center=True
+    pointing,
+    ontime,
+    bkg,
+    geom,
+    oversampling=None,
+    use_region_center=True,
+    obstime=None,
 ):
     """Compute background map from background IRFs.
 
     Parameters
     ----------
     pointing : `~gammapy.data.FixedPointingInfo` or `~astropy.coordinates.SkyCoord`
         Observation pointing
@@ -126,20 +133,22 @@
     ontime : `~astropy.units.Quantity`
         Observation ontime. i.e. not corrected for deadtime
         see https://gamma-astro-data-formats.readthedocs.io/en/latest/irfs/full_enclosure/bkg/index.html#notes)  # noqa: E501
     bkg : `~gammapy.irf.Background3D`
         Background rate model
     geom : `~gammapy.maps.WcsGeom`
         Reference geometry
-    oversampling: int
+    oversampling : int
         Oversampling factor in energy, used for the background model evaluation.
-    use_region_center: bool
+    use_region_center : bool
         If geom is a RegionGeom, whether to just
         consider the values at the region center
         or the instead the sum over the whole region
+    obstime : `~astropy.time.Time`
+        Observation time to use
 
     Returns
     -------
     background : `~gammapy.maps.WcsNDMap`
         Background predicted counts sky cube in reco energy
     """
     # TODO:
@@ -153,49 +162,67 @@
 
     # Get altaz coords for map
     if oversampling is not None:
         geom = geom.upsample(factor=oversampling, axis_name="energy")
 
     coords = {"energy": geom.axes["energy"].edges.reshape((-1, 1, 1))}
 
-    pointing_radec = (
-        pointing.radec if isinstance(pointing, FixedPointingInfo) else pointing
-    )
+    if isinstance(pointing, FixedPointingInfo):
+        # for backwards compatibility, obstime should be required
+        if obstime is None:
+            warnings.warn(
+                "Future versions of gammapy will require the obstime keyword for this function",
+                DeprecationWarning,
+            )
+            obstime = pointing.obstime
+
+        pointing_icrs = pointing.get_icrs(obstime)
+    else:
+        pointing_icrs = pointing
 
     if not use_region_center:
         image_geom = geom.to_wcs_geom().to_image()
         region_coord, weights = geom.get_wcs_coord_and_weights()
         idx = image_geom.coord_to_idx(region_coord)
         sky_coord = region_coord.skycoord
         d_omega = image_geom.solid_angle().T[idx]
     else:
         image_geom = geom.to_image()
         map_coord = image_geom.get_coord()
         sky_coord = map_coord.skycoord
         d_omega = image_geom.solid_angle()
 
     if bkg.has_offset_axis:
-        coords["offset"] = sky_coord.separation(pointing_radec)
+        coords["offset"] = sky_coord.separation(pointing_icrs)
     else:
         if bkg.fov_alignment == FoVAlignment.ALTAZ:
             if not isinstance(pointing, FixedPointingInfo):
-                raise (
-                    TypeError,
+                raise TypeError(
                     "make_map_background_irf requires FixedPointingInfo if "
                     "BackgroundIRF.fov_alignement is ALTAZ",
                 )
-            altaz_coord = sky_coord.transform_to(pointing.altaz_frame)
+
+            # for backwards compatibility, obstime should be required
+            if obstime is None:
+                warnings.warn(
+                    "Future versions of gammapy will require the obstime keyword for this function",
+                    DeprecationWarning,
+                )
+                obstime = pointing.obstime
+
+            pointing_altaz = pointing.get_altaz(obstime)
+            altaz_coord = sky_coord.transform_to(pointing_altaz.frame)
 
             # Compute FOV coordinates of map relative to pointing
             fov_lon, fov_lat = sky_to_fov(
-                altaz_coord.az, altaz_coord.alt, pointing.altaz.az, pointing.altaz.alt
+                altaz_coord.az, altaz_coord.alt, pointing_altaz.az, pointing_altaz.alt
             )
         elif bkg.fov_alignment == FoVAlignment.RADEC:
             # Create OffsetFrame
-            frame = SkyOffsetFrame(origin=pointing_radec)
+            frame = SkyOffsetFrame(origin=pointing_icrs)
             pseudo_fov_coord = sky_coord.transform_to(frame)
             fov_lon = pseudo_fov_coord.lon
             fov_lat = pseudo_fov_coord.lat
         else:
             raise ValueError(
                 f"Unsupported background coordinate system: {bkg.fov_alignment!r}"
             )
@@ -399,28 +426,31 @@
     table["acceptance_off"] = 0.0
 
     alpha_tot = np.zeros(len(table))
     livetime_tot = 0
 
     create_off = position_off is None
     for observation in observations:
-        separation = position.separation(observation.events.radec)
+        event_position = observation.events.radec
+        pointing = observation.get_pointing_icrs(observation.tmid)
+
+        separation = position.separation(event_position)
         counts, _ = np.histogram(separation**2, theta_squared_axis.edges)
         table["counts"] += counts
 
         if create_off:
             # Estimate the position of the mirror position
-            pos_angle = observation.pointing_radec.position_angle(position)
-            sep_angle = observation.pointing_radec.separation(position)
-            position_off = observation.pointing_radec.directional_offset_by(
+            pos_angle = pointing.position_angle(position)
+            sep_angle = pointing.separation(position)
+            position_off = pointing.directional_offset_by(
                 pos_angle + Angle(np.pi, "rad"), sep_angle
             )
 
         # Angular distance of the events from the mirror position
-        separation_off = position_off.separation(observation.events.radec)
+        separation_off = position_off.separation(event_position)
 
         # Extract the ON and OFF theta2 distribution from the two positions.
         counts_off, _ = np.histogram(separation_off**2, theta_squared_axis.edges)
         table["counts_off"] += counts_off
 
         # Normalisation between ON and OFF is one
         acceptance = np.ones(theta_squared_axis.nbin)
```

### Comparing `gammapy-1.0rc2/gammapy/maps/__init__.py` & `gammapy-1.1rc1/gammapy/maps/__init__.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/maps/axes.py` & `gammapy-1.1rc1/gammapy/maps/axes.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,25 +1,29 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import copy
 import inspect
+import logging
 from collections.abc import Sequence
 import numpy as np
 import scipy
 import astropy.units as u
 from astropy.io import fits
 from astropy.table import Column, Table, hstack
 from astropy.time import Time
 from astropy.utils import lazyproperty
 import matplotlib.pyplot as plt
+from gammapy.utils.deprecation import deprecated_attribute
 from gammapy.utils.interpolation import interpolation_scale
 from gammapy.utils.time import time_ref_from_dict, time_ref_to_dict
 from .utils import INVALID_INDEX, edges_from_lo_hi
 
 __all__ = ["MapAxes", "MapAxis", "TimeMapAxis", "LabelMapAxis"]
 
+log = logging.getLogger(__name__)
+
 
 def flat_if_equal(array):
     if array.ndim == 2 and np.all(array == array[0]):
         return array[0]
     else:
         return array
 
@@ -61,14 +65,15 @@
     "migra": "Energy / True Energy",
     "fov_lon": "FoV Lon.",
     "fov_lat": "FoV Lat.",
     "time": "Time",
 }
 
 DEFAULT_LABEL_TEMPLATE = "{quantity} [{unit}]"
+UNIT_STRING_FORMAT = "latex_inline"
 
 
 class MapAxis:
     """Class representing an axis of a map.
 
     Provides methods for
     transforming to/from axis and pixel coordinates.  An axis is
@@ -96,17 +101,18 @@
         quantities). 'edges' should be used where map values are
         defined by an integral over coordinate intervals (e.g. a
         counts histogram).
     unit : str
         String specifying the data units.
     """
 
+    append = deprecated_attribute("append", "1.1", alternative="concatenate")
+
     # TODO: Cache an interpolation object?
     def __init__(self, nodes, interp="lin", name="", node_type="edges", unit=""):
-
         if not isinstance(name, str):
             raise TypeError(f"Name must be a string, got: {type(name)!r}")
 
         if len(nodes) != len(np.unique(nodes)):
             raise ValueError("MapAxis: node values must be unique")
 
         if ~(np.all(nodes == np.sort(nodes)) or np.all(nodes[::-1] == np.sort(nodes))):
@@ -371,15 +377,15 @@
         ax : `~matplotlib.pyplot.Axis`
             Formatted plot axis
         """
         ax.set_xscale(self.as_plot_scale)
 
         xlabel = DEFAULT_LABEL_TEMPLATE.format(
             quantity=PLOT_AXIS_LABEL.get(self.name, self.name.capitalize()),
-            unit=ax.xaxis.units,
+            unit=ax.xaxis.units.to_string(UNIT_STRING_FORMAT),
         )
         ax.set_xlabel(xlabel)
         xmin, xmax = self.bounds
         if not xmin == xmax:
             ax.set_xlim(self.bounds)
         return ax
 
@@ -396,15 +402,15 @@
         ax : `~matplotlib.pyplot.Axis`
             Formatted plot axis
         """
         ax.set_yscale(self.as_plot_scale)
 
         ylabel = DEFAULT_LABEL_TEMPLATE.format(
             quantity=PLOT_AXIS_LABEL.get(self.name, self.name.capitalize()),
-            unit=ax.yaxis.units,
+            unit=ax.yaxis.units.to_string(UNIT_STRING_FORMAT),
         )
         ax.set_ylabel(ylabel)
         ax.set_ylim(self.bounds)
         return ax
 
     @property
     def iter_by_edges(self):
@@ -634,29 +640,29 @@
             coordinates.  Default: 'lin'.
         """
         if len(edges) < 2:
             raise ValueError("Edges array must have at least two elements.")
 
         return cls(edges, node_type="edges", **kwargs)
 
-    def append(self, axis):
-        """Append another map axis to this axis
+    def concatenate(self, axis):
+        """Concatenate another `MapAxis` to this `MapAxis` into a new `MapAxis` object.
 
         Name, interp type and node type must agree between the axes. If the node
         type is "edges", the edges must be contiguous and non-overlapping.
 
         Parameters
         ----------
         axis : `MapAxis`
-            Axis to append.
+            Axis to concatenate with.
 
         Returns
         -------
         axis : `MapAxis`
-            Appended axis
+            Concatenation of the two axis.
         """
         if self.node_type != axis.node_type:
             raise ValueError(
                 f"Node type must agree, got {self.node_type} and {axis.node_type}"
             )
 
         if self.name != axis.name:
@@ -718,15 +724,15 @@
         -------
         axis : `MapAxis`
             Merged axis
         """
         ax_stacked = axes[0]
 
         for ax in axes[1:]:
-            ax_stacked = ax_stacked.append(ax)
+            ax_stacked = ax_stacked.concatenate(ax)
 
         return ax_stacked
 
     def pix_to_coord(self, pix):
         """Transform from pixel to axis coordinates.
 
         Parameters
@@ -880,15 +886,16 @@
     def _init_copy(self, **kwargs):
         """Init map axis instance by copying missing init arguments from self."""
         argnames = inspect.getfullargspec(self.__init__).args
         argnames.remove("self")
 
         for arg in argnames:
             value = getattr(self, "_" + arg)
-            kwargs.setdefault(arg, copy.deepcopy(value))
+            if arg not in kwargs:
+                kwargs[arg] = copy.deepcopy(value)
 
         return self.__class__(**kwargs)
 
     def copy(self, **kwargs):
         """Copy `MapAxis` instance and overwrite given attributes.
 
         Parameters
@@ -1298,14 +1305,21 @@
             # background models are stored in reconstructed energy
             hduclass = table.meta.get("HDUCLAS2")
             if hduclass in {"BKG", "RAD_MAX"} and column_prefix == "ENERG":
                 name = "energy"
 
             edges_lo = table[f"{column_prefix}_LO"].quantity[0]
             edges_hi = table[f"{column_prefix}_HI"].quantity[0]
+            # for a single-valued array, it can happen that the value is stored/extracted as a scalar
+            if edges_lo.isscalar:
+                log.warning(
+                    f"'{column_prefix}' axis is stored as a scalar -- converting to 1D array."
+                )
+                edges_lo = edges_lo[np.newaxis]
+                edges_hi = edges_hi[np.newaxis]
 
             if np.allclose(edges_hi, edges_lo):
                 axis = MapAxis.from_nodes(edges_hi, interp=interp, name=name)
             else:
                 edges = edges_from_lo_hi(edges_lo, edges_hi)
                 axis = MapAxis.from_edges(edges, interp=interp, name=name)
         elif format == "gtpsf":
@@ -1985,15 +1999,15 @@
 
                 # TODO: what is good way to check whether it is a given axis type?
                 try:
                     axis = LabelMapAxis.from_table(table, format=format, idx=idx)
                 except (KeyError, TypeError):
                     try:
                         axis = TimeMapAxis.from_table(table, format=format, idx=idx)
-                    except (KeyError, ValueError):
+                    except (KeyError, ValueError, IndexError):
                         axis = MapAxis.from_table(table, format=format, idx=idx)
 
                 axes.append(axis)
         elif format == "gadf-dl3":
             for column_prefix in IRF_DL3_AXES_SPECIFICATION:
                 try:
                     axis = MapAxis.from_table(
@@ -2145,18 +2159,18 @@
         Axis name
     interp : str
         Interpolation method used to transform between axis and pixel
         coordinates.  For now only 'lin' is supported.
     """
 
     node_type = "intervals"
-    time_format = "iso"
 
     def __init__(self, edges_min, edges_max, reference_time, name="time", interp="lin"):
         self._name = name
+        self._time_format = "iso"
 
         edges_min = u.Quantity(edges_min, ndmin=1)
         edges_max = u.Quantity(edges_max, ndmin=1)
 
         if not edges_min.unit.is_equivalent("s"):
             raise ValueError(
                 f"Time edges min must have a valid time unit, got {edges_min.unit}"
@@ -2295,26 +2309,34 @@
 
     @property
     def time_edges(self):
         """Time edges"""
         return self.reference_time + self.edges
 
     @property
+    def time_format(self):
+        return self._time_format
+
+    @time_format.setter
+    def time_format(self, val):
+        if val not in ["iso", "mjd"]:
+            raise ValueError(f"Invalid time_format: {self.time_format}")
+        self._time_format = val
+
+    @property
     def as_plot_xerr(self):
         """Plot x error"""
         xn, xp = self.time_mid - self.time_min, self.time_max - self.time_mid
 
         if self.time_format == "iso":
             x_errn = xn.to_datetime()
             x_errp = xp.to_datetime()
-        elif self.time_format == "mjd":
+        else:
             x_errn = xn.to("day")
             x_errp = xp.to("day")
-        else:
-            raise ValueError(f"Invalid time_format: {self.time_format}")
 
         return x_errn, x_errp
 
     @property
     def as_plot_labels(self):
         """Plot labels"""
         labels = []
@@ -2326,29 +2348,26 @@
         return labels
 
     @property
     def as_plot_edges(self):
         """Plot edges"""
         if self.time_format == "iso":
             edges = self.time_edges.to_datetime()
-        elif self.time_format == "mjd":
-            edges = self.time_edges.mjd * u.day
         else:
-            raise ValueError(f"Invalid time_format: {self.time_format}")
+            edges = self.time_edges.mjd * u.day
 
         return edges
 
     @property
     def as_plot_center(self):
         """Plot center"""
         if self.time_format == "iso":
             center = self.time_mid.datetime
-        elif self.time_format == "mjd":
+        else:
             center = self.time_mid.mjd * u.day
-
         return center
 
     def format_plot_xaxis(self, ax):
         """Format plot axis
 
         Parameters
         ----------
@@ -2366,21 +2385,22 @@
             quantity=PLOT_AXIS_LABEL.get(self.name, self.name.capitalize()),
             unit=self.time_format,
         )
         ax.set_xlabel(xlabel)
 
         if self.time_format == "iso":
             ax.xaxis.set_major_formatter(DateFormatter("%Y-%m-%d %H:%M:%S"))
-            plt.setp(
-                ax.xaxis.get_majorticklabels(),
-                rotation=30,
-                ha="right",
-                rotation_mode="anchor",
-            )
-
+        else:
+            ax.xaxis.set_major_formatter("{x:,.5f}")
+        plt.setp(
+            ax.xaxis.get_majorticklabels(),
+            rotation=30,
+            ha="right",
+            rotation_mode="anchor",
+        )
         return ax
 
     def assert_name(self, required_name):
         """Assert axis name if a specific one is required.
 
         Parameters
         ----------
@@ -2551,15 +2571,16 @@
     def _init_copy(self, **kwargs):
         """Init map axis instance by copying missing init arguments from self."""
         argnames = inspect.getfullargspec(self.__init__).args
         argnames.remove("self")
 
         for arg in argnames:
             value = getattr(self, "_" + arg)
-            kwargs.setdefault(arg, copy.deepcopy(value))
+            if arg not in kwargs:
+                kwargs[arg] = copy.deepcopy(value)
 
         return self.__class__(**kwargs)
 
     def copy(self, **kwargs):
         """Copy `MapAxis` instance and overwrite given attributes.
 
         Parameters
@@ -2626,15 +2647,15 @@
             Array of lower edge times.
         time_max : `~astropy.time.Time`
             Array of lower edge times.
         unit : `~astropy.units.Unit` or str
             The unit to convert the edges to. Default is 'd' (day).
         interp : str
             Interpolation method used to transform between axis and pixel
-            coordinates.  Valid options are 'log', 'lin', and 'sqrt'.
+            coordinates.  Currently, only 'lin' is supported.
         name : str
             Axis name
 
         Returns
         -------
         axis : `TimeMapAxis`
             Time map axis.
@@ -2682,19 +2703,35 @@
             reference_time = time_ref_from_dict(meta=meta)
             name = "time"
             edges_min = table["Hist_Start"][:-1]
             edges_max = table["Hist_Start"][1:]
         elif format == "lightcurve":
             # TODO: is this a good format? It just supports mjd...
             name = "time"
-            scale = table.meta.get("TIMESYS", "utc")
-            time_min = Time(table["time_min"].data, format="mjd", scale=scale)
-            time_max = Time(table["time_max"].data, format="mjd", scale=scale)
-            reference_time = Time("2001-01-01T00:00:00")
-            reference_time.format = "mjd"
+            time_ref_dict = dict(
+                MJDREFF=table.meta.get("MJDREFF", 0),
+                MJDREFI=table.meta.get("MJDREFI", 0),
+                TIMESYS=table.meta.get("TIMESYS", "utc"),
+                TIMEUNIT=table.meta.get("TIMEUNIT", "d"),
+            )
+            reference_time = time_ref_from_dict(time_ref_dict, format="mjd")
+            time_min = reference_time + table["time_min"].data * u.Unit(
+                time_ref_dict["TIMEUNIT"]
+            )
+            time_max = reference_time + table["time_max"].data * u.Unit(
+                time_ref_dict["TIMEUNIT"]
+            )
+
+            if reference_time.mjd == 0:
+                # change to a more recent reference time
+                reference_time = Time(
+                    "2001-01-01T00:00:00", scale=time_ref_dict["TIMESYS"]
+                )
+                reference_time.format = "mjd"
+
             edges_min = (time_min - reference_time).to("s")
             edges_max = (time_max - reference_time).to("s")
         else:
             raise ValueError(f"Not a supported format: {format}")
 
         return cls(
             edges_min=edges_min,
@@ -2727,14 +2764,47 @@
             edges_min=tmin.to("s"),
             edges_max=tmax.to("s"),
             reference_time=gti.time_ref,
             name=name,
         )
 
     @classmethod
+    def from_gti_bounds(cls, gti, t_delta, name="time"):
+        """Create a time axis from an input GTI.
+
+        The unit for the axis is taken from the t_delta quantity.
+
+        Parameters
+        ----------
+        gti : `GTI`
+            GTI table
+        t_delta : `~astropy.units.Quantity`
+            Time binning
+        name : str
+            Axis name
+
+        Returns
+        -------
+        axis : `TimeMapAxis`
+            Time map axis.
+
+        """
+        time_min = gti.time_start[0]
+        time_max = gti.time_stop[-1]
+
+        nbin = int(((time_max - time_min) / t_delta).to(""))
+        return TimeMapAxis.from_time_bounds(
+            time_min=time_min,
+            time_max=time_max,
+            nbin=nbin,
+            name=name,
+            unit=t_delta.unit,
+        )
+
+    @classmethod
     def from_time_bounds(cls, time_min, time_max, nbin, unit="d", name="time"):
         """Create linearly spaced time axis from bounds
 
         Parameters
         ----------
         time_min : `~astropy.time.Time`
             Lower bound
@@ -2795,14 +2865,16 @@
     labels : list of str
         Labels to be used for the axis nodes.
     name : str
         Name of the axis.
 
     """
 
+    append = deprecated_attribute("append", "1.1", alternative="concatenate")
+
     node_type = "label"
 
     def __init__(self, labels, name=""):
         unique_labels = np.unique(labels)
 
         if not len(unique_labels) == len(labels):
             raise ValueError("Node labels must be unique")
@@ -3115,7 +3187,70 @@
         axis : `~LabelMapAxis`
             Sliced axis object.
         """
         return self.__class__(
             labels=self._labels[idx],
             name=self.name,
         )
+
+    @classmethod
+    def from_stack(cls, axes):
+        """Create a label map axis by merging a list of axis.
+
+        Parameter
+        ---------
+        axes : list of `LabelMapAxis`
+            A list of map axis to be merged.
+
+        Returns
+        -------
+        axis : `LabelMapAxis`
+            Merged axis.
+        """
+
+        axis_stacked = axes[0]
+
+        for ax in axes[1:]:
+            axis_stacked = axis_stacked.concatenate(ax)
+
+        return axis_stacked
+
+    def concatenate(self, axis):
+        """Concatenate another `LabelMapAxis` to this `LabelMapAxis` into a new `LabelMapAxis` object.
+
+        Names must agree between the axes. labels must be unique.
+
+        Parameters
+        ----------
+        axis : `LabelMapAxis`
+            Axis to concatenate with.
+
+        Returns
+        -------
+        axis : `LabelMapAxis`
+            Concatenation of the two axis.
+        """
+        if not isinstance(axis, LabelMapAxis):
+            raise TypeError(
+                f"axis must be an instance of LabelMapAxis, got {axis.__class__.__name__} instead."
+            )
+
+        if self.name != axis.name:
+            raise ValueError(f"Names must agree, got {self.name} and {axis.name} ")
+
+        merged_labels = np.append(self.center, axis.center)
+
+        return LabelMapAxis(merged_labels, self.name)
+
+    def squash(self):
+        """Create a new axis object by squashing the axis into one bin.
+
+        The label of the new axis is given as "first-label...last-label".
+
+        Returns
+        -------
+        axis : `~MapAxis`
+            Sliced axis object.
+        """
+        return LabelMapAxis(
+            labels=[self.center[0] + "..." + self.center[-1]], name=self._name
+        )
```

### Comparing `gammapy-1.0rc2/gammapy/maps/coord.py` & `gammapy-1.1rc1/gammapy/maps/coord.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/maps/core.py` & `gammapy-1.1rc1/gammapy/maps/core.py`

 * *Files 4% similar despite different names*

```diff
@@ -4,14 +4,15 @@
 import inspect
 import json
 from collections import OrderedDict
 import numpy as np
 from astropy import units as u
 from astropy.io import fits
 import matplotlib.pyplot as plt
+from gammapy.utils.deprecation import deprecated
 from gammapy.utils.random import InverseCDFSampler, get_random_state
 from gammapy.utils.scripts import make_path
 from gammapy.utils.units import energy_unit_format
 from .axes import MapAxis
 from .coord import MapCoord
 from .geom import pix_tuple_to_idx
 from .io import JsonQuantityDecoder
@@ -58,15 +59,16 @@
         """Init map instance by copying missing init arguments from self."""
         argnames = inspect.getfullargspec(self.__init__).args
         argnames.remove("self")
         argnames.remove("dtype")
 
         for arg in argnames:
             value = getattr(self, "_" + arg)
-            kwargs.setdefault(arg, copy.deepcopy(value))
+            if arg not in kwargs:
+                kwargs[arg] = copy.deepcopy(value)
 
         return self.from_geom(**kwargs)
 
     @property
     def is_mask(self):
         """Whether map is mask with bool dtype"""
         return self.data.dtype == bool
@@ -992,16 +994,16 @@
         """
         coords = geom.get_coord()
         map_copy = self.copy()
 
         if preserve_counts:
             if geom.ndim > 2 and geom.axes[0] != self.geom.axes[0]:
                 raise ValueError(
-                    f"Energy axis do not match: expected {self.geom.axes[0]},"
-                    " but got {geom.axes[0]}."
+                    f"Energy axes do not match, expected: \n {self.geom.axes[0]},"
+                    f" but got: \n {geom.axes[0]}."
                 )
             map_copy.data /= map_copy.geom.solid_angle().to_value("deg2")
 
         if map_copy.is_mask:
             # TODO: check this NaN handling is needed
             data = map_copy.get_by_coord(coords)
             data = np.nan_to_num(data, nan=fill_value).astype(bool)
@@ -1082,17 +1084,26 @@
                         factor=factor,
                         preserve_counts=preserve_counts,
                         axis_name=base_ax.name,
                     )
             output_map = output_map.resample(geom, preserve_counts=preserve_counts)
         return output_map
 
-    def fill_events(self, events):
-        """Fill event coordinates (`~gammapy.data.EventList`)."""
-        self.fill_by_coord(events.map_coord(self.geom))
+    def fill_events(self, events, weights=None):
+        """Fill event coordinates (`~gammapy.data.EventList`).
+
+        Parameters
+        ----------
+        events : `~gammapy.data.EventList`
+            Events to be fill in the map.
+        weights : `~numpy.ndarray`
+            Weights vector. Default is weight of one. The weights vector must be of the same length
+            as the events column length.
+        """
+        self.fill_by_coord(events.map_coord(self.geom), weights=weights)
 
     def fill_by_coord(self, coords, weights=None):
         """Fill pixels at ``coords`` with given ``weights``.
 
         Parameters
         ----------
         coords : tuple or `~gammapy.maps.MapCoord`
@@ -1190,15 +1201,15 @@
         Parameters
         ----------
         figsize : tuple of int
             Figsize to plot on
         ncols : int
             Number of columns to plot
         **kwargs : dict
-            Keyword arguments passed to `Map.plot`.
+            Keyword arguments passed to `WcsNDMap.plot`.
 
         Returns
         -------
         axes : `~numpy.ndarray` of `~matplotlib.pyplot.Axes`
             Axes grid
         """
         if len(self.geom.axes) > 1:
@@ -1378,14 +1389,15 @@
                     "Can't copy and change data size of the map. "
                     f" Current shape {self.geom.data_shape},"
                     f" requested shape {geom.data_shape}"
                 )
 
         return self._init_copy(**kwargs)
 
+    @deprecated("v1.1", alternative="gammapy.datasets.apply_edisp")
     def apply_edisp(self, edisp):
         """Apply energy dispersion to map. Requires energy axis.
 
         Parameters
         ----------
         edisp : `gammapy.irf.EDispKernel`
             Energy dispersion matrix
@@ -1403,15 +1415,15 @@
             data = np.rollaxis(data, -1, loc)
             energy_axis = edisp.axes["energy"].copy(name="energy")
         else:
             data = self.data
             energy_axis = self.geom.axes["energy_true"].copy(name="energy")
 
         geom = self.geom.to_image().to_cube(axes=[energy_axis])
-        return self._init_copy(geom=geom, data=data)
+        return self.__class__(geom=geom, data=data, unit=self.unit)
 
     def mask_nearest_position(self, position):
         """Given a sky coordinate return nearest valid position in the mask
 
         If the mask contains additional axes, the mask is reduced over those.
 
         Parameters
@@ -1903,7 +1915,116 @@
         coords_pix = sampler.sample(n_events)
         coords = self.geom.pix_to_coord(coords_pix[::-1])
 
         # TODO: pix_to_coord should return a MapCoord object
         cdict = OrderedDict(zip(self.geom.axes_names, coords))
 
         return MapCoord.create(cdict, frame=self.geom.frame)
+
+    def reorder_axes(self, axes_names):
+        """Return a new map re-ordering the non-spatial axes order.
+
+        Parameters
+        ----------
+        axes_names : list of str
+            the list of axes names in the required order
+
+        Returns
+        -------
+        map : `~gammapy.maps.Map`
+            the map with axes re-ordered
+        """
+        old_axes = self.geom.axes
+        if not set(old_axes.names) == set(axes_names):
+            raise ValueError(f"{old_axes.names} is not compatible with {axes_names}")
+
+        new_axes = [old_axes[_] for _ in axes_names]
+        new_geom = self.geom.to_image().to_cube(new_axes)
+
+        old_indices = [old_axes.index_data(ax) for ax in axes_names]
+        new_indices = [new_geom.axes.index_data(ax) for ax in axes_names]
+
+        data = np.moveaxis(self.data, old_indices, new_indices)
+
+        return Map.from_geom(new_geom, data=data)
+
+    def dot(self, other):
+        """Apply dot product with the input map.
+
+        The input Map has to share a single MapAxis with the current Map.
+        Because it has no spatial dimension, it must be a `~gammapy.maps.RegionNDMap`.
+
+        Parameters
+        ----------
+        other : `~gammapy.maps.RegionNDMap`
+            Map to apply the dot product to.
+            It must share a unique non-spatial MapAxis with the current Map.
+
+        Returns
+        -------
+        map : `~gammapy.maps.Map`
+            Map with dot product applied.
+        """
+        from .region import RegionNDMap
+
+        if not isinstance(other, RegionNDMap):
+            raise TypeError(
+                f"Dot product can be applied to a RegionNDMap. Got {type(other)} instead."
+            )
+
+        common_names = list(
+            set(other.geom.axes.names).intersection(self.geom.axes.names)
+        )
+
+        if len(common_names) == 0:
+            raise ValueError(
+                "Map geometries have no axis in common. Cannot apply dot product."
+            )
+        elif len(common_names) > 1:
+            raise ValueError(
+                f"Map geometries have more than one axis in common: {common_names}."
+                "Cannot apply dot product."
+            )
+
+        axis_name = common_names[0]
+
+        if self.geom.axes[axis_name] != other.geom.axes[axis_name]:
+            raise ValueError(
+                f"Axes {axis_name} are not equal. Cannot apply dot product."
+            )
+
+        loc = self.geom.axes.index_data(axis_name)
+        other_loc = other.geom.axes.index_data(axis_name)
+
+        # move axes because numpy dot product is performed on last axis of a and second-to-last axis of b
+        data = np.moveaxis(self.data, loc, -1)
+
+        if len(other.geom.axes) > 1:
+            other_data = np.moveaxis(other.data[..., 0, 0], other_loc, -2)
+        else:
+            other_data = other.data[..., 0, 0]
+
+        data = np.dot(data, other_data)
+
+        # prepare new axes with expected shape (i.e. common axis replaced by other's axes)
+        index = self.geom.axes.index(axis_name)
+        axes1 = self.geom.axes.drop(axis_name)
+        inserted_axes = other.geom.axes.drop(axis_name)
+        new_axes = axes1[:index] + inserted_axes + axes1[index:]
+
+        # reorder axes to get the expected shape
+        remaining_axes = np.arange(len(inserted_axes))
+        old_axes_pos = -1 - remaining_axes
+        new_axes_pos = loc + remaining_axes[::-1]
+
+        data = np.moveaxis(data, old_axes_pos, new_axes_pos)
+
+        geom = self.geom.to_image().to_cube(new_axes)
+        return self._init_copy(geom=geom, data=data)
+
+    def __matmul__(self, other):
+        """Apply dot product with the input map.
+
+        The input Map has to share a single MapAxis with the current Map.
+        Because it has no spatial dimension, it must be a `~gammapy.maps.RegionNDMap`.
+        """
+        return self.dot(other)
```

### Comparing `gammapy-1.0rc2/gammapy/maps/hpx/core.py` & `gammapy-1.1rc1/gammapy/maps/hpx/core.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/maps/hpx/geom.py` & `gammapy-1.1rc1/gammapy/maps/hpx/geom.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/maps/hpx/io.py` & `gammapy-1.1rc1/gammapy/maps/hpx/io.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/maps/hpx/ndmap.py` & `gammapy-1.1rc1/gammapy/maps/hpx/ndmap.py`

 * *Files 1% similar despite different names*

```diff
@@ -494,28 +494,26 @@
             img = img.astype(float)
 
             if self.geom.nest:
                 # reorder to ring to do the smoothing
                 img = hp.pixelfunc.reorder(img, n2r=True)
 
             if kernel == "gauss":
-                data = hp.sphtfunc.smoothing(
-                    img, sigma=width, pol=False, verbose=False, lmax=lmax
-                )
+                data = hp.sphtfunc.smoothing(img, sigma=width, pol=False, lmax=lmax)
             elif kernel == "disk":
                 # create the step function in angular space
                 theta = np.linspace(0, width)
                 beam = np.ones(len(theta))
                 beam[theta > width] = 0
                 # convert to the spherical harmonics space
                 window_beam = hp.sphtfunc.beam2bl(beam, theta, lmax)
                 # normalize the window beam
                 window_beam = window_beam / window_beam.max()
                 data = hp.sphtfunc.smoothing(
-                    img, beam_window=window_beam, pol=False, verbose=False, lmax=lmax
+                    img, beam_window=window_beam, pol=False, lmax=lmax
                 )
             else:
                 raise ValueError(f"Invalid kernel: {kernel!r}")
 
             if self.geom.nest:
                 # reorder back to nest after the smoothing
                 data = hp.pixelfunc.reorder(data, r2n=True)
@@ -700,15 +698,15 @@
                 img = hp.pixelfunc.reorder(img, n2r=True)
             radial_profile = np.reshape(values[:, idx], (values.shape[0],))
             window_beam = hp.sphtfunc.beam2bl(
                 np.flip(radial_profile), np.flip(angles), lmax
             )
             window_beam = window_beam / window_beam.max()
             data = hp.sphtfunc.smoothing(
-                img, beam_window=window_beam, pol=False, verbose=False, lmax=lmax
+                img, beam_window=window_beam, pol=False, lmax=lmax
             )
             if nest:
                 # reorder back to nest after the convolution
                 data = hp.pixelfunc.reorder(data, r2n=True)
 
             convolved_data[idx] = data[ipix]
         return self._init_copy(data=convolved_data)
@@ -1005,20 +1003,20 @@
 
                 idx0 = np.argsort(pix0[0])
                 idx1 = np.argsort(pix1[0])
 
                 pix0 = (pix0[0][idx0][:3], pix0[1][idx0][:3])
                 pix1 = (pix1[0][idx1][1:], pix1[1][idx1][1:])
 
-                patches.append(Polygon(np.vstack((pix0[0], pix0[1])).T, True))
-                patches.append(Polygon(np.vstack((pix1[0], pix1[1])).T, True))
+                patches.append(Polygon(np.vstack((pix0[0], pix0[1])).T, closed=True))
+                patches.append(Polygon(np.vstack((pix1[0], pix1[1])).T, closed=True))
                 data.append(self.data[i])
                 data.append(self.data[i])
             else:
-                polygon = Polygon(np.vstack((idx[0], idx[1])).T, True)
+                polygon = Polygon(np.vstack((idx[0], idx[1])).T, closed=True)
                 patches.append(polygon)
                 data.append(self.data[i])
 
         p = PatchCollection(patches, linewidths=0, edgecolors="None")
         p.set_array(np.array(data))
         ax.add_collection(p)
         ax.autoscale_view()
```

### Comparing `gammapy-1.0rc2/gammapy/maps/hpx/tests/test_geom.py` & `gammapy-1.1rc1/gammapy/maps/hpx/tests/test_geom.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/maps/hpx/tests/test_ndmap.py` & `gammapy-1.1rc1/gammapy/maps/hpx/tests/test_ndmap.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/maps/hpx/utils.py` & `gammapy-1.1rc1/gammapy/maps/hpx/utils.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/maps/io.py` & `gammapy-1.1rc1/gammapy/maps/io.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/maps/maps.py` & `gammapy-1.1rc1/gammapy/maps/maps.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/maps/region/geom.py` & `gammapy-1.1rc1/gammapy/maps/region/geom.py`

 * *Files 2% similar despite different names*

```diff
@@ -395,15 +395,14 @@
             width = self.width
         wcs_geom_region = WcsGeom(wcs=self.wcs, npix=self.wcs.array_shape)
         wcs_geom = wcs_geom_region.cutout(position=self.center_skydir, width=width)
         wcs_geom = wcs_geom.to_cube(self.axes)
         return wcs_geom
 
     def to_binsz_wcs(self, binsz):
-
         """Change the bin size of the underlying WCS geometry.
 
         Parameters
         ----------
         binzs : float, string or `~astropy.quantity.Quantity`
 
         Returns
@@ -458,47 +457,47 @@
 
         Returns
         -------
         region : `~RegionGeom`
             RegionGeom with the added axes.
         """
         axes = copy.deepcopy(self.axes) + axes
-        return self._init_copy(axes=axes)
+        return self._init_copy(region=self.region, wcs=self.wcs, axes=axes)
 
     def to_image(self):
         """Remove non-spatial axes to create a 2D region.
 
         Returns
         -------
         region : `~RegionGeom`
             RegionGeom without any non-spatial axes.
         """
-        return self._init_copy(axes=None)
+        return self._init_copy(region=self.region, wcs=self.wcs, axes=None)
 
     def upsample(self, factor, axis_name=None):
         """Upsample a non-spatial dimension of the region by a given factor.
 
         Returns
         -------
         region : `~RegionGeom`
             RegionGeom with the upsampled axis.
         """
         axes = self.axes.upsample(factor=factor, axis_name=axis_name)
-        return self._init_copy(axes=axes)
+        return self._init_copy(region=self.region, wcs=self.wcs, axes=axes)
 
     def downsample(self, factor, axis_name):
         """Downsample a non-spatial dimension of the region by a given factor.
 
         Returns
         -------
         region : `~RegionGeom`
             RegionGeom with the downsampled axis.
         """
         axes = self.axes.downsample(factor=factor, axis_name=axis_name)
-        return self._init_copy(axes=axes)
+        return self._init_copy(region=self.region, wcs=self.wcs, axes=axes)
 
     def pix_to_coord(self, pix):
         lon = np.where(
             (-0.5 < pix[0]) & (pix[0] < 0.5),
             self.center_skydir.data.lon,
             np.nan * u.deg,
         )
```

### Comparing `gammapy-1.0rc2/gammapy/maps/region/ndmap.py` & `gammapy-1.1rc1/gammapy/maps/region/ndmap.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,16 +1,17 @@
 from itertools import product
 import numpy as np
-from scipy.ndimage.measurements import label as ndi_label
+from scipy.ndimage import label as ndi_label
 from astropy import units as u
 from astropy.io import fits
 from astropy.nddata import block_reduce
 from astropy.table import Table
 from astropy.visualization import quantity_support
 import matplotlib.pyplot as plt
+from gammapy.maps.axes import UNIT_STRING_FORMAT
 from gammapy.utils.interpolation import ScaledRegularGridInterpolator, StatProfileScale
 from gammapy.utils.scripts import make_path
 from ..axes import MapAxes
 from ..core import Map
 from ..geom import pix_tuple_to_idx
 from ..region import RegionGeom
 from ..utils import INVALID_INDEX
@@ -114,15 +115,14 @@
                     x=axis.as_plot_center,
                     y=quantity,
                     yerr=yerr,
                     uplims=uplims,
                     label=label,
                     **kwargs,
                 )
-
         axis.format_plot_xaxis(ax=ax)
 
         if "energy" in axis_name:
             ax.set_yscale("log", nonpositive="clip")
 
         if len(self.geom.axes) > 1:
             plt.legend()
@@ -159,15 +159,15 @@
         with quantity_support():
             weights = self.data[:, 0, 0]
             ax.hist(
                 axis.as_plot_center, bins=axis.as_plot_edges, weights=weights, **kwargs
             )
 
         if not self.unit.is_unity():
-            ax.set_ylabel(f"Data [{self.unit}]")
+            ax.set_ylabel(f"Data [{self.unit.to_string(UNIT_STRING_FORMAT)}]")
 
         axis.format_plot_xaxis(ax=ax)
         ax.set_yscale("log")
         return ax
 
     def plot_interactive(self):
         raise NotImplementedError(
```

### Comparing `gammapy-1.0rc2/gammapy/maps/region/tests/test_geom.py` & `gammapy-1.1rc1/gammapy/maps/region/tests/test_geom.py`

 * *Files 2% similar despite different names*

```diff
@@ -386,15 +386,16 @@
     assert_allclose(area.value, geom.solid_angle().value, rtol=1e-3)
     assert region_coord.shape == weights.shape
 
 
 def test_region_nd_map_plot(region):
     geom = RegionGeom(region)
 
-    ax = plt.subplot(projection=geom.wcs)
+    fig = plt.figure()
+    ax = fig.add_subplot(projection=geom.wcs)
     with mpl_plot_check():
         geom.plot_region(ax=ax)
 
 
 def test_region_geom_to_from_hdu(region):
     axis1 = MapAxis.from_edges([1, 10] * u.TeV, name="energy", interp="log")
     geom = RegionGeom.create(region, axes=[axis1])
```

### Comparing `gammapy-1.0rc2/gammapy/maps/region/tests/test_ndmap.py` & `gammapy-1.1rc1/gammapy/maps/region/tests/test_ndmap.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,14 +12,15 @@
     LabelMapAxis,
     Map,
     MapAxis,
     RegionGeom,
     RegionNDMap,
     TimeMapAxis,
 )
+from gammapy.utils.deprecation import GammapyDeprecationWarning
 from gammapy.utils.testing import mpl_plot_check, requires_data
 
 
 @pytest.fixture
 def region_map():
     axis = MapAxis.from_energy_bounds("1 TeV", "10 TeV", nbin=6, name="energy")
     m = Map.create(
@@ -54,27 +55,14 @@
         axes=[axis],
         unit="1/TeV",
     )
     m.data = np.arange(m.data.size, dtype=float).reshape(m.geom.data_shape)
     return m
 
 
-@pytest.fixture
-def region_map_true():
-    axis = MapAxis.from_energy_bounds("1 TeV", "10 TeV", nbin=6, name="energy_true")
-    m = Map.create(
-        region="icrs;circle(83.63, 21.51, 1)",
-        map_type="region",
-        axes=[axis],
-        unit="1/TeV",
-    )
-    m.data = np.arange(m.data.size, dtype=float).reshape(m.geom.data_shape)
-    return m
-
-
 def test_region_nd_map(region_map):
     assert_allclose(region_map.data.sum(), 15)
     assert region_map.geom.frame == "icrs"
     assert region_map.unit == "TeV-1"
     assert region_map.data.dtype == float
     assert "RegionNDMap" in str(region_map)
     assert "1 / TeV" in str(region_map)
@@ -98,15 +86,16 @@
     assert_allclose(region_map_summed_weights.data, 10)
 
 
 def test_region_nd_map_plot(region_map):
     with mpl_plot_check():
         region_map.plot()
 
-    ax = plt.subplot(projection=region_map.geom.wcs)
+    fig = plt.figure()
+    ax = fig.add_subplot(1, 1, 1, projection=region_map.geom.wcs)
     with mpl_plot_check():
         region_map.plot_region(ax=ax)
 
 
 def test_region_nd_map_plot_two_axes():
     energy_axis = MapAxis.from_energy_edges([1, 3, 10] * u.TeV)
 
@@ -171,15 +160,15 @@
     assert_allclose(region_map.sum_over_axes(), 15)
 
     stacked = region_map.copy()
     stacked.stack(region_map)
     assert_allclose(stacked.data.sum(), 30)
 
     stacked = region_map.copy()
-    weights = Map.from_geom(region_map.geom, dtype=np.int)
+    weights = Map.from_geom(region_map.geom, dtype=np.int_)
     stacked.stack(region_map, weights=weights)
     assert_allclose(stacked.data.sum(), 15)
 
 
 def test_stack_different_unit():
     region = "icrs;circle(0, 0, 1)"
     axis = MapAxis.from_energy_bounds("1 TeV", "10 TeV", nbin=3)
@@ -252,42 +241,47 @@
 @requires_data()
 def test_region_nd_map_fill_events(region_map):
     filename = "$GAMMAPY_DATA/hess-dl3-dr1/data/hess_dl3_dr1_obs_id_023523.fits.gz"
     events = EventList.read(filename)
     region_map = Map.from_geom(region_map.geom)
     region_map.fill_events(events)
 
+    weights = np.linspace(0, 1, len(events.time))
+    region_map2 = Map.from_geom(region_map.geom)
+    region_map2.fill_events(events, weights=weights)
+
     assert_allclose(region_map.data.sum(), 665)
+    assert_allclose(region_map2.data.sum(), 328.33487)
 
 
 @requires_data()
 def test_region_nd_map_fill_events_point_sky_region(point_region_map):
     filename = "$GAMMAPY_DATA/hess-dl3-dr1/data/hess_dl3_dr1_obs_id_023523.fits.gz"
     events = EventList.read(filename).select_offset([70.0, 71] * u.deg)
     region_map = Map.from_geom(point_region_map.geom)
     region_map.fill_events(events)
 
     assert_allclose(region_map.data.sum(), 0)
 
+    weights = np.linspace(0, 1, len(events.time))
+    region_map = Map.from_geom(point_region_map.geom)
+    region_map.fill_events(events, weights=weights)
+    assert_allclose(region_map.data.sum(), 0)
 
-def test_apply_edisp(region_map_true):
-    e_true = region_map_true.geom.axes[0]
-    e_reco = MapAxis.from_energy_bounds("1 TeV", "10 TeV", nbin=3)
+
+def test_apply_edisp(point_region_map):
+    e_true = MapAxis.from_energy_bounds("1 TeV", "10 TeV", nbin=3, name="energy_true")
+    e_reco = point_region_map.geom.axes[0]
 
     edisp = EDispKernel.from_diagonal_response(
         energy_axis_true=e_true, energy_axis=e_reco
     )
 
-    m = region_map_true.apply_edisp(edisp)
-    assert m.geom.data_shape == (3, 1, 1)
-
-    e_reco = m.geom.axes[0].edges
-    assert e_reco.unit == "TeV"
-    assert m.geom.axes[0].name == "energy"
-    assert_allclose(e_reco[[0, -1]].value, [1, 10])
+    with pytest.raises(GammapyDeprecationWarning):
+        point_region_map.apply_edisp(edisp)
 
 
 def test_region_nd_map_resample_axis():
     axis_1 = MapAxis.from_edges([1, 2, 3, 4, 5], name="test-1")
     axis_2 = MapAxis.from_edges([1, 2, 3, 4], name="test-2")
 
     geom = RegionGeom.create(
```

### Comparing `gammapy-1.0rc2/gammapy/maps/tests/test_axes.py` & `gammapy-1.1rc1/gammapy/maps/tests/test_axes.py`

 * *Files 4% similar despite different names*

```diff
@@ -384,14 +384,27 @@
 
     assert labels[0] == "0.00e+00 deg"
 
     assert_allclose(axis.center, axis.as_plot_center)
     assert_allclose(axis.edges, axis.as_plot_edges)
 
 
+def test_map_axis_concatenate():
+    axis_1 = MapAxis.from_bounds(0, 10, 10, name="axis")
+    axis_2 = MapAxis.from_bounds(10, 20, 10, name="axis")
+    axis_2_other_name = MapAxis.from_bounds(10, 20, 10, name="other_axis")
+
+    axis_12 = axis_1.concatenate(axis_2)
+
+    assert_equal(axis_12.edges, np.linspace(0, 20, 21))
+
+    with pytest.raises(ValueError):
+        axis_1.concatenate(axis_2_other_name)
+
+
 def test_time_axis(time_intervals):
     axis = TimeMapAxis(
         time_intervals["t_min"], time_intervals["t_max"], time_intervals["t_ref"]
     )
 
     axis_copy = axis.copy()
 
@@ -558,26 +571,70 @@
 
     axis = TimeMapAxis.from_table(table, format="gadf")
 
     assert axis.nbin == 10
     assert_allclose(axis.time_mid[0].mjd, 53778.25)
 
 
+def test_from_table_time_axis_lightcurve_format():
+    t0 = Time("2006-02-12", scale="tt")
+    t_min = np.linspace(0, 10, 10) * u.d
+    t_max = t_min + 12 * u.h
+
+    table = Table()
+    table["time_min"] = t_min.to_value("h")
+    table["time_max"] = t_max.to_value("h")
+    table.meta.update(time_ref_to_dict(t0))
+    table.meta["TIMEUNIT"] = "h"
+
+    axis = TimeMapAxis.from_table(table, format="lightcurve")
+
+    assert axis.nbin == 10
+    assert_allclose(axis.time_mid[0].mjd, 53778.25)
+    assert axis.time_mid.scale == "tt"
+    t0.format = "mjd"
+    assert_time_allclose(axis.reference_time, t0)
+
+
 @requires_data()
 def test_from_gti_time_axis():
     filename = "$GAMMAPY_DATA/hess-dl3-dr1/data/hess_dl3_dr1_obs_id_020136.fits.gz"
     filename = make_path(filename)
     gti = GTI.read(filename)
 
     axis = TimeMapAxis.from_gti(gti)
     expected = Time(53090.123451203704, format="mjd", scale="tt")
     assert_time_allclose(axis.time_min[0], expected)
     assert axis.nbin == 1
 
 
+def test_from_gti_bounds():
+    start = u.Quantity([1, 2], "min")
+    stop = u.Quantity([1.5, 2.5], "min")
+    time_ref = Time("2010-01-01 00:00:00.0")
+
+    gti = GTI.create(start, stop, time_ref)
+
+    axis = TimeMapAxis.from_gti_bounds(
+        gti=gti,
+        t_delta=10 * u.s,
+    )
+
+    assert axis.nbin == 8
+    expected = Time("2010-01-01 00:01:00.0")
+    # GTI.create() changes the reference time format
+    expected.format = "mjd"
+
+    assert_time_allclose(axis.time_min[0], expected)
+
+    expected = Time("2010-01-01 00:02:30.0")
+    expected.format = "mjd"
+    assert_time_allclose(axis.time_max[-1], expected)
+
+
 def test_map_with_time_axis(time_intervals):
     time_axis = TimeMapAxis(
         time_intervals["t_min"], time_intervals["t_max"], time_intervals["t_ref"]
     )
     energy_axis = MapAxis.from_energy_bounds(0.1, 10, 2, unit="TeV")
     region_map = RegionNDMap.create(
         region="fk5; circle(0,0,0.1)", axes=[energy_axis, time_axis]
@@ -735,25 +792,91 @@
 
     with mpl_plot_check():
         ax = plt.gca()
         with quantity_support():
             ax.plot(axis.center, np.ones_like(axis.center))
 
     ax1 = axis.format_plot_xaxis(ax=ax)
-    assert ax1.xaxis.label.properties()["text"] == "True Energy [TeV]"
+    assert ax1.xaxis.units == u.Unit("TeV")
+    assert " ".join(ax1.axes.axes.get_xlabel().split()[:2]) == "True Energy"
+
+
+def test_time_format(time_intervals):
+    axis = TimeMapAxis(
+        time_intervals["t_min"],
+        time_intervals["t_max"],
+        time_intervals["t_ref"],
+        name="time",
+    )
+    with pytest.raises(ValueError):
+        axis.time_format = "null"
 
 
 def test_time_map_axis_format_plot_xaxis(time_intervals):
     axis = TimeMapAxis(
         time_intervals["t_min"],
         time_intervals["t_max"],
         time_intervals["t_ref"],
         name="time",
     )
 
     with mpl_plot_check():
         ax = plt.gca()
         with quantity_support():
-            ax.plot(axis.center, np.ones_like(axis.center))
+            ax.plot(axis.as_plot_center, np.ones_like(axis.center))
 
     ax1 = axis.format_plot_xaxis(ax=ax)
-    assert ax1.xaxis.label.properties()["text"] == "Time [iso]"
+    assert ax1.axes.axes.get_xlabel().split()[0] == "Time"
+    assert ax1.axes.axes.get_xlabel().split()[1] == "[iso]"
+
+    axis.time_format = "mjd"
+    with mpl_plot_check():
+        ax = plt.gca()
+        with quantity_support():
+            ax.plot(axis.as_plot_center, np.ones_like(axis.center))
+    ax2 = axis.format_plot_xaxis(ax=ax)
+    assert ax2.axes.axes.get_xlabel().split()[1] == "[mjd]"
+
+
+def test_single_valued_axis():
+    # this will be interpreted as a scalar value
+    # that is against the specifications, but we allow it nevertheless
+    theta_values = np.array([0.5]) * u.deg
+    table = Table(data=[theta_values, theta_values], names=["THETA_LO", "THETA_HI"])
+    _ = MapAxis.from_table(table, format="gadf-dl3", column_prefix="THETA")
+
+    # this is a proper array-like axis with just a single value
+    theta_values = np.array([[0.5]]) * u.deg
+    table = Table(data=[theta_values, theta_values], names=["THETA_LO", "THETA_HI"])
+    _ = MapAxis.from_table(table, format="gadf-dl3", column_prefix="THETA")
+
+
+def test_label_map_axis_concatenate():
+    label1 = LabelMapAxis(["aa", "bb"], name="letters")
+    label2 = LabelMapAxis(["cc", "dd"], name="letters")
+    label3 = LabelMapAxis(["ee", "ff"], name="other_letters")
+
+    label_append12 = label1.concatenate(label2)
+
+    assert_equal(label_append12.center, np.array(["aa", "bb", "cc", "dd"], dtype="<U2"))
+    assert label_append12.name == "letters"
+    with pytest.raises(ValueError):
+        label2.concatenate(label3)
+
+
+def test_label_map_axis_from_stack():
+    label1 = LabelMapAxis(["a", "b", "c"], name="letters")
+    label2 = LabelMapAxis(["d", "e"], name="letters")
+    label3 = LabelMapAxis(["f"], name="letters")
+
+    label_stack = LabelMapAxis.from_stack([label1, label2, label3])
+
+    assert_equal(label_stack.center, np.array(["a", "b", "c", "d", "e", "f"]))
+    assert label_stack.name == "letters"
+
+
+def test_label_map_axis_squash():
+    label = LabelMapAxis(["a", "b", "c"], name="Letters")
+    squash_label = label.squash()
+
+    assert squash_label.nbin == 1
+    assert_equal(squash_label.center, np.array(["a...c"]))
```

### Comparing `gammapy-1.0rc2/gammapy/maps/tests/test_coord.py` & `gammapy-1.1rc1/gammapy/maps/tests/test_coord.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/maps/tests/test_core.py` & `gammapy-1.1rc1/gammapy/maps/tests/test_core.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,16 +1,25 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import pytest
 import numpy as np
 from numpy.testing import assert_allclose, assert_equal
 import astropy.units as u
 from astropy.coordinates import SkyCoord
 from astropy.units import Quantity, Unit
-from gammapy.maps import HpxGeom, HpxNDMap, Map, MapAxis, TimeMapAxis, WcsGeom, WcsNDMap
-from gammapy.utils.testing import mpl_plot_check
+from gammapy.maps import (
+    HpxGeom,
+    HpxNDMap,
+    Map,
+    MapAxis,
+    RegionNDMap,
+    TimeMapAxis,
+    WcsGeom,
+    WcsNDMap,
+)
+from gammapy.utils.testing import modify_unit_order_astropy_5_3, mpl_plot_check
 
 pytest.importorskip("healpy")
 
 map_axes = [
     MapAxis.from_bounds(1.0, 10.0, 3, interp="log", name="energy"),
     MapAxis.from_bounds(0.1, 1.0, 4, interp="log", name="time"),
 ]
@@ -231,15 +240,15 @@
     # as well as the behaviour for the property get and set.
 
     m = Map.create(npix=(2, 1))
 
     assert isinstance(m.unit, u.CompositeUnit)
     assert m._unit == u.one
     m._unit = u.Unit("cm-2 s-1")
-    assert m.unit.to_string() == "1 / (cm2 s)"
+    assert m.unit.to_string() == modify_unit_order_astropy_5_3("1 / (cm2 s)")
 
     assert isinstance(m.meta, dict)
     m.meta = {"spam": 42}
     assert isinstance(m.meta, dict)
 
     # The rest of the tests are for the `data` property
 
@@ -272,15 +281,14 @@
 
 
 map_arithmetics_args = [("wcs"), ("hpx")]
 
 
 @pytest.mark.parametrize(("map_type"), map_arithmetics_args)
 def test_map_arithmetics(map_type):
-
     m1 = Map.create(binsz=0.1, width=1.0, map_type=map_type, skydir=(0, 0), unit="m2")
 
     m2 = Map.create(binsz=0.1, width=1.0, map_type=map_type, skydir=(0, 0), unit="m2")
     m2.data += 1.0
 
     # addition
     m1 += 1 * u.cm**2
@@ -804,7 +812,108 @@
     geom = m_4d.geom.rename_axes("energy", "energy_true")
     assert m_4d.geom.axes.names == ["energy", "time"]
     assert geom.axes.names == ["energy_true", "time"]
 
     new_map = m_4d.rename_axes("energy", "energy_true")
     assert m_4d.geom.axes.names == ["energy", "time"]
     assert new_map.geom.axes.names == ["energy_true", "time"]
+
+
+def test_reorder_axes_fail():
+    axis1 = MapAxis.from_edges((0, 1, 3), name="axis1")
+    axis2 = MapAxis.from_edges((0, 1, 2, 3, 4), name="axis2")
+
+    some_map = RegionNDMap.create(region=None, axes=[axis1, axis2])
+
+    with pytest.raises(ValueError):
+        some_map.reorder_axes(["axis3", "axis1"])
+
+    with pytest.raises(ValueError):
+        some_map.reorder_axes("axis3")
+
+
+def test_reorder_axes():
+    axis1 = MapAxis.from_edges((0, 1, 3), name="axis1")
+    axis2 = MapAxis.from_edges((0, 1, 2, 3, 4), name="axis2")
+    axis3 = MapAxis.from_edges((0, 1, 2, 3), name="axis3")
+
+    some_map = RegionNDMap.create(region=None, axes=[axis1, axis2, axis3])
+
+    some_map.data[:, 1, :] = 1
+
+    new_map = some_map.reorder_axes(["axis2", "axis1", "axis3"])
+
+    assert new_map.geom.axes.names == ["axis2", "axis1", "axis3"]
+    assert new_map.geom.data_shape == (3, 2, 4, 1, 1)
+
+    assert_allclose(new_map.data[:, :, 1], 1)
+
+
+def test_map_dot_product_fail():
+    axis1 = MapAxis.from_edges((0, 1, 2, 3), name="axis1")
+    axis2 = MapAxis.from_edges((0, 1, 2, 3, 4), name="axis2")
+    axis3 = MapAxis.from_edges((0, 1, 2), name="axis1")
+
+    map1 = WcsNDMap.create(npix=5, axes=[axis1])
+    map2 = RegionNDMap.create(region=None, axes=[axis2, axis3])
+    map3 = RegionNDMap.create(region=None, axes=[axis2, axis3])
+
+    with pytest.raises(TypeError):
+        map1.dot(map1)
+
+    with pytest.raises(ValueError):
+        map1.dot(map2)
+
+    with pytest.raises(ValueError):
+        map1.dot(map3)
+
+
+def test_map_dot_product():
+    axis1 = MapAxis.from_edges((0, 1, 3), name="axis1")
+    axis2 = MapAxis.from_edges((0, 1, 2, 3, 4), name="axis2")
+
+    map1 = WcsNDMap.create(npix=(5, 6), axes=[axis1])
+    map2 = RegionNDMap.create(region=None, axes=[axis1, axis2])
+
+    map1.data[0, ...] = 1
+    map1.data[1, ...] = 2
+    map2.data[0, 0, ...] = 1
+    map2.data[1, 1, ...] = 2
+
+    dot_map = map1 @ map2
+
+    assert dot_map.geom.axes.names == ["axis2"]
+    assert_allclose(dot_map.data[:, 0, 0], [1, 4, 0, 0])
+
+    map3 = RegionNDMap.create(region=None, axes=[axis1])
+    map3.data[1, 0, 0] = 1
+
+    dot_map = map1.dot(map3)
+    assert dot_map.geom.axes.names == []
+    assert_allclose(dot_map.data[0, 0], 2)
+
+    axis3 = MapAxis.from_edges((0, 1, 2, 3), name="axis3")
+    axis4 = MapAxis.from_edges((1, 2, 3, 4, 5), name="axis4")
+
+    map4 = RegionNDMap.create(region=None, axes=[axis2, axis3, axis4])
+    map4.data[...] = 1
+
+    dot_map = map4.dot(map2)
+
+    assert dot_map.geom.axes.names == ["axis1", "axis3", "axis4"]
+    assert dot_map.data.shape == (4, 3, 2, 1, 1)
+
+    dot_map = map2.dot(map4)
+
+    assert dot_map.geom.axes.names == ["axis1", "axis3", "axis4"]
+    assert dot_map.data.shape == (4, 3, 2, 1, 1)
+    assert_allclose(dot_map.data[0, 0, :, 0, 0], [1, 2])
+
+    map5 = RegionNDMap.create(region=None, axes=[axis3, axis2, axis4])
+    map5.data[:, 0, :, :, :] = 1
+
+    dot_map = map5.dot(map2)
+
+    assert dot_map.geom.axes.names == ["axis3", "axis1", "axis4"]
+    assert dot_map.data.shape == (4, 2, 3, 1, 1)
+
+    assert_allclose(dot_map.data[0, :, 0, 0, 0], [1, 0])
```

### Comparing `gammapy-1.0rc2/gammapy/maps/tests/test_counts.py` & `gammapy-1.1rc1/gammapy/maps/tests/test_counts.py`

 * *Files 16% similar despite different names*

```diff
@@ -29,14 +29,19 @@
     # 3D with energy axis
     axis = MapAxis.from_edges([9, 11, 13], name="energy", unit="TeV")
     m = Map.create(npix=(2, 1), binsz=10, axes=[axis])
     m.fill_events(events)
     assert m.data.sum() == 1
     assert_allclose(m.data[0, 0, 0], 1)
 
+    weights = np.array([0.5, 1])
+    m = Map.create(npix=(2, 1), binsz=10, axes=[axis])
+    m.fill_events(events, weights=weights)
+    assert_allclose(m.data.sum(), 0.5)
+
 
 @requires_dependency("healpy")
 def test_map_fill_events_hpx(events):
     # 2D map
     m = Map.from_geom(HpxGeom(1))
     m.fill_events(events)
     assert m.data[4] == 2
@@ -44,14 +49,19 @@
     # 3D with energy axis
     axis = MapAxis.from_edges([9, 11, 13], name="energy", unit="TeV")
     m = Map.from_geom(HpxGeom(1, axes=[axis]))
     m.fill_events(events)
     assert m.data[0, 4] == 1
     assert m.data[1, 4] == 1
 
+    weights = np.array([0.5, 1])
+    m = Map.from_geom(HpxGeom(1, axes=[axis]))
+    m.fill_events(events, weights=weights)
+    assert_allclose(m.data.sum(), 1.5)
+
 
 def test_map_fill_events_keyerror(events):
     axis = MapAxis([0, 1, 2], name="nokey")
     m = WcsNDMap.create(binsz=0.1, npix=10, axes=[axis])
     with pytest.raises(KeyError):
         m.fill_events(events)
```

### Comparing `gammapy-1.0rc2/gammapy/maps/tests/test_maps.py` & `gammapy-1.1rc1/gammapy/maps/tests/test_maps.py`

 * *Files 0% similar despite different names*

```diff
@@ -80,9 +80,9 @@
     assert len(maps) == 3
     assert maps["map1"].geom == geom
     assert maps["map2"].unit == ""
     assert maps["map3"].data.dtype == np.float32
     assert len(maps_kwargs) == 3
     assert maps_kwargs["map1"].unit == "cm2s"
     assert maps_kwargs["map1"].data.dtype == np.float64
-    assert maps_kwargs["map2"].data.dtype == np.bool
+    assert maps_kwargs["map2"].data.dtype == bool
     assert maps_kwargs["map3"].data[2, 2] == 12
```

### Comparing `gammapy-1.0rc2/gammapy/maps/utils.py` & `gammapy-1.1rc1/gammapy/maps/utils.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/maps/wcs/core.py` & `gammapy-1.1rc1/gammapy/maps/wcs/core.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/maps/wcs/geom.py` & `gammapy-1.1rc1/gammapy/maps/wcs/geom.py`

 * *Files 1% similar despite different names*

```diff
@@ -11,14 +11,15 @@
 from astropy.utils import lazyproperty
 from astropy.wcs import WCS
 from astropy.wcs.utils import (
     celestial_frame_to_wcs,
     proj_plane_pixel_scales,
     wcs_to_celestial_frame,
 )
+from regions import RectangleSkyRegion
 from gammapy.utils.array import round_up_to_even, round_up_to_odd
 from ..axes import MapAxes
 from ..coord import MapCoord, skycoord_to_lonlat
 from ..geom import Geom, get_shape, pix_tuple_to_idx
 from ..utils import INVALID_INDEX, _check_binsz, _check_width
 
 __all__ = ["WcsGeom"]
@@ -31,15 +32,14 @@
 
     param = [np.array(p, ndmin=1, dtype=dtype) for p in param]
 
     if len(param) == 1:
         param = [param[0].copy(), param[0].copy()]
 
     for i, p in enumerate(param):
-
         if p.size > 1 and p.shape != shape:
             raise ValueError
 
         if p.shape == shape:
             continue
 
         param[i] = p * np.ones(shape, dtype=dtype)
@@ -405,18 +405,26 @@
 
         wcs.array_shape = npix[0].flat[0], npix[1].flat[0]
         wcs.wcs.datfix()
         return cls(wcs, npix, cdelt=binsz, axes=axes)
 
     @property
     def footprint(self):
-        """Footprint of the geometry"""
+        """Footprint of the geometry as (`SkyCoord`)"""
         coords = self.wcs.calc_footprint()
         return SkyCoord(coords, frame=self.frame, unit="deg")
 
+    @property
+    def footprint_rectangle_sky_region(self):
+        """Footprint of the geometry as (`RectangleSkyRegion`)"""
+        width, height = self.width
+        return RectangleSkyRegion(
+            center=self.center_skydir, width=width[0], height=height[0]
+        )
+
     @classmethod
     def from_aligned(cls, geom, skydir, width):
         """Create an aligned geometry from an existing one
 
         Parameters
         ----------
         geom : `~WcsGeom`
@@ -490,15 +498,14 @@
         else:
             npix = (header["NAXIS1"], header["NAXIS2"])
             cdelt = None
 
         return cls(wcs, npix, cdelt=cdelt, axes=axes)
 
     def _make_bands_cols(self):
-
         cols = []
         if not self.is_regular:
             cols += [
                 fits.Column(
                     "NPIX",
                     "2I",
                     dim="(2)",
@@ -873,26 +880,25 @@
         cutout : `~gammapy.maps.WcsNDMap`
             Cutout map
         """
         width = _check_width(width) * u.deg
 
         binsz = self.pixel_scales
         width_npix = np.clip((width / binsz).to_value(""), 1, None)
-        width = width_npix * binsz
 
         if odd_npix:
-            width = round_up_to_odd(width_npix)
+            width_npix = round_up_to_odd(width_npix)
 
         dummy_data = np.empty(self.to_image().data_shape, dtype=bool)
         c2d = Cutout2D(
             data=dummy_data,
             wcs=self.wcs,
             position=position,
             # Cutout2D takes size with order (lat, lon)
-            size=width[::-1],
+            size=width_npix[::-1],
             mode=mode,
         )
         return self._init_copy(wcs=c2d.wcs, npix=c2d.shape[::-1])
 
     def boundary_mask(self, width):
         """Create a mask applying binary erosion with a given width from geom edges
```

### Comparing `gammapy-1.0rc2/gammapy/maps/wcs/ndmap.py` & `gammapy-1.1rc1/gammapy/maps/wcs/ndmap.py`

 * *Files 15% similar despite different names*

```diff
@@ -5,21 +5,15 @@
 import scipy.ndimage as ndi
 import scipy.signal
 import astropy.units as u
 from astropy.convolution import Tophat2DKernel
 from astropy.coordinates import SkyCoord
 from astropy.io import fits
 from astropy.nddata import block_reduce
-from regions import (
-    PixCoord,
-    PointPixelRegion,
-    PointSkyRegion,
-    RectangleSkyRegion,
-    SkyRegion,
-)
+from regions import PixCoord, PointPixelRegion, PointSkyRegion, SkyRegion
 import matplotlib.pyplot as plt
 from gammapy.utils.interpolation import ScaledRegularGridInterpolator
 from gammapy.utils.units import unit_from_fits_image_hdu
 from ..geom import pix_tuple_to_idx
 from ..utils import INVALID_INDEX
 from .core import WcsMap
 from .geom import WcsGeom
@@ -122,36 +116,69 @@
 
         return map_out
 
     def get_by_idx(self, idx):
         idx = pix_tuple_to_idx(idx)
         return self.data.T[idx]
 
-    def interp_by_coord(self, coords, method="linear", fill_value=None):
+    def interp_by_coord(
+        self, coords, method="linear", fill_value=None, values_scale="lin"
+    ):
+        """Interpolate map values at the given map coordinates.
+
+        Parameters
+        ----------
+        coords : tuple, dict or `~gammapy.maps.MapCoord`
+            Coordinate arrays for each dimension of the map.  Tuple
+            should be ordered as (lon, lat, x_0, ..., x_n) where x_i
+            are coordinates for non-spatial dimensions of the map.
+            "lon" and "lat" are optional and will be taken at the center
+            of the region by default.
+        method : {"linear", "nearest"}
+            Method to interpolate data values. By default linear
+            interpolation is performed.
+        fill_value : None or float value
+            The value to use for points outside of the interpolation domain.
+            If None, values outside the domain are extrapolated.
+        values_scale : {"lin", "log", "sqrt"}
+            Optional value scaling. Default is "lin".
+
+        Returns
+        -------
+        vals : `~numpy.ndarray`
+            Interpolated pixel values.
+        """
 
         if self.geom.is_regular:
             pix = self.geom.coord_to_pix(coords)
-            return self.interp_by_pix(pix, method=method, fill_value=fill_value)
+            return self.interp_by_pix(
+                pix, method=method, fill_value=fill_value, values_scale=values_scale
+            )
         else:
             return self._interp_by_coord_griddata(coords, method=method)
 
-    def interp_by_pix(self, pix, method="linear", fill_value=None):
+    def interp_by_pix(self, pix, method="linear", fill_value=None, values_scale="lin"):
         if not self.geom.is_regular:
             raise ValueError("interp_by_pix only supported for regular geom.")
 
         grid_pix = [np.arange(n, dtype=float) for n in self.data.shape[::-1]]
 
         if np.any(np.isfinite(self.data)):
             data = self.data.copy().T
             data[~np.isfinite(data)] = 0.0
         else:
             data = self.data.T
 
         fn = ScaledRegularGridInterpolator(
-            grid_pix, data, fill_value=None, bounds_error=False, method=method
+            grid_pix,
+            data,
+            fill_value=None,
+            bounds_error=False,
+            method=method,
+            values_scale=values_scale,
         )
         interp_data = fn(tuple(pix), clip=False)
 
         if fill_value is not None:
             idxs = self.geom.pix_to_idx(pix, clip=False)
             invalid = np.broadcast_arrays(*[idx == -1 for idx in idxs])
             mask = np.any(invalid, axis=0)
@@ -492,14 +519,41 @@
         lat.set_major_formatter("d")
 
         lon.set_ticklabel(color="w", alpha=0.8)
         lon.grid(alpha=0.2, linestyle="solid", color="w")
         lat.grid(alpha=0.2, linestyle="solid", color="w")
         return ax
 
+    def cutout_and_mask_region(self, region=None):
+        """Compute cutout and mask for a given region of the map.
+
+        The function will estimate the minimal size of the cutout, which encloses
+        the region.
+
+        Parameters
+        ----------
+        region: `~regions.Region`
+             Extended region
+
+        Returns
+        -------
+        cutout, mask : tuple of `WcsNDMap`
+            Cutout and mask map
+        """
+        from gammapy.maps import RegionGeom
+
+        if region is None:
+            region = self.geom.footprint_rectangle_sky_region
+
+        geom = RegionGeom.from_regions(regions=region, wcs=self.geom.wcs)
+        cutout = self.cutout(position=geom.center_skydir, width=geom.width)
+
+        mask = cutout.geom.to_image().region_mask([region])
+        return self.__class__(data=cutout.data, geom=cutout.geom, unit=self.unit), mask
+
     def to_region_nd_map(
         self, region=None, func=np.nansum, weights=None, method="nearest"
     ):
         """Get region ND map in a given region.
 
         By default the whole map region is considered.
 
@@ -518,50 +572,137 @@
         Returns
         -------
         spectrum : `~gammapy.maps.RegionNDMap`
             Spectrum in the given region.
         """
         from gammapy.maps import RegionGeom, RegionNDMap
 
-        if isinstance(region, SkyCoord):
-            region = PointSkyRegion(region)
-        elif region is None:
-            width, height = self.geom.width
-            region = RectangleSkyRegion(
-                center=self.geom.center_skydir, width=width[0], height=height[0]
-            )
+        if region is None:
+            region = self.geom.footprint_rectangle_sky_region
 
         if weights is not None:
             if not self.geom == weights.geom:
                 raise ValueError("Incompatible spatial geoms between map and weights")
 
-        geom = RegionGeom(region=region, axes=self.geom.axes, wcs=self.geom.wcs)
+        geom = RegionGeom.from_regions(
+            regions=region, axes=self.geom.axes, wcs=self.geom.wcs
+        )
 
-        if isinstance(region, PointSkyRegion):
+        if geom.is_all_point_sky_regions:
             coords = geom.get_coord()
             data = self.interp_by_coord(coords=coords, method=method)
+
             if weights is not None:
                 data *= weights.interp_by_coord(coords=coords, method=method)
             # Casting needed as interp_by_coord transforms boolean
             data = data.astype(self.data.dtype)
         else:
-            cutout = self.cutout(position=geom.center_skydir, width=geom.width)
+            cutout, mask = self.cutout_and_mask_region(region=region)
 
             if weights is not None:
                 weights_cutout = weights.cutout(
                     position=geom.center_skydir, width=geom.width
                 )
                 cutout.data *= weights_cutout.data
 
-            mask = cutout.geom.to_image().region_mask([region]).data
             idx_y, idx_x = np.where(mask)
             data = func(cutout.data[..., idx_y, idx_x], axis=-1)
 
         return RegionNDMap(geom=geom, data=data, unit=self.unit, meta=self.meta.copy())
 
+    def to_region_nd_map_histogram(
+        self, region=None, bins_axis=None, nbin=100, density=False
+    ):
+        """Convert map into region map by histogramming.
+
+        By default it creates a linearly spaced axis with 100 bins between
+        (-max(abs(data)), max(abs(data))) within the given region.
+
+        Parameters
+        ----------
+        region: `~regions.Region`
+            Region to histogram over.
+        bins_axis : `MapAxis`
+            Binning of the histogram.
+        nbin : int
+            Number of bins to use if no bins_axis is given.
+        density : bool
+            Normalize integral of the histogram to 1.
+
+
+        Examples
+        --------
+        This is how to use the method to create energy dependent histograms:
+
+        ::
+
+            from gammapy.maps import MapAxis, Map
+            import numpy as np
+
+            random_state = np.random.RandomState(seed=0)
+
+            energy_axis = MapAxis.from_energy_bounds("1 TeV", "10 TeV", nbin=3)
+
+            data = Map.create(axes=[energy_axis], width=10, unit="cm2 s-1", binsz=0.02)
+            data.data = random_state.normal(
+                size=data.data.shape, loc=0, scale=np.array([1.0, 2.0, 3.0]).reshape((-1, 1, 1))
+            )
+
+            hist = data.to_region_nd_map_histogram()
+            hist.plot(axis_name="bins")
+
+
+        Returns
+        -------
+        region_map : `RegionNDMap`
+            Region map with histogram.
+
+        """
+        from gammapy.maps import MapAxis, RegionGeom, RegionNDMap
+
+        if isinstance(region, (PointSkyRegion, SkyCoord)):
+            raise ValueError("Histogram method not supported for point regions")
+
+        cutout, mask = self.cutout_and_mask_region(region=region)
+        idx_y, idx_x = np.where(mask)
+        quantity = cutout.quantity[..., idx_y, idx_x]
+
+        value = np.abs(quantity).max()
+
+        if bins_axis is None:
+            bins_axis = MapAxis.from_bounds(
+                -value,
+                value,
+                nbin=nbin,
+                interp="lin",
+                unit=self.unit,
+                name="bins",
+            )
+
+        if not bins_axis.unit.is_equivalent(self.unit):
+            raise ValueError("Unit of bins_axis must be equivalent to unit of map.")
+
+        axes = [bins_axis] + list(self.geom.axes)
+        geom_hist = RegionGeom(region=region, axes=axes, wcs=self.geom.wcs)
+
+        # This is likely not the most efficient way to do this
+        data = np.apply_along_axis(
+            lambda a: np.histogram(a, bins=bins_axis.edges, density=density)[0],
+            axis=-1,
+            arr=quantity,
+        )
+
+        if density:
+            unit = 1.0 / bins_axis.unit
+            data = data.value
+        else:
+            unit = ""
+
+        return RegionNDMap.from_geom(geom=geom_hist, data=data, unit=unit)
+
     def mask_contains_region(self, region):
         """Check if input region is contained in a boolean mask map.
 
         Parameters
         ----------
         region: `~regions.SkyRegion` or `~regions.PixRegion`
              Region or list of Regions (pixel or sky regions accepted).
```

### Comparing `gammapy-1.0rc2/gammapy/maps/wcs/tests/test_geom.py` & `gammapy-1.1rc1/gammapy/maps/wcs/tests/test_geom.py`

 * *Files 4% similar despite different names*

```diff
@@ -616,7 +616,17 @@
 
 def test_wcs_geom_to_even_npix():
     geom = WcsGeom.create(skydir=(0, 0), binsz=1, width=(3, 3))
 
     geom_even = geom.to_even_npix()
 
     assert geom_even.data_shape == (4, 4)
+
+
+def test_wcs_geom_no_zero_shape_cut():
+    geom = WcsGeom.create(skydir=(0, 2.5), binsz=(360, 5), width=(360, 180))
+    skydir = SkyCoord(110.0, 75.0, unit="deg", frame="icrs")
+
+    geom_cut = geom.cutout(skydir, width=5)
+
+    assert geom_cut.data_shape != (1, 0)
+    assert geom_cut.data_shape == (1, 1)
```

### Comparing `gammapy-1.0rc2/gammapy/maps/wcs/tests/test_ndmap.py` & `gammapy-1.1rc1/gammapy/maps/wcs/tests/test_ndmap.py`

 * *Files 2% similar despite different names*

```diff
@@ -916,7 +916,57 @@
     m_c = m.cutout(position=position, width="3 deg")
     m_cc = m_c.cutout(position=position, width="2 deg")
 
     m_new = Map.create(width="10 deg")
     m_new.stack(m_cc)
     m_c_new = m_new.cutout(position=position, width="2 deg")
     np.testing.assert_allclose(m_c_new.data, m_cc.data)
+
+
+def test_to_region_nd_map_histogram_basic():
+    random_state = np.random.RandomState(seed=0)
+
+    energy_axis = MapAxis.from_energy_bounds("1 TeV", "10 TeV", nbin=3)
+
+    data = Map.create(axes=[energy_axis], width=10, unit="cm2 s-1", binsz=0.02)
+    data.data = random_state.normal(
+        size=data.data.shape, loc=0, scale=np.array([1.0, 2.0, 3.0]).reshape((-1, 1, 1))
+    )
+
+    hist = data.to_region_nd_map_histogram()
+    assert hist.data.shape == (3, 100, 1, 1)
+    assert hist.unit == ""
+    assert hist.geom.axes[0].name == "bins"
+    assert_allclose(hist.data[:, 50, 0, 0], [29019, 14625, 9794])
+
+    hist = data.to_region_nd_map_histogram(density=True, nbin=50)
+    assert hist.data.shape == (3, 50, 1, 1)
+    assert hist.unit == 1 / (u.cm**2 / u.s)
+    assert hist.geom.axes[0].name == "bins"
+    assert_allclose(hist.data[:, 25, 0, 0], [0.378215, 0.196005, 0.131782], atol=1e-5)
+
+
+def test_to_region_nd_map_histogram_advanced():
+    random_state = np.random.RandomState(seed=0)
+
+    energy_axis = MapAxis.from_energy_bounds("1 TeV", "10 TeV", nbin=3)
+    label_axis = LabelMapAxis(["a", "b"], name="label")
+
+    data = Map.create(axes=[energy_axis, label_axis], width=10, binsz=0.02)
+
+    data.data = random_state.normal(
+        size=data.data.shape,
+        loc=0,
+        scale=np.array([[1.0, 2.0, 3.0]]).reshape((-1, 1, 1)),
+    )
+
+    region = CircleSkyRegion(center=SkyCoord(0, 0, unit="deg"), radius=3 * u.deg)
+
+    bins_axis = MapAxis.from_edges([-2, -1, 0, 1, 2], name="my-bins")
+    hist = data.to_region_nd_map_histogram(region=region, bins_axis=bins_axis)
+
+    assert hist.data.shape == (2, 3, 4, 1, 1)
+    assert hist.unit == ""
+    assert hist.geom.axes[0].name == "my-bins"
+    assert_allclose(
+        hist.data[:, :, 2, 0, 0], [[24189, 13587, 9212], [24053, 13410, 9186]]
+    )
```

### Comparing `gammapy-1.0rc2/gammapy/modeling/covariance.py` & `gammapy-1.1rc1/gammapy/modeling/covariance.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,28 +1,18 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 """Covariance class"""
 import numpy as np
 import scipy
 import matplotlib.pyplot as plt
+from gammapy.utils.parallel import is_ray_initialized
 from .parameter import Parameters
 
 __all__ = ["Covariance"]
 
 
-def copy_covariance(func):
-    """Copy covariance decorator for model objects."""
-
-    def decorate(self, **kwargs):
-        result = func(self, **kwargs)
-        result.covariance = self.covariance.data.copy()
-        return result
-
-    return decorate
-
-
 class Covariance:
     """Parameter covariance class
 
     Parameters
     ----------
     parameters : `~gammapy.modeling.Parameters`
         Parameter list
@@ -137,14 +127,17 @@
 
         Parameters
         ----------
         parameters : `Parameters`
             Sub list of parameters.
 
         """
+        if is_ray_initialized():
+            # This copy is required to make the covariance setting work with ray
+            self._data = self._data.copy()
 
         idx = [self.parameters.index(par) for par in covar.parameters]
 
         if not np.allclose(self.data[np.ix_(idx, idx)], covar.data):
             self.data[idx, :] = 0
             self.data[:, idx] = 0
```

### Comparing `gammapy-1.0rc2/gammapy/modeling/fit.py` & `gammapy-1.1rc1/gammapy/modeling/fit.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import itertools
 import logging
 import numpy as np
+from astropy.table import Table
+from gammapy.utils.deprecation import deprecated
 from gammapy.utils.pbar import progress_bar
-from gammapy.utils.table import table_from_row_data
 from .covariance import Covariance
 from .iminuit import (
     confidence_iminuit,
     contour_iminuit,
     covariance_iminuit,
     optimize_iminuit,
 )
@@ -133,14 +134,18 @@
 
         self.optimize_opts = optimize_opts
         self.covariance_opts = covariance_opts
         self.confidence_opts = confidence_opts
         self._minuit = None
 
     @property
+    @deprecated(
+        "v1.1",
+        message="The IMinuit object is attached to the OptimizeResult object instead.",
+    )
     def minuit(self):
         """Iminuit object"""
         return self._minuit
 
     @staticmethod
     def _parse_datasets(datasets):
         from gammapy.datasets import Datasets
@@ -163,15 +168,17 @@
         """
         optimize_result = self.optimize(datasets=datasets)
 
         if self.backend not in registry.register["covariance"]:
             log.warning("No covariance estimate - not supported by this backend.")
             return FitResult(optimize_result=optimize_result)
 
-        covariance_result = self.covariance(datasets=datasets)
+        covariance_result = self.covariance(
+            datasets=datasets, optimize_result=optimize_result
+        )
 
         optimize_result.models.covariance = Covariance(
             optimize_result.models.parameters, covariance_result.matrix
         )
 
         return FitResult(
             optimize_result=optimize_result,
@@ -213,15 +220,15 @@
             **kwargs,
         )
 
         if backend == "minuit":
             self._minuit = optimizer
             kwargs["method"] = "migrad"
 
-        trace = table_from_row_data(info.pop("trace"))
+        trace = Table(info.pop("trace"))
 
         if self.store_trace:
             idx = [
                 parameters.index(par)
                 for par in parameters.unique_parameters.free_parameters
             ]
             unique_names = np.array(datasets.models.parameters_unique_names)[idx]
@@ -233,37 +240,44 @@
 
         return OptimizeResult(
             models=datasets.models.copy(),
             total_stat=datasets.stat_sum(),
             backend=backend,
             method=kwargs.get("method", backend),
             trace=trace,
+            minuit=optimizer,
             **info,
         )
 
-    def covariance(self, datasets):
+    def covariance(self, datasets, optimize_result=None):
         """Estimate the covariance matrix.
 
         Assumes that the model parameters are already optimised.
 
         Parameters
         ----------
         datasets : `Datasets` or list of `Dataset`
             Datasets to optimize.
+        optimize_result : `OptimizeResult`
+            Optimization result. Can be optionally used to pass the state of the IMinuit object
+            to the covariance estimation. This might save computation time in certain cases.
 
         Returns
         -------
         result : `CovarianceResult`
             Results
         """
         datasets, unique_pars = self._parse_datasets(datasets=datasets)
         parameters = datasets.models.parameters
 
         kwargs = self.covariance_opts.copy()
-        kwargs["minuit"] = self.minuit
+
+        if optimize_result is not None and optimize_result.backend == "minuit":
+            kwargs["minuit"] = optimize_result.minuit
+
         backend = kwargs.pop("backend", self.backend)
         compute = registry.get("covariance", backend)
 
         with unique_pars.restore_status():
             if self.backend == "minuit":
                 method = "hesse"
             else:
@@ -274,21 +288,24 @@
             )
 
             matrix = Covariance.from_factor_matrix(
                 parameters=parameters, matrix=factor_matrix
             )
             datasets.models.covariance = matrix
 
+        if optimize_result:
+            optimize_result.models.covariance = matrix.data.copy()
+
         # TODO: decide what to return, and fill the info correctly!
         return CovarianceResult(
             backend=backend,
             method=method,
             success=info["success"],
             message=info["message"],
-            matrix=matrix.data.copy(),
+            matrix=optimize_result.models.covariance.data,
         )
 
     def confidence(self, datasets, parameter, sigma=1, reoptimize=True):
         """Estimate confidence interval.
 
         Extra ``kwargs`` are passed to the backend.
         E.g. `iminuit.Minuit.minos` supports a ``maxcall`` option.
@@ -561,22 +578,28 @@
         """Covariance matrix (`~numpy.ndarray`)"""
         return self._matrix
 
 
 class OptimizeResult(FitStepResult):
     """Optimize result object."""
 
-    def __init__(self, models, nfev, total_stat, trace, **kwargs):
+    def __init__(self, models, nfev, total_stat, trace, minuit=None, **kwargs):
         self._models = models
         self._nfev = nfev
         self._total_stat = total_stat
         self._trace = trace
+        self._minuit = minuit
         super().__init__(**kwargs)
 
     @property
+    def minuit(self):
+        """Minuit object"""
+        return self._minuit
+
+    @property
     def parameters(self):
         """Best fit parameters"""
         return self.models.parameters
 
     @property
     def models(self):
         """Best fit models"""
@@ -613,20 +636,21 @@
         Result of the optimization step.
     covariance_result : `CovarianceResult`
         Result of the covariance step.
     """
 
     def __init__(self, optimize_result=None, covariance_result=None):
         self._optimize_result = optimize_result
-
-        if covariance_result:
-            self.optimize_result.models.covariance = covariance_result.matrix
-
         self._covariance_result = covariance_result
 
+    @property
+    def minuit(self):
+        """Minuit object"""
+        return self.optimize_result.minuit
+
     # TODO: is the convenience access needed?
     @property
     def parameters(self):
         """Best fit parameters of the optimization step"""
         return self.optimize_result.parameters
 
     # TODO: is the convenience access needed?
```

### Comparing `gammapy-1.0rc2/gammapy/modeling/iminuit.py` & `gammapy-1.1rc1/gammapy/modeling/iminuit.py`

 * *Files 6% similar despite different names*

```diff
@@ -87,15 +87,15 @@
     }
     optimizer = minuit
 
     return factors, info, optimizer
 
 
 def covariance_iminuit(parameters, function, **kwargs):
-    minuit = kwargs["minuit"]
+    minuit = kwargs.get("minuit")
 
     if minuit is None:
         minuit, _ = setup_iminuit(
             parameters=parameters, function=function, store_trace=False, **kwargs
         )
         minuit.hesse()
 
@@ -171,20 +171,25 @@
     return {
         "success": True,
         "x": contour[:, 0],
         "y": contour[:, 1],
     }
 
 
-# this code is copied from https://github.com/iminuit/iminuit/blob/master/iminuit/_minimize.py#L95
+# This code is copied from https://github.com/scikit-hep/iminuit/blob/v2.21.0/src/iminuit/minimize.py#L124-L136
 def _get_message(m, parameters):
-    message = "Optimization terminated successfully."
-    success = m.accurate
+    success = m.valid
     success &= np.all(np.isfinite([par.value for par in parameters]))
-    if not success:
+    if success:
+        message = "Optimization terminated successfully."
+        if m.accurate:
+            message += "."
+        else:
+            message += ", but uncertainties are unreliable."
+    else:
         message = "Optimization failed."
         fmin = m.fmin
         if fmin.has_reached_call_limit:
             message += " Call limit was reached."
         if fmin.is_above_max_edm:
             message += " Estimated distance to minimum too large."
     return message
```

### Comparing `gammapy-1.0rc2/gammapy/modeling/likelihood.py` & `gammapy-1.1rc1/gammapy/modeling/likelihood.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/modeling/models/__init__.py` & `gammapy-1.1rc1/gammapy/modeling/models/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,14 +11,15 @@
 from .spatial import (
     ConstantFluxSpatialModel,
     ConstantSpatialModel,
     DiskSpatialModel,
     GaussianSpatialModel,
     GeneralizedGaussianSpatialModel,
     PointSpatialModel,
+    PiecewiseNormSpatialModel,
     Shell2SpatialModel,
     ShellSpatialModel,
     SpatialModel,
     TemplateSpatialModel,
 )
 from .spectral import (
     BrokenPowerLawSpectralModel,
@@ -93,14 +94,15 @@
     "MeyerCrabSpectralModel",
     "Model",
     "Models",
     "ModelBase",
     "MODEL_REGISTRY",
     "NaimaSpectralModel",
     "PiecewiseNormSpectralModel",
+    "PiecewiseNormSpatialModel",
     "PointSpatialModel",
     "PowerLaw2SpectralModel",
     "PowerLawNormSpectralModel",
     "PowerLawSpectralModel",
     "PowerLawTemporalModel",
     "scale_plot_flux",
     "ScaleSpectralModel",
@@ -129,14 +131,15 @@
 SPATIAL_MODEL_REGISTRY = Registry(
     [
         ConstantSpatialModel,
         TemplateSpatialModel,
         DiskSpatialModel,
         GaussianSpatialModel,
         GeneralizedGaussianSpatialModel,
+        PiecewiseNormSpatialModel,
         PointSpatialModel,
         ShellSpatialModel,
         Shell2SpatialModel,
     ]
 )
 """Registry of spatial model classes."""
```

### Comparing `gammapy-1.0rc2/gammapy/modeling/models/core.py` & `gammapy-1.1rc1/gammapy/modeling/models/core.py`

 * *Files 3% similar despite different names*

```diff
@@ -7,15 +7,14 @@
 import astropy.units as u
 from astropy.coordinates import SkyCoord
 from astropy.table import Table
 import matplotlib.pyplot as plt
 import yaml
 from gammapy.maps import Map, RegionGeom
 from gammapy.modeling import Covariance, Parameter, Parameters
-from gammapy.modeling.covariance import copy_covariance
 from gammapy.utils.scripts import make_name, make_path
 
 __all__ = ["Model", "Models", "DatasetModels", "ModelBase"]
 
 
 log = logging.getLogger(__name__)
 
@@ -91,14 +90,19 @@
             else:
                 par = value
 
             setattr(self, par.name, par)
 
         self._covariance = Covariance(self.parameters)
 
+        covariance_data = kwargs.get("covariance_data", None)
+
+        if covariance_data is not None:
+            self.covariance = covariance_data
+
     def __getattribute__(self, name):
         value = object.__getattribute__(self, name)
 
         if isinstance(value, Parameter):
             return value.__get__(self, None)
 
         return value
@@ -159,15 +163,14 @@
     @property
     def parameters(self):
         """Parameters (`~gammapy.modeling.Parameters`)"""
         return Parameters(
             [getattr(self, name) for name in self.default_parameters.names]
         )
 
-    @copy_covariance
     def copy(self, **kwargs):
         """A deep copy."""
         return copy.deepcopy(self)
 
     def to_dict(self, full_output=False):
         """Create dict for YAML serialisation"""
         tag = self.tag[0] if isinstance(self.tag, list) else self.tag
@@ -222,14 +225,17 @@
             data["parameters"], cls.default_parameters
         )
 
         # TODO: this is a special case for spatial models, maybe better move to
         #  `SpatialModel` base class
         if "frame" in data:
             kwargs["frame"] = data["frame"]
+        # TODO: same as above for temporal models
+        if "scale" in data:
+            kwargs["scale"] = data["scale"]
 
         return cls.from_parameters(parameters, **kwargs)
 
     def __str__(self):
         string = f"{self.__class__.__name__}\n"
         if len(self.parameters) > 0:
             string += f"\n{self.parameters.to_table()}"
@@ -322,45 +328,54 @@
 class DatasetModels(collections.abc.Sequence):
     """Immutable models container
 
     Parameters
     ----------
     models : `SkyModel`, list of `SkyModel` or `Models`
         Sky models
+    covariance_data : `~numpy.ndarray`
+        Covariance data
     """
 
-    def __init__(self, models=None):
+    def __init__(self, models=None, covariance_data=None):
         if models is None:
             models = []
 
         if isinstance(models, (Models, DatasetModels)):
             models = models._models
         elif isinstance(models, ModelBase):
             models = [models]
         elif not isinstance(models, list):
             raise TypeError(f"Invalid type: {models!r}")
 
         unique_names = []
+
         for model in models:
             if model.name in unique_names:
                 raise (ValueError("Model names must be unique"))
             unique_names.append(model.name)
 
         self._models = models
         self._covar_file = None
+
         self._covariance = Covariance(self.parameters)
 
+        # Set separataly because this trigggers the update mechanism on the sub-models
+        if covariance_data is not None:
+            self.covariance = covariance_data
+
     def _check_covariance(self):
         if not self.parameters == self._covariance.parameters:
             self._covariance = Covariance.from_stack(
                 [model.covariance for model in self._models]
             )
 
     @property
     def covariance(self):
+        """Covariance (`~gammapy.modeling.Covariance`)"""
         self._check_covariance()
 
         for model in self._models:
             self._covariance.set_subcovariance(model.covariance)
 
         return self._covariance
 
@@ -371,14 +386,15 @@
 
         for model in self._models:
             subcovar = self._covariance.get_subcovariance(model.covariance.parameters)
             model.covariance = subcovar
 
     @property
     def parameters(self):
+        """Parameters (`~gammapy.modeling.Parameters`)"""
         return Parameters.from_stack([_.parameters for _ in self._models])
 
     @property
     def parameters_unique_names(self):
         """List of unique parameter names as model_name.par_type.par_name"""
         names = []
         for model in self:
@@ -387,14 +403,15 @@
                 name = ".".join(components)
                 names.append(name)
 
         return names
 
     @property
     def names(self):
+        """List of model names"""
         return [m.name for m in self._models]
 
     @classmethod
     def read(cls, filename):
         """Read from YAML file."""
         yaml_str = make_path(filename).read_text()
         path, filename = split(filename)
@@ -518,14 +535,16 @@
             models_data.append(model_data)
             if (
                 hasattr(model, "spatial_model")
                 and model.spatial_model is not None
                 and "template" in model.spatial_model.tag
             ):
                 model.spatial_model.write(overwrite=overwrite_templates)
+            if model.tag == "TemplateNPredModel":
+                model.write(overwrite=overwrite_templates)
 
         if self._covar_file is not None:
             return {
                 "components": models_data,
                 "covariance": str(self._covar_file),
             }
         else:
@@ -585,15 +604,14 @@
         for idx, name in enumerate(names):
             values = self.covariance.data[idx]
             table[str(idx)] = values
 
         table.write(make_path(filename), **kwargs)
 
     def __str__(self):
-
         self.update_link_label()
 
         str_ = f"{self.__class__.__name__}\n\n"
 
         for idx, model in enumerate(self):
             str_ += f"Component {idx}: "
             str_ += str(model)
@@ -628,15 +646,14 @@
 
     def __len__(self):
         return len(self._models)
 
     def _ipython_key_completions_(self):
         return self.names
 
-    @copy_covariance
     def copy(self, copy_data=False):
         """A deep copy.
 
         Parameters
         ----------
         copy_data : bool
             Whether to copy data attached to template models
@@ -648,15 +665,17 @@
         """
         models = []
 
         for model in self:
             model_copy = model.copy(name=model.name, copy_data=copy_data)
             models.append(model_copy)
 
-        return self.__class__(models=models)
+        return self.__class__(
+            models=models, covariance_data=self.covariance.data.copy()
+        )
 
     def select(
         self,
         name_substring=None,
         datasets_names=None,
         tag=None,
         model_type=None,
```

### Comparing `gammapy-1.0rc2/gammapy/modeling/models/cube.py` & `gammapy-1.1rc1/gammapy/modeling/models/cube.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,24 +1,29 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 """Cube models (axes: lon, lat, energy)."""
 
+import logging
+import os
 import numpy as np
 import astropy.units as u
 from astropy.nddata import NoOverlapError
+from astropy.time import Time
 from gammapy.maps import Map, MapAxis, WcsGeom
 from gammapy.modeling import Covariance, Parameters
-from gammapy.modeling.covariance import copy_covariance
 from gammapy.modeling.parameter import _get_parameters_str
 from gammapy.utils.fits import LazyFitsData
 from gammapy.utils.scripts import make_name, make_path
 from .core import Model, ModelBase, Models
 from .spatial import ConstantSpatialModel, SpatialModel
 from .spectral import PowerLawNormSpectralModel, SpectralModel, TemplateSpectralModel
 from .temporal import TemporalModel
 
+log = logging.getLogger(__name__)
+
+
 __all__ = [
     "create_fermi_isotropic_diffuse_model",
     "FoVBackgroundModel",
     "SkyModel",
     "TemplateNPredModel",
 ]
 
@@ -54,14 +59,15 @@
         self,
         spectral_model,
         spatial_model=None,
         temporal_model=None,
         name=None,
         apply_irf=None,
         datasets_names=None,
+        covariance_data=None,
     ):
         self.spatial_model = spatial_model
         self.spectral_model = spectral_model
         self.temporal_model = temporal_model
         self._name = make_name(name)
 
         if apply_irf is None:
@@ -74,52 +80,62 @@
         is_norm = np.array([par.is_norm for par in spectral_model.parameters])
 
         if not np.any(is_norm):
             raise ValueError(
                 "Spectral model used with SkyModel requires a norm type parameter."
             )
 
-        super().__init__()
+        super().__init__(covariance_data=covariance_data)
 
     @property
     def _models(self):
         models = self.spectral_model, self.spatial_model, self.temporal_model
         return [model for model in models if model is not None]
 
     def _check_covariance(self):
         if not self.parameters == self._covariance.parameters:
             self._covariance = Covariance.from_stack(
                 [model.covariance for model in self._models],
             )
 
     def _check_unit(self):
-        from gammapy.data.gti import GTI
-
-        # evaluate over a test geom to check output unit
-        # TODO simpler way to test this ?
         axis = MapAxis.from_energy_bounds(
             "0.1 TeV", "10 TeV", nbin=1, name="energy_true"
         )
 
         geom = WcsGeom.create(skydir=self.position, npix=(2, 2), axes=[axis])
-
-        gti = GTI.create(1 * u.day, 2 * u.day)
-        value = self.evaluate_geom(geom, gti)
-
+        time = Time(55555, format="mjd")
         if self.apply_irf["exposure"]:
-            ref_unit = u.Unit("cm-2 s-1 MeV-1 sr-1")
+            ref_unit = u.Unit("cm-2 s-1 MeV-1")
         else:
-            ref_unit = u.Unit("sr-1")
+            ref_unit = u.Unit("")
+        obt_unit = self.spectral_model(axis.center).unit
 
-        if self.spatial_model is None:
-            ref_unit = ref_unit / u.Unit("sr-1")
+        if self.spatial_model:
+            obt_unit = obt_unit * self.spatial_model.evaluate_geom(geom).unit
+            ref_unit = ref_unit / u.sr
 
-        if not value.unit.is_equivalent(ref_unit):
+        if self.temporal_model:
+            if u.Quantity(self.temporal_model(time)).unit.is_equivalent(
+                self.spectral_model(axis.center).unit
+            ):
+                obt_unit = (
+                    (
+                        self.temporal_model(time)
+                        * self.spatial_model.evaluate_geom(geom).unit
+                    )
+                    .to(obt_unit.to_string())
+                    .unit
+                )
+            else:
+                obt_unit = obt_unit * u.Quantity(self.temporal_model(time)).unit
+
+        if not obt_unit.is_equivalent(ref_unit):
             raise ValueError(
-                f"SkyModel unit {value.unit} is not equivalent to {ref_unit}"
+                f"SkyModel unit {obt_unit} is not equivalent to {ref_unit}"
             )
 
     @property
     def covariance(self):
         self._check_covariance()
 
         for model in self._models:
@@ -377,15 +393,14 @@
 
         if self.temporal_model:
             integral = self.temporal_model.integral(gti.time_start, gti.time_stop)
             value = value * np.sum(integral)
 
         return Map.from_geom(geom=geom, data=value.value, unit=value.unit)
 
-    @copy_covariance
     def copy(self, name=None, copy_data=False, **kwargs):
         """Copy sky model
 
         Parameters
         ----------
         name : str
             Assign a new name to the copied model.
@@ -411,14 +426,15 @@
 
         kwargs.setdefault("name", make_name(name))
         kwargs.setdefault("spectral_model", self.spectral_model.copy())
         kwargs.setdefault("spatial_model", spatial_model)
         kwargs.setdefault("temporal_model", temporal_model)
         kwargs.setdefault("apply_irf", self.apply_irf.copy())
         kwargs.setdefault("datasets_names", self.datasets_names)
+        kwargs.setdefault("covariance_data", self.covariance.data.copy())
 
         return self.__class__(**kwargs)
 
     def to_dict(self, full_output=False):
         """Create dict for YAML serilisation"""
         data = {}
         data["name"] = self.name
@@ -584,47 +600,62 @@
     the instrumental background attached to a `MapDataset` or
     `SpectrumDataset`.
 
     Parameters
     ----------
     spectral_model : `~gammapy.modeling.models.SpectralModel`
         Normalized spectral model.
+        Default is `~gammapy.modeling.models.PowerLawNormSpectralModel`
     dataset_name : str
         Dataset name
-
+    spatial_model : `~gammapy.modeling.models.SpatialModel`
+        Unitless Spatial model (unit is dropped on evaluation if defined).
+        Default is None.
     """
 
     tag = ["FoVBackgroundModel", "fov-bkg"]
 
-    def __init__(self, spectral_model=None, dataset_name=None):
+    def __init__(
+        self,
+        spectral_model=None,
+        dataset_name=None,
+        spatial_model=None,
+        covariance_data=None,
+    ):
         if dataset_name is None:
             raise ValueError("Dataset name a is required argument")
 
         self.datasets_names = [dataset_name]
 
         if spectral_model is None:
             spectral_model = PowerLawNormSpectralModel()
 
         if not spectral_model.is_norm_spectral_model:
             raise ValueError("A norm spectral model is required.")
 
+        self._spatial_model = spatial_model
         self._spectral_model = spectral_model
-        super().__init__()
+        super().__init__(covariance_data=covariance_data)
 
     @staticmethod
     def contributes(*args, **kwargs):
         """FoV background models always contribute"""
         return True
 
     @property
     def spectral_model(self):
         """Spectral norm model"""
         return self._spectral_model
 
     @property
+    def spatial_model(self):
+        """Spatial norm model"""
+        return self._spatial_model
+
+    @property
     def name(self):
         """Model name"""
         return self.datasets_names[0] + "-bkg"
 
     @property
     def parameters(self):
         """Model parameters"""
@@ -647,21 +678,32 @@
 
         str_ += "\n\n"
         return str_.expandtabs(tabsize=2)
 
     def evaluate_geom(self, geom):
         """Evaluate map"""
         coords = geom.get_coord(sparse=True)
-        return self.evaluate(energy=coords["energy"])
+        return self.evaluate(**coords._data)
 
-    def evaluate(self, energy):
+    def evaluate(self, energy, lon=None, lat=None):
         """Evaluate model"""
-        return self.spectral_model(energy)
+        value = self.spectral_model(energy)
+        if self.spatial_model is not None:
+            if lon is not None and lat is not None:
+                if self.spatial_model.is_energy_dependent:
+                    return self.spatial_model(lon, lat, energy).value * value
+                else:
+                    return self.spatial_model(lon, lat).value * value
+            else:
+                raise ValueError(
+                    "lon and lat are required if a spatial model is defined"
+                )
+        else:
+            return value
 
-    @copy_covariance
     def copy(self, name=None, copy_data=False, **kwargs):
         """Copy FoVBackgroundModel
 
         Parameters
         ----------
         name : str
             Ignored, present for API compatibility.
@@ -673,52 +715,64 @@
         Returns
         -------
         model : `FoVBackgroundModel`
             Copied FoV background model.
         """
         kwargs.setdefault("spectral_model", self.spectral_model.copy())
         kwargs.setdefault("dataset_name", self.datasets_names[0])
+        kwargs.setdefault("covariance_data", self.covariance.data.copy())
         return self.__class__(**kwargs)
 
     def to_dict(self, full_output=False):
         data = {}
         data["type"] = self.tag[0]
         data["datasets_names"] = self.datasets_names
-        data["spectral"] = self.spectral_model.to_dict(full_output=full_output)[
-            "spectral"
-        ]
+        data.update(self.spectral_model.to_dict(full_output=full_output))
+        if self.spatial_model is not None:
+            data.update(self.spatial_model.to_dict(full_output))
         return data
 
     @classmethod
     def from_dict(cls, data):
         """Create model from dict
 
         Parameters
         ----------
         data : dict
             Data dictionary
         """
-        from gammapy.modeling.models import SPECTRAL_MODEL_REGISTRY
+        from gammapy.modeling.models import (
+            SPATIAL_MODEL_REGISTRY,
+            SPECTRAL_MODEL_REGISTRY,
+        )
 
         spectral_data = data.get("spectral")
         if spectral_data is not None:
             model_class = SPECTRAL_MODEL_REGISTRY.get_cls(spectral_data["type"])
-            spectral_model = model_class.from_dict(spectral_data)
+            spectral_model = model_class.from_dict({"spectral": spectral_data})
         else:
             spectral_model = None
 
+        spatial_data = data.get("spatial")
+        if spatial_data is not None:
+            model_class = SPATIAL_MODEL_REGISTRY.get_cls(spatial_data["type"])
+            spatial_model = model_class.from_dict(spatial_data)
+        else:
+            spatial_model = None
+
         datasets_names = data.get("datasets_names")
 
         if datasets_names is None:
             raise ValueError("FoVBackgroundModel must define a dataset name")
 
         if len(datasets_names) > 1:
             raise ValueError("FoVBackgroundModel can only be assigned to one dataset")
 
         return cls(
+            spatial_model=spatial_model,
             spectral_model=spectral_model,
             dataset_name=datasets_names[0],
         )
 
     def reset_to_default(self):
         """Reset parameter values to default"""
         values = self.spectral_model.default_parameters.value
@@ -746,27 +800,32 @@
         Background model map
     spectral_model : `~gammapy.modeling.models.SpectralModel`
         Normalized spectral model,
         default is `~gammapy.modeling.models.PowerLawNormSpectralModel`
     copy_data : bool
         Create a deepcopy of the map data or directly use the original. True by
         default, can be turned to False to save memory in case of large maps.
+    spatial_model : `~gammapy.modeling.models.SpatialModel`
+        Unitless Spatial model (unit is dropped on evaluation if defined).
+        Default is None.
     """
 
     tag = "TemplateNPredModel"
     map = LazyFitsData(cache=True)
 
     def __init__(
         self,
         map,
         spectral_model=None,
         name=None,
         filename=None,
         datasets_names=None,
         copy_data=True,
+        spatial_model=None,
+        covariance_data=None,
     ):
         if isinstance(map, Map):
             axis = map.geom.axes["energy"]
             if axis.node_type != "edges":
                 raise ValueError(
                     'Need an integrated map, energy axis node_type="edges"'
                 )
@@ -779,28 +838,28 @@
         self._name = make_name(name)
         self.filename = filename
 
         if spectral_model is None:
             spectral_model = PowerLawNormSpectralModel()
             spectral_model.tilt.frozen = True
 
+        self.spatial_model = spatial_model
         self.spectral_model = spectral_model
 
         if isinstance(datasets_names, str):
             datasets_names = [datasets_names]
 
         if isinstance(datasets_names, list):
             if len(datasets_names) != 1:
                 raise ValueError(
                     "Currently background models can only be assigned to one dataset."
                 )
         self.datasets_names = datasets_names
-        super().__init__()
+        super().__init__(covariance_data=covariance_data)
 
-    @copy_covariance
     def copy(self, name=None, copy_data=False, **kwargs):
         """Copy template npred model.
 
         Parameters
         ----------
         name : str
             Assign a new name to the copied model.
@@ -815,14 +874,15 @@
             Copied template npred model.
         """
         name = make_name(name)
         kwargs.setdefault("map", self.map)
         kwargs.setdefault("spectral_model", self.spectral_model.copy())
         kwargs.setdefault("filename", self.filename)
         kwargs.setdefault("datasets_names", self.datasets_names)
+        kwargs.setdefault("covariance_data", self.covariance.data.copy())
         return self.__class__(name=name, copy_data=copy_data, **kwargs)
 
     @property
     def name(self):
         return self._name
 
     @property
@@ -855,57 +915,72 @@
         Returns
         -------
         background_map : `~gammapy.maps.Map`
             Background evaluated on the Map
         """
         value = self.spectral_model(self.energy_center).value
         back_values = self.map.data * value
+        if self.spatial_model is not None:
+            value = self.spatial_model.evaluate_geom(self.map.geom).value
+            back_values *= value
         return self.map.copy(data=back_values)
 
     def to_dict(self, full_output=False):
         data = {}
         data["name"] = self.name
         data["type"] = self.tag
+        if self.spatial_model is not None:
+            data["spatial"] = self.spatial_model.to_dict(full_output)["spatial"]
         data["spectral"] = self.spectral_model.to_dict(full_output)["spectral"]
 
         if self.filename is not None:
             data["filename"] = self.filename
 
         if self.datasets_names is not None:
             data["datasets_names"] = self.datasets_names
 
         return data
 
+    def write(self, overwrite=False):
+        if self.filename is None:
+            raise IOError("Missing filename")
+        elif os.path.isfile(make_path(self.filename)) and not overwrite:
+            log.warning("Template file already exits, and overwrite is False")
+        else:
+            self.map.write(self.filename)
+
     @classmethod
     def from_dict(cls, data):
-        from gammapy.modeling.models import SPECTRAL_MODEL_REGISTRY
+        from gammapy.modeling.models import (
+            SPATIAL_MODEL_REGISTRY,
+            SPECTRAL_MODEL_REGISTRY,
+        )
 
         spectral_data = data.get("spectral")
-
         if spectral_data is not None:
             model_class = SPECTRAL_MODEL_REGISTRY.get_cls(spectral_data["type"])
-            spectral_model = model_class.from_dict(spectral_data)
+            spectral_model = model_class.from_dict({"spectral": spectral_data})
         else:
             spectral_model = None
 
+        spatial_data = data.get("spatial")
+        if spatial_data is not None:
+            model_class = SPATIAL_MODEL_REGISTRY.get_cls(spatial_data["type"])
+            spatial_model = model_class.from_dict(spatial_data)
+        else:
+            spatial_model = None
+
         if "filename" in data:
             bkg_map = Map.read(data["filename"])
-        elif "map" in data:
-            bkg_map = data["map"]
         else:
-            # TODO: for now create a fake map for serialization,
-            # uptdated in MapDataset.from_dict()
-            axis = MapAxis.from_edges(np.logspace(-1, 1, 2), unit=u.TeV, name="energy")
-            geom = WcsGeom.create(
-                skydir=(0, 0), npix=(1, 1), frame="galactic", axes=[axis]
-            )
-            bkg_map = Map.from_geom(geom)
+            raise IOError("Missing filename")
 
         return cls(
             map=bkg_map,
+            spatial_model=spatial_model,
             spectral_model=spectral_model,
             name=data["name"],
             datasets_names=data.get("datasets_names"),
             filename=data.get("filename"),
         )
 
     def cutout(self, position, width, mode="trim", name=None):
```

### Comparing `gammapy-1.0rc2/gammapy/modeling/models/spatial.py` & `gammapy-1.1rc1/gammapy/modeling/models/spatial.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,44 +1,48 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 """Spatial models."""
 import logging
 import os
 import numpy as np
 import scipy.integrate
 import scipy.special
+from scipy.interpolate import griddata
 import astropy.units as u
 from astropy.coordinates import Angle, SkyCoord
 from astropy.coordinates.angle_utilities import angular_separation, position_angle
 from astropy.utils import lazyproperty
 from regions import (
     CircleAnnulusSkyRegion,
     CircleSkyRegion,
     EllipseSkyRegion,
     PointSkyRegion,
     RectangleSkyRegion,
 )
 import matplotlib.pyplot as plt
-from gammapy.maps import Map, WcsGeom
-from gammapy.modeling import Parameter
-from gammapy.modeling.covariance import copy_covariance
+from gammapy.maps import Map, MapCoord, WcsGeom
+from gammapy.modeling import Parameter, Parameters
+from gammapy.utils.deprecation import deprecated
 from gammapy.utils.gauss import Gauss2DPDF
+from gammapy.utils.interpolation import interpolation_scale
+from gammapy.utils.regions import region_circle_to_ellipse, region_to_frame
 from gammapy.utils.scripts import make_path
 from .core import ModelBase
 
 __all__ = [
     "ConstantFluxSpatialModel",
     "ConstantSpatialModel",
     "DiskSpatialModel",
     "GaussianSpatialModel",
     "GeneralizedGaussianSpatialModel",
     "PointSpatialModel",
     "Shell2SpatialModel",
     "ShellSpatialModel",
     "SpatialModel",
     "TemplateSpatialModel",
+    "PiecewiseNormSpatialModel",
 ]
 
 
 log = logging.getLogger(__name__)
 
 MAX_OVERSAMPLING = 200
 
@@ -154,19 +158,20 @@
 
     def evaluate_geom(self, geom):
         """Evaluate model on `~gammapy.maps.Geom`
 
         Parameters
         ----------
         geom : `~gammapy.maps.WcsGeom`
+            Map geometry
 
         Returns
         -------
-        `~gammapy.maps.Map`
-
+        map : `~gammapy.maps.Map`
+            Map containing the value in each spatial bin.
         """
         coords = geom.get_coord(frame=self.frame, sparse=True)
 
         if self.is_energy_dependent:
             return self(coords.lon, coords.lat, energy=coords["energy_true"])
         else:
             return self(coords.lon, coords.lat)
@@ -188,16 +193,16 @@
             The geom on which the integration is performed
         oversampling_factor : int or None
             The oversampling factor to use for integration.
             Default is None: the factor is estimated from the model minimimal bin size
 
         Returns
         -------
-        `~gammapy.maps.Map` or `gammapy.maps.RegionNDMap`, containing
-                the integral value in each spatial bin.
+        map : `~gammapy.maps.Map` or `gammapy.maps.RegionNDMap`
+            Map containing the integral value in each spatial bin.
         """
         wcs_geom = geom
         mask = None
 
         if geom.is_region:
             wcs_geom = geom.to_wcs_geom().to_image()
 
@@ -296,14 +301,15 @@
         m = self._get_plot_map(geom)
         if not m.geom.is_flat:
             raise TypeError(
                 "Use .plot_interactive() or .plot_grid() for Map dimension > 2"
             )
         return m.plot(ax=ax, **kwargs)
 
+    @deprecated("v1.0.1", alternative="plot_interactive")
     def plot_interative(self, ax=None, geom=None, **kwargs):
         """Plot spatial model.
 
         Parameters
         ----------
         ax : `~matplotlib.axes.Axes`, optional
             Axis
@@ -319,14 +325,37 @@
         """
 
         m = self._get_plot_map(geom)
         if m.geom.is_image:
             raise TypeError("Use .plot() for 2D Maps")
         m.plot_interactive(ax=ax, **kwargs)
 
+    def plot_interactive(self, ax=None, geom=None, **kwargs):
+        """Plot spatial model.
+
+        Parameters
+        ----------
+        ax : `~matplotlib.axes.Axes`, optional
+            Axis
+        geom : `~gammapy.maps.WcsGeom`, optional
+            Geom to use for plotting.
+        **kwargs : dict
+            Keyword arguments passed to `~gammapy.maps.WcsMap.plot()`
+
+        Returns
+        -------
+        ax : `~matplotlib.axes.Axes`, optional
+            Axis
+        """
+
+        m = self._get_plot_map(geom)
+        if m.geom.is_image:
+            raise TypeError("Use .plot() for 2D Maps")
+        m.plot_interactive(ax=ax, **kwargs)
+
     def plot_error(self, ax=None, **kwargs):
         """Plot position error
 
         Parameters
         ----------
         ax : `~matplotlib.axes.Axes`, optional
             Axis
@@ -377,27 +406,27 @@
             raise TypeError("Use .plot() for 2D Maps")
         m = self._get_plot_map(geom)
         m.plot_grid(**kwargs)
 
     @classmethod
     def from_position(cls, position, **kwargs):
         """Define the position of the model using a sky coord
-
+           The model will be created in the frame of the sky coord
         Parameters
         ----------
         position : `~astropy.coordinates.SkyCoord`
             Position
 
         Returns
         -------
         model : `SpatialModel`
             Spatial model
         """
         lon_0, lat_0 = position.data.lon, position.data.lat
-        return cls(lon_0=lon_0, lat_0=lat_0, frame=position.frame, **kwargs)
+        return cls(lon_0=lon_0, lat_0=lat_0, frame=position.frame.name, **kwargs)
 
     @property
     def evaluation_radius(self):
         """Evaluation radius"""
         return None
 
     @property
@@ -771,14 +800,51 @@
             center=self.position,
             height=2 * self.r_0.quantity,
             width=2 * minor_axis,
             angle=self.phi.quantity,
             **kwargs,
         )
 
+    @classmethod
+    def from_region(cls, region, **kwargs):
+        """Create a `DiskSpatialModel from a ~regions.EllipseSkyRegion`
+
+        Parameters
+        ----------
+        region : `~regions.EllipseSkyRegion` or ~regions.CircleSkyRegion`
+            region to create model from
+        kwargs : keywords passed to `~gammapy.modeling.models.DiskSpatialModel`
+
+        Returns
+        -------
+        spatial_model : `~gammapy.modeling.models.DiskSpatialModel`
+        """
+        if isinstance(region, CircleSkyRegion):
+            region = region_circle_to_ellipse(region)
+        if not isinstance(region, EllipseSkyRegion):
+            raise ValueError(
+                f"Please provide a `CircleSkyRegion` "
+                f"or `EllipseSkyRegion`, got {type(region)} instead."
+            )
+        frame = kwargs.pop("frame", region.center.frame)
+        region = region_to_frame(region, frame=frame)
+
+        if region.height > region.width:
+            major_axis, minor_axis = region.height, region.width
+            phi = region.angle
+        else:
+            minor_axis, major_axis = region.height, region.width
+            phi = 90 * u.deg + region.angle
+
+        kwargs.setdefault("phi", phi)
+        kwargs.setdefault("e", np.sqrt(1.0 - np.power(minor_axis / major_axis, 2)))
+        kwargs.setdefault("r_0", major_axis / 2.0)
+
+        return cls.from_position(region.center, **kwargs)
+
 
 class ShellSpatialModel(SpatialModel):
     r"""Shell model.
 
     For more information see :ref:`shell-spatial-model`.
 
     Parameters
@@ -1019,32 +1085,35 @@
         Map template.
     meta : dict, optional
         Meta information, meta['filename'] will be used for serialization
     normalize : bool
         Normalize the input map so that it integrates to unity.
     interp_kwargs : dict
         Interpolation keyword arguments passed to `gammapy.maps.Map.interp_by_coord`.
-        Default arguments are {'method': 'linear', 'fill_value': 0}.
+        Default arguments are {'method': 'linear', 'fill_value': 0, "values_scale": "log"}.
     Filename : str
         Name of the map file
     copy_data : bool
         Create a deepcopy of the map data or directly use the original. True by
         default, can be turned to False to save memory in case of large maps.
+    **kwargs : dict
+        Keyword arguments forwarded to `SpatialModel.__init__`.
     """
 
     tag = ["TemplateSpatialModel", "template"]
 
     def __init__(
         self,
         map,
         meta=None,
         normalize=True,
         interp_kwargs=None,
         filename=None,
         copy_data=True,
+        **kwargs,
     ):
         if (map.data < 0).any():
             log.warning("Map has negative values. Check and fix this!")
 
         if filename is not None:
             filename = str(make_path(filename))
 
@@ -1072,20 +1141,20 @@
             self._map = map.copy(data=map.data)
 
         self.meta = {} if meta is None else meta
 
         interp_kwargs = {} if interp_kwargs is None else interp_kwargs
         interp_kwargs.setdefault("method", "linear")
         interp_kwargs.setdefault("fill_value", 0)
+        interp_kwargs.setdefault("values_scale", "log")
 
         self._interp_kwargs = interp_kwargs
         self.filename = filename
-        super().__init__()
+        super().__init__(**kwargs)
 
-    @copy_covariance
     def copy(self, copy_data=False, **kwargs):
         """Copy model
 
         Parameters
         ----------
         copy_data : bool
             Whether to copy the data.
@@ -1185,15 +1254,15 @@
         data["spatial"]["normalize"] = self.normalize
         data["spatial"]["unit"] = str(self.map.unit)
         return data
 
     def write(self, overwrite=False):
         if self.filename is None:
             raise IOError("Missing filename")
-        elif os.path.isfile(self.filename) and not overwrite:
+        elif os.path.isfile(make_path(self.filename)) and not overwrite:
             log.warning("Template file already exits, and overwrite is False")
         else:
             self.map.write(self.filename, overwrite=overwrite)
 
     def to_region(self, **kwargs):
         """Model outline from template map boundary (`~regions.RectangleSkyRegion`)."""
         return RectangleSkyRegion(
@@ -1204,11 +1273,132 @@
         )
 
     def plot(self, ax=None, geom=None, **kwargs):
         if geom is None:
             geom = self.map.geom
         super().plot(ax=ax, geom=geom, **kwargs)
 
+    @deprecated("v1.0.1", alternative="plot_interactive")
     def plot_interative(self, ax=None, geom=None, **kwargs):
         if geom is None:
             geom = self.map.geom
-        super().plot_interative(ax=ax, geom=geom, **kwargs)
+        super().plot_interactive(ax=ax, geom=geom, **kwargs)
+
+    def plot_interactive(self, ax=None, geom=None, **kwargs):
+        if geom is None:
+            geom = self.map.geom
+        super().plot_interactive(ax=ax, geom=geom, **kwargs)
+
+
+class PiecewiseNormSpatialModel(SpatialModel):
+    """Piecewise spatial correction
+       with a free normalization at each fixed nodes.
+
+       For more information see :ref:`piecewise-norm-spatial`.
+
+    Parameters
+    ----------
+    coord : `gammapy.maps.MapCoord`
+        Flat coordinates list at which the model values are given (nodes).
+    norms : `~numpy.ndarray` or list of `Parameter`
+        Array with the initial norms of the model at energies ``energy``.
+        A normalisation parameters is created for each value.
+        Default is one at each node.
+    interp : str
+        Interpolation scaling in {"log", "lin"}. Default is "lin"
+    """
+
+    tag = ["PiecewiseNormSpatialModel", "piecewise-norm"]
+
+    def __init__(self, coords, norms=None, interp="lin", **kwargs):
+        self._coords = coords
+        self._interp = interp
+
+        if norms is None:
+            norms = np.ones(coords.shape)
+
+        if len(norms) != coords.shape[0]:
+            raise ValueError("dimension mismatch")
+
+        if len(norms) < 4:
+            raise ValueError("Input arrays must contain at least 4 elements")
+
+        if self.is_energy_dependent:
+            raise ValueError("Energy dependent nodes are not supported")
+
+        if not isinstance(norms[0], Parameter):
+            parameters = Parameters(
+                [Parameter(f"norm_{k}", norm) for k, norm in enumerate(norms)]
+            )
+        else:
+            parameters = Parameters(norms)
+        self.default_parameters = parameters
+        super().__init__(**kwargs)
+
+    @property
+    def coords(self):
+        """Energy nodes"""
+        return self._coords
+
+    @property
+    def norms(self):
+        """Norm values"""
+        return u.Quantity([p.quantity for p in self.parameters])
+
+    @property
+    def is_energy_dependent(self):
+        keys = self.coords._data.keys()
+        return "energy" in keys or "energy_true" in keys
+
+    def evaluate(self, lon, lat, energy=None, **norms):
+        """Evaluate the model at given coordinates."""
+        scale = interpolation_scale(scale=self._interp)
+        v_nodes = scale(self.norms.value)
+        coords = [value.value for value in self.coords._data.values()]
+        # TODO: apply axes scaling in this loop
+        coords = list(zip(*coords))
+        # by default rely on CloughTocher2DInterpolator
+        # (Piecewise cubic, C1 smooth, curvature-minimizing interpolant)
+        interpolated = griddata(coords, v_nodes, (lon, lat), method="cubic")
+        return scale.inverse(interpolated) * self.norms.unit
+
+    def evaluate_geom(self, geom):
+        """Evaluate model on `~gammapy.maps.Geom`
+
+        Parameters
+        ----------
+        geom : `~gammapy.maps.WcsGeom`
+            Map geometry
+
+        Returns
+        -------
+        map : `~gammapy.maps.Map`
+            Map containing the value in each spatial bin.
+
+        """
+        coords = geom.get_coord(frame=self.frame, sparse=True)
+        return self(coords.lon, coords.lat)
+
+    def to_dict(self, full_output=False):
+        data = super().to_dict(full_output=full_output)
+        for key, value in self.coords._data.items():
+            data["spatial"][key] = {
+                "data": value.data.tolist(),
+                "unit": str(value.unit),
+            }
+        return data
+
+    @classmethod
+    def from_dict(cls, data):
+        """Create model from dict"""
+        data = data["spatial"]
+        lon = u.Quantity(data["lon"]["data"], data["lon"]["unit"])
+        lat = u.Quantity(data["lat"]["data"], data["lat"]["unit"])
+        coords = MapCoord.create((lon, lat))
+
+        parameters = Parameters.from_dict(data["parameters"])
+        return cls.from_parameters(parameters, coords=coords, frame=data["frame"])
+
+    @classmethod
+    def from_parameters(cls, parameters, **kwargs):
+        """Create model from parameters"""
+        return cls(norms=parameters, **kwargs)
```

### Comparing `gammapy-1.0rc2/gammapy/modeling/models/spectral.py` & `gammapy-1.1rc1/gammapy/modeling/models/spectral.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,22 +1,24 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 """Spectral models for Gammapy."""
 import logging
 import operator
 import os
+from pathlib import Path
 import numpy as np
 import scipy.optimize
 import scipy.special
 import astropy.units as u
 from astropy import constants as const
 from astropy.table import Table
 from astropy.utils.decorators import classproperty
 from astropy.visualization import quantity_support
 import matplotlib.pyplot as plt
 from gammapy.maps import MapAxis, RegionNDMap
+from gammapy.maps.axes import UNIT_STRING_FORMAT
 from gammapy.modeling import Parameter, Parameters
 from gammapy.utils.integrate import trapz_loglog
 from gammapy.utils.interpolation import (
     ScaledRegularGridInterpolator,
     interpolation_scale,
 )
 from gammapy.utils.roots import find_roots
@@ -49,14 +51,21 @@
     "SpectralModel",
     "SuperExpCutoffPowerLaw3FGLSpectralModel",
     "SuperExpCutoffPowerLaw4FGLDR3SpectralModel",
     "SuperExpCutoffPowerLaw4FGLSpectralModel",
     "TemplateSpectralModel",
 ]
 
+EBL_DATA_BUILTIN = {}
+EBL_DATA_BUILTIN["franceschini"] = "$GAMMAPY_DATA/ebl/ebl_franceschini.fits.gz"
+EBL_DATA_BUILTIN["dominguez"] = "$GAMMAPY_DATA/ebl/ebl_dominguez11.fits.gz"
+EBL_DATA_BUILTIN["finke"] = "$GAMMAPY_DATA/ebl/frd_abs.fits.gz"
+EBL_DATA_BUILTIN["franceschini17"] = "$GAMMAPY_DATA/ebl/ebl_franceschini_2017.fits.gz"
+EBL_DATA_BUILTIN["saldana-lopez21"] = "$GAMMAPY_DATA/ebl/ebl_saldana-lopez_2021.fits.gz"
+
 
 def scale_plot_flux(flux, energy_power=0):
     """Scale flux to plot
 
     Parameters
     ----------
     flux : `Map`
@@ -180,15 +189,15 @@
             df = fct(**kwargs) - f_0
 
             df_dp[idx] = df.value / eps[idx]
             parameter.value -= eps[idx]
 
         f_cov = df_dp.T @ self.covariance @ df_dp
         f_err = np.sqrt(np.diagonal(f_cov))
-        return u.Quantity([f_0.value, f_err], unit=f_0.unit)
+        return u.Quantity([np.atleast_1d(f_0.value), f_err], unit=f_0.unit).squeeze()
 
     def evaluate_error(self, energy, epsilon=1e-4):
         """Evaluate spectral model with error propagation.
 
         Parameters
         ----------
         energy : `~astropy.units.Quantity`
@@ -496,42 +505,67 @@
             ax.fill_between(energy.center, y_lo, y_hi, **kwargs)
 
         self._plot_format_ax(ax, energy_power, sed_type)
         return ax
 
     @staticmethod
     def _plot_format_ax(ax, energy_power, sed_type):
-        ax.set_xlabel(f"Energy [{ax.xaxis.units}]")
+        ax.set_xlabel(f"Energy [{ax.xaxis.units.to_string(UNIT_STRING_FORMAT)}]")
         if energy_power > 0:
-            ax.set_ylabel(f"e{energy_power} * {sed_type} [{ax.yaxis.units}]")
+            ax.set_ylabel(
+                f"e{energy_power} * {sed_type} [{ax.yaxis.units.to_string(UNIT_STRING_FORMAT)}]"
+            )
         else:
-            ax.set_ylabel(f"{sed_type} [{ax.yaxis.units}]")
+            ax.set_ylabel(
+                f"{sed_type} [{ax.yaxis.units.to_string(UNIT_STRING_FORMAT)}]"
+            )
 
         ax.set_xscale("log", nonpositive="clip")
         ax.set_yscale("log", nonpositive="clip")
 
     def spectral_index(self, energy, epsilon=1e-5):
         """Compute spectral index at given energy.
 
         Parameters
         ----------
         energy : `~astropy.units.Quantity`
             Energy at which to estimate the index
-        epsilon : float
+        epsilon : float, optional
             Fractional energy increment to use for determining the spectral index.
+            default = 1e-5
 
         Returns
         -------
         index : float
             Estimated spectral index.
         """
         f1 = self(energy)
         f2 = self(energy * (1 + epsilon))
         return np.log(f1 / f2) / np.log(1 + epsilon)
 
+    def spectral_index_error(self, energy, epsilon=1e-5):
+        """Evaluate the error on spectral index at the given energy
+
+        Parameters
+        ----------
+        energy : `~astropy.units.Quantity`
+            Energy at which to estimate the index
+        epsilon : float, optional
+            Fractional energy increment to use for determining the spectral index
+            default = 1e-5
+
+        Returns
+        -------
+        index, index_error : tuple of float
+            Estimated spectral index and its error
+        """
+        return self._propagate_error(
+            epsilon=epsilon, fct=self.spectral_index, energy=energy
+        )
+
     def inverse(self, value, energy_min=0.1 * u.TeV, energy_max=100 * u.TeV):
         """Return energy for a given function value of the spectral model.
 
         Calls the `scipy.optimize.brentq` numerical root finding method.
 
         Parameters
         ----------
@@ -647,14 +681,21 @@
                 "type": self.tag[0],
                 "model1": dict1["spectral"],  # for cleaner output
                 "model2": dict2["spectral"],
                 "operator": self.operator.__name__,
             }
         }
 
+    def evaluate(self, energy, *args):
+        args1 = args[: len(self.model1.parameters)]
+        args2 = args[len(self.model1.parameters) :]
+        val1 = self.model1.evaluate(energy, *args1)
+        val2 = self.model2.evaluate(energy, *args2)
+        return self.operator(val1, val2)
+
     @classmethod
     def from_dict(cls, data):
         from gammapy.modeling.models import SPECTRAL_MODEL_REGISTRY
 
         data = data["spectral"]
         model1_cls = SPECTRAL_MODEL_REGISTRY.get_cls(data["model1"]["type"])
         model1 = model1_cls.from_dict({"spectral": data["model1"]})
@@ -1079,54 +1120,60 @@
     """
 
     tag = ["PiecewiseNormSpectralModel", "piecewise-norm"]
 
     def __init__(self, energy, norms=None, interp="log"):
         self._energy = energy
         self._interp = interp
+        self._norm = Parameter(
+            "_norm", 1, unit="", interp="log", is_norm=True, frozen=True
+        )
 
         if norms is None:
             norms = np.ones(len(energy))
 
         if len(norms) != len(energy):
             raise ValueError("dimension mismatch")
 
         if len(norms) < 2:
             raise ValueError("Input arrays must contain at least 2 elements")
 
+        parameters_list = [self._norm]
         if not isinstance(norms[0], Parameter):
-            parameters = Parameters(
-                [Parameter(f"norm_{k}", norm) for k, norm in enumerate(norms)]
-            )
+            parameters_list += [
+                Parameter(f"norm_{k}", norm) for k, norm in enumerate(norms)
+            ]
         else:
-            parameters = Parameters(norms)
+            parameters_list += norms
 
-        self.default_parameters = parameters
+        self.default_parameters = Parameters(parameters_list)
         super().__init__()
 
     @property
     def energy(self):
         """Energy nodes"""
         return self._energy
 
     @property
     def norms(self):
         """Norm values"""
-        return u.Quantity(self.parameters.value)
+        return u.Quantity([p.value for p in self.parameters if p.name != "_norm"])
 
     def evaluate(self, energy, **norms):
         scale = interpolation_scale(scale=self._interp)
         e_eval = scale(np.atleast_1d(energy.value))
         e_nodes = scale(self.energy.to(energy.unit).value)
         v_nodes = scale(self.norms)
         log_interp = scale.inverse(np.interp(e_eval, e_nodes, v_nodes))
-        return log_interp
+        return self._norm.quantity * log_interp
 
     def to_dict(self, full_output=False):
         data = super().to_dict(full_output=full_output)
+        if data["spectral"]["parameters"][0]["name"] == "_norm":
+            data["spectral"]["parameters"].pop(0)
         data["spectral"]["energy"] = {
             "data": self.energy.data.tolist(),
             "unit": str(self.energy.unit),
         }
         return data
 
     @classmethod
@@ -1822,25 +1869,26 @@
         self._evaluate_table_model = ScaledRegularGridInterpolator(
             points=(self.param, self.energy), values=self.data, **interp_kwargs
         )
         super().__init__(redshift=redshift, alpha_norm=alpha_norm)
 
     def to_dict(self, full_output=False):
         data = super().to_dict(full_output=full_output)
+        param = u.Quantity(self.param)
         if self.filename is None:
             data["spectral"]["energy"] = {
                 "data": self.energy.data.tolist(),
                 "unit": str(self.energy.unit),
             }
             data["spectral"]["param"] = {
-                "data": self.param.data.tolist(),
-                "unit": str(self.param.unit),
+                "data": param.data.tolist(),
+                "unit": str(param.unit),
             }
             data["spectral"]["values"] = {
-                "data": self.data.data.tolist(),
+                "data": self.data.value.tolist(),
                 "unit": str(self.data.unit),
             }
         else:
             data["spectral"]["filename"] = str(self.filename)
         return data
 
     @classmethod
@@ -1849,15 +1897,25 @@
         redshift = [p["value"] for p in data["parameters"] if p["name"] == "redshift"][
             0
         ]
         alpha_norm = [
             p["value"] for p in data["parameters"] if p["name"] == "alpha_norm"
         ][0]
         if "filename" in data:
-            return cls.read(data["filename"], redshift=redshift, alpha_norm=alpha_norm)
+            if os.path.exists(data["filename"]):
+                return cls.read(
+                    data["filename"], redshift=redshift, alpha_norm=alpha_norm
+                )
+            else:
+                for reference, filename in EBL_DATA_BUILTIN.items():
+                    if Path(filename).stem in data["filename"]:
+                        return cls.read_builtin(
+                            reference, redshift=redshift, alpha_norm=alpha_norm
+                        )
+                raise IOError(f'File {data["filename"]} not found')
         else:
             energy = u.Quantity(data["energy"]["data"], data["energy"]["unit"])
             param = u.Quantity(data["param"]["data"], data["param"]["unit"])
             values = u.Quantity(data["values"]["data"], data["values"]["unit"])
             return cls(
                 energy=energy,
                 param=param,
@@ -1914,42 +1972,44 @@
         model.filename = filename
         return model
 
     @classmethod
     def read_builtin(
         cls, reference="dominguez", redshift=0.1, alpha_norm=1, interp_kwargs=None
     ):
-        """Read  from one of the built-in absorption models.
+        """Read from one of the built-in absorption models.
 
         Parameters
         ----------
         reference : {'franceschini', 'dominguez', 'finke'}
             name of one of the available model in gammapy-data
         redshift : float
             Redshift of the absorption model
         alpha_norm: float
             Norm of the EBL model
 
         References
         ----------
-        .. [1] Franceschini et al., "Extragalactic optical-infrared background radiation, its time evolution and the cosmic photon-photon opacity",  # noqa: E501
+        .. [1] Franceschini et al. (2008), "Extragalactic optical-infrared background radiation, its time evolution and the cosmic photon-photon opacity",  # noqa: E501
             `Link <https://ui.adsabs.harvard.edu/abs/2008A%26A...487..837F>`__
-        .. [2] Dominguez et al., " Extragalactic background light inferred from AEGIS galaxy-SED-type fractions"  # noqa: E501
+        .. [2] Dominguez et al. (2011), " Extragalactic background light inferred from AEGIS galaxy-SED-type fractions"  # noqa: E501
             `Link <https://ui.adsabs.harvard.edu/abs/2011MNRAS.410.2556D>`__
-        .. [3] Finke et al., "Modeling the Extragalactic Background Light from Stars and Dust"
+        .. [3] Finke et al. (2010), "Modeling the Extragalactic Background Light from Stars and Dust"
             `Link <https://ui.adsabs.harvard.edu/abs/2010ApJ...712..238F>`__
-
+        .. [4] Franceschini et al. (2017), "The extragalactic background light revisited and the cosmic photon-photon opacity"
+            `Link <https://ui.adsabs.harvard.edu/abs/2017A%26A...603A..34F/abstract>`__
+        .. [5] Saldana-Lopez et al. (2021) "An observational determination of the evolving extragalactic background light from the multiwavelength HST/CANDELS survey in the Fermi and CTA era"
+            `Link <https://ui.adsabs.harvard.edu/abs/2021MNRAS.507.5144S/abstract>`__
         """
-        models = {}
-        models["franceschini"] = "$GAMMAPY_DATA/ebl/ebl_franceschini.fits.gz"
-        models["dominguez"] = "$GAMMAPY_DATA/ebl/ebl_dominguez11.fits.gz"
-        models["finke"] = "$GAMMAPY_DATA/ebl/frd_abs.fits.gz"
 
         return cls.read(
-            models[reference], redshift, alpha_norm, interp_kwargs=interp_kwargs
+            EBL_DATA_BUILTIN[reference],
+            redshift,
+            alpha_norm,
+            interp_kwargs=interp_kwargs,
         )
 
     def evaluate(self, energy, redshift, alpha_norm):
         """Evaluate model for energy and parameter value."""
         absorption = np.clip(self._evaluate_table_model((redshift, energy)), 0, 1)
         return np.power(absorption, alpha_norm)
 
@@ -2173,21 +2233,21 @@
             * np.exp(-((energy - mean) ** 2) / (2 * sigma**2))
         )
 
     def integral(self, energy_min, energy_max, **kwargs):
         r"""Integrate Gaussian analytically.
 
         .. math::
-            F(E_{min}, E_{max}) = \frac{N_0}{2} \left[ erf(\frac{E - \bar{E}}{\sqrt{2} \sigma})\right]_{E_{min}}^{E_{max}}  # noqa: E501
+            F(E_{min}, E_{max}) = \frac{N_0}{2} \left[ erf(\frac{E - \bar{E}}{\sqrt{2} \sigma})\right]_{E_{min}}^{E_{max}}
 
         Parameters
         ----------
         energy_min, energy_max : `~astropy.units.Quantity`
             Lower and upper bound of integration range
-        """
+        """  # noqa: E501
         # kwargs are passed to this function but not used
         # this is to get a consistent API with SpectralModel.integral()
         u_min = (
             (energy_min - self.mean.quantity) / (np.sqrt(2) * self.sigma.quantity)
         ).to_value("")
         u_max = (
             (energy_max - self.mean.quantity) / (np.sqrt(2) * self.sigma.quantity)
@@ -2199,24 +2259,24 @@
             * (scipy.special.erf(u_max) - scipy.special.erf(u_min))
         )
 
     def energy_flux(self, energy_min, energy_max):
         r"""Compute energy flux in given energy range analytically.
 
         .. math::
-            G(E_{min}, E_{max}) =  \frac{N_0 \sigma}{\sqrt{2*\pi}}* \left[ - \exp(\frac{E_{min}-\bar{E}}{\sqrt{2} \sigma})   # noqa: E501
-            \right]_{E_{min}}^{E_{max}} + \frac{N_0 * \bar{E}}{2} \left[ erf(\frac{E - \bar{E}}{\sqrt{2} \sigma})   # noqa: E501
+            G(E_{min}, E_{max}) =  \frac{N_0 \sigma}{\sqrt{2*\pi}}* \left[ - \exp(\frac{E_{min}-\bar{E}}{\sqrt{2} \sigma})
+            \right]_{E_{min}}^{E_{max}} + \frac{N_0 * \bar{E}}{2} \left[ erf(\frac{E - \bar{E}}{\sqrt{2} \sigma})
              \right]_{E_{min}}^{E_{max}}
 
 
         Parameters
         ----------
         energy_min, energy_max : `~astropy.units.Quantity`
             Lower and upper bound of integration range.
-        """
+        """  # noqa: E501
         u_min = (
             (energy_min - self.mean.quantity) / (np.sqrt(2) * self.sigma.quantity)
         ).to_value("")
         u_max = (
             (energy_max - self.mean.quantity) / (np.sqrt(2) * self.sigma.quantity)
         ).to_value("")
         a = self.amplitude.quantity * self.sigma.quantity / np.sqrt(2 * np.pi)
```

### Comparing `gammapy-1.0rc2/gammapy/modeling/models/spectral_cosmic_ray.py` & `gammapy-1.1rc1/gammapy/modeling/models/spectral_cosmic_ray.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/modeling/models/spectral_crab.py` & `gammapy-1.1rc1/gammapy/modeling/models/spectral_crab.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/modeling/models/temporal.py` & `gammapy-1.1rc1/gammapy/modeling/models/temporal.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,21 +1,22 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 """Time-dependent models."""
 import logging
 import numpy as np
 import scipy.interpolate
 from astropy import units as u
+from astropy.io import fits
 from astropy.table import Table
 from astropy.time import Time
 from astropy.utils import lazyproperty
 from gammapy.maps import MapAxis, RegionNDMap, TimeMapAxis
 from gammapy.modeling import Parameter
 from gammapy.utils.random import InverseCDFSampler, get_random_state
 from gammapy.utils.scripts import make_path
-from gammapy.utils.time import time_ref_from_dict
+from gammapy.utils.time import time_ref_from_dict, time_ref_to_dict
 from .core import ModelBase, _build_parameters_from_dict
 
 __all__ = [
     "ConstantTemporalModel",
     "ExpDecayTemporalModel",
     "GaussianTemporalModel",
     "GeneralizedGaussianTemporalModel",
@@ -34,30 +35,74 @@
 class TemporalModel(ModelBase):
     """Temporal model base class.
 
     Evaluates on  astropy.time.Time objects"""
 
     _type = "temporal"
 
-    def __call__(self, time):
+    def __init__(self, **kwargs):
+        scale = kwargs.pop("scale", "utc")
+
+        if scale not in Time.SCALES:
+            raise ValueError(
+                f"{scale} is not a valid time scale. Choose from {Time.SCALES}"
+            )
+
+        self.scale = scale
+        super().__init__(**kwargs)
+
+    def __call__(self, time, energy=None):
         """Evaluate model
 
         Parameters
         ----------
         time : `~astropy.time.Time`
             Time object
+        energy : `~astropy.units.Quantity`
+            Energy (optional)
+
+        Returns
+        -------
+        values : `~astropy.units.Quantity`
+            Model values
         """
         kwargs = {par.name: par.quantity for par in self.parameters}
-        time = u.Quantity(time.mjd, "day")
+
+        if energy is not None:
+            kwargs["energy"] = energy
+
+        time = Time(time, scale=self.scale).mjd * u.d
         return self.evaluate(time, **kwargs)
 
     @property
     def type(self):
         return self._type
 
+    @property
+    def is_energy_dependent(self):
+        return False
+
+    @property
+    def reference_time(self):
+        """Reference time in mjd"""
+        return Time(self.t_ref.value, format="mjd", scale=self.scale)
+
+    @reference_time.setter
+    def reference_time(self, t_ref):
+        """Reference time"""
+        if not isinstance(t_ref, Time):
+            raise TypeError(f"{t_ref} is not a {Time} object")
+        self.t_ref.value = Time(t_ref, scale=self.scale).mjd
+
+    def to_dict(self, full_output=False):
+        """Create dict for YAML serilisation"""
+        data = super().to_dict(full_output)
+        data["temporal"]["scale"] = self.scale
+        return data
+
     @staticmethod
     def time_sum(t_min, t_max):
         """Total time between t_min and t_max
 
         Parameters
         ----------
         t_min, t_max : `~astropy.time.Time`
@@ -125,40 +170,32 @@
             Passed to `~gammapy.utils.random.get_random_state`.
 
         Returns
         -------
         time : `~astropy.units.Quantity`
             Array with times of the sampled events.
         """
-        t_min = Time(t_min)
-        t_max = Time(t_max)
+        t_min = Time(t_min, scale=self.scale)
+        t_max = Time(t_max, scale=self.scale)
         t_delta = u.Quantity(t_delta)
         random_state = get_random_state(random_state)
 
-        ontime = u.Quantity((t_max - t_min).sec, "s")
-
-        time_unit = (
-            u.Unit(self.table.meta["TIMEUNIT"])
-            if hasattr(self, "table")
-            else ontime.unit
-        )
-
-        t_step = t_delta.to_value(time_unit)
-        t_step = (t_step * u.s).to("d")
-
-        t = Time(np.arange(t_min.mjd, t_max.mjd, t_step.value), format="mjd")
+        ontime = u.Quantity((t_max - t_min).sec, t_delta.unit)
+        n_step = (ontime / t_delta).to_value("")
+        t_step = ontime / n_step
+
+        indices = np.arange(n_step + 1)
+        steps = indices * t_step
+        t = Time(t_min + steps, format="mjd")
 
         pdf = self(t)
 
         sampler = InverseCDFSampler(pdf=pdf, random_state=random_state)
         time_pix = sampler.sample(n_events)[0]
-        time = (
-            np.interp(time_pix, np.arange(len(t)), t.value - min(t.value)) * t_step.unit
-        ).to(time_unit)
-
+        time = np.interp(time_pix, indices, steps)
         return t_min + time
 
     def integral(self, t_min, t_max, oversampling_factor=100, **kwargs):
         """Evaluate the integrated flux within the given time intervals
 
         Parameters
         ----------
@@ -173,15 +210,15 @@
         -------
         norm : float
             Integrated flux norm on the given time intervals
         """
         t_values, steps = np.linspace(
             t_min.mjd, t_max.mjd, oversampling_factor, retstep=True, axis=-1
         )
-        times = Time(t_values, format="mjd")
+        times = Time(t_values, format="mjd", scale=self.scale)
         values = self(times)
         integral = np.sum(values, axis=-1) * steps
         return integral / self.time_sum(t_min, t_max).to_value("d")
 
 
 class ConstantTemporalModel(TemporalModel):
     """Constant temporal model.
@@ -255,15 +292,15 @@
         -------
         norm : float
             Integrated flux norm on the given time intervals
         """
         pars = self.parameters
         alpha = pars["alpha"]
         beta = pars["beta"].quantity
-        t_ref = Time(pars["t_ref"].quantity, format="mjd")
+        t_ref = self.reference_time
         value = alpha * (t_max - t_min) + beta / 2.0 * (
             (t_max - t_ref) * (t_max - t_ref) - (t_min - t_ref) * (t_min - t_ref)
         )
         return value / self.time_sum(t_min, t_max)
 
 
 class ExpDecayTemporalModel(TemporalModel):
@@ -303,15 +340,15 @@
         Returns
         -------
         norm : float
             Integrated flux norm on the given time intervals
         """
         pars = self.parameters
         t0 = pars["t0"].quantity
-        t_ref = Time(pars["t_ref"].quantity, format="mjd")
+        t_ref = self.reference_time
         value = self.evaluate(t_max, t0, t_ref) - self.evaluate(t_min, t0, t_ref)
         return -t0 * value / self.time_sum(t_min, t_max)
 
 
 class GaussianTemporalModel(TemporalModel):
     r"""A Gaussian temporal profile
 
@@ -348,15 +385,15 @@
         Returns
         -------
         norm : float
             Integrated flux norm on the given time intervals
         """
         pars = self.parameters
         sigma = pars["sigma"].quantity
-        t_ref = Time(pars["t_ref"].quantity, format="mjd")
+        t_ref = self.reference_time
         norm = np.sqrt(np.pi / 2) * sigma
 
         u_min = (t_min - t_ref) / (np.sqrt(2) * sigma)
         u_max = (t_max - t_ref) / (np.sqrt(2) * sigma)
 
         integral = norm * (scipy.special.erf(u_max) - scipy.special.erf(u_min))
         return integral / self.time_sum(t_min, t_max)
@@ -412,14 +449,18 @@
 
     The ``norm`` is supposed to be a unit-less multiplicative factor in the model,
     to be multiplied with a spectral model.
 
     The model does linear interpolation for times between the given ``(time, energy, norm)``
     values.
 
+    When the temporal model is energy-dependent, the default interpolation scheme is
+    linear with a log scale for the values. The interpolation method and scale values
+    can be changed with the ``method`` and ``values_scale`` arguments.
+
     For more information see :ref:`LightCurve-temporal-model`.
 
     Examples
     --------
     Read an example light curve object:
 
     >>> from gammapy.modeling.models import LightCurveTemplateTemporalModel
@@ -453,52 +494,68 @@
     >>> light_curve.integral(t_min, t_max)
     array([0.0074388942, 0.0071144081, 0.0068115544])
     """
 
     tag = ["LightCurveTemplateTemporalModel", "template"]
 
     _t_ref_default = Time("2000-01-01")
-    t_ref = Parameter("t_ref", _t_ref_default.mjd, unit="day", frozen=False)
-
-    def __init__(self, map, t_ref=None, filename=None):
+    t_ref = Parameter("t_ref", _t_ref_default.mjd, unit="day", frozen=True)
 
+    def __init__(self, map, t_ref=None, filename=None, method=None, values_scale=None):
         if (map.data < 0).any():
             log.warning("Map has negative values. Check and fix this!")
 
-        if map.geom.has_energy_axis:
-            raise NotImplementedError(
-                "LightCurveTemplateTemporalModel does not"
-                f" support energy axis, got {map.geom.axes.names}"
-            )
-
         self.map = map.copy()
         super().__init__()
 
         if t_ref:
-            self.t_ref.value = Time(t_ref, format="mjd").mjd
+            self.reference_time = t_ref
 
         self.filename = filename
 
+        if method is None:
+            method = "linear"
+
+        if values_scale is None:
+            if self.is_energy_dependent:
+                values_scale = "log"
+            else:
+                values_scale = "lin"
+
+        self.method = method
+        self.values_scale = values_scale
+
     def __str__(self):
         start_time = self.t_ref.quantity + self.map.geom.axes["time"].edges[0]
         end_time = self.t_ref.quantity + self.map.geom.axes["time"].edges[-1]
-        norm_min = np.min(self.map.data)
-        norm_max = np.max(self.map.data)
+        norm_min = np.nanmin(self.map.data)
+        norm_max = np.nanmax(self.map.data)
 
         prnt = (
             f"{self.__class__.__name__} model summary:\n "
             f"Reference time: {self.t_ref.value} MJD \n "
             f"Start time: {start_time.value} MJD \n "
             f"End time: {end_time.value} MJD \n "
             f"Norm min: {norm_min} \n"
             f"Norm max: {norm_max}"
         )
 
+        if self.is_energy_dependent:
+            energy_min = self.map.geom.axes["energy"].center[0]
+            energy_max = self.map.geom.axes["energy"].center[-1]
+            prnt1 = f"Energy min: {energy_min} \n" f"Energy max: {energy_max} \n"
+            prnt = prnt + prnt1
+
         return prnt
 
+    @property
+    def is_energy_dependent(self):
+        """Whether the model is energy dependent"""
+        return self.map.geom.has_energy_axis
+
     @classmethod
     def from_table(cls, table, filename=None):
         """Create a template model from an astropy table
 
         Parameters
         ----------
         table : `~astropy.table.Table`
@@ -511,23 +568,28 @@
         model : `LightCurveTemplateTemporalModel`
             Light curve template model
         """
         columns = [_.lower() for _ in table.colnames]
         if "time" not in columns:
             raise ValueError("A TIME column is necessary")
 
-        t_ref = time_ref_from_dict(table.meta)
+        t_ref = time_ref_from_dict(table.meta, scale="utc")
         nodes = table["TIME"]
-        time_axis = MapAxis.from_nodes(
-            nodes=nodes, name="time", unit=table.meta["TIMEUNIT"]
-        )
+
+        ax_unit = nodes.quantity.unit
+
+        if not ax_unit.is_equivalent("d"):
+            try:
+                ax_unit = u.Unit(table.meta["TIMEUNIT"])
+            except KeyError:
+                raise ValueError("Time unit not found in the table")
+
+        time_axis = MapAxis.from_nodes(nodes=nodes, name="time", unit=ax_unit)
         axes = [time_axis]
-        m = RegionNDMap.create(
-            region=None, axes=axes, meta=table.meta, data=table["NORM"]
-        )
+        m = RegionNDMap.create(region=None, axes=axes, data=table["NORM"])
 
         return cls(m, t_ref=t_ref, filename=filename)
 
     @classmethod
     def read(cls, filename, format="table"):
         """Read a template model
 
@@ -545,29 +607,39 @@
         """
         filename = str(make_path(filename))
         if format == "table":
             table = Table.read(filename)
             return cls.from_table(table, filename=filename)
 
         elif format == "map":
-            m = RegionNDMap.read(filename)
-            t_ref = time_ref_from_dict(m.meta)
+            with fits.open(filename) as hdulist:
+                header = hdulist["SKYMAP_BANDS"].header
+                t_ref = time_ref_from_dict(header)
+                # TODO : Ugly hack to prevent creating a TimeMapAxis
+                # By default, MapAxis.from_table tries to create a
+                # TimeMapAxis, failing which, it creates a normal MapAxis.
+                # This ugly hack forces the fail. We need a normal Axis to
+                # have the evaluate method work
+                hdulist["SKYMAP_BANDS"].header.pop("MJDREFI")
+                m = RegionNDMap.from_hdulist(hdulist)
             return cls(m, t_ref=t_ref, filename=filename)
 
         else:
             raise ValueError(
                 f"Not a valid format: '{format}', choose from: {'table', 'map'}"
             )
 
     def to_table(self):
         """Convert model to an astropy table"""
+        if self.is_energy_dependent:
+            raise NotImplementedError("Not supported for energy dependent models")
         table = Table(
             data=[self.map.geom.axes["time"].center, self.map.quantity],
             names=["TIME", "NORM"],
-            meta=self.map.meta,
+            meta=time_ref_to_dict(self.reference_time, scale=self.scale),
         )
         return table
 
     def write(self, filename, format="table", overwrite=False):
         """Write a model to disk as per the specified format
 
         Parameters:
@@ -583,29 +655,65 @@
         if self.filename is None:
             raise IOError("Missing filename")
 
         if format == "table":
             table = self.to_table()
             table.write(filename, overwrite=overwrite)
         elif format == "map":
-            self.map.write(filename, overwrite=overwrite)
+            # RegionNDMap.from_hdulist does not update the header
+            hdulist = self.map.to_hdulist()
+            hdulist["SKYMAP_BANDS"].header.update(
+                time_ref_to_dict(self.reference_time, scale=self.scale)
+            )
+            hdulist.writeto(filename, overwrite=overwrite)
         else:
             raise ValueError("Not a valid format, choose from ['map', 'table']")
 
-    def evaluate(self, time, t_ref=None):
-        """Evaluate the model at given coordinates."""
+    def evaluate(self, time, t_ref=None, energy=None):
+        """Evaluate the model at given coordinates.
+
+        Parameters
+        ----------
+        time: `~astropy.time.Time`
+            array of times where the model is evaluated;
+        t_ref: `~gammapy.modeling.Parameter`
+            Reference time for the model;
+        energy: `~astropy.units.Quantity`
+            array of energies where the model is evaluated;
 
+        Returns
+        -------
+        values : `~astropy.units.Quantity`
+            Model values
+        """
         if t_ref is None:
-            t_ref = Time(self.t_ref.value, format="mjd")
+            t_ref = self.reference_time
 
         t = (time - t_ref).to_value(self.map.geom.axes["time"].unit)
         coords = {"time": t}
-        val = self.map.interp_by_coord(coords)
+
+        if self.is_energy_dependent:
+            if energy is None:
+                energy = self.map.geom.axes["energy"].center
+
+            coords["energy"] = energy.reshape(-1, 1)
+
+        val = self.map.interp_by_coord(
+            coords, method=self.method, values_scale=self.values_scale
+        )
         val = np.clip(val, 0, a_max=None)
-        return u.Quantity(val, self.map.unit, copy=False)
+        return u.Quantity(val, unit=self.map.unit, copy=False)
+
+    def integral(self, t_min, t_max, oversampling_factor=100, **kwargs):
+        if self.is_energy_dependent:
+            raise NotImplementedError(
+                "Integral not supported for energy dependent models"
+            )
+
+        return super().integral(t_min, t_max, oversampling_factor, **kwargs)
 
     @classmethod
     def from_dict(cls, data):
         data = data["temporal"]
         filename = data["filename"]
         format = data.get("format", "table")
         return cls.read(filename, format)
@@ -614,14 +722,60 @@
         """Create dict for YAML serialisation"""
         data = super().to_dict(full_output)
         data["temporal"]["filename"] = self.filename
         data["temporal"]["format"] = format
         data["temporal"]["unit"] = str(self.map.unit)
         return data
 
+    def plot(self, time_range, ax=None, n_points=100, energy=None, **kwargs):
+        """
+        Plot Temporal Model.
+
+        Parameters
+        ----------
+        time_range : `~astropy.time.Time`
+            times to plot the model
+        ax : `~matplotlib.axes.Axes`, optional
+            Axis to plot on
+        n_points : int
+            Number of bins to plot model
+        energy : `~astropy.units.quantity`
+            energies to compute the model at for energy dependent models, optional
+        **kwargs : dict
+            Keywords forwarded to `~matplotlib.pyplot.errorbar`
+        Returns
+        -------
+        ax : `~matplotlib.axes.Axes`, optional
+            axis
+        """
+        if not self.is_energy_dependent:
+            super().plot(time_range=time_range, ax=ax, n_points=n_points, **kwargs)
+        else:
+            time_min, time_max = Time(time_range, scale=self.scale)
+            time_axis = TimeMapAxis.from_time_bounds(
+                time_min=time_min, time_max=time_max, nbin=n_points
+            )
+            if energy is None:
+                energy_axis = self.map.geom.axes["energy"]
+            else:
+                energy_axis = MapAxis.from_nodes(
+                    nodes=energy, name="energy", interp="log"
+                )
+
+            m = RegionNDMap.create(region=None, axes=[time_axis, energy_axis])
+            kwargs.setdefault("marker", "None")
+            kwargs.setdefault("ls", "-")
+            m.quantity = self.evaluate(
+                time=time_axis.time_mid, energy=energy_axis.center
+            )
+            ax = m.plot(axis_name="time", ax=ax, **kwargs)
+            ax.set_ylabel("Norm / A.U.")
+
+            return ax, m
+
 
 class PowerLawTemporalModel(TemporalModel):
     """Temporal model with a Power Law decay.
 
     For more information see :ref:`powerlaw-temporal-model`.
 
     Parameters
@@ -660,15 +814,15 @@
         -------
         norm : float
             Integrated flux norm on the given time intervals
         """
         pars = self.parameters
         alpha = pars["alpha"].quantity
         t0 = pars["t0"].quantity
-        t_ref = Time(pars["t_ref"].quantity, format="mjd")
+        t_ref = self.reference_time
         if alpha != -1:
             value = self.evaluate(t_max, alpha + 1.0, t_ref, t0) - self.evaluate(
                 t_min, alpha + 1.0, t_ref, t0
             )
             return t0 / (alpha + 1.0) * value / self.time_sum(t_min, t_max)
         else:
             value = np.log((t_max - t_ref) / (t_min - t_ref))
@@ -716,20 +870,21 @@
         -------
         norm : float
             Integrated flux norm on the given time intervals
         """
         pars = self.parameters
         omega = pars["omega"].quantity.to_value("rad/day")
         amp = pars["amp"].value
-        t_ref = Time(pars["t_ref"].quantity, format="mjd")
-        value = (t_max - t_min) - amp / omega * (
-            np.sin(omega * (t_max - t_ref).to_value("day"))
-            - np.sin(omega * (t_min - t_ref).to_value("day"))
+        t_ref = self.reference_time
+
+        value = (t_max - t_min).to_value(u.day) - amp / omega * (
+            np.sin(omega * (t_max - t_ref).to_value(u.day))
+            - np.sin(omega * (t_min - t_ref).to_value(u.day))
         )
-        return value / self.time_sum(t_min, t_max)
+        return value / self.time_sum(t_min, t_max).to_value(u.day)
 
 
 class TemplatePhaseCurveTemporalModel(TemporalModel):
     """Temporal phase curve model.
 
     A timing solution is used to compute the phase corresponding to time and
     a template phase curve is used to determine the associated ``norm``.
@@ -886,15 +1041,15 @@
         norm: The model integrated flux
         """
         kwargs = {par.name: par.quantity for par in self.parameters}
         ph_min, n_min = self._time_to_phase(t_min.mjd * u.d, **kwargs)
         ph_max, n_max = self._time_to_phase(t_max.mjd * u.d, **kwargs)
 
         # here we assume that the frequency does not change during the integration boundaries
-        delta_t = (t_min.mjd - self.t_ref.value) * u.d
+        delta_t = (t_min - self.reference_time).to(u.d)
         frequency = self.f0.quantity + delta_t * (
             self.f1.quantity + delta_t * self.f2.quantity / 2
         )
 
         # Compute integral of one phase
         phase_integral = self._interpolator.antiderivative()(
             1
```

### Comparing `gammapy-1.0rc2/gammapy/modeling/models/tests/data/example2.yaml` & `gammapy-1.1rc1/gammapy/modeling/models/tests/data/example2.yaml`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/modeling/models/tests/data/examples.yaml` & `gammapy-1.1rc1/gammapy/modeling/models/tests/data/examples.yaml`

 * *Files 5% similar despite different names*

```diff
@@ -1,11 +1,12 @@
 components:
 - name: background_irf
   datasets_names: CTA-gc
   type: TemplateNPredModel
+  filename: $GAMMAPY_DATA/tests/models/background_irf.fits
   parameters:
   - name: norm
     value: 1.01
     scale: 1.0
     unit: ''
     min: 0.0
     max: .nan
@@ -26,22 +27,22 @@
     frozen: true
 - name: source0
   type: SkyModel
   spatial:
     type: PointSpatialModel
     parameters:
     - name: lon_0
-      value: -50.
+      value: -0.5
       scale: 0.01
       unit: deg
       min: -180.0
       max: 180.0
       frozen: true
     - name: lat_0
-      value: -0.05
+      value: -0.0005
       scale: 0.01
       unit: deg
       min: -90.0
       max: 90.0
       frozen: true
   spectral:
     type: ExpCutoffPowerLawSpectralModel
@@ -64,15 +65,15 @@
       value: 1.0
       scale: 1.0
       unit: TeV
       min: .nan
       max: .nan
       frozen: true
     - name: lambda_
-      value: 0.06
+      value: 0.006
       scale: 0.1
       unit: TeV-1
       min: .nan
       max: .nan
       frozen: false
 - name: source1
   type: SkyModel
```

### Comparing `gammapy-1.0rc2/gammapy/modeling/models/tests/data/make.py` & `gammapy-1.1rc1/gammapy/modeling/models/tests/data/make.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/modeling/models/tests/test_core.py` & `gammapy-1.1rc1/gammapy/modeling/models/tests/test_core.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/modeling/models/tests/test_cube.py` & `gammapy-1.1rc1/gammapy/modeling/models/tests/test_cube.py`

 * *Files 10% similar despite different names*

```diff
@@ -11,28 +11,33 @@
 from gammapy.data.gti import GTI
 from gammapy.datasets.map import MapEvaluator
 from gammapy.irf import EDispKernel, PSFKernel
 from gammapy.maps import Map, MapAxis, RegionGeom, RegionNDMap, WcsGeom
 from gammapy.modeling import Parameter
 from gammapy.modeling.models import (
     CompoundSpectralModel,
+    ConstantSpatialModel,
     ConstantSpectralModel,
     ConstantTemporalModel,
+    FoVBackgroundModel,
     GaussianSpatialModel,
+    LightCurveTemplateTemporalModel,
     LogParabolaSpectralModel,
     Models,
+    PiecewiseNormSpatialModel,
     PointSpatialModel,
     PowerLawNormSpectralModel,
     PowerLawSpectralModel,
     SkyModel,
     SpatialModel,
     TemplateNPredModel,
     TemplateSpatialModel,
     create_fermi_isotropic_diffuse_model,
 )
+from gammapy.utils.scripts import make_path
 from gammapy.utils.testing import mpl_plot_check, requires_data
 
 
 @pytest.fixture(scope="session")
 def sky_model():
     spatial_model = GaussianSpatialModel(
         lon_0="3 deg", lat_0="4 deg", sigma="3 deg", frame="galactic"
@@ -138,22 +143,39 @@
 @pytest.fixture(scope="session")
 def sky_models_2(sky_model):
     sky_model_4 = sky_model.copy(name="source-4")
     sky_model_5 = sky_model.copy(name="source-5")
     return Models([sky_model_4, sky_model_5])
 
 
+@requires_data()
 def test_sky_model_init():
     with pytest.raises(TypeError):
         spatial_model = GaussianSpatialModel()
         SkyModel(spectral_model=1234, spatial_model=spatial_model)
 
     with pytest.raises(TypeError):
         SkyModel(spectral_model=PowerLawSpectralModel(), spatial_model=1234)
 
+    # test init of energy dependent temporal models
+    filename = make_path(
+        "$GAMMAPY_DATA/gravitational_waves/GW_example_DC_map_file.fits.gz"
+    )
+    temporal_model = LightCurveTemplateTemporalModel.read(filename, format="map")
+    spatial_model = PointSpatialModel()
+    spectral_model_fake = ConstantSpectralModel()
+
+    model = SkyModel(
+        spatial_model=spatial_model,
+        spectral_model=spectral_model_fake,
+        temporal_model=temporal_model,
+        name="test-source",
+    )
+    assert model.name == "test-source"
+
 
 def test_sky_model_spatial_none_io(tmpdir):
     pwl = PowerLawSpectralModel()
     model = SkyModel(spectral_model=pwl, name="test")
     models = Models([model])
 
     filename = tmpdir / "test-models-none.yaml"
@@ -217,24 +239,30 @@
     assert_allclose(npred2.data.sum(), 7.352e-06, rtol=1e-3)
 
 
 def test_background_model_io(tmpdir, background):
     filename = str(tmpdir / "test-bkg-file.fits")
     bkg = TemplateNPredModel(background, filename=filename)
     bkg.spectral_model.norm.value = 2.0
-    bkg.map.write(filename, overwrite=True)
+    bkg.write(overwrite=True)
     bkg_dict = bkg.to_dict()
     bkg_read = bkg.from_dict(bkg_dict)
 
     assert_allclose(
         bkg_read.evaluate().data.sum(), background.data.sum() * 2.0, rtol=1e-3
     )
     assert bkg_read.filename == filename
 
 
+def test_background_model_io_missing_file(tmpdir, background):
+    bkg = TemplateNPredModel(background, filename=None)
+    with pytest.raises(IOError):
+        bkg.write(overwrite=True)
+
+
 def test_background_model_copy(background):
     background_copy = background.copy()
     bkg = TemplateNPredModel(background_copy)
     bkg.map.data += 1.0
     assert np.all(
         background_copy.data == background.data
     )  # Check that the original map is unchanged
@@ -423,15 +451,15 @@
         )
         assert model.map.unit == "cm-2 s-1 MeV-1 sr-1"
 
         # Check pixel inside map
         val = model.evaluate(0 * u.deg, 0 * u.deg, 100 * u.GeV)
         assert val.unit == "cm-2 s-1 MeV-1 sr-1"
         assert val.shape == (1,)
-        assert_allclose(val.value, 1.396424e-12, rtol=1e-5)
+        assert_allclose(val.value, 1.395156e-12, rtol=1e-5)
 
     @staticmethod
     def test_evaluation_radius(diffuse_model):
         radius = diffuse_model.evaluation_radius
         assert radius.unit == "deg"
         assert_allclose(radius.value, 4)
 
@@ -716,7 +744,104 @@
 
 def test_sky_model_contributes_point_region():
     model = SkyModel.create("pl", "point")
 
     geom = RegionGeom.create("icrs;point(0.05, 0.05)", binsz_wcs="0.01 deg")
     mask = RegionNDMap.from_geom(geom)
     assert np.any(model.contributes(mask))
+
+
+def test_spatial_model_background(background):
+
+    geom = background.geom
+
+    spatial_model = ConstantSpatialModel(frame="galactic")
+    identical_npred = TemplateNPredModel(
+        background, spatial_model=spatial_model
+    ).evaluate()
+    assert_allclose(identical_npred, background.data)
+
+    reference = FoVBackgroundModel(
+        spatial_model=None, dataset_name="test"
+    ).evaluate_geom(geom)
+    identical = FoVBackgroundModel(
+        spatial_model=spatial_model, dataset_name="test"
+    ).evaluate_geom(geom)
+    assert_allclose(identical, reference)
+
+    spatial_model2 = ConstantSpatialModel(frame="galactic")
+    spatial_model2.value.value = 2
+    twice_npred = TemplateNPredModel(
+        background, spatial_model=spatial_model2
+    ).evaluate()
+    assert_allclose(twice_npred, background.data * 2)
+
+    twice = FoVBackgroundModel(
+        spatial_model=spatial_model2, dataset_name="test"
+    ).evaluate_geom(geom)
+    assert_allclose(twice, reference * 2)
+
+
+def test_spatial_model_io_background(tmp_path, background):
+
+    spatial_model = ConstantSpatialModel(frame="galactic")
+
+    fbkg_irf = str(tmp_path / "background_irf_test.fits")
+
+    model = TemplateNPredModel(background, spatial_model=None, filename=fbkg_irf)
+    model.write()
+
+    model_dict = model.to_dict()
+    assert "spatial" not in model_dict
+    new_model = TemplateNPredModel.from_dict(model_dict)
+    assert new_model.spatial_model is None
+
+    model = TemplateNPredModel(
+        background, spatial_model=spatial_model, filename=fbkg_irf
+    )
+    model_dict = model.to_dict()
+    assert "spatial" in model_dict
+    new_model = TemplateNPredModel.from_dict(model_dict)
+    assert isinstance(new_model.spatial_model, ConstantSpatialModel)
+
+    model = FoVBackgroundModel(spatial_model=None, dataset_name="test")
+    model_dict = model.to_dict()
+    assert "spatial" not in model_dict
+    new_model = FoVBackgroundModel.from_dict(model_dict)
+    assert new_model.spatial_model is None
+
+    model = FoVBackgroundModel(spatial_model=spatial_model, dataset_name="test")
+    model_dict = model.to_dict()
+    assert "spatial" in model_dict
+    new_model = FoVBackgroundModel.from_dict(model_dict)
+    assert isinstance(new_model.spatial_model, ConstantSpatialModel)
+
+
+def test_piecewise_spatial_model_background(background):
+
+    geom = background.geom
+    coords = geom.to_image().get_coord().flat
+
+    spatial_model = PiecewiseNormSpatialModel(coords, frame="galactic")
+    identical_npred = TemplateNPredModel(
+        background, spatial_model=spatial_model
+    ).evaluate()
+    assert_allclose(identical_npred, background.data)
+
+    reference = Map.from_geom(geom, data=1)
+    identical = FoVBackgroundModel(
+        spatial_model=spatial_model, dataset_name="test"
+    ).evaluate_geom(geom)
+    assert_allclose(identical, reference)
+
+    spatial_model2 = PiecewiseNormSpatialModel(
+        coords, norms=2 * np.ones(coords.shape[0]), frame="galactic"
+    )
+    twice_npred = TemplateNPredModel(
+        background, spatial_model=spatial_model2
+    ).evaluate()
+    assert_allclose(twice_npred, background.data * 2)
+
+    twice = FoVBackgroundModel(
+        spatial_model=spatial_model2, dataset_name="test"
+    ).evaluate_geom(geom)
+    assert_allclose(twice, reference * 2.0)
```

### Comparing `gammapy-1.0rc2/gammapy/modeling/models/tests/test_io.py` & `gammapy-1.1rc1/gammapy/modeling/models/tests/test_io.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,30 +1,30 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import operator
-
 import pytest
 import numpy as np
 from numpy.testing import assert_allclose
 import astropy.units as u
 from astropy.utils.data import get_pkg_data_filename
 from gammapy.maps import Map, MapAxis, RegionNDMap
 from gammapy.modeling.models import (
     MODEL_REGISTRY,
+    CompoundSpectralModel,
     ConstantTemporalModel,
     EBLAbsorptionNormSpectralModel,
     ExpDecayTemporalModel,
+    FoVBackgroundModel,
     GaussianTemporalModel,
     LinearTemporalModel,
+    LogParabolaSpectralModel,
     Model,
     Models,
     PiecewiseNormSpectralModel,
     PowerLawSpectralModel,
-    LogParabolaSpectralModel,
     PowerLawTemporalModel,
-    CompoundSpectralModel,
     SineTemporalModel,
     SkyModel,
     TemplateNPredModel,
 )
 from gammapy.utils.scripts import read_yaml, write_yaml
 from gammapy.utils.testing import requires_data
 
@@ -36,15 +36,14 @@
     models_data = read_yaml(filename)
     models = Models.from_dict(models_data)
     return models
 
 
 @requires_data()
 def test_dict_to_skymodels(models):
-
     assert len(models) == 5
 
     model0 = models[0]
     assert isinstance(model0, TemplateNPredModel)
     assert model0.name == "background_irf"
 
     model0 = models[1]
@@ -104,69 +103,152 @@
     assert "TemplateSpectralModel" in model2.spectral_model.tag
     assert "TemplateSpatialModel" in model2.spatial_model.tag
 
     assert not model2.spatial_model.normalize
 
 
 @requires_data()
-def test_sky_models_io(tmp_path, models):
+def test_sky_models_io(tmpdir, models):
     # TODO: maybe change to a test case where we create a model programmatically?
     models.covariance = np.eye(len(models.parameters))
-    models.write(tmp_path / "tmp.yaml", full_output=True)
-    models = Models.read(tmp_path / "tmp.yaml")
+    models.write(tmpdir / "tmp.yaml", full_output=True, overwrite_templates=False)
+    models = Models.read(tmpdir / "tmp.yaml")
+
     assert models._covar_file == "tmp_covariance.dat"
+
     assert_allclose(models.covariance.data, np.eye(len(models.parameters)))
     assert_allclose(models.parameters["lat_0"].min, -90.0)
 
     # TODO: not sure if we should just round-trip, or if we should
     # check YAML file content (e.g. against a ref file in the repo)
     # or check serialised dict content
 
 
+@requires_data()
+def test_sky_models_io_auto_write(tmp_path, models):
+    models_new = models.copy()
+    fsource2 = str(tmp_path / "source2_test.fits")
+    fbkg_iem = str(tmp_path / "cube_iem_test.fits")
+    fbkg_irf = str(tmp_path / "background_irf_test.fits")
+
+    models_new["source2"].spatial_model.filename = fsource2
+    models_new["cube_iem"].spatial_model.filename = fbkg_iem
+    models_new["background_irf"].filename = fbkg_irf
+    models_new.write(tmp_path / "tmp.yaml", full_output=True)
+
+    models = Models.read(tmp_path / "tmp.yaml")
+    assert models._covar_file == "tmp_covariance.dat"
+    assert models["source2"].spatial_model.filename == fsource2
+    assert models["cube_iem"].spatial_model.filename == fbkg_iem
+    assert models["background_irf"].filename == fbkg_irf
+
+    assert_allclose(
+        models_new["source2"].spatial_model.map.data,
+        models["source2"].spatial_model.map.data,
+    )
+    assert_allclose(
+        models_new["cube_iem"].spatial_model.map.data,
+        models["cube_iem"].spatial_model.map.data,
+    )
+    assert_allclose(
+        models_new["background_irf"].map.data, models["background_irf"].map.data
+    )
+
+
 def test_piecewise_norm_spectral_model_init():
     with pytest.raises(ValueError):
         PiecewiseNormSpectralModel(
-            energy=[
-                1,
-            ]
-            * u.TeV,
+            energy=[1] * u.TeV,
             norms=[1, 5],
         )
 
     with pytest.raises(ValueError):
         PiecewiseNormSpectralModel(
-            energy=[
-                1,
-            ]
-            * u.TeV,
-            norms=[
-                1,
-            ],
+            energy=[1] * u.TeV,
+            norms=[1],
         )
 
 
 def test_piecewise_norm_spectral_model_io():
     energy = [1, 3, 7, 10] * u.TeV
     norms = [1, 5, 3, 0.5] * u.Unit("")
 
     model = PiecewiseNormSpectralModel(energy=energy, norms=norms)
-    model.parameters[0].value = 2
+    model.parameters["norm_0"].value = 2
 
     model_dict = model.to_dict()
 
     parnames = [_["name"] for _ in model_dict["spectral"]["parameters"]]
     for k, parname in enumerate(parnames):
         assert parname == f"norm_{k}"
 
     new_model = PiecewiseNormSpectralModel.from_dict(model_dict)
 
-    assert_allclose(new_model.parameters[0].value, 2)
+    assert_allclose(new_model.parameters["norm_0"].value, 2)
     assert_allclose(new_model.energy, energy)
     assert_allclose(new_model.norms, [2, 5, 3, 0.5])
 
+    bkg = FoVBackgroundModel(spectral_model=model, dataset_name="")
+    bkg_dict = bkg.to_dict()
+    new_bkg = FoVBackgroundModel.from_dict(bkg_dict)
+
+    assert_allclose(new_bkg.spectral_model.parameters["norm_0"].value, 2)
+    assert_allclose(new_bkg.spectral_model.energy, energy)
+    assert_allclose(new_bkg.spectral_model.norms, [2, 5, 3, 0.5])
+
+
+@requires_data()
+def test_absorption_io_invalid_path(tmp_path):
+    dominguez = EBLAbsorptionNormSpectralModel.read_builtin("dominguez", redshift=0.5)
+    dominguez.filename = "/not/a/valid/path/ebl_dominguez11.fits.gz"
+    assert len(dominguez.parameters) == 2
+
+    model_dict = dominguez.to_dict()
+    parnames = [_["name"] for _ in model_dict["spectral"]["parameters"]]
+    assert parnames == [
+        "alpha_norm",
+        "redshift",
+    ]
+    new_model = EBLAbsorptionNormSpectralModel.from_dict(model_dict)
+
+    assert new_model.redshift.value == 0.5
+    assert new_model.alpha_norm.name == "alpha_norm"
+    assert new_model.alpha_norm.value == 1
+    assert_allclose(new_model.energy, dominguez.energy)
+    assert_allclose(new_model.param, dominguez.param)
+    assert len(new_model.parameters) == 2
+
+    dominguez.filename = "/not/a/valid/path/dominguez.fits.gz"
+    model_dict = dominguez.to_dict()
+    with pytest.raises(IOError):
+        EBLAbsorptionNormSpectralModel.from_dict(model_dict)
+
+
+@requires_data()
+def test_absorption_io_no_filename(tmp_path):
+    dominguez = EBLAbsorptionNormSpectralModel.read_builtin("dominguez", redshift=0.5)
+    dominguez.filename = None
+    assert len(dominguez.parameters) == 2
+
+    model_dict = dominguez.to_dict()
+    parnames = [_["name"] for _ in model_dict["spectral"]["parameters"]]
+    assert parnames == [
+        "alpha_norm",
+        "redshift",
+    ]
+
+    new_model = EBLAbsorptionNormSpectralModel.from_dict(model_dict)
+
+    assert new_model.redshift.value == 0.5
+    assert new_model.alpha_norm.name == "alpha_norm"
+    assert new_model.alpha_norm.value == 1
+    assert_allclose(new_model.energy, dominguez.energy)
+    assert_allclose(new_model.param, dominguez.param)
+    assert len(new_model.parameters) == 2
+
 
 @requires_data()
 def test_absorption_io(tmp_path):
     dominguez = EBLAbsorptionNormSpectralModel.read_builtin("dominguez", redshift=0.5)
     assert len(dominguez.parameters) == 2
 
     model_dict = dominguez.to_dict()
@@ -342,15 +424,14 @@
         if "@" in line:
             assert "reference" in line
             n_link += 1
     assert n_link == 2
 
 
 def test_to_dict_not_default():
-
     model = PowerLawSpectralModel()
     model.index.min = -1
     model.index.max = -5
     model.index.frozen = True
     mdict = model.to_dict(full_output=False)
 
     index_dict = mdict["spectral"]["parameters"][0]
@@ -365,15 +446,14 @@
     model_2 = model.from_dict(mdict)
     assert model_2.index.min == model.index.min
     assert model_2.index.max == model.index.max
     assert model_2.index.frozen == model.index.frozen
 
 
 def test_to_dict_unfreeze_parameters_frozen_by_default():
-
     model = PowerLawSpectralModel()
 
     mdict = model.to_dict(full_output=False)
     index_dict = mdict["spectral"]["parameters"][2]
     assert "frozen" not in index_dict
 
     model.reference.frozen = False
```

### Comparing `gammapy-1.0rc2/gammapy/modeling/models/tests/test_management.py` & `gammapy-1.1rc1/gammapy/modeling/models/tests/test_management.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/modeling/models/tests/test_spatial.py` & `gammapy-1.1rc1/gammapy/modeling/models/tests/test_spatial.py`

 * *Files 15% similar despite different names*

```diff
@@ -8,23 +8,26 @@
 from regions import (
     CircleAnnulusSkyRegion,
     CircleSkyRegion,
     EllipseSkyRegion,
     PointSkyRegion,
     RectangleSkyRegion,
 )
-from gammapy.maps import Map, MapAxis, RegionGeom, WcsGeom
+from gammapy.maps import Map, MapAxis, MapCoord, RegionGeom, WcsGeom
 from gammapy.modeling.models import (
     ConstantSpatialModel,
     DiskSpatialModel,
     GaussianSpatialModel,
     GeneralizedGaussianSpatialModel,
+    PiecewiseNormSpatialModel,
     PointSpatialModel,
+    PowerLawSpectralModel,
     Shell2SpatialModel,
     ShellSpatialModel,
+    SkyModel,
     TemplateSpatialModel,
 )
 from gammapy.utils.testing import mpl_plot_check, requires_data
 
 
 def test_sky_point_source():
     geom = WcsGeom.create(skydir=(2.4, 2.3), npix=(10, 10), binsz=0.3)
@@ -219,14 +222,72 @@
     value_edge_pwidth = model(0 * u.deg, r_0 + edge / 2)
     assert_allclose((value_edge_pwidth / value_center).to_value(""), 0.05)
 
     value_edge_nwidth = model(0 * u.deg, r_0 - edge / 2)
     assert_allclose((value_edge_nwidth / value_center).to_value(""), 0.95)
 
 
+def test_disk_from_region():
+    region = EllipseSkyRegion(
+        center=SkyCoord(20, 17, unit="deg"),
+        height=0.3 * u.deg,
+        width=1.0 * u.deg,
+        angle=30 * u.deg,
+    )
+    disk = DiskSpatialModel.from_region(region, frame="galactic")
+    assert_allclose(disk.parameters["lon_0"].value, 132.666, rtol=1e-2)
+    assert_allclose(disk.parameters["lat_0"].value, -45.33118067, rtol=1e-2)
+    assert_allclose(disk.parameters["r_0"].quantity, 0.5 * u.deg, rtol=1e-2)
+    assert_allclose(disk.parameters["e"].value, 0.9539, rtol=1e-2)
+    assert_allclose(disk.parameters["phi"].quantity, 110.946048 * u.deg)
+
+    reg1 = disk.to_region()
+    assert_allclose(reg1.height, region.width, rtol=1e-2)
+
+    center = SkyCoord(20, 17, unit="deg", frame="galactic")
+    region = EllipseSkyRegion(
+        center=center,
+        height=1 * u.deg,
+        width=0.3 * u.deg,
+        angle=30 * u.deg,
+    )
+    disk = DiskSpatialModel.from_region(region, frame="icrs")
+    reg1 = disk.to_region()
+    assert_allclose(reg1.angle, -30.323 * u.deg, rtol=1e-2)
+    assert_allclose(reg1.height, region.height, rtol=1e-3)
+
+    region = CircleSkyRegion(center=region.center, radius=1.0 * u.deg)
+    disk = DiskSpatialModel.from_region(region)
+    assert_allclose(disk.parameters["e"].value, 0.0, rtol=1e-2)
+    assert_allclose(disk.parameters["lon_0"].value, 20, rtol=1e-2)
+    assert disk.frame == "galactic"
+
+    geom = WcsGeom.create(skydir=center, npix=(10, 10), binsz=0.3)
+    res = disk.evaluate_geom(geom)
+    assert_allclose(np.sum(res.value), 50157.904662)
+
+    region = PointSkyRegion(center=region.center)
+    with pytest.raises(ValueError):
+        DiskSpatialModel.from_region(region)
+
+
+def test_from_position():
+    center = SkyCoord(20, 17, unit="deg")
+    spatial_model = GaussianSpatialModel.from_position(
+        position=center, sigma=0.5 * u.deg
+    )
+    geom = WcsGeom.create(skydir=center, npix=(10, 10), binsz=0.3)
+    res = spatial_model.evaluate_geom(geom)
+    assert_allclose(np.sum(res.value), 36307.440813)
+    model = SkyModel(
+        spectral_model=PowerLawSpectralModel(), spatial_model=spatial_model
+    )
+    assert_allclose(model.position.ra.value, center.ra.value, rtol=1e-3)
+
+
 def test_sky_shell():
     width = 2 * u.deg
     rad = 2 * u.deg
     model = ShellSpatialModel(lon_0="1 deg", lat_0="45 deg", radius=rad, width=width)
     lon = [1, 2, 4] * u.deg
     lat = 45 * u.deg
     val = model(lon, lat)
@@ -280,28 +341,28 @@
 
     assert "WARNING" in [_.levelname for _ in caplog.records]
     assert "Missing spatial template unit, assuming sr^-1" in [
         _.message for _ in caplog.records
     ]
 
     assert val.unit == "sr-1"
-    desired = [3269.178107, 0]
+    desired = [3265.6559, 0]
     assert_allclose(val.value, desired)
 
     res = model.evaluate_geom(model.map.geom)
     assert_allclose(np.sum(res.value), 32826159.74707)
     radius = model.evaluation_radius
 
     assert radius.unit == "deg"
     assert_allclose(radius.value, 0.64, rtol=1.0e-2)
     assert model.frame == "fk5"
     assert isinstance(model.to_region(), RectangleSkyRegion)
 
     with pytest.raises(TypeError):
-        model.plot_interative()
+        model.plot_interactive()
 
     with pytest.raises(TypeError):
         model.plot_grid()
 
 
 @requires_data()
 def test_sky_diffuse_map_3d():
@@ -466,18 +527,58 @@
     geom = RegionGeom(region=square, axes=[axis])
 
     integral = model.integrate_geom(geom).data
 
     assert_allclose(integral, 1, rtol=0.0001)
 
 
-def test_temlatemap_clip():
+def test_templatemap_clip():
     model_map = Map.create(map_type="wcs", width=(2, 2), binsz=0.5, unit="sr-1")
     model_map.data += 1.0
     model = TemplateSpatialModel(model_map)
     model.map.data = model.map.data * -1
 
     lon = np.array([0, 0.2, 0.3]) * u.deg
     lat = np.array([0, 0.2, 0.3]) * u.deg
 
     val = model.evaluate(lon, lat)
     assert_allclose(val, 0, rtol=0.0001)
+
+
+def test_piecewise_spatial_model():
+    geom = WcsGeom.create(skydir=(2.4, 2.3), npix=(2, 2), binsz=0.3, frame="galactic")
+    coords = MapCoord.create(geom.footprint)
+    coords["lon"] *= u.deg
+    coords["lat"] *= u.deg
+
+    model = PiecewiseNormSpatialModel(coords, frame="galactic")
+
+    assert_allclose(model(*geom.to_image().center_coord), 1.0)
+
+    norms = np.arange(coords.shape[0])
+
+    model = PiecewiseNormSpatialModel(coords, norms, frame="galactic")
+
+    assert not model.is_energy_dependent
+
+    expected = np.array([[0, 3], [1, 2]])
+    assert_allclose(model(*geom.to_image().get_coord()), expected, atol=1e-5)
+
+    assert_allclose(model.evaluate_geom(geom.to_image()), expected, atol=1e-5)
+
+    assert_allclose(model.evaluate_geom(geom), expected, atol=1e-5)
+
+    model_dict = model.to_dict()
+    new_model = PiecewiseNormSpatialModel.from_dict(model_dict)
+
+    assert_allclose(new_model.evaluate_geom(geom.to_image()), expected, atol=1e-5)
+
+
+def test_piecewise_spatial_model_3d():
+    axis = MapAxis.from_energy_bounds("1 TeV", "10 TeV", nbin=3)
+    geom = WcsGeom.create(
+        skydir=(2.4, 2.3), npix=(2, 2), binsz=0.3, frame="galactic", axes=[axis]
+    )
+    coords = geom.get_coord().flat
+
+    with pytest.raises(ValueError):
+        PiecewiseNormSpatialModel(coords, frame="galactic")
```

### Comparing `gammapy-1.0rc2/gammapy/modeling/models/tests/test_spectral.py` & `gammapy-1.1rc1/gammapy/modeling/models/tests/test_spectral.py`

 * *Files 4% similar despite different names*

```diff
@@ -433,34 +433,42 @@
         amplitude=1e-12 * u.Unit("TeV-1 cm-2 s-1"), reference=1 * u.Unit("TeV"), index=2
     )
     pwl.amplitude.error = 0.1e-12 * u.Unit("TeV-1 cm-2 s-1")
 
     with mpl_plot_check():
         ax1 = pwl.plot((1 * u.TeV, 100 * u.TeV), sed_type="dnde")
         ax2 = pwl.plot_error((1 * u.TeV, 100 * u.TeV), sed_type="dnde")
-        assert ax1.axes.axes.get_ylabel() == "dnde [1 / (cm2 s TeV)]"
-        assert ax2.axes.axes.get_ylabel() == "dnde [1 / (cm2 s TeV)]"
+        assert ax1.yaxis.units == u.Unit("1 / (s cm2 TeV)")
+        assert ax1.axes.axes.get_ylabel().split()[0] == "dnde"
+        assert ax2.yaxis.units == u.Unit("1 / (s cm2 TeV)")
+        assert ax2.axes.axes.get_ylabel().split()[0] == "dnde"
 
     with mpl_plot_check():
         ax1 = pwl.plot((1 * u.TeV, 100 * u.TeV), sed_type="e2dnde")
         ax2 = pwl.plot_error((1 * u.TeV, 100 * u.TeV), sed_type="e2dnde")
-        assert ax1.axes.axes.get_ylabel() == "e2dnde [erg / (cm2 s)]"
-        assert ax2.axes.axes.get_ylabel() == "e2dnde [erg / (cm2 s)]"
+        assert ax1.yaxis.units == u.Unit("erg / (cm2 s)")
+        assert ax1.axes.axes.get_ylabel().split()[0] == "e2dnde"
+        assert ax2.yaxis.units == u.Unit("erg / (cm2 s)")
+        assert ax2.axes.axes.get_ylabel().split()[0] == "e2dnde"
 
     with mpl_plot_check():
         ax1 = pwl.plot((1 * u.TeV, 100 * u.TeV), sed_type="flux")
         ax2 = pwl.plot_error((1 * u.TeV, 100 * u.TeV), sed_type="flux")
-        assert ax1.axes.axes.get_ylabel() == "flux [1 / (cm2 s)]"
-        assert ax2.axes.axes.get_ylabel() == "flux [1 / (cm2 s)]"
+        assert ax1.yaxis.units == u.Unit("1 / (s cm2)")
+        assert ax1.axes.axes.get_ylabel().split()[0] == "flux"
+        assert ax2.yaxis.units == u.Unit("1 / (s cm2)")
+        assert ax2.axes.axes.get_ylabel().split()[0] == "flux"
 
     with mpl_plot_check():
         ax1 = pwl.plot((1 * u.TeV, 100 * u.TeV), sed_type="eflux")
         ax2 = pwl.plot_error((1 * u.TeV, 100 * u.TeV), sed_type="eflux")
-        assert ax1.axes.axes.get_ylabel() == "eflux [erg / (cm2 s)]"
-        assert ax2.axes.axes.get_ylabel() == "eflux [erg / (cm2 s)]"
+        assert ax1.yaxis.units == u.Unit("erg / (cm2 s)")
+        assert ax1.axes.axes.get_ylabel().split()[0] == "eflux"
+        assert ax2.yaxis.units == u.Unit("erg / (cm2 s)")
+        assert ax2.axes.axes.get_ylabel().split()[0] == "eflux"
 
 
 def test_to_from_dict():
     spectrum = TEST_MODELS[1]
     model = spectrum["model"]
 
     model_dict = model.to_dict()
@@ -666,14 +674,35 @@
     assert model_dict["spectral"]["operator"] == "mul"
     model_class = SPECTRAL_MODEL_REGISTRY.get_cls(model_dict["spectral"]["type"])
     new_model = model_class.from_dict(model_dict)
     assert isinstance(new_model, CompoundSpectralModel)
     assert np.allclose(new_model(energy), 2 * values)
 
 
+def test_evaluate_spectral_model_compound():
+    energy = [1.00e06, 1.25e06, 1.58e06, 1.99e06] * u.MeV
+    model = TEST_MODELS[-2]["model"]
+    values = model.evaluate(energy, *[p.quantity for p in model.parameters])
+    assert_allclose(values, model(energy))
+
+    model = TEST_MODELS[-3]["model"]
+    values = model.evaluate(energy, *[p.quantity for p in model.parameters])
+    assert_allclose(values, model(energy))
+
+
+def test_evaluate_nested_spectral_model_compound():
+    energy = [1.00e06, 1.25e06, 1.58e06, 1.99e06] * u.MeV
+    model1 = TEST_MODELS[-2]["model"]
+    model2 = TEST_MODELS[-3]["model"]
+
+    model = model1 + model2
+    values = model.evaluate(energy, *[p.quantity for p in model.parameters])
+    assert_allclose(values, model(energy))
+
+
 @requires_dependency("naima")
 class TestNaimaModel:
     # Used to test model value at 2 TeV
     energy = 2 * u.TeV
 
     # Used to test model integral and energy flux
     energy_min = 1 * u.TeV
@@ -882,15 +911,15 @@
 class TestSpectralModelErrorPropagation:
     """Test spectral model error propagation.
 
     https://github.com/gammapy/gammapy/blob/master/docs/development/pigs/pig-014.rst#proposal
     https://nbviewer.jupyter.org/github/gammapy/gammapy-extra/blob/master/experiments/uncertainty_estimation_prototype.ipynb
     """
 
-    def setup(self):
+    def setup_method(self):
         self.model = LogParabolaSpectralModel(
             amplitude=3.76e-11 * u.Unit("cm-2 s-1 TeV-1"),
             reference=1 * u.TeV,
             alpha=2.44,
             beta=0.25,
         )
         self.model.covariance = [
@@ -928,14 +957,26 @@
     def test_energy_flux_error(self):
         out = self.model.energy_flux_error(1 * u.TeV, 10 * u.TeV)
         assert out.unit == "TeV cm-2 s-1"
         assert out.shape == (2,)
         assert_allclose(out.data, [4.119e-11, 8.157e-12], rtol=1e-3)
 
 
+def test_logpar_index_error():
+    model = LogParabolaSpectralModel(
+        amplitude=3.81e-11 / u.cm**2 / u.s / u.TeV,
+        reference=1 * u.TeV,
+        alpha=2.19,
+        beta=0.226,
+    )
+    model.alpha.error = 0.4
+    out = model.spectral_index_error(energy=1.0 * u.TeV)
+    assert_allclose(out, [2.19, 0.4], rtol=1e-3)
+
+
 def test_dnde_error_ecpl_model():
     # Regression test for ECPL model
     # https://github.com/gammapy/gammapy/issues/2007
     model = ExpCutoffPowerLawSpectralModel(
         amplitude=2.076183759227292e-12 * u.Unit("cm-2 s-1 TeV-1"),
         index=1.8763343736076483,
         lambda_=0.08703226432146616 * u.Unit("TeV-1"),
@@ -1125,7 +1166,13 @@
     template.filename = str(tmpdir / "template_ND_ebl_franceschini.fits")
     template.write()
     dict_ = template.to_dict()
     template_new = TemplateNDSpectralModel.from_dict(dict_)
     assert_allclose(template_new.map.data, region_map.data)
     assert len(template.parameters) == 1
     assert_allclose(template.parameters["redshift"].value, 0.1)
+
+
+def test_is_norm_spectral_models():
+    for test_model in TEST_MODELS:
+        m = test_model["model"]
+        assert np.any([p.is_norm for p in m.parameters])
```

### Comparing `gammapy-1.0rc2/gammapy/modeling/models/tests/test_spectral_cosmic_ray.py` & `gammapy-1.1rc1/gammapy/modeling/models/tests/test_spectral_cosmic_ray.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/modeling/models/tests/test_spectral_crab.py` & `gammapy-1.1rc1/gammapy/modeling/models/tests/test_spectral_crab.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/modeling/models/tests/test_temporal.py` & `gammapy-1.1rc1/gammapy/modeling/models/tests/test_temporal.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import pytest
 import numpy as np
 from numpy.testing import assert_allclose
 from astropy import units as u
 from astropy.table import Table
 from astropy.time import Time
-from gammapy.data.gti import GTI
 from gammapy.modeling.models import (
     ConstantTemporalModel,
     ExpDecayTemporalModel,
     GaussianTemporalModel,
     GeneralizedGaussianTemporalModel,
     LightCurveTemplateTemporalModel,
     LinearTemporalModel,
@@ -42,35 +41,91 @@
 @requires_data()
 def test_light_curve_evaluate(light_curve):
     t = Time(59500, format="mjd")
     val = light_curve(t)
     assert_allclose(val, 0.015512, rtol=1e-5)
 
 
+@requires_data()
+def test_energy_dependent_lightcurve(tmp_path):
+    filename = "$GAMMAPY_DATA/gravitational_waves/GW_example_DC_map_file.fits.gz"
+    mod = LightCurveTemplateTemporalModel.read(filename, format="map")
+
+    assert mod.is_energy_dependent is True
+
+    t = Time(55555.6157407407, format="mjd")
+    val = mod.evaluate(t, energy=[0.3, 2] * u.TeV)
+    assert_allclose(val.data, [[2.278068e-21], [4.280503e-23]], rtol=1e-5)
+
+    t = Time([55555, 55556, 55557], format="mjd")
+    val = mod.evaluate(t)
+    assert val.data.shape == (41, 3)
+
+    with mpl_plot_check():
+        mod.plot(
+            time_range=(Time(55555.50, format="mjd"), Time(55563.0, format="mjd")),
+            energy=[0.3, 2, 10.0] * u.TeV,
+        )
+    filename = make_path(tmp_path / "test.fits")
+    with pytest.raises(NotImplementedError):
+        mod.write(filename=filename, format="table", overwrite=True)
+    with pytest.raises(NotImplementedError):
+        time_start = Time("2010-01-01T00:00:00") + [1, 3, 5] * u.hour
+        time_stop = Time("2010-01-01T00:00:00") + [2, 3.5, 6] * u.hour
+        mod.integral(time_start, time_stop)
+
+
 def ph_curve(x, amplitude=0.5, x0=0.01):
     return 100.0 + amplitude * np.sin(2 * np.pi * (x - x0) / 1.0)
 
 
 @requires_data()
 def test_light_curve_to_from_table(light_curve):
     table = light_curve.to_table()
-    lc1 = LightCurveTemplateTemporalModel.from_table((table))
+    assert_allclose(table.meta["MJDREFI"], 59000)
+    assert_allclose(table.meta["MJDREFF"], 0.4991992, rtol=1e-6)
+    assert table.meta["TIMESYS"] == "utc"
+    lc1 = LightCurveTemplateTemporalModel.from_table(table)
     assert lc1.map == light_curve.map
+    assert_allclose(
+        lc1.reference_time.value, Time(59000.5, format="mjd").value, rtol=1e-2
+    )
+
+    # test failing cases
+    table1 = table.copy()
+    table1["TIME"].unit = None
+    table.meta = None
+    with pytest.raises(ValueError, match="Time unit not found in the table"):
+        LightCurveTemplateTemporalModel.from_table(table1)
 
 
 @requires_data()
 def test_light_curve_to_dict(light_curve):
     data = light_curve.to_dict()
     assert data["temporal"]["format"] == "table"
     assert data["temporal"]["unit"] == ""
     assert data["temporal"]["type"] == "LightCurveTemplateTemporalModel"
     assert data["temporal"]["parameters"][0]["name"] == "t_ref"
 
-    l1 = LightCurveTemplateTemporalModel.from_dict(data)
-    assert l1.map == light_curve.map
+    lc1 = LightCurveTemplateTemporalModel.from_dict(data)
+    assert lc1.map == light_curve.map
+    assert_allclose(
+        lc1.reference_time.value, light_curve.reference_time.value, rtol=1e-9
+    )
+
+
+@requires_data()
+def test_light_curve_map_serialisation(light_curve, tmp_path):
+    filename = str(make_path(tmp_path / "tmp.fits"))
+    light_curve.write(filename, format="map")
+    lc1 = LightCurveTemplateTemporalModel.read(filename, format="map")
+    assert_allclose(
+        lc1.reference_time.value, light_curve.reference_time.value, rtol=1e-9
+    )
+    assert lc1.map == light_curve.map
 
 
 def test_time_sampling_template():
     time_ref = Time(55197.00000000, format="mjd")
     livetime = 3.0 * u.hr
     sigma = 0.5 * u.h
     t_min = "2010-01-01T00:00:00"
@@ -124,37 +179,40 @@
 def test_lightcurve_temporal_model_integral():
     time = np.arange(0, 10, 0.06) * u.hour
     table = Table()
     table["TIME"] = time
     table["NORM"] = np.ones(len(time))
     table.meta = dict(MJDREFI=55197.0, MJDREFF=0, TIMEUNIT="hour")
     temporal_model = LightCurveTemplateTemporalModel.from_table(table)
+    assert not temporal_model.is_energy_dependent
 
-    start = [1, 3, 5] * u.hour
-    stop = [2, 3.5, 6] * u.hour
-    gti = GTI.create(start, stop, reference_time=Time("2010-01-01T00:00:00"))
-
-    val = temporal_model.integral(gti.time_start, gti.time_stop)
+    time_start = Time("2010-01-01T00:00:00") + [1, 3, 5] * u.hour
+    time_stop = Time("2010-01-01T00:00:00") + [2, 3.5, 6] * u.hour
+    val = temporal_model.integral(time_start, time_stop)
     assert len(val) == 3
     assert_allclose(np.sum(val), 1.0101, rtol=1e-5)
 
+    with mpl_plot_check():
+        temporal_model.plot(
+            time_range=(Time(55555.50, format="mjd"), Time(55563.0, format="mjd"))
+        )
+
 
 def test_constant_temporal_model_evaluate():
     temporal_model = ConstantTemporalModel()
     t = Time(46300, format="mjd")
     val = temporal_model(t)
     assert_allclose(val, 1.0, rtol=1e-5)
 
 
 def test_constant_temporal_model_integral():
     temporal_model = ConstantTemporalModel()
-    start = [1, 3, 5] * u.day
-    stop = [2, 3.5, 6] * u.day
-    gti = GTI.create(start, stop)
-    val = temporal_model.integral(gti.time_start, gti.time_stop)
+    time_start = Time("2010-01-01T00:00:00") + [1, 3, 5] * u.day
+    time_stop = Time("2010-01-01T00:00:00") + [2, 3.5, 6] * u.day
+    val = temporal_model.integral(time_start, time_stop)
     assert len(val) == 3
     assert_allclose(np.sum(val), 1.0, rtol=1e-5)
 
 
 def test_linear_temporal_model_evaluate():
     t = Time(46301, format="mjd")
     t_ref = 46300 * u.d
@@ -164,18 +222,17 @@
 
 
 def test_linear_temporal_model_integral():
     t_ref = Time(55555, format="mjd")
     temporal_model = LinearTemporalModel(
         alpha=1.0, beta=0.1 / u.day, t_ref=t_ref.mjd * u.d
     )
-    start = [1, 3, 5] * u.day
-    stop = [2, 3.5, 6] * u.day
-    gti = GTI.create(start, stop, reference_time=t_ref)
-    val = temporal_model.integral(gti.time_start, gti.time_stop)
+    time_start = t_ref + [1, 3, 5] * u.day
+    time_stop = t_ref + [2, 3.5, 6] * u.day
+    val = temporal_model.integral(time_start, time_stop)
     assert len(val) == 3
     assert_allclose(np.sum(val), 1.345, rtol=1e-5)
 
 
 def test_exponential_temporal_model_evaluate():
     t = Time(46301, format="mjd")
     t_ref = 46300 * u.d
@@ -185,18 +242,17 @@
     assert_allclose(val, 0.6065306597126334, rtol=1e-5)
 
 
 def test_exponential_temporal_model_integral():
     t_ref = Time(55555, format="mjd")
 
     temporal_model = ExpDecayTemporalModel(t_ref=t_ref.mjd * u.d)
-    start = [1, 3, 5] * u.day
-    stop = [2, 3.5, 6] * u.day
-    gti = GTI.create(start, stop, reference_time=t_ref)
-    val = temporal_model.integral(gti.time_start, gti.time_stop)
+    time_start = t_ref + [1, 3, 5] * u.day
+    time_stop = t_ref + [2, 3.5, 6] * u.day
+    val = temporal_model.integral(time_start, time_stop)
     assert len(val) == 3
     assert_allclose(np.sum(val), 0.102557, rtol=1e-5)
 
 
 def test_gaussian_temporal_model_evaluate():
     t = Time(46301, format="mjd")
     t_ref = 46300 * u.d
@@ -204,19 +260,18 @@
     temporal_model = GaussianTemporalModel(t_ref=t_ref, sigma=sigma)
     val = temporal_model(t)
     assert_allclose(val, 0.882497, rtol=1e-5)
 
 
 def test_gaussian_temporal_model_integral():
     temporal_model = GaussianTemporalModel(t_ref=50003 * u.d, sigma="2.0 day")
-    start = [1, 3, 5] * u.day
-    stop = [2, 3.5, 6] * u.day
     t_ref = Time(50000, format="mjd")
-    gti = GTI.create(start, stop, reference_time=t_ref)
-    val = temporal_model.integral(gti.time_start, gti.time_stop)
+    time_start = t_ref + [1, 3, 5] * u.day
+    time_stop = t_ref + [2, 3.5, 6] * u.day
+    val = temporal_model.integral(time_start, time_stop)
     assert len(val) == 3
     assert_allclose(np.sum(val), 0.682679, rtol=1e-5)
 
 
 def test_generalized_gaussian_temporal_model_evaluate():
     t = Time(46301, format="mjd")
     t_ref = 46300 * u.d
@@ -232,44 +287,43 @@
 
 def test_generalized_gaussian_temporal_model_integral():
     temporal_model = GeneralizedGaussianTemporalModel(
         t_ref=50003 * u.d, t_rise="2.0 day", t_decay="2.0 day", eta=1 / 2
     )
     start = 1 * u.day
     stop = 2 * u.day
-    t_ref = Time(50000, format="mjd")
-    gti = GTI.create(start, stop, reference_time=t_ref)
-    val = temporal_model.integral(gti.time_start, gti.time_stop)
-    assert_allclose(val, 0.759115, rtol=1e-4)
+    t_ref = Time(50000, format="mjd", scale="utc")
+    time_start = t_ref + start
+    time_stop = t_ref + stop
+    val = temporal_model.integral(time_start, time_stop)
+    assert_allclose(val, 0.758918, rtol=1e-4)
 
 
 def test_powerlaw_temporal_model_evaluate():
     t = Time(46302, format="mjd")
     t_ref = 46300 * u.d
     alpha = -2.0
     temporal_model = PowerLawTemporalModel(t_ref=t_ref, alpha=alpha)
     val = temporal_model(t)
     assert_allclose(val, 0.25, rtol=1e-5)
 
 
 def test_powerlaw_temporal_model_integral():
     t_ref = Time(55555, format="mjd")
     temporal_model = PowerLawTemporalModel(alpha=-2.0, t_ref=t_ref.mjd * u.d)
-    start = 1 * u.day
-    stop = 4 * u.day
-    gti = GTI.create(start, stop, reference_time=t_ref)
-    val = temporal_model.integral(gti.time_start, gti.time_stop)
+    time_start = t_ref + [1] * u.day
+    time_stop = t_ref + [4] * u.day
+    val = temporal_model.integral(time_start, time_stop)
     assert len(val) == 1
     assert_allclose(np.sum(val), 0.25, rtol=1e-5)
 
     temporal_model.parameters["alpha"].value = -1
-    start = [1, 3, 5] * u.day
-    stop = [2, 3.5, 6] * u.day
-    gti = GTI.create(start, stop, reference_time=t_ref)
-    val = temporal_model.integral(gti.time_start, gti.time_stop)
+    time_start = t_ref + [1, 3, 5] * u.day
+    time_stop = t_ref + [2, 3.5, 6] * u.day
+    val = temporal_model.integral(time_start, time_stop)
 
     assert len(val) == 3
     assert_allclose(np.sum(val), 0.411847, rtol=1e-5)
 
 
 def test_sine_temporal_model_evaluate():
     t = Time(46302, format="mjd")
@@ -280,18 +334,17 @@
     assert_allclose(val, 1.5, rtol=1e-5)
 
 
 def test_sine_temporal_model_integral():
     t_ref = Time(55555, format="mjd")
     omega = np.pi / 4.0 * u.rad / u.day
     temporal_model = SineTemporalModel(amp=0.5, omega=omega, t_ref=t_ref.mjd * u.d)
-    start = [1, 3, 5] * u.day
-    stop = [2, 3.5, 6] * u.day
-    gti = GTI.create(start, stop, reference_time=t_ref)
-    val = temporal_model.integral(gti.time_start, gti.time_stop)
+    time_start = t_ref + [1, 3, 5] * u.day
+    time_stop = t_ref + [2, 3.5, 6] * u.day
+    val = temporal_model.integral(time_start, time_stop)
     assert len(val) == 3
     assert_allclose(np.sum(val), 1.08261, rtol=1e-5)
 
 
 @requires_data()
 def test_to_dict(light_curve):
 
@@ -380,7 +433,34 @@
     times = Time(t_ref, format="mjd") + [0.0, 0.5, 0.65, 1.0] * P0
     norm = model(times)
 
     assert_allclose(norm, [0.05, 0.15, 1.0, 0.05])
 
     with mpl_plot_check():
         model.plot_phasogram(n_points=200)
+
+
+def test_model_scale():
+    model = GaussianTemporalModel(t_ref=50003.2503033 * u.d, sigma="2.43 day")
+    assert model.scale == "utc"
+    model.scale = "tai"
+    assert_allclose(model.reference_time.mjd, 50003.2503033, rtol=1e-9)
+    dict1 = model.to_dict()
+    model1 = GaussianTemporalModel.from_dict(dict1)
+    assert model1.scale == "tai"
+    assert_allclose(model1.sigma.quantity, 2.43 * u.d, rtol=1e-3)
+    time_start = model.reference_time + [1, 3, 5] * u.day
+    time_stop = model.reference_time + [2, 3.5, 6] * u.day
+    val = model.integral(time_start, time_stop)
+    assert_allclose(np.sum(val), 0.442833, rtol=1e-5)
+
+    model1.reference_time = Time(52398.23456, format="mjd", scale="utc")
+    assert model1.scale == "tai"
+    assert_allclose(model1.t_ref.value, 52398.23493, rtol=1e-9)
+
+    with pytest.raises(TypeError):
+        model1.reference_time = 23456
+
+    with pytest.raises(ValueError):
+        model = GaussianTemporalModel(
+            t_ref=50003.2503033 * u.d, sigma="2.43 day", scale="ms"
+        )
```

### Comparing `gammapy-1.0rc2/gammapy/modeling/parameter.py` & `gammapy-1.1rc1/gammapy/modeling/parameter.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,16 +2,16 @@
 """Model parameter classes."""
 import collections.abc
 import copy
 import itertools
 import logging
 import numpy as np
 from astropy import units as u
+from astropy.table import Table
 from gammapy.utils.interpolation import interpolation_scale
-from gammapy.utils.table import table_from_row_data
 
 __all__ = ["Parameter", "Parameters"]
 
 log = logging.getLogger(__name__)
 
 
 def _get_parameters_str(parameters):
@@ -130,15 +130,15 @@
         # TODO: move this to a setter method that can be called from `__set__` also!
         # Having it here is bad: behaviour not clear if Quantity and `unit` is passed.
         if isinstance(value, u.Quantity) or isinstance(value, str):
             val = u.Quantity(value)
             self.value = val.value
             self.unit = val.unit
         else:
-            self.factor = value
+            self.value = float(value)
             self.unit = unit
 
         self.scan_min = scan_min
         self.scan_max = scan_max
         self.scan_values = scan_values
         self.scan_n_values = scan_n_values
         self.scan_n_sigma = scan_n_sigma
@@ -543,14 +543,19 @@
         return cls(pars)
 
     def copy(self):
         """A deep copy"""
         return copy.deepcopy(self)
 
     @property
+    def norm_parameters(self):
+        """List of norm parameters"""
+        return self.__class__([par for par in self._parameters if par.is_norm])
+
+    @property
     def free_parameters(self):
         """List of free parameters"""
         return self.__class__([par for par in self._parameters if not par.frozen])
 
     @property
     def unique_parameters(self):
         """Unique parameters (`Parameters`)."""
@@ -611,15 +616,15 @@
             d = p.to_dict()
             if "link" not in d:
                 d["link"] = ""
             for key in ["scale_method", "interp"]:
                 if key in d:
                     del d[key]
             rows.append({**dict(type=p.type), **d})
-        table = table_from_row_data(rows)
+        table = Table(rows)
 
         table["value"].format = ".4e"
         for name in ["error", "min", "max"]:
             table[name].format = ".3e"
 
         return table
```

### Comparing `gammapy-1.0rc2/gammapy/modeling/scipy.py` & `gammapy-1.1rc1/gammapy/modeling/scipy.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/modeling/sherpa.py` & `gammapy-1.1rc1/gammapy/modeling/sherpa.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/modeling/tests/test_covariance.py` & `gammapy-1.1rc1/gammapy/modeling/tests/test_covariance.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/modeling/tests/test_fit.py` & `gammapy-1.1rc1/gammapy/modeling/tests/test_fit.py`

 * *Files 1% similar despite different names*

```diff
@@ -86,14 +86,15 @@
 @pytest.mark.parametrize("backend", ["minuit"])
 def test_run(backend):
     dataset = MyDataset()
     fit = Fit(backend=backend)
     result = fit.run([dataset])
     pars = dataset.models.parameters
 
+    assert fit._minuit is not None
     assert result.success
     assert result.optimize_result.method == "migrad"
     assert result.covariance_result.method == "hesse"
     assert result.covariance_result.success
 
     assert_allclose(pars["x"].value, 2, rtol=1e-3)
     assert_allclose(pars["y"].value, 3e2, rtol=1e-3)
```

### Comparing `gammapy-1.0rc2/gammapy/modeling/tests/test_iminuit.py` & `gammapy-1.1rc1/gammapy/modeling/tests/test_iminuit.py`

 * *Files 0% similar despite different names*

```diff
@@ -6,16 +6,16 @@
 from gammapy.modeling.models import ModelBase, Models
 
 pytest.importorskip("iminuit")
 
 
 class MyModel(ModelBase):
     x = Parameter("x", 2.1, error=0.2)
-    y = Parameter("y", 3.1, scale=1e5, error=3e4)
-    z = Parameter("z", 4.1, scale=1e-5, error=4e-6)
+    y = Parameter("y", 3.1e5, scale=1e5, error=3e4)
+    z = Parameter("z", 4.1e-5, scale=1e-5, error=4e-6)
     name = "test"
     datasets_names = ["test"]
 
 
 class MyDataset:
     def __init__(self, name="test"):
         self.name = name
```

### Comparing `gammapy-1.0rc2/gammapy/modeling/tests/test_parameter.py` & `gammapy-1.1rc1/gammapy/modeling/tests/test_parameter.py`

 * *Files 6% similar despite different names*

```diff
@@ -34,29 +34,29 @@
     assert "WARNING" in [_.levelname for _ in caplog.records]
     message1 = "Value 50.0 is outside bounds [0.0, 40.0] for parameter 'spam'"
     assert message1 in [_.message for _ in caplog.records]
 
 
 def test_parameter_scale():
     # Basic check how scale is used for value, min, max
-    par = Parameter("spam", 42, "deg", 10, 400, 500)
+    par = Parameter("spam", 420, "deg", 10, 400, 500)
 
     assert par.value == 420
     assert par.min == 400
     assert_allclose(par.factor_min, 40)
     assert par.max == 500
     assert_allclose(par.factor_max, 50)
 
     par.value = 70
     assert par.scale == 10
     assert_allclose(par.factor, 7)
 
 
 def test_parameter_quantity():
-    par = Parameter("spam", 42, "deg", 10)
+    par = Parameter("spam", 420, "deg", 10)
 
     quantity = par.quantity
     assert quantity.unit == "deg"
     assert quantity.value == 420
 
     par.quantity = "70 deg"
     assert_allclose(par.factor, 7)
@@ -243,18 +243,18 @@
         "min": 0,
         "max": np.nan,
         "frozen": True,
         "unit": "GeV",
     }
     par.update_from_dict(data)
     assert par.name == "test"
-    assert par.factor == 3
-    assert par.value == 3e-10
+    assert_allclose(par.factor, 3)
+    assert_allclose(par.value, 3e-10)
     assert par.unit == "GeV"
-    assert par.min == 0
+    assert_allclose(par.min, 0)
     assert par.max is np.nan
     assert par.frozen
     data = {
         "model": "gc",
         "type": "spectral",
         "name": "test2",
         "value": 3e-10,
```

### Comparing `gammapy-1.0rc2/gammapy/modeling/tests/test_scipy.py` & `gammapy-1.1rc1/gammapy/modeling/tests/test_scipy.py`

 * *Files 1% similar despite different names*

```diff
@@ -24,16 +24,16 @@
             + ((z - z_opt) / z_err) ** 2
         )
 
 
 @pytest.fixture()
 def pars():
     x = Parameter("x", 2.1)
-    y = Parameter("y", 3.1, scale=1e5)
-    z = Parameter("z", 4.1, scale=1e-5)
+    y = Parameter("y", 3.1e5, scale=1e5)
+    z = Parameter("z", 4.1e-5, scale=1e-5)
     return Parameters([x, y, z])
 
 
 @pytest.mark.parametrize("method", ["Nelder-Mead", "L-BFGS-B", "Powell", "BFGS"])
 def test_scipy_basic(pars, method):
     ds = MyDataset(pars)
     factors, info, optimizer = optimize_scipy(
```

### Comparing `gammapy-1.0rc2/gammapy/modeling/tests/test_sherpa.py` & `gammapy-1.1rc1/gammapy/modeling/tests/test_sherpa.py`

 * *Files 1% similar despite different names*

```diff
@@ -21,16 +21,16 @@
             + ((z - z_opt) / z_err) ** 2
         )
 
 
 @pytest.fixture()
 def pars():
     x = Parameter("x", 2.1)
-    y = Parameter("y", 3.1, scale=1e5)
-    z = Parameter("z", 4.1, scale=1e-5)
+    y = Parameter("y", 3.1e5, scale=1e5)
+    z = Parameter("z", 4.1e-5, scale=1e-5)
     return Parameters([x, y, z])
 
 
 # TODO: levmar doesn't work yet; needs array of statval as return in likelihood
 # method='gridsearch' would require very low tolerance asserts, not added for now
```

### Comparing `gammapy-1.0rc2/gammapy/scripts/analysis.py` & `gammapy-1.1rc1/gammapy/scripts/analysis.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/scripts/check.py` & `gammapy-1.1rc1/gammapy/scripts/check.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/scripts/download.py` & `gammapy-1.1rc1/gammapy/scripts/download.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/scripts/info.py` & `gammapy-1.1rc1/gammapy/scripts/info.py`

 * *Files 4% similar despite different names*

```diff
@@ -28,14 +28,15 @@
     "pandas",
     "healpy",
     "iminuit",
     "sherpa",
     "naima",
     "emcee",
     "corner",
+    "ray",
 ]
 
 GAMMAPY_ENV_VARIABLES = ["GAMMAPY_DATA"]
 
 
 @click.command(name="info")
 @click.option("--system/--no-system", default=True, help="Show system info")
```

### Comparing `gammapy-1.0rc2/gammapy/scripts/main.py` & `gammapy-1.1rc1/gammapy/scripts/main.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/scripts/tests/test_analysis.py` & `gammapy-1.1rc1/gammapy/scripts/tests/test_analysis.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/scripts/tests/test_download.py` & `gammapy-1.1rc1/gammapy/scripts/tests/test_download.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/scripts/tests/test_info.py` & `gammapy-1.1rc1/gammapy/scripts/tests/test_info.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/scripts/tests/test_main.py` & `gammapy-1.1rc1/gammapy/scripts/tests/test_main.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/stats/__init__.py` & `gammapy-1.1rc1/gammapy/stats/__init__.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,11 +1,17 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 """Statistics."""
 from .counts_statistic import CashCountsStatistic, WStatCountsStatistic
-from .fit_statistics import cash, cstat, get_wstat_gof_terms, get_wstat_mu_bkg, wstat
+from .fit_statistics import (
+    cash,
+    cstat,
+    get_wstat_gof_terms,
+    get_wstat_mu_bkg,
+    wstat,
+)
 from .fit_statistics_cython import (
     cash_sum_cython,
     f_cash_root_cython,
     norm_bounds_cython,
 )
 
 __all__ = [
```

### Comparing `gammapy-1.0rc2/gammapy/stats/counts_statistic.py` & `gammapy-1.1rc1/gammapy/stats/counts_statistic.py`

 * *Files 15% similar despite different names*

```diff
@@ -57,14 +57,43 @@
     @property
     def p_value(self):
         """Return p_value of measured excess.
         Here the value accounts only for the positive excess significance (i.e. one-sided).
         """
         return 0.5 * chi2.sf(self.ts, 1)
 
+    def __str__(self):
+        str_ = "\t{:32}: {{n_on:.2f}} \n".format("Total counts")
+        str_ += "\t{:32}: {{background:.2f}}\n".format("Total background counts")
+        str_ += "\t{:32}: {{excess:.2f}}\n".format("Total excess counts")
+        str_ += "\t{:32}: {{significance:.2f}}\n".format("Total significance")
+        str_ += "\t{:32}: {{p_value:.3f}}\n".format("p - value")
+        str_ += "\t{:32}: {{n_bins:.0f}}\n".format("Total number of bins")
+        info = self.info_dict()
+        info["n_bins"] = np.array(self.n_on).size
+        str_ = str_.format(**info)
+
+        return str_.expandtabs(tabsize=2)
+
+    def info_dict(self):
+        """A dictionary of the relevant quantities
+
+        Returns
+        -------
+        info_dict : dict
+            Dictionary with summary info
+        """
+        info_dict = {}
+        info_dict["n_on"] = self.n_on
+        info_dict["background"] = self.n_bkg
+        info_dict["excess"] = self.n_sig
+        info_dict["significance"] = self.sqrt_ts
+        info_dict["p_value"] = self.p_value
+        return info_dict
+
     def compute_errn(self, n_sigma=1.0):
         """Compute downward excess uncertainties.
 
         Searches the signal value for which the test statistics is n_sigma**2 away from the maximum.
 
         Parameters
         ----------
@@ -246,14 +275,34 @@
         return cash(self.n_on, self.mu_bkg + 0)
 
     @property
     def stat_max(self):
         """Stat value for best fit hypothesis, i.e. expected signal mu = n_on - mu_bkg"""
         return cash(self.n_on, self.n_on)
 
+    def info_dict(self):
+        """A dictionary of the relevant quantities
+
+        Returns
+        -------
+        info_dict : dict
+            Dictionary with summary info
+        """
+        info_dict = super().info_dict()
+        info_dict["mu_bkg"] = self.mu_bkg
+        return info_dict
+
+    def __str__(self):
+        str_ = f"{self.__class__.__name__}\n"
+        str_ += super().__str__()
+        str_ += "\t{:32}: {:.2f} \n".format(
+            "Predicted background counts", self.info_dict()["mu_bkg"]
+        )
+        return str_.expandtabs(tabsize=2)
+
     def _stat_fcn(self, mu, delta=0, index=None):
         return cash(self.n_on[index], self.mu_bkg[index] + mu) - delta
 
     def _n_sig_matching_significance_fcn(self, n_sig, significance, index):
         TS0 = cash(n_sig + self.mu_bkg[index], self.mu_bkg[index])
         TS1 = cash(n_sig + self.mu_bkg[index], self.mu_bkg[index] + n_sig)
         return np.sign(n_sig) * np.sqrt(np.clip(TS0 - TS1, 0, None)) - significance
@@ -316,14 +365,39 @@
     def stat_max(self):
         """Stat value for best fit hypothesis
 
         i.e. expected signal mu = n_on - alpha * n_off - mu_sig
         """
         return wstat(self.n_on, self.n_off, self.alpha, self.n_sig + self.mu_sig)
 
+    def info_dict(self):
+        """A dictionary of the relevant quantities
+
+        Returns
+        -------
+        info_dict : dict
+            Dictionary with summary info
+        """
+        info_dict = super().info_dict()
+        info_dict["n_off"] = self.n_off
+        info_dict["alpha"] = self.alpha
+        info_dict["mu_sig"] = self.mu_sig
+        return info_dict
+
+    def __str__(self):
+        str_ = f"{self.__class__.__name__}\n"
+        str_ += super().__str__()
+        info_dict = self.info_dict()
+        str_ += "\t{:32}: {:.2f} \n".format("Off counts", info_dict["n_off"])
+        str_ += "\t{:32}: {:.2f} \n".format("alpha ", info_dict["alpha"])
+        str_ += "\t{:32}: {:.2f} \n".format(
+            "Predicted signal counts", info_dict["mu_sig"]
+        )
+        return str_.expandtabs(tabsize=2)
+
     def _stat_fcn(self, mu, delta=0, index=None):
         return (
             wstat(
                 self.n_on[index],
                 self.n_off[index],
                 self.alpha[index],
                 (mu + self.mu_sig[index]),
```

### Comparing `gammapy-1.0rc2/gammapy/stats/fit_statistics.py` & `gammapy-1.1rc1/gammapy/stats/fit_statistics.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/stats/fit_statistics_cython.pyx` & `gammapy-1.1rc1/gammapy/stats/fit_statistics_cython.pyx`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/stats/tests/test_counts_statistic.py` & `gammapy-1.1rc1/gammapy/stats/tests/test_counts_statistic.py`

 * *Files 14% similar despite different names*

```diff
@@ -245,7 +245,36 @@
     assert_allclose(stat_sum.alpha, 0.0925925925925925)
 
     stat_sum = stat.sum(axis=(0, 1))
 
     assert stat_sum.n_on.shape == (3,)
     assert_allclose(stat_sum.n_on, (20, 40, 60))
     assert_allclose(stat_sum.n_bkg, (10, 14, 26))
+
+
+def test_CountStatistic_str():
+    cash = CashCountsStatistic(n_on=4, mu_bkg=2)
+    assert "Predicted background counts" in str(cash)
+    assert "CashCountsStatistic" in str(cash)
+    assert "Total significance" in str(cash)
+
+    wstat = WStatCountsStatistic(n_on=5, n_off=4, alpha=0.2, mu_sig=2)
+    assert "Off counts" in str(wstat)
+    assert "alpha " in str(wstat)
+    assert "Total counts " in str(wstat)
+    assert "WStatCountsStatistic" in str(wstat)
+
+
+def test_counts_statistic_infodict():
+    c1 = CashCountsStatistic(n_on=[3, 6], mu_bkg=[2, 1])
+    info_dict = c1.sum().info_dict()
+    assert_allclose(info_dict["n_on"], 9)
+    assert_allclose(info_dict["significance"], 2.788, rtol=1e-3)
+
+    w1 = WStatCountsStatistic(n_on=[3, 6], n_off=[2, 1], alpha=[1, 2])
+    info_dict = w1.info_dict()
+    assert_allclose(info_dict["n_off"], [2, 1])
+    assert_allclose(info_dict["significance"], [0.44872, 1.14942], rtol=1e-3)
+
+    info_dict = w1.sum().info_dict()
+    assert_allclose(info_dict["excess"], 5.0)
+    assert_allclose(info_dict["significance"], 1.288731, rtol=1e-3)
```

### Comparing `gammapy-1.0rc2/gammapy/stats/tests/test_fit_statistics.py` & `gammapy-1.1rc1/gammapy/stats/tests/test_fit_statistics.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/stats/tests/test_variability.py` & `gammapy-1.1rc1/gammapy/stats/tests/test_variability.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/stats/variability.py` & `gammapy-1.1rc1/gammapy/stats/variability.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/utils/array.py` & `gammapy-1.1rc1/gammapy/utils/array.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/utils/check.py` & `gammapy-1.1rc1/gammapy/utils/check.py`

 * *Files 7% similar despite different names*

```diff
@@ -15,10 +15,10 @@
         Path to download the data, if not present.
     """
     if "GAMMAPY_DATA" not in os.environ:
         log.info(
             "Missing example datasets, downloading to {download_datasets_path} now..."
         )
         cli_download_datasets.callback(out=download_datasets_path, release=RELEASE)
-        os.env["GAMMAPY_DATA"] = download_datasets_path
+        os.environ["GAMMAPY_DATA"] = download_datasets_path
 
     cli_info.callback(system=True, version=True, dependencies=True, envvar=True)
```

### Comparing `gammapy-1.0rc2/gammapy/utils/coordinates/fov.py` & `gammapy-1.1rc1/gammapy/utils/coordinates/fov.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/utils/coordinates/other.py` & `gammapy-1.1rc1/gammapy/utils/coordinates/other.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/utils/coordinates/tests/test_fov.py` & `gammapy-1.1rc1/gammapy/utils/coordinates/tests/test_fov.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/utils/docs.py` & `gammapy-1.1rc1/gammapy/utils/docs.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/utils/fits.py` & `gammapy-1.1rc1/gammapy/utils/fits.py`

 * *Files 2% similar despite different names*

```diff
@@ -90,14 +90,19 @@
             from gammapy.data.gti import GTI
 
             return GTI.read(filename, hdu=hdu)
         elif hdu_class == "map":
             from gammapy.maps import Map
 
             return Map.read(filename, hdu=hdu, format=self.format)
+        elif hdu_class == "pointing":
+            # FIXME: support loading the pointing table
+            from gammapy.data import FixedPointingInfo
+
+            return FixedPointingInfo.read(filename, hdu=hdu)
         else:
             cls = IRF_REGISTRY.get_cls(hdu_class)
 
             return cls.read(filename, hdu=hdu)
 
 
 class LazyFitsData(object):
```

### Comparing `gammapy-1.0rc2/gammapy/utils/gauss.py` & `gammapy-1.1rc1/gammapy/utils/gauss.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/utils/integrate.py` & `gammapy-1.1rc1/gammapy/utils/integrate.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/utils/interpolation.py` & `gammapy-1.1rc1/gammapy/utils/interpolation.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/utils/pbar.py` & `gammapy-1.1rc1/gammapy/utils/pbar.py`

 * *Files 7% similar despite different names*

```diff
@@ -34,11 +34,10 @@
     # Necessary because iterable may be a zip
     iterable_to_list = list(iterable)
     total = len(iterable_to_list)
 
     return tqdm(
         iterable_to_list,
         total=total,
-        mininterval=0,
         disable=not SHOW_PROGRESS_BAR,
         desc=desc,
     )
```

### Comparing `gammapy-1.0rc2/gammapy/utils/random/inverse_cdf.py` & `gammapy-1.1rc1/gammapy/utils/random/inverse_cdf.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/utils/random/tests/test_inverse_cdf.py` & `gammapy-1.1rc1/gammapy/utils/random/tests/test_inverse_cdf.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/utils/random/tests/test_random.py` & `gammapy-1.1rc1/gammapy/utils/random/tests/test_random.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/utils/random/utils.py` & `gammapy-1.1rc1/gammapy/utils/random/utils.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/utils/regions.py` & `gammapy-1.1rc1/gammapy/utils/regions.py`

 * *Files 11% similar despite different names*

```diff
@@ -17,23 +17,25 @@
 from scipy.optimize import Bounds, minimize
 from astropy import units as u
 from astropy.coordinates import SkyCoord
 from regions import (
     CircleAnnulusSkyRegion,
     CircleSkyRegion,
     CompoundSkyRegion,
+    EllipseSkyRegion,
     RectangleSkyRegion,
     Regions,
 )
 
 __all__ = [
     "compound_region_to_regions",
     "make_concentric_annulus_sky_regions",
     "make_orthogonal_rectangle_sky_regions",
     "regions_to_compound_region",
+    "region_to_frame",
 ]
 
 
 def compound_region_center(compound_region):
     """Compute center for a CompoundRegion
 
     The center of the compound region is defined here as the geometric median
@@ -227,7 +229,49 @@
             center=center,
             inner_radius=r_in,
             outer_radius=r_out,
         )
         regions.append(region)
 
     return regions
+
+
+def region_to_frame(region, frame):
+    """Convert a region to a different frame
+
+    Parameters
+    ----------
+    region : `~regions.SkyRegion`
+        region to transform
+    frame : "icrs" or "galactic"
+        frame to tranform the region into
+
+    Returns
+    -------
+    region_new : `~regions.SkyRegion`
+        region in the given frame
+    """
+    from gammapy.maps import WcsGeom
+
+    wcs = WcsGeom.create(skydir=region.center, binsz=0.01, frame=frame).wcs
+    region_new = region.to_pixel(wcs).to_sky(wcs)
+    return region_new
+
+
+def region_circle_to_ellipse(region):
+    """Convert a CircleSkyRegion to an EllipseSkyRegion
+
+    Parameters
+    ----------
+    region : `~regions.CircleSkyRegion`
+        region to transform
+
+    Returns
+    -------
+    region_new : `~regions.EllipseSkyRegion`
+        Elliptical region with same major and minor axis
+    """
+
+    region_new = EllipseSkyRegion(
+        center=region.center, width=region.radius, height=region.radius
+    )
+    return region_new
```

### Comparing `gammapy-1.0rc2/gammapy/utils/registry.py` & `gammapy-1.1rc1/gammapy/utils/registry.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/utils/roots.py` & `gammapy-1.1rc1/gammapy/utils/roots.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/utils/scripts.py` & `gammapy-1.1rc1/gammapy/utils/scripts.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/utils/table.py` & `gammapy-1.1rc1/gammapy/utils/table.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 """Table helper utilities."""
 import numpy as np
 from astropy.table import Table
 from astropy.units import Quantity
+from .deprecation import deprecated
 from .units import standardise_unit
 
 __all__ = [
     "hstack_columns",
     "table_from_row_data",
     "table_row_to_dict",
     "table_standardise_units_copy",
@@ -81,20 +82,22 @@
     -------
     data : `dict`
         Row data
     """
     data = {}
     for name, col in row.columns.items():
         val = row[name]
+
         if make_quantity and col.unit:
             val = Quantity(val, unit=col.unit)
         data[name] = val
     return data
 
 
+@deprecated("v1.1", alternative="astropy.table.Table")
 def table_from_row_data(rows, **kwargs):
     """Helper function to create table objects from row data.
 
     Works with quantities.
 
     Parameters
     ----------
```

### Comparing `gammapy-1.0rc2/gammapy/utils/testing.py` & `gammapy-1.1rc1/gammapy/utils/testing.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,27 +1,32 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 """Utilities for testing"""
 import os
 import sys
 from numpy.testing import assert_allclose
+import astropy
 import astropy.units as u
 from astropy.coordinates import SkyCoord
 from astropy.time import Time
+from astropy.utils.introspection import minversion
 import matplotlib.pyplot as plt
 
 __all__ = [
     "assert_quantity_allclose",
     "assert_skycoord_allclose",
     "assert_time_allclose",
     "Checker",
     "mpl_plot_check",
     "requires_data",
     "requires_dependency",
 ]
 
+
+ASTROPY_LT_5_3 = minversion(astropy, "5.3.dev")
+
 # Cache for `requires_dependency`
 _requires_dependency_cache = {}
 
 
 def requires_dependency(name):
     """Decorator to declare required dependencies for tests.
 
@@ -233,7 +238,23 @@
         unknown_checks = sorted(set(checks).difference(self.CHECKS.keys()))
         if unknown_checks:
             raise ValueError(f"Unknown checks: {unknown_checks!r}")
 
         for check in checks:
             method = getattr(self, self.CHECKS[check])
             yield from method()
+
+
+UNIT_REPLACEMENTS_ASTROPY_5_3 = {
+    "cm2 s TeV": "TeV s cm2",
+    "1 / (cm2 s)": "1 / (s cm2)",
+    "erg / (cm2 s)": "erg / (s cm2)",
+}
+
+
+def modify_unit_order_astropy_5_3(expected_str):
+    """Modify unit order for tests with astropy >= 5.3"""
+    if ASTROPY_LT_5_3:
+        for old, new in UNIT_REPLACEMENTS_ASTROPY_5_3.items():
+            expected_str = expected_str.replace(old, new)
+
+    return expected_str
```

### Comparing `gammapy-1.0rc2/gammapy/utils/tests/test_array.py` & `gammapy-1.1rc1/gammapy/utils/tests/test_array.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/utils/tests/test_fits.py` & `gammapy-1.1rc1/gammapy/utils/tests/test_fits.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/utils/tests/test_gauss.py` & `gammapy-1.1rc1/gammapy/utils/tests/test_gauss.py`

 * *Files 5% similar despite different names*

```diff
@@ -5,15 +5,15 @@
 from gammapy.utils.gauss import Gauss2DPDF, MultiGauss2D
 
 
 class TestGauss2DPDF:
     """Note that we test __call__ and dpdtheta2 by
     checking that their integrals as advertised are 1."""
 
-    def setup(self):
+    def setup_method(self):
         self.gs = [
             Gauss2DPDF(0.1 * u.deg),
             Gauss2DPDF(1 * u.deg),
             Gauss2DPDF(1 * u.deg),
         ]
 
     def test_call(self):
```

### Comparing `gammapy-1.0rc2/gammapy/utils/tests/test_integrate.py` & `gammapy-1.1rc1/gammapy/utils/tests/test_integrate.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/utils/tests/test_interpolation.py` & `gammapy-1.1rc1/gammapy/utils/tests/test_interpolation.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/utils/tests/test_regions.py` & `gammapy-1.1rc1/gammapy/utils/tests/test_regions.py`

 * *Files 12% similar despite different names*

```diff
@@ -6,18 +6,20 @@
 in https://astropy-regions.readthedocs.io that we rely on in Gammapy.
 That package is still work in progress and not fully developed and
 stable, so need to establish a bit what works and what doesn't.
 """
 from numpy.testing import assert_allclose, assert_equal
 import astropy.units as u
 from astropy.coordinates import SkyCoord
-from regions import Regions
+from regions import CircleSkyRegion, EllipseSkyRegion, Regions
 from gammapy.utils.regions import (
     SphericalCircleSkyRegion,
     compound_region_center,
+    region_circle_to_ellipse,
+    region_to_frame,
     regions_to_compound_region,
 )
 
 
 def test_compound_region_center():
     regions_ds9 = (
         "galactic;"
@@ -76,7 +78,27 @@
     region = SphericalCircleSkyRegion(
         center=SkyCoord(10 * u.deg, 20 * u.deg), radius=10 * u.deg
     )
 
     coord = SkyCoord([20.1, 22] * u.deg, 20 * u.deg)
     mask = region.contains(coord)
     assert_equal(mask, [True, False])
+
+
+def test_region_to_frame():
+    region = EllipseSkyRegion(
+        center=SkyCoord(20, 17, unit="deg"),
+        height=0.3 * u.deg,
+        width=1.0 * u.deg,
+        angle=30 * u.deg,
+    )
+    region_new = region_to_frame(region, "galactic")
+    assert_allclose(region_new.angle, 20.946 * u.deg, rtol=1e-3)
+    assert_allclose(region_new.center.l, region.center.galactic.l, rtol=1e-3)
+
+
+def test_region_circle_to_ellipse():
+    region = CircleSkyRegion(center=SkyCoord(20, 17, unit="deg"), radius=1.0 * u.deg)
+    region_new = region_circle_to_ellipse(region)
+    assert_allclose(region_new.height, region.radius, rtol=1e-3)
+    assert_allclose(region_new.width, region.radius, rtol=1e-3)
+    assert_allclose(region_new.angle, 0.0 * u.deg, rtol=1e-3)
```

### Comparing `gammapy-1.0rc2/gammapy/utils/tests/test_roots.py` & `gammapy-1.1rc1/gammapy/utils/tests/test_roots.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/utils/tests/test_scripts.py` & `gammapy-1.1rc1/gammapy/utils/tests/test_scripts.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/utils/tests/test_table.py` & `gammapy-1.1rc1/gammapy/utils/tests/test_table.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 # Licensed under a 3-clause BSD style license - see LICENSE.rst
 import pytest
 from numpy.testing import assert_allclose
 import astropy.units as u
 from astropy.table import Column, Table
+from gammapy.utils.deprecation import GammapyDeprecationWarning
 from gammapy.utils.table import (
     table_from_row_data,
     table_row_to_dict,
     table_standardise_units_copy,
 )
 
 
@@ -39,11 +40,14 @@
     actual = table_row_to_dict(table[1])
     expected = {"a": 2, "b": 2 * u.m, "c": "yy"}
     assert actual == expected
 
 
 def test_table_from_row_data():
     rows = [dict(a=1, b=1 * u.m, c="x"), dict(a=2, b=2 * u.km, c="yy")]
-    table = table_from_row_data(rows)
+
+    with pytest.warns(GammapyDeprecationWarning):
+        table = table_from_row_data(rows)
+
     assert isinstance(table, Table)
     assert table["b"].unit == "m"
     assert_allclose(table["b"].data, [1, 2000])
```

### Comparing `gammapy-1.0rc2/gammapy/utils/tests/test_units.py` & `gammapy-1.1rc1/gammapy/utils/tests/test_units.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/utils/units.py` & `gammapy-1.1rc1/gammapy/utils/units.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/visualization/cmap.py` & `gammapy-1.1rc1/gammapy/visualization/cmap.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/visualization/heatmap.py` & `gammapy-1.1rc1/gammapy/visualization/heatmap.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/visualization/panel.py` & `gammapy-1.1rc1/gammapy/visualization/panel.py`

 * *Files 3% similar despite different names*

```diff
@@ -40,29 +40,29 @@
         """Get width and height of the axis in world coordinates."""
         p = self.parameters
 
         # compute aspect ratio of the axis
         aspect = ax.bbox.width / ax.bbox.height
 
         # compute width and height in world coordinates
-        height = np.abs(p["ylim"].diff())
+        height = np.abs(p["ylim"].diff()[0])
         width = aspect * height
 
         left, bottom = p["xlim"][0].wrap_at("180d"), p["ylim"][0]
 
-        width_all = np.abs(p["xlim"].wrap_at("180d").diff())
+        width_all = np.abs(p["xlim"].wrap_at("180d").diff()[0])
         xoverlap = ((p["npanels"] * width) - width_all) / (p["npanels"] - 1.0)
         if xoverlap < 0:
             raise ValueError(
                 "No overlap between panels. Please reduce figure "
                 "height or increase vertical space between the panels."
             )
 
         left = left - panel * (width - xoverlap)
-        return left[0], bottom, width, height
+        return left, bottom, width, height
 
     def _set_ax_fov(self, ax, panel):
         left, bottom, width, height = self._get_ax_extend(ax, panel)
 
         # set fov
         xlim = Angle([left, left - width])
         ylim = Angle([bottom, bottom + height])
```

### Comparing `gammapy-1.0rc2/gammapy/visualization/tests/test_cmap.py` & `gammapy-1.1rc1/gammapy/visualization/tests/test_cmap.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/visualization/tests/test_panel.py` & `gammapy-1.1rc1/gammapy/visualization/tests/test_panel.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/gammapy/visualization/utils.py` & `gammapy-1.1rc1/gammapy/visualization/utils.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,14 +1,16 @@
 import numpy as np
 from scipy.interpolate import CubicSpline
+from astropy.visualization import make_lupton_rgb
 import matplotlib.pyplot as plt
+from gammapy.maps.axes import UNIT_STRING_FORMAT
 
 __all__ = [
     "plot_contour_line",
-    "plot_spectrum_datasets_off_regions",
+    "plot_map_rgb",
     "plot_theta_squared_table",
 ]
 
 
 ARTIST_TO_LINE_PROPERTIES = {
     "color": "markeredgecolor",
     "edgecolor": "markeredgecolor",
@@ -16,112 +18,68 @@
     "facecolor": "markerfacecolor",
     "fc": "markerfacecolor",
     "linewidth": "markerwidth",
     "lw": "markerwidth",
 }
 
 
-def plot_spectrum_datasets_off_regions(
-    datasets, ax=None, legend=None, legend_kwargs=None, **kwargs
-):
-    """Plot the off regions of spectrum datasets.
+def plot_map_rgb(map_, ax=None, **kwargs):
+    """
+    Plot RGB image on matplotlib WCS axes.
+
+    This function is based on the `~astropy.visualization.make_lupton_rgb` function. The input map must
+    contain 1 non-spatial axis with exactly 3 bins. If this is not the case, the map has to be resampled
+    before using the `plot_map_rgb` function (e.g. as shown in the code example below).
 
     Parameters
     ----------
-    datasets : `~gammapy.datasets.Datasets` or list of `~gammapy.datasets.SpectrumDatasetOnOff`
-        List of spectrum on-off datasets.
-    ax : `~astropy.visualization.wcsaxes.WCSAxes`
-        Axes object to plot on.
-    legend : bool
-        Whether to add/display the labels of the off regions in a legend. By default True if
-        ``len(datasets) <= 10``.
-    legend_kwargs : dict
-        Keyword arguments used in `matplotlib.axes.Axes.legend`. The ``handler_map`` cannot be
-        overridden.
+    map_ : `~gammapy.maps.WcsNDMap`
+        WCS map. The map must contain 1 non-spatial axis with exactly 3 bins.
+    ax : `~astropy.visualization.wcsaxes.WCSAxes`, optional
+        WCS axis object to plot on.
     **kwargs : dict
-        Keyword arguments used in `gammapy.maps.RegionNDMap.plot_region`. Can contain a
-        `~cycler.Cycler` in a ``prop_cycle`` argument.
+        Keyword arguments passed to `~astropy.visualization.make_lupton_rgb`.
 
-    Notes
-    -----
-    Properties from the ``prop_cycle`` have maximum priority, except ``color``,
-    ``edgecolor``/``color`` is selected from the sources below in this order:
-    ``kwargs["edgecolor"]``, ``kwargs["prop_cycle"]``, ``matplotlib.rcParams["axes.prop_cycle"]``
-    ``matplotlib.rcParams["patch.edgecolor"]``, ``matplotlib.rcParams["patch.facecolor"]``
-    is never used.
+    Returns
+    -------
+    ax : `~astropy.visualization.wcsaxes.WCSAxes`
+        WCS axis object
 
     Examples
     --------
-    Plot forcibly without legend and with thick circles::
-
-        plot_spectrum_datasets_off_regions(datasets, ax, legend=False, linewidth=2.5)
-
-    Plot that quantifies the overlap of off regions::
-
-        plot_spectrum_datasets_off_regions(datasets, ax, alpha=0.3, facecolor='black')
-
-    Plot that cycles through colors (``edgecolor``) and line styles together::
-
-        plot_spectrum_datasets_off_regions(datasets, ax, prop_cycle=plt.cycler(color=list('rgb'), ls=['--', '-', ':']))  # noqa: E501
+    >>> from gammapy.visualization.utils import plot_map_rgb
+    >>> from gammapy.maps import Map, MapAxis
+    >>> import astropy.units as u
+    >>> map_ = Map.read("$GAMMAPY_DATA/cta-1dc-gc/cta-1dc-gc.fits.gz")
+    >>> axis_rgb = MapAxis.from_energy_edges(
+    >>>     [0.1, 0.2, 0.5, 10], unit=u.TeV, name="energy", interp="log"
+    >>> )
+    >>> map_ = map_.resample_axis(axis_rgb)
+    >>> kwargs = {"stretch": 0.5, "Q": 1, "minimum": 0.15}
+    >>> plot_map_rgb(map_.smooth(0.08*u.deg), **kwargs)
+    """
+    geom = map_.geom
+    if len(geom.axes) != 1 or geom.axes[0].nbin != 3:
+        raise ValueError(
+            "One non-spatial axis with exactly 3 bins is needed to plot an RGB image"
+        )
 
-    Plot that uses a modified `~matplotlib.rcParams`, has two legend columns, static and
-    dynamic colors, but only shows labels for ``datasets1`` and ``datasets2``. Note that
-    ``legend_kwargs`` only applies if it's given in the last function call with ``legend=True``::
+    data = [data_slice / np.nanmax(data_slice.flatten()) for data_slice in map_.data]
+    data = make_lupton_rgb(*data, **kwargs)
 
-        plt.rc('legend', columnspacing=1, fontsize=9)
-        plot_spectrum_datasets_off_regions(datasets1, ax, legend=True, edgecolor='cyan')
-        plot_spectrum_datasets_off_regions(datasets2, ax, legend=True, legend_kwargs=dict(ncol=2))
-        plot_spectrum_datasets_off_regions(datasets3, ax, legend=False, edgecolor='magenta')
-    """
-    from matplotlib.legend_handler import HandlerPatch, HandlerTuple
-    from matplotlib.patches import CirclePolygon, Patch
+    ax = map_._plot_default_axes(ax=ax)
+    ax.imshow(data)
 
-    if ax is None:
-        ax = plt.subplot(projection=datasets[0].counts_off.geom.wcs)
+    if geom.is_allsky:
+        ax = map_._plot_format_allsky(ax)
+    else:
+        ax = map_._plot_format(ax)
 
-    legend = legend or legend is None and len(datasets) <= 10
-    legend_kwargs = legend_kwargs or {}
-    handles, labels = [], []
-
-    prop_cycle = kwargs.pop("prop_cycle", plt.rcParams["axes.prop_cycle"])
-
-    for props, dataset in zip(prop_cycle(), datasets):
-        plot_kwargs = kwargs.copy()
-        plot_kwargs["facecolor"] = "None"
-        plot_kwargs.setdefault("edgecolor", props.pop("color"))
-        plot_kwargs.update(props)
-
-        dataset.counts_off.plot_region(ax, **plot_kwargs)
-
-        # create proxy artist for the custom legend
-        if legend:
-            handle = Patch(**plot_kwargs)
-            handles.append(handle)
-            labels.append(dataset.name)
-
-    if legend:
-        legend = ax.get_legend()
-        if legend:
-            handles = legend.legendHandles + handles
-            labels = [text.get_text() for text in legend.texts] + labels
-
-        handles = [(handle, handle) for handle in handles]
-        tuple_handler = HandlerTuple(ndivide=None, pad=0)
-
-        def patch_func(
-            legend, orig_handle, xdescent, ydescent, width, height, fontsize
-        ):
-            radius = width / 2
-            return CirclePolygon((radius - xdescent, height / 2 - ydescent), radius)
-
-        patch_handler = HandlerPatch(patch_func)
-
-        legend_kwargs.setdefault("handletextpad", 0.5)
-        legend_kwargs["handler_map"] = {Patch: patch_handler, tuple: tuple_handler}
-        ax.legend(handles, labels, **legend_kwargs)
+    # without this the axis limits are changed when calling scatter
+    ax.autoscale(enable=False)
 
     return ax
 
 
 def plot_contour_line(ax, x, y, **kwargs):
     """Plot smooth curve from contour points"""
     xf = x
@@ -214,9 +172,9 @@
     ax0.set_ylabel("Counts")
     ax0.set_xticks([])
     ax0.set_xlabel("")
     ax0.legend()
 
     ax1 = plt.subplot(2, 1, 2)
     ax1.errorbar(x, table["sqrt_ts"], xerr=xerr, linestyle="None")
-    ax1.set_xlabel(f"Theta  [{theta2_axis.unit}]")
+    ax1.set_xlabel(f"Theta [{theta2_axis.unit.to_string(UNIT_STRING_FORMAT)}]")
     ax1.set_ylabel("Significance")
```

### Comparing `gammapy-1.0rc2/gammapy.egg-info/PKG-INFO` & `gammapy-1.1rc1/gammapy.egg-info/PKG-INFO`

 * *Files 6% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: gammapy
-Version: 1.0rc2
+Version: 1.1rc1
 Summary: A Python package for gamma-ray astronomy
 Home-page: https://gammapy.org
 Author: The Gammapy developers
 Author-email: gammapy-coordination-l@in2p3.fr
 License: BSD 3-Clause
 Platform: any
 Classifier: Intended Audience :: Science/Research
@@ -14,17 +14,18 @@
 Classifier: Programming Language :: Cython
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: Implementation :: CPython
 Classifier: Topic :: Scientific/Engineering :: Astronomy
-Requires-Python: >=3.8
+Requires-Python: >=3.9
 Description-Content-Type: text/x-rst
 Provides-Extra: all
+Provides-Extra: cov
 Provides-Extra: test
 Provides-Extra: docs
 License-File: LICENSE.rst
 
 
 * Webpage: https://gammapy.org
 * Documentation: https://docs.gammapy.org
```

### Comparing `gammapy-1.0rc2/gammapy.egg-info/SOURCES.txt` & `gammapy-1.1rc1/gammapy.egg-info/SOURCES.txt`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 .codacy.yml
 .gitignore
 .mailmap
 .pre-commit-config.yaml
 CITATION
 CITATION.cff
 CODE_OF_CONDUCT.md
+CONTRIBUTING.md
 LICENSE.rst
 LONG_DESCRIPTION.rst
 MANIFEST.in
 Makefile
 README.rst
 codemeta.json
 environment-dev.yml
@@ -20,19 +21,21 @@
 ./gammapy/stats/fit_statistics_cython.pyx
 .github/PULL_REQUEST_TEMPLATE.md
 .github/ISSUE_TEMPLATE/bug_report.md
 .github/ISSUE_TEMPLATE/feature_request.md
 .github/workflows/cffconvert.yml
 .github/workflows/ci.yml
 .github/workflows/dispatch.yml
+.github/workflows/dispatch_benchmark.yml
 .github/workflows/greetings.yml
 .github/workflows/release.yml
 dev/README.rst
 dev/authors.py
 dev/codemeta.py
+dev/github_summary.py
 dev/prepare-release.py
 dev/codespell/exclude-file.txt
 dev/codespell/ignore-words.txt
 docs/Makefile
 docs/conf.py
 docs/index.rst
 docs/make.bat
@@ -143,15 +146,17 @@
 docs/release-notes/v0.3.rst
 docs/release-notes/v0.4.rst
 docs/release-notes/v0.5.rst
 docs/release-notes/v0.6.rst
 docs/release-notes/v0.7.rst
 docs/release-notes/v0.8.rst
 docs/release-notes/v0.9.rst
+docs/release-notes/v1.0.1.rst
 docs/release-notes/v1.0.rst
+docs/release-notes/v1.1.rst
 docs/user-guide/catalog.rst
 docs/user-guide/dl3.rst
 docs/user-guide/estimators.rst
 docs/user-guide/hli.rst
 docs/user-guide/howto.rst
 docs/user-guide/index.rst
 docs/user-guide/modeling.rst
@@ -212,14 +217,15 @@
 examples/README.rst
 examples/models/README.txt
 examples/models/spatial/README.rst
 examples/models/spatial/plot_constant.py
 examples/models/spatial/plot_disk.py
 examples/models/spatial/plot_gauss.py
 examples/models/spatial/plot_gen_gauss.py
+examples/models/spatial/plot_piecewise_norm_spatial.py
 examples/models/spatial/plot_point.py
 examples/models/spatial/plot_shell.py
 examples/models/spatial/plot_shell2.py
 examples/models/spatial/plot_template.py
 examples/models/spectral/README.rst
 examples/models/spectral/plot_absorbed.py
 examples/models/spectral/plot_broken_powerlaw.py
@@ -262,14 +268,15 @@
 examples/tutorials/analysis-2d/modeling_2D.py
 examples/tutorials/analysis-2d/ring_background.py
 examples/tutorials/analysis-3d/README.rst
 examples/tutorials/analysis-3d/analysis_3d.py
 examples/tutorials/analysis-3d/analysis_mwl.py
 examples/tutorials/analysis-3d/cta_data_analysis.py
 examples/tutorials/analysis-3d/event_sampling.py
+examples/tutorials/analysis-3d/event_sampling_nrg_depend_models.py
 examples/tutorials/analysis-3d/flux_profiles.py
 examples/tutorials/analysis-3d/simulate_3d.py
 examples/tutorials/analysis-time/README.rst
 examples/tutorials/analysis-time/light_curve.py
 examples/tutorials/analysis-time/light_curve_flare.py
 examples/tutorials/analysis-time/light_curve_simulation.py
 examples/tutorials/analysis-time/pulsar_analysis.py
@@ -282,14 +289,15 @@
 examples/tutorials/api/maps.py
 examples/tutorials/api/mask_maps.py
 examples/tutorials/api/model_management.py
 examples/tutorials/api/models.py
 examples/tutorials/data/README.rst
 examples/tutorials/data/cta.py
 examples/tutorials/data/fermi_lat.py
+examples/tutorials/data/hawc.py
 examples/tutorials/data/hess.py
 examples/tutorials/scripts/README.rst
 examples/tutorials/scripts/survey_map.py
 examples/tutorials/scripts/survey_map.rst
 examples/tutorials/starting/README.rst
 examples/tutorials/starting/analysis_1.py
 examples/tutorials/starting/analysis_2.py
@@ -381,14 +389,15 @@
 gammapy/data/filters.py
 gammapy/data/gti.py
 gammapy/data/hdu_index_table.py
 gammapy/data/obs_table.py
 gammapy/data/observations.py
 gammapy/data/observers.py
 gammapy/data/pointing.py
+gammapy/data/utils.py
 gammapy/data/tests/__init__.py
 gammapy/data/tests/test_data_store.py
 gammapy/data/tests/test_event_list.py
 gammapy/data/tests/test_filters.py
 gammapy/data/tests/test_gti.py
 gammapy/data/tests/test_hdu_index_table.py
 gammapy/data/tests/test_obs_table.py
@@ -408,14 +417,15 @@
 gammapy/datasets/tests/test_datasets.py
 gammapy/datasets/tests/test_evaluator.py
 gammapy/datasets/tests/test_flux_points.py
 gammapy/datasets/tests/test_io.py
 gammapy/datasets/tests/test_map.py
 gammapy/datasets/tests/test_simulate.py
 gammapy/datasets/tests/test_spectrum.py
+gammapy/datasets/tests/test_utils.py
 gammapy/estimators/__init__.py
 gammapy/estimators/core.py
 gammapy/estimators/flux.py
 gammapy/estimators/parameter.py
 gammapy/estimators/profile.py
 gammapy/estimators/utils.py
 gammapy/estimators/map/__init__.py
@@ -545,42 +555,46 @@
 gammapy/modeling/__init__.py
 gammapy/modeling/covariance.py
 gammapy/modeling/fit.py
 gammapy/modeling/iminuit.py
 gammapy/modeling/likelihood.py
 gammapy/modeling/parameter.py
 gammapy/modeling/scipy.py
+gammapy/modeling/selection.py
 gammapy/modeling/sherpa.py
 gammapy/modeling/models/__init__.py
 gammapy/modeling/models/core.py
 gammapy/modeling/models/cube.py
 gammapy/modeling/models/spatial.py
 gammapy/modeling/models/spectral.py
 gammapy/modeling/models/spectral_cosmic_ray.py
 gammapy/modeling/models/spectral_crab.py
 gammapy/modeling/models/temporal.py
+gammapy/modeling/models/utils.py
 gammapy/modeling/models/tests/__init__.py
 gammapy/modeling/models/tests/test_core.py
 gammapy/modeling/models/tests/test_cube.py
 gammapy/modeling/models/tests/test_io.py
 gammapy/modeling/models/tests/test_management.py
 gammapy/modeling/models/tests/test_spatial.py
 gammapy/modeling/models/tests/test_spectral.py
 gammapy/modeling/models/tests/test_spectral_cosmic_ray.py
 gammapy/modeling/models/tests/test_spectral_crab.py
 gammapy/modeling/models/tests/test_temporal.py
+gammapy/modeling/models/tests/test_utils.py
 gammapy/modeling/models/tests/data/example2.yaml
 gammapy/modeling/models/tests/data/examples.yaml
 gammapy/modeling/models/tests/data/make.py
 gammapy/modeling/tests/__init__.py
 gammapy/modeling/tests/test_covariance.py
 gammapy/modeling/tests/test_fit.py
 gammapy/modeling/tests/test_iminuit.py
 gammapy/modeling/tests/test_parameter.py
 gammapy/modeling/tests/test_scipy.py
+gammapy/modeling/tests/test_selection.py
 gammapy/modeling/tests/test_sherpa.py
 gammapy/scripts/__init__.py
 gammapy/scripts/analysis.py
 gammapy/scripts/check.py
 gammapy/scripts/download.py
 gammapy/scripts/info.py
 gammapy/scripts/main.py
@@ -589,28 +603,33 @@
 gammapy/scripts/tests/test_download.py
 gammapy/scripts/tests/test_info.py
 gammapy/scripts/tests/test_main.py
 gammapy/stats/__init__.py
 gammapy/stats/counts_statistic.py
 gammapy/stats/fit_statistics.py
 gammapy/stats/fit_statistics_cython.pyx
+gammapy/stats/utils.py
 gammapy/stats/variability.py
 gammapy/stats/tests/__init__.py
 gammapy/stats/tests/test_counts_statistic.py
 gammapy/stats/tests/test_fit_statistics.py
+gammapy/stats/tests/test_utils.py
 gammapy/stats/tests/test_variability.py
 gammapy/tests/__init__.py
 gammapy/utils/__init__.py
 gammapy/utils/array.py
 gammapy/utils/check.py
+gammapy/utils/cluster.py
+gammapy/utils/deprecation.py
 gammapy/utils/docs.py
 gammapy/utils/fits.py
 gammapy/utils/gauss.py
 gammapy/utils/integrate.py
 gammapy/utils/interpolation.py
+gammapy/utils/parallel.py
 gammapy/utils/pbar.py
 gammapy/utils/regions.py
 gammapy/utils/registry.py
 gammapy/utils/roots.py
 gammapy/utils/scripts.py
 gammapy/utils/table.py
 gammapy/utils/testing.py
@@ -626,26 +645,30 @@
 gammapy/utils/random/inverse_cdf.py
 gammapy/utils/random/utils.py
 gammapy/utils/random/tests/__init__.py
 gammapy/utils/random/tests/test_inverse_cdf.py
 gammapy/utils/random/tests/test_random.py
 gammapy/utils/tests/__init__.py
 gammapy/utils/tests/test_array.py
+gammapy/utils/tests/test_deprecation.py
 gammapy/utils/tests/test_fits.py
 gammapy/utils/tests/test_gauss.py
 gammapy/utils/tests/test_integrate.py
 gammapy/utils/tests/test_interpolation.py
+gammapy/utils/tests/test_parallel.py
 gammapy/utils/tests/test_regions.py
 gammapy/utils/tests/test_roots.py
 gammapy/utils/tests/test_scripts.py
 gammapy/utils/tests/test_table.py
 gammapy/utils/tests/test_time.py
 gammapy/utils/tests/test_units.py
 gammapy/visualization/__init__.py
 gammapy/visualization/cmap.py
+gammapy/visualization/datasets.py
 gammapy/visualization/heatmap.py
 gammapy/visualization/panel.py
 gammapy/visualization/utils.py
 gammapy/visualization/tests/__init__.py
 gammapy/visualization/tests/test_cmap.py
+gammapy/visualization/tests/test_datasets.py
 gammapy/visualization/tests/test_panel.py
 gammapy/visualization/tests/test_utils.py
```

### Comparing `gammapy-1.0rc2/setup.cfg` & `gammapy-1.1rc1/setup.cfg`

 * *Files 5% similar despite different names*

```diff
@@ -25,22 +25,22 @@
 	Programming Language :: Python :: 3.10
 	Programming Language :: Python :: Implementation :: CPython
 	Topic :: Scientific/Engineering :: Astronomy
 
 [options]
 zip_safe = False
 packages = find:
-python_requires = >=3.8
+python_requires = >=3.9
 setup_requires = setuptools_scm
 install_requires = 
-	numpy>=1.20
-	scipy>=1.4
+	numpy>=1.21
+	scipy>=1.5,!=1.10
 	astropy>=5.0
 	regions>=0.5.0
-	pyyaml>=5.1
+	pyyaml>=5.3
 	click>=7.0
 	pydantic>=1.4
 	iminuit>=2.8.0
 	matplotlib>=3.4
 
 [options.entry_points]
 console_scripts = 
@@ -49,22 +49,31 @@
 [options.extras_require]
 all = 
 	naima
 	sherpa; platform_system != "Windows"
 	healpy; platform_system != "Windows"
 	requests
 	tqdm
-	ipywidgets
+	ipywidgets<8.0.5
+	ray
+cov = 
+	naima
+	sherpa; platform_system != "Windows"
+	healpy; platform_system != "Windows"
+	requests
+	tqdm
+	ipywidgets<8.0.5
 test = 
 	pytest-astropy
 	pytest-xdist
 	pytest
 	docutils
 	sphinx
 docs = 
+	astropy>=5.0,<5.3
 	sphinx-astropy
 	sphinx
 	sphinx-click
 	sphinx-gallery
 	sphinx-panels
 	sphinx-copybutton
 	pydata-sphinx-theme==0.8.1
```

### Comparing `gammapy-1.0rc2/setup.py` & `gammapy-1.1rc1/setup.py`

 * *Files identical despite different names*

### Comparing `gammapy-1.0rc2/tox.ini` & `gammapy-1.1rc1/tox.ini`

 * *Files 13% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 [tox]
 minversion = 2.0
 envlist =
-    py{38,39,310}-test{,-alldeps,-devdeps}{,-cov}
-    py{38,39,310}-test-numpy{120,121,122,123}
-    py{38,39,310}-test-astropy{50,lts}
+    py{39,310, 311}-test{,-alldeps,-devdeps}{,-cov}
+    py{39,310, 311}-test-numpy{121,122,123,124}
+    py{39,310, 311}-test-astropy{50,lts}
     build_docs
     linkcheck
     codestyle
 requires =
     setuptools >= 30.3.0
     pip >= 19.3.1
 isolated_build = true
@@ -15,15 +15,24 @@
     NIGHTLY = https://pypi.anaconda.org/scipy-wheels-nightly/simple
 
 [testenv]
 # Suppress display of matplotlib plots generated during docs build
 setenv = MPLBACKEND=agg
 
 # Pass through the following environment variables which may be needed for the CI
-passenv = HOME WINDIR LC_ALL LC_CTYPE CC CI TRAVIS GAMMAPY_DATA PKG_CONFIG_PATH
+passenv = 
+    HOME
+    WINDIR
+    LC_ALL
+    LC_CTYPE
+    CC
+    CI
+    TRAVIS
+    GAMMAPY_DATA
+    PKG_CONFIG_PATH
 
 # Run the tests in a temporary directory to make sure that we don't import
 # this package from the source tree
 changedir = .tmp/{envname}
 
 # tox environments are constructed with so-called 'factors' (or terms)
 # separated by hyphens, e.g. test-devdeps-cov. Lines below starting with factor:
@@ -35,53 +44,57 @@
 #
 description =
     run tests
     alldeps: with all optional dependencies
     devdeps: with the latest developer version of key dependencies
     oldestdeps: with the oldest supported version of key dependencies
     cov: and test coverage
-    numpy120: with numpy 1.20.*
     numpy121: with numpy 1.21.*
     numpy122: with numpy 1.22.*
     numpy123: with numpy 1.23.*
+    numpy124: with numpy 1.24.*
     astropy50: with astropy 5.0.*
     astropylts: with the latest astropy LTS
 
 # The following provides some specific pinnings for key packages
 deps =
 
     cov: coverage
-    numpy120: numpy==1.20.*
     numpy121: numpy==1.21.*
     numpy122: numpy==1.22.*
     numpy123: numpy==1.23.*
+    numpy124: numpy==1.24.*
 
     astropy50: astropy==5.0.*
     astropylts: astropy==5.0.*
+    astropylts: matplotlib==3.6.*
 
-    oldestdeps: numpy==1.20.*
+    oldestdeps: numpy==1.21.*
     oldestdeps: matplotlib==3.4.*
-    oldestdeps: scipy==1.4.*
-    oldestdeps: pyyaml==5.1.*
+    oldestdeps: scipy==1.5.*
+    oldestdeps: pyyaml==5.3.*
     oldestdeps: astropy==5.0.*
     oldestdeps: click==7.0.*
     oldestdeps: regions==0.5.*
     oldestdeps: pydantic==1.4.*
     oldestdeps: iminuit==2.8.*
     
     devdeps: scipy>=0.0.dev0
     devdeps: numpy>=0.0.dev0
     devdeps: matplotlib>=0.0.dev0
     devdeps: git+https://github.com/astropy/astropy.git#egg=astropy
     devdeps: git+https://github.com/scikit-hep/iminuit.git#egg=iminuit
 
+    build_docs: sphinx-gallery<0.13
+
 # The following indicates which extras_require from setup.cfg will be installed
 extras =
     test
     alldeps: all
+    cov: cov
 
 commands =
     pip freeze
     !cov: pytest --pyargs gammapy {posargs}
     cov: pytest --doctest-rst --pyargs gammapy {toxinidir}/docs --cov gammapy --cov-config={toxinidir}/setup.cfg {posargs}
     cov: coverage xml -o {toxinidir}/coverage.xml
```

